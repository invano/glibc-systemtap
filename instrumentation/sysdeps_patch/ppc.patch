diff --git a/sysdeps/powerpc/power6/wcschr.c b/sysdeps/powerpc/power6/wcschr.c
deleted file mode 100644
index 2bbb515..0000000
--- a/sysdeps/powerpc/power6/wcschr.c
+++ /dev/null
@@ -1,96 +0,0 @@
-/* wcschr.c - Wide Character Search for POWER6+.
-   Copyright (C) 2012-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; see the file COPYING.LIB.  If
-   not, see <http://www.gnu.org/licenses/>.  */
-
-#include <wchar.h>
-
-#ifndef WCSCHR
-# define WCSCHR __wcschr
-# define DEFAULT_WCSCHR
-#endif
-
-/* Find the first occurrence of WC in WCS.  */
-wchar_t *
-WCSCHR (const wchar_t *wcs, const wchar_t wc)
-{
-  const wchar_t *wcs2 = wcs + 1;
-
-  if (*wcs == wc)
-    return (wchar_t *) wcs;
-  if (*wcs == L'\0')
-    return NULL;
-
-  do
-    {
-      wcs += 2;
-
-      if (*wcs2 == wc)
-        return (wchar_t *) wcs2;
-      if (*wcs2 == L'\0')
-        return NULL;
-       wcs2 += 2;
-
-      if (*wcs == wc)
-        return (wchar_t *) wcs;
-      if (*wcs == L'\0')
-        return NULL;
-      wcs += 2;
-
-      if (*wcs2 == wc)
-        return (wchar_t *) wcs2;
-      if (*wcs2 == L'\0')
-        return NULL;
-      wcs2 += 2;
-
-      if (*wcs == wc)
-        return (wchar_t *) wcs;
-      if (*wcs == L'\0')
-        return NULL;
-      wcs += 2;
-
-      if (*wcs2 == wc)
-        return (wchar_t *) wcs2;
-      if (*wcs2 == L'\0')
-        return NULL;
-      wcs2 += 2;
-
-      if (*wcs == wc)
-        return (wchar_t *) wcs;
-      if (*wcs == L'\0')
-        return NULL;
-      wcs += 2;
-
-      if (*wcs2 == wc)
-        return (wchar_t *) wcs2;
-      if (*wcs2 == L'\0')
-        return NULL;
-      wcs2 += 2;
-
-      if (*wcs == wc)
-        return (wchar_t *) wcs;
-    }
-  while (*wcs != L'\0');
-
-  return NULL;
-}
-#ifdef DEFAULT_WCSCHR
-libc_hidden_def (__wcschr)
-weak_alias (__wcschr, wcschr)
-libc_hidden_weak (wcschr)
-#else
-libc_hidden_def (wcschr)
-#endif
diff --git a/sysdeps/powerpc/power6/wcscpy.c b/sysdeps/powerpc/power6/wcscpy.c
deleted file mode 100644
index 202a5f8..0000000
--- a/sysdeps/powerpc/power6/wcscpy.c
+++ /dev/null
@@ -1,105 +0,0 @@
-/* wcscpy.c - Wide Character Copy for POWER6+.
-   Copyright (C) 2012-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; see the file COPYING.LIB.  If
-   not, see <http://www.gnu.org/licenses/>.  */
-
-#include <stddef.h>
-#include <wchar.h>
-
-#ifndef WCSCPY
-# define WCSCPY wcscpy
-#endif
-
-/* Copy SRC to DEST.  */
-wchar_t *
-WCSCPY (wchar_t *dest, const wchar_t *src)
-{
-  wint_t c,d;
-  wchar_t *wcp, *wcp2;
-
-  if (__alignof__ (wchar_t) >= sizeof (wchar_t))
-    {
-      const ptrdiff_t off = dest - src;
-
-      wcp = (wchar_t *) src;
-      wcp2 = wcp + 1 ;
-
-      do
-        {
-          d = *wcp;
-          wcp[off] = d;
-          if (d == L'\0')
-            return dest;
-          wcp += 2;
-
-          c = *wcp2;
-          wcp2[off] = c;
-          if (c == L'\0')
-            return dest;
-          wcp2 += 2;
-
-          d = *wcp;
-          wcp[off] = d;
-          if (d == L'\0')
-            return dest;
-          wcp += 2;
-
-          c = *wcp2;
-          wcp2[off] = c;
-          if (c == L'\0')
-            return dest;
-          wcp2 += 2;
-
-          d = *wcp;
-          wcp[off] = d;
-          if (d == L'\0')
-            return dest;
-          wcp += 2;
-
-          c = *wcp2;
-          wcp2[off] = c;
-          if (c == L'\0')
-            return dest;
-          wcp2 += 2;
-
-          d = *wcp;
-          wcp[off] = d;
-          if (d == L'\0')
-            return dest;
-          wcp += 2;
-
-          c = *wcp2;
-          wcp2[off] = c;
-          if (c == L'\0')
-            return dest;
-          wcp2 += 2;
-        }
-      while (c != L'\0');
-
-    }
-  else
-    {
-      wcp = dest;
-
-      do
-        {
-          c = *src++;
-          *wcp++ = c;
-        }
-      while (c != L'\0');
-    }
-  return dest;
-}
diff --git a/sysdeps/powerpc/power6/wcsrchr.c b/sysdeps/powerpc/power6/wcsrchr.c
deleted file mode 100644
index 9ba9593..0000000
--- a/sysdeps/powerpc/power6/wcsrchr.c
+++ /dev/null
@@ -1,89 +0,0 @@
-/* wcsrchr.c - Wide Character Reverse Search for POWER6+.
-   Copyright (C) 2012-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; see the file COPYING.LIB.  If
-   not, see <http://www.gnu.org/licenses/>.  */
-
-#include <wchar.h>
-
-#ifndef WCSRCHR
-# define WCSRCHR wcsrchr
-#endif
-
-/* Find the last occurrence of WC in WCS.  */
-wchar_t *
-WCSRCHR (const wchar_t *wcs, const wchar_t wc)
-{
-  const wchar_t *wcs2 = wcs + 1;
-  const wchar_t *retval = NULL;
-
-  if (*wcs == wc)
-    retval = wcs;
-
-  if (*wcs == L'\0') return (wchar_t *) retval;
-
-  do
-    {
-    wcs+=2;
-
-    if (*wcs2 == wc)
-      retval = wcs2;
-    if (*wcs2 == L'\0')
-      return (wchar_t *) retval;
-    wcs2+=2;
-
-    if (*wcs == wc)
-      retval = wcs;
-    if (*wcs == L'\0')
-      return (wchar_t *) retval;
-    wcs+=2;
-
-    if (*wcs2 == wc)
-      retval = wcs2;
-    if (*wcs2 == L'\0')
-      return (wchar_t *) retval;
-    wcs2+=2;
-
-    if (*wcs == wc)
-      retval = wcs;
-    if (*wcs == L'\0')
-      return (wchar_t *) retval;
-    wcs+=2;
-
-    if (*wcs2 == wc)
-      retval = wcs2;
-    if (*wcs2 == L'\0')
-      return (wchar_t *) retval;
-    wcs2+=2;
-
-    if (*wcs == wc)
-      retval = wcs;
-    if (*wcs == L'\0')
-      return (wchar_t *) retval;
-    wcs+=2;
-
-    if (*wcs2 == wc)
-      retval = wcs2;
-    if (*wcs2 == L'\0')
-      return (wchar_t *) retval;
-    wcs2+=2;
-
-    if (*wcs == wc)
-      retval = wcs;
-    }
-  while (*wcs != L'\0');
-
-  return (wchar_t *) retval;
-}
diff --git a/sysdeps/powerpc/powerpc32/405/memcmp.S b/sysdeps/powerpc/powerpc32/405/memcmp.S
deleted file mode 100644
index da5a588..0000000
--- a/sysdeps/powerpc/powerpc32/405/memcmp.S
+++ /dev/null
@@ -1,128 +0,0 @@
-/* Optimized memcmp implementation for PowerPC476.
-   Copyright (C) 2010-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library.  If not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* memcmp
-
-       r3:source1 address, return equality
-       r4:source2 address
-       r5:byte count
-
-       Check 2 words from src1 and src2. If unequal jump to end and
-       return src1 > src2 or src1 < src2.
-       If count = zero check bytes before zero counter and then jump to end and
-       return src1 > src2, src1 < src2 or src1 = src2.
-       If src1 = src2 and no null, repeat. */
-
-EALIGN (memcmp, 5, 0)
-       srwi.   r6,r5,5
-       beq     L(preword2_count_loop)
-       mtctr   r6
-       clrlwi  r5,r5,27
-
-L(word8_compare_loop):
-       lwz     r10,0(r3)
-       lwz     r6,4(r3)
-       lwz     r8,0(r4)
-       lwz     r9,4(r4)
-       cmplw   cr5,r8,r10
-       cmplw   cr1,r9,r6
-       bne     cr5,L(st2)
-       bne     cr1,L(st1)
-       lwz     r10,8(r3)
-       lwz     r6,12(r3)
-       lwz     r8,8(r4)
-       lwz     r9,12(r4)
-       cmplw   cr5,r8,r10
-       cmplw   cr1,r9,r6
-       bne     cr5,L(st2)
-       bne     cr1,L(st1)
-       lwz     r10,16(r3)
-       lwz     r6,20(r3)
-       lwz     r8,16(r4)
-       lwz     r9,20(r4)
-       cmplw   cr5,r8,r10
-       cmplw   cr1,r9,r6
-       bne     cr5,L(st2)
-       bne     cr1,L(st1)
-       lwz     r10,24(r3)
-       lwz     r6,28(r3)
-       addi    r3,r3,0x20
-       lwz     r8,24(r4)
-       lwz     r9,28(r4)
-       addi    r4,r4,0x20
-       cmplw   cr5,r8,r10
-       cmplw   cr1,r9,r6
-       bne     cr5,L(st2)
-       bne     cr1,L(st1)
-       bdnz    L(word8_compare_loop)
-
-L(preword2_count_loop):
-       srwi.   r6,r5,3
-       beq     L(prebyte_count_loop)
-       mtctr   r6
-       clrlwi  r5,r5,29
-
-L(word2_count_loop):
-       lwz     r10,0(r3)
-       lwz     r6,4(r3)
-       addi    r3,r3,0x08
-       lwz     r8,0(r4)
-       lwz     r9,4(r4)
-       addi    r4,r4,0x08
-       cmplw   cr5,r8,r10
-       cmplw   cr1,r9,r6
-       bne     cr5,L(st2)
-       bne     cr1,L(st1)
-       bdnz    L(word2_count_loop)
-
-L(prebyte_count_loop):
-       addi    r5,r5,1
-       mtctr   r5
-       bdz     L(end_memcmp)
-
-L(byte_count_loop):
-       lbz     r6,0(r3)
-       addi    r3,r3,0x01
-       lbz     r8,0(r4)
-       addi    r4,r4,0x01
-       cmplw   cr5,r8,r6
-       bne     cr5,L(st2)
-       bdnz    L(byte_count_loop)
-
-L(end_memcmp):
-       addi    r3,r0,0
-       blr
-
-L(l_r):
-       addi    r3,r0,1
-       blr
-
-L(st1):
-       blt     cr1,L(l_r)
-       addi    r3,r0,-1
-       blr
-
-L(st2):
-       blt     cr5,L(l_r)
-       addi    r3,r0,-1
-       blr
-END (memcmp)
-libc_hidden_builtin_def (memcmp)
-weak_alias (memcmp,bcmp)
diff --git a/sysdeps/powerpc/powerpc32/405/memcpy.S b/sysdeps/powerpc/powerpc32/405/memcpy.S
deleted file mode 100644
index 12b8a98..0000000
--- a/sysdeps/powerpc/powerpc32/405/memcpy.S
+++ /dev/null
@@ -1,130 +0,0 @@
-/* Optimized memcpy implementation for PowerPC476.
-   Copyright (C) 2010-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library.  If not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* memcpy
-
-       r0:return address
-       r3:destination address
-       r4:source address
-       r5:byte count
-
-       Save return address in r0.
-       If destinationn and source are unaligned and copy count is greater than 256
-       then copy 0-3 bytes to make destination aligned.
-       If 32 or more bytes to copy we use 32 byte copy loop.
-       Finaly we copy 0-31 extra bytes. */
-
-EALIGN (memcpy, 5, 0)
-/* Check if bytes to copy are greater than 256 and if
-       source and destination are unaligned */
-       cmpwi   r5,0x0100
-       addi    r0,r3,0
-       ble     L(string_count_loop)
-       neg     r6,r3
-       clrlwi. r6,r6,30
-       beq     L(string_count_loop)
-       neg     r6,r4
-       clrlwi. r6,r6,30
-       beq     L(string_count_loop)
-       mtctr   r6
-       subf    r5,r6,r5
-
-L(unaligned_bytecopy_loop): /* Align destination by coping 0-3 bytes */
-       lbz     r8,0x0(r4)
-       addi    r4,r4,1
-       stb     r8,0x0(r3)
-       addi    r3,r3,1
-       bdnz    L(unaligned_bytecopy_loop)
-       srwi.   r7,r5,5
-       beq     L(preword2_count_loop)
-       mtctr   r7
-
-L(word8_count_loop_no_dcbt): /* Copy 32 bytes at a time */
-       lwz     r6,0(r4)
-       lwz     r7,4(r4)
-       lwz     r8,8(r4)
-       lwz     r9,12(r4)
-       subi    r5,r5,0x20
-       stw     r6,0(r3)
-       stw     r7,4(r3)
-       stw     r8,8(r3)
-       stw     r9,12(r3)
-       lwz     r6,16(r4)
-       lwz     r7,20(r4)
-       lwz     r8,24(r4)
-       lwz     r9,28(r4)
-       addi    r4,r4,0x20
-       stw     r6,16(r3)
-       stw     r7,20(r3)
-       stw     r8,24(r3)
-       stw     r9,28(r3)
-       addi    r3,r3,0x20
-       bdnz    L(word8_count_loop_no_dcbt)
-
-L(preword2_count_loop): /* Copy remaining 0-31 bytes */
-       clrlwi. r12,r5,27
-       beq     L(end_memcpy)
-       mtxer   r12
-       lswx    r5,0,r4
-       stswx   r5,0,r3
-       mr       r3,r0
-       blr
-
-L(string_count_loop): /* Copy odd 0-31 bytes */
-       clrlwi. r12,r5,28
-       add     r3,r3,r5
-       add     r4,r4,r5
-       beq     L(pre_string_copy)
-       mtxer   r12
-       subf    r4,r12,r4
-       subf    r3,r12,r3
-       lswx    r6,0,r4
-       stswx   r6,0,r3
-
-L(pre_string_copy): /* Check how many 32 byte chunks to copy */
-       srwi.   r7,r5,4
-       beq     L(end_memcpy)
-       mtctr   r7
-
-L(word4_count_loop_no_dcbt): /* Copy 32 bytes at a time */
-       lwz     r6,-4(r4)
-       lwz     r7,-8(r4)
-       lwz     r8,-12(r4)
-       lwzu    r9,-16(r4)
-       stw     r6,-4(r3)
-       stw     r7,-8(r3)
-       stw     r8,-12(r3)
-       stwu    r9,-16(r3)
-       bdz     L(end_memcpy)
-       lwz     r6,-4(r4)
-       lwz     r7,-8(r4)
-       lwz     r8,-12(r4)
-       lwzu    r9,-16(r4)
-       stw     r6,-4(r3)
-       stw     r7,-8(r3)
-       stw     r8,-12(r3)
-       stwu    r9,-16(r3)
-       bdnz    L(word4_count_loop_no_dcbt)
-
-L(end_memcpy):
-       mr       r3,r0
-       blr
-END (memcpy)
-libc_hidden_builtin_def (memcpy)
diff --git a/sysdeps/powerpc/powerpc32/405/memset.S b/sysdeps/powerpc/powerpc32/405/memset.S
deleted file mode 100644
index 14f35da..0000000
--- a/sysdeps/powerpc/powerpc32/405/memset.S
+++ /dev/null
@@ -1,152 +0,0 @@
-/* Optimized memset for PowerPC405,440,464 (32-byte cacheline).
-   Copyright (C) 2012-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library.  If not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* memset
-
-       r3:destination address and return address
-       r4:source integer to copy
-       r5:byte count
-       r11:sources integer to copy in all 32 bits of reg
-       r12:temp return address
-
-       Save return address in r12
-       If destinationn is unaligned and count is greater tha 255 bytes
-       set 0-3 bytes to make destination aligned
-       If count is greater tha 255 bytes and setting zero to memory
-       use dbcz to set memeory when we can
-       otherwsie do the follwoing
-       If 16 or more words to set we use 16 word copy loop.
-       Finaly we set 0-15 extra bytes with string store. */
-
-EALIGN (memset, 5, 0)
-       rlwinm  r11,r4,0,24,31
-       rlwimi  r11,r4,8,16,23
-       rlwimi  r11,r11,16,0,15
-       addi    r12,r3,0
-       cmpwi   r5,0x00FF
-       ble     L(preword8_count_loop)
-       cmpwi   r4,0x00
-       beq     L(use_dcbz)
-       neg     r6,r3
-       clrlwi. r6,r6,30
-       beq     L(preword8_count_loop)
-       addi    r8,0,1
-       mtctr   r6
-       subi    r3,r3,1
-
-L(unaligned_bytecopy_loop):
-       stbu    r11,0x1(r3)
-       subf.   r5,r8,r5
-       beq     L(end_memset)
-       bdnz    L(unaligned_bytecopy_loop)
-       addi    r3,r3,1
-
-L(preword8_count_loop):
-       srwi.   r6,r5,4
-       beq     L(preword2_count_loop)
-       mtctr   r6
-       addi    r3,r3,-4
-       mr      r8,r11
-       mr      r9,r11
-       mr      r10,r11
-
-L(word8_count_loop_no_dcbt):
-       stwu    r8,4(r3)
-       stwu    r9,4(r3)
-       subi    r5,r5,0x10
-       stwu    r10,4(r3)
-       stwu    r11,4(r3)
-       bdnz    L(word8_count_loop_no_dcbt)
-       addi    r3,r3,4
-
-L(preword2_count_loop):
-       clrlwi. r7,r5,28
-       beq     L(end_memset)
-       mr      r8,r11
-       mr      r9,r11
-       mr      r10,r11
-       mtxer   r7
-       stswx   r8,0,r3
-
-L(end_memset):
-       addi    r3,r12,0
-       blr
-
-L(use_dcbz):
-       neg     r6,r3
-       clrlwi. r7,r6,28
-       beq     L(skip_string_loop)
-       mr      r8,r11
-       mr      r9,r11
-       mr      r10,r11
-       subf    r5,r7,r5
-       mtxer   r7
-       stswx   r8,0,r3
-       add     r3,r3,r7
-
-L(skip_string_loop):
-       clrlwi  r8,r6,27
-       srwi.   r8,r8,4
-       beq     L(dcbz_pre_loop)
-       mtctr   r8
-
-L(word_loop):
-       stw     r11,0(r3)
-       subi    r5,r5,0x10
-       stw     r11,4(r3)
-       stw     r11,8(r3)
-       stw     r11,12(r3)
-       addi    r3,r3,0x10
-       bdnz    L(word_loop)
-
-L(dcbz_pre_loop):
-       srwi    r6,r5,5
-       mtctr   r6
-       addi    r7,0,0
-
-L(dcbz_loop):
-       dcbz    r3,r7
-       addi    r3,r3,0x20
-       subi    r5,r5,0x20
-       bdnz    L(dcbz_loop)
-       srwi.   r6,r5,4
-       beq     L(postword2_count_loop)
-       mtctr   r6
-
-L(postword8_count_loop):
-       stw     r11,0(r3)
-       subi    r5,r5,0x10
-       stw     r11,4(r3)
-       stw     r11,8(r3)
-       stw     r11,12(r3)
-       addi    r3,r3,0x10
-       bdnz    L(postword8_count_loop)
-
-L(postword2_count_loop):
-       clrlwi. r7,r5,28
-       beq     L(end_memset)
-       mr      r8,r11
-       mr      r9,r11
-       mr      r10,r11
-       mtxer   r7
-       stswx   r8,0,r3
-       b       L(end_memset)
-END (memset)
-libc_hidden_builtin_def (memset)
diff --git a/sysdeps/powerpc/powerpc32/405/strcmp.S b/sysdeps/powerpc/powerpc32/405/strcmp.S
deleted file mode 100644
index 62420da..0000000
--- a/sysdeps/powerpc/powerpc32/405/strcmp.S
+++ /dev/null
@@ -1,134 +0,0 @@
-/* Optimized strcmp implementation for PowerPC476.
-   Copyright (C) 2010-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library.  If not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* strcmp
-
-       Register Use
-       r0:temp return equality
-       r3:source1 address, return equality
-       r4:source2 address
-
-       Implementation description
-       Check 2 words from src1 and src2. If unequal jump to end and
-       return src1 > src2 or src1 < src2.
-       If null check bytes before null and then jump to end and
-       return src1 > src2, src1 < src2 or src1 = src2.
-       If src1 = src2 and no null, repeat. */
-
-EALIGN (strcmp,5,0)
-       neg     r7,r3
-       clrlwi  r7,r7,20
-       neg     r8,r4
-       clrlwi  r8,r8,20
-       srwi.   r7,r7,5
-       beq     L(byte_loop)
-       srwi.   r8,r8,5
-       beq     L(byte_loop)
-       cmplw   r7,r8
-       mtctr   r7
-       ble     L(big_loop)
-       mtctr   r8
-
-L(big_loop):
-       lwz     r5,0(r3)
-       lwz     r6,4(r3)
-       lwz     r8,0(r4)
-       lwz     r9,4(r4)
-       dlmzb.  r12,r5,r6
-       bne     L(end_check)
-       cmplw   r5,r8
-       bne     L(st1)
-       cmplw   r6,r9
-       bne     L(st1)
-       lwz     r5,8(r3)
-       lwz     r6,12(r3)
-       lwz     r8,8(r4)
-       lwz     r9,12(r4)
-       dlmzb.  r12,r5,r6
-       bne     L(end_check)
-       cmplw   r5,r8
-       bne     L(st1)
-       cmplw   r6,r9
-       bne     L(st1)
-       lwz     r5,16(r3)
-       lwz     r6,20(r3)
-       lwz     r8,16(r4)
-       lwz     r9,20(r4)
-       dlmzb.  r12,r5,r6
-       bne     L(end_check)
-       cmplw   r5,r8
-       bne     L(st1)
-       cmplw   r6,r9
-       bne     L(st1)
-       lwz     r5,24(r3)
-       lwz     r6,28(r3)
-       addi    r3,r3,0x20
-       lwz     r8,24(r4)
-       lwz     r9,28(r4)
-       addi    r4,r4,0x20
-       dlmzb.  r12,r5,r6
-       bne     L(end_check)
-       cmplw   r5,r8
-       bne     L(st1)
-       cmplw   r6,r9
-       bne     L(st1)
-       bdnz    L(big_loop)
-       b       L(byte_loop)
-
-L(end_check):
-       subfic  r12,r12,4
-       blt     L(end_check2)
-       rlwinm  r12,r12,3,0,31
-       srw     r5,r5,r12
-       srw     r8,r8,r12
-       cmplw   r5,r8
-       bne     L(st1)
-       b       L(end_strcmp)
-
-L(end_check2):
-       addi    r12,r12,4
-       cmplw   r5,r8
-       rlwinm  r12,r12,3,0,31
-       bne     L(st1)
-       srw     r6,r6,r12
-       srw     r9,r9,r12
-       cmplw   r6,r9
-       bne     L(st1)
-
-L(end_strcmp):
-       addi    r3,r0,0
-       blr
-
-L(st1):
-       mfcr    r3
-       blr
-
-L(byte_loop):
-       lbz     r5,0(r3)
-       addi    r3,r3,1
-       lbz     r6,0(r4)
-       addi    r4,r4,1
-       cmplw   r5,r6
-       bne     L(st1)
-       cmpwi   r5,0
-       beq     L(end_strcmp)
-       b       L(byte_loop)
-END (strcmp)
-libc_hidden_builtin_def (strcmp)
diff --git a/sysdeps/powerpc/powerpc32/405/strcpy.S b/sysdeps/powerpc/powerpc32/405/strcpy.S
deleted file mode 100644
index 2244b53..0000000
--- a/sysdeps/powerpc/powerpc32/405/strcpy.S
+++ /dev/null
@@ -1,107 +0,0 @@
-/* Optimized strcpy implementation for PowerPC476.
-   Copyright (C) 2010-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library.  If not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* strcpy
-
-       Register Use
-       r3:destination and return address
-       r4:source address
-       r10:temp destination address
-
-       Implementation description
-       Loop by checking 2 words at a time, with dlmzb. Check if there is a null
-       in the 2 words. If there is a null jump to end checking to determine
-       where in the last 8 bytes it is. Copy the appropriate bytes of the last
-       8 according to the null position. */
-
-EALIGN (strcpy, 5, 0)
-       neg     r7,r4
-       subi    r4,r4,1
-       clrlwi. r8,r7,29
-       subi    r10,r3,1
-       beq     L(pre_word8_loop)
-       mtctr   r8
-
-L(loop):
-       lbzu    r5,0x01(r4)
-       cmpi    cr5,r5,0x0
-       stbu    r5,0x01(r10)
-       beq     cr5,L(end_strcpy)
-       bdnz    L(loop)
-
-L(pre_word8_loop):
-       subi    r4,r4,3
-       subi    r10,r10,3
-
-L(word8_loop):
-       lwzu    r5,0x04(r4)
-       lwzu    r6,0x04(r4)
-       dlmzb.  r11,r5,r6
-       bne     L(byte_copy)
-       stwu    r5,0x04(r10)
-       stwu    r6,0x04(r10)
-       lwzu    r5,0x04(r4)
-       lwzu    r6,0x04(r4)
-       dlmzb.  r11,r5,r6
-       bne     L(byte_copy)
-       stwu    r5,0x04(r10)
-       stwu    r6,0x04(r10)
-       lwzu    r5,0x04(r4)
-       lwzu    r6,0x04(r4)
-       dlmzb.  r11,r5,r6
-       bne     L(byte_copy)
-       stwu    r5,0x04(r10)
-       stwu    r6,0x04(r10)
-       lwzu    r5,0x04(r4)
-       lwzu    r6,0x04(r4)
-       dlmzb.  r11,r5,r6
-       bne     L(byte_copy)
-       stwu    r5,0x04(r10)
-       stwu    r6,0x04(r10)
-       b       L(word8_loop)
-
-L(last_bytes_copy):
-       stwu    r5,0x04(r10)
-       subi    r11,r11,4
-       mtctr   r11
-       addi    r10,r10,3
-       subi    r4,r4,1
-
-L(last_bytes_copy_loop):
-       lbzu    r5,0x01(r4)
-       stbu    r5,0x01(r10)
-       bdnz    L(last_bytes_copy_loop)
-       blr
-
-L(byte_copy):
-       blt     L(last_bytes_copy)
-       mtctr   r11
-       addi    r10,r10,3
-       subi    r4,r4,5
-
-L(last_bytes_copy_loop2):
-       lbzu    r5,0x01(r4)
-       stbu    r5,0x01(r10)
-       bdnz    L(last_bytes_copy_loop2)
-
-L(end_strcpy):
-       blr
-END (strcpy)
-libc_hidden_builtin_def (strcpy)
diff --git a/sysdeps/powerpc/powerpc32/405/strlen.S b/sysdeps/powerpc/powerpc32/405/strlen.S
deleted file mode 100644
index eb84c8d..0000000
--- a/sysdeps/powerpc/powerpc32/405/strlen.S
+++ /dev/null
@@ -1,75 +0,0 @@
-/* Optimized strlen implementation for PowerPC476.
-   Copyright (C) 2010-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library.  If not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* strlen
-
-       Register Use
-       r3:source address and return length of string
-       r4:byte counter
-
-       Implementation description
-       Load 2 words at a time and count bytes, if we find null we subtract one from
-       the count and return the count value. We need to subtract one because
-       we don't count the null character as a byte. */
-
-EALIGN (strlen,5,0)
-       neg     r7,r3
-       clrlwi. r8,r7,29
-       addi    r4,0,0
-       beq     L(byte_count_loop)
-       mtctr   r8
-
-L(loop):
-       lbz     r5,0(r3)
-       cmpi    cr5,r5,0x0
-       addi    r3,r3,0x1
-       addi    r4,r4,0x1
-       beq     cr5,L(end_strlen)
-       bdnz    L(loop)
-
-L(byte_count_loop):
-       lwz     r5,0(r3)
-       lwz     r6,4(r3)
-       dlmzb.  r12,r5,r6
-       add     r4,r4,r12
-       bne     L(end_strlen)
-       lwz     r5,8(r3)
-       lwz     r6,12(r3)
-       dlmzb.  r12,r5,r6
-       add     r4,r4,r12
-       bne     L(end_strlen)
-       lwz     r5,16(r3)
-       lwz     r6,20(r3)
-       dlmzb.  r12,r5,r6
-       add     r4,r4,r12
-       bne     L(end_strlen)
-       lwz     r5,24(r3)
-       lwz     r6,28(r3)
-       addi    r3,r3,0x20
-       dlmzb.  r12,r5,r6
-       add     r4,r4,r12
-       bne     L(end_strlen)
-       b       L(byte_count_loop)
-
-L(end_strlen):
-       addi    r3,r4,-1
-       blr
-END (strlen)
-libc_hidden_builtin_def (strlen)
diff --git a/sysdeps/powerpc/powerpc32/405/strncmp.S b/sysdeps/powerpc/powerpc32/405/strncmp.S
deleted file mode 100644
index c63100d..0000000
--- a/sysdeps/powerpc/powerpc32/405/strncmp.S
+++ /dev/null
@@ -1,128 +0,0 @@
-/* Optimized strncmp implementation for PowerPC476.
-   Copyright (C) 2010-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library.  If not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* strncmp
-
-       Register Use
-       r0:temp return equality
-       r3:source1 address, return equality
-       r4:source2 address
-       r5:byte count
-
-       Implementation description
-       Touch in 3 lines of D-cache.
-       If source1 or source2 is unaligned copy 0-3 bytes to make source1 aligned
-       Check 2 words from src1 and src2. If unequal jump to end and
-       return src1 > src2 or src1 < src2.
-       If null check bytes before null and then jump to end and
-       return src1 > src2, src1 < src2 or src1 = src2.
-       If count = zero check bytes before zero counter and then jump to end and
-       return src1 > src2, src1 < src2 or src1 = src2.
-       If src1 = src2 and no null, repeat. */
-
-EALIGN (strncmp,5,0)
-       neg     r7,r3
-       clrlwi  r7,r7,20
-       neg     r8,r4
-       clrlwi  r8,r8,20
-       srwi.   r7,r7,3
-       beq     L(prebyte_count_loop)
-       srwi.   r8,r8,3
-       beq     L(prebyte_count_loop)
-       cmplw   r7,r8
-       mtctr   r7
-       ble     L(preword2_count_loop)
-       mtctr   r8
-
-L(preword2_count_loop):
-       srwi.   r6,r5,3
-       beq     L(prebyte_count_loop)
-       mfctr   r7
-       cmplw   r6,r7
-       bgt     L(set_count_loop)
-       mtctr   r6
-       clrlwi  r5,r5,29
-
-L(word2_count_loop):
-       lwz     r10,0(r3)
-       lwz     r6,4(r3)
-       addi    r3,r3,0x08
-       lwz     r8,0(r4)
-       lwz     r9,4(r4)
-       addi    r4,r4,0x08
-       dlmzb.  r12,r10,r6
-       bne     L(end_check)
-       cmplw   r10,r8
-       bne     L(st1)
-       cmplw   r6,r9
-       bne     L(st1)
-       bdnz    L(word2_count_loop)
-
-L(prebyte_count_loop):
-       addi    r5,r5,1
-       mtctr   r5
-       bdz     L(end_strncmp)
-
-L(byte_count_loop):
-       lbz     r6,0(r3)
-       addi    r3,r3,1
-       lbz     r7,0(r4)
-       addi    r4,r4,1
-       cmplw   r6,r7
-       bne     L(st1)
-       cmpwi   r6,0
-       beq     L(end_strncmp)
-       bdnz    L(byte_count_loop)
-       b       L(end_strncmp)
-
-L(set_count_loop):
-       slwi    r7,r7,3
-       subf    r5,r7,r5
-       b       L(word2_count_loop)
-
-L(end_check):
-       subfic  r12,r12,4
-       blt     L(end_check2)
-       rlwinm  r12,r12,3,0,31
-       srw     r10,r10,r12
-       srw     r8,r8,r12
-       cmplw   r10,r8
-       bne     L(st1)
-       b       L(end_strncmp)
-
-L(end_check2):
-       addi    r12,r12,4
-       cmplw   r10,r8
-       rlwinm  r12,r12,3,0,31
-       bne     L(st1)
-       srw     r6,r6,r12
-       srw     r9,r9,r12
-       cmplw   r6,r9
-       bne     L(st1)
-
-L(end_strncmp):
-       addi    r3,r0,0
-       blr
-
-L(st1):
-       mfcr    r3
-       blr
-END (strncmp)
-libc_hidden_builtin_def (strncmp)
diff --git a/sysdeps/powerpc/powerpc32/476/memset.S b/sysdeps/powerpc/powerpc32/476/memset.S
deleted file mode 100644
index 3249d3f..0000000
--- a/sysdeps/powerpc/powerpc32/476/memset.S
+++ /dev/null
@@ -1,152 +0,0 @@
-/* Optimized memset for PowerPC476 (128-byte cacheline).
-   Copyright (C) 2010-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library.  If not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* memset
-
-       r3:destination address and return address
-       r4:source integer to copy
-       r5:byte count
-       r11:sources integer to copy in all 32 bits of reg
-       r12:temp return address
-
-       Save return address in r12
-       If destinationn is unaligned and count is greater tha 255 bytes
-       set 0-3 bytes to make destination aligned
-       If count is greater tha 255 bytes and setting zero to memory
-       use dbcz to set memeory when we can
-       otherwsie do the follwoing
-       If 16 or more words to set we use 16 word copy loop.
-       Finaly we set 0-15 extra bytes with string store. */
-
-EALIGN (memset, 5, 0)
-       rlwinm  r11,r4,0,24,31
-       rlwimi  r11,r4,8,16,23
-       rlwimi  r11,r11,16,0,15
-       addi    r12,r3,0
-       cmpwi   r5,0x00FF
-       ble     L(preword8_count_loop)
-       cmpwi   r4,0x00
-       beq     L(use_dcbz)
-       neg     r6,r3
-       clrlwi. r6,r6,30
-       beq     L(preword8_count_loop)
-       addi    r8,0,1
-       mtctr   r6
-       subi    r3,r3,1
-
-L(unaligned_bytecopy_loop):
-       stbu    r11,0x1(r3)
-       subf.   r5,r8,r5
-       beq     L(end_memset)
-       bdnz    L(unaligned_bytecopy_loop)
-       addi    r3,r3,1
-
-L(preword8_count_loop):
-       srwi.   r6,r5,4
-       beq     L(preword2_count_loop)
-       mtctr   r6
-       addi    r3,r3,-4
-       mr      r8,r11
-       mr      r9,r11
-       mr      r10,r11
-
-L(word8_count_loop_no_dcbt):
-       stwu    r8,4(r3)
-       stwu    r9,4(r3)
-       subi    r5,r5,0x10
-       stwu    r10,4(r3)
-       stwu    r11,4(r3)
-       bdnz    L(word8_count_loop_no_dcbt)
-       addi    r3,r3,4
-
-L(preword2_count_loop):
-       clrlwi. r7,r5,28
-       beq     L(end_memset)
-       mr      r8,r11
-       mr      r9,r11
-       mr      r10,r11
-       mtxer   r7
-       stswx   r8,0,r3
-
-L(end_memset):
-       addi    r3,r12,0
-       blr
-
-L(use_dcbz):
-       neg     r6,r3
-       clrlwi. r7,r6,28
-       beq     L(skip_string_loop)
-       mr      r8,r11
-       mr      r9,r11
-       mr      r10,r11
-       subf    r5,r7,r5
-       mtxer   r7
-       stswx   r8,0,r3
-       add     r3,r3,r7
-
-L(skip_string_loop):
-       clrlwi  r8,r6,25
-       srwi.   r8,r8,4
-       beq     L(dcbz_pre_loop)
-       mtctr   r8
-
-L(word_loop):
-       stw     r11,0(r3)
-       subi    r5,r5,0x10
-       stw     r11,4(r3)
-       stw     r11,8(r3)
-       stw     r11,12(r3)
-       addi    r3,r3,0x10
-       bdnz    L(word_loop)
-
-L(dcbz_pre_loop):
-       srwi    r6,r5,7
-       mtctr   r6
-       addi    r7,0,0
-
-L(dcbz_loop):
-       dcbz    r3,r7
-       addi    r3,r3,0x80
-       subi    r5,r5,0x80
-       bdnz    L(dcbz_loop)
-       srwi.   r6,r5,4
-       beq     L(postword2_count_loop)
-       mtctr   r6
-
-L(postword8_count_loop):
-       stw     r11,0(r3)
-       subi    r5,r5,0x10
-       stw     r11,4(r3)
-       stw     r11,8(r3)
-       stw     r11,12(r3)
-       addi    r3,r3,0x10
-       bdnz    L(postword8_count_loop)
-
-L(postword2_count_loop):
-       clrlwi. r7,r5,28
-       beq     L(end_memset)
-       mr      r8,r11
-       mr      r9,r11
-       mr      r10,r11
-       mtxer   r7
-       stswx   r8,0,r3
-       b       L(end_memset)
-END (memset)
-libc_hidden_builtin_def (memset)
diff --git a/sysdeps/powerpc/powerpc32/a2/memcpy.S b/sysdeps/powerpc/powerpc32/a2/memcpy.S
deleted file mode 100644
index 196b6d9..0000000
--- a/sysdeps/powerpc/powerpc32/a2/memcpy.S
+++ /dev/null
@@ -1,527 +0,0 @@
-/* Optimized memcpy implementation for PowerPC A2.
-   Copyright (C) 2010-2018 Free Software Foundation, Inc.
-   Contributed by Michael Brutman <brutman@us.ibm.com>.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-#define PREFETCH_AHEAD 4        /* no cache lines SRC prefetching ahead  */
-#define ZERO_AHEAD 2            /* no cache lines DST zeroing ahead  */
-
-	.machine  a2
-EALIGN (memcpy, 5, 0)
-	CALL_MCOUNT
-
-	dcbt    0,r4            /* Prefetch ONE SRC cacheline  */
-	cmplwi  cr1,r5,16       /* is size < 16 ?  */
-	mr      r6,r3           /* Copy dest reg to r6; */
-	blt+    cr1,L(shortcopy)
-
-
-	/* Big copy (16 bytes or more)
-
-	   Figure out how far to the nearest quadword boundary, or if we are
-	   on one already.
-
-	   r3 - return value (always)
-	   r4 - current source addr
-	   r5 - copy length
-	   r6 - current dest addr
-	*/
-
-	neg     r8,r3           /* LS 4 bits = # bytes to 8-byte dest bdry  */
-	clrlwi  r8,r8,32-4      /* align to 16byte boundary  */
-	sub     r7,r4,r3        /* compute offset to src from dest */
-	cmplwi  cr0,r8,0        /* Were we aligned on a 16 byte bdy? */
-	beq+    L(dst_aligned)
-
-
-
-	/* Destination is not aligned on quadword boundary.  Get us to one.
-
-	   r3 - return value (always)
-	   r4 - current source addr
-	   r5 - copy length
-	   r6 - current dest addr
-	   r7 - offset to src from dest
-	   r8 - number of bytes to quadword boundary
-	*/
-
-	mtcrf   0x01,r8         /* put #bytes to boundary into cr7  */
-	subf    r5,r8,r5        /* adjust remaining len */
-
-	bf      cr7*4+3,1f
-	lbzx    r0,r7,r6        /* copy 1 byte addr */
-	stb     r0,0(r6)
-	addi    r6,r6,1
-1:
-	bf      cr7*4+2,2f
-	lhzx    r0,r7,r6        /* copy 2 byte addr */
-	sth     r0,0(r6)
-	addi    r6,r6,2
-2:
-	bf      cr7*4+1,4f
-	lwzx    r0,r7,r6        /* copy 4 byte addr */
-	stw     r0,0(r6)
-	addi    r6,r6,4
-4:
-	bf      cr7*4+0,8f
-	lfdx    r0,r7,r6        /* copy 8 byte addr */
-	stfd    r0,0(r6)
-	addi    r6,r6,8
-8:
-	add     r4,r7,r6        /* update src addr */
-
-
-
-	/* Dest is quadword aligned now.
-
-	   Lots of decisions to make.  If we are copying less than a cache
-	   line we won't be here long.  If we are not on a cache line
-	   boundary we need to get there.  And then we need to figure out
-	   how many cache lines ahead to pre-touch.
-
-	   r3 - return value (always)
-	   r4 - current source addr
-	   r5 - copy length
-	   r6 - current dest addr
-	*/
-
-
-	.align  4
-L(dst_aligned):
-
-
-#ifdef SHARED
-	mflr    r0
-/* Establishes GOT addressability so we can load __cache_line_size
-   from static. This value was set from the aux vector during startup.  */
-	SETUP_GOT_ACCESS(r9,got_label)
-	addis   r9,r9,__cache_line_size-got_label@ha
-	lwz     r9,__cache_line_size-got_label@l(r9)
-	mtlr    r0
-#else
-/* Load __cache_line_size from static. This value was set from the
-   aux vector during startup.  */
-	lis     r9,__cache_line_size@ha
-	lwz     r9,__cache_line_size@l(r9)
-#endif
-
-	cmplwi  cr5, r9, 0
-	bne+    cr5,L(cachelineset)
-
-/* __cache_line_size not set: generic byte copy without much optimization */
-	andi.	r0,r5,1		/* If length is odd copy one byte.  */
-	beq	L(cachelinenotset_align)
-	lbz	r7,0(r4)	/* Read one byte from source.  */
-	addi	r5,r5,-1	/* Update length.  */
-	addi	r4,r4,1		/* Update source pointer address.  */
-	stb	r7,0(r6)	/* Store one byte on dest.  */
-	addi	r6,r6,1		/* Update dest pointer address.  */
-L(cachelinenotset_align):
-	cmpwi   cr7,r5,0	/* If length is 0 return.  */
-	beqlr	cr7
-	ori	r2,r2,0		/* Force a new dispatch group.  */
-L(cachelinenotset_loop):
-	addic.	r5,r5,-2	/* Update length.  */
-	lbz	r7,0(r4)	/* Load 2 bytes from source.  */
-	lbz	r8,1(r4)
-	addi	r4,r4,2		/* Update source pointer address.  */
-	stb	r7,0(r6)	/* Store 2 bytes on dest.  */
-	stb	r8,1(r6)
-	addi	r6,r6,2		/* Update dest pointer address.  */
-	bne	L(cachelinenotset_loop)
-	blr
-
-
-L(cachelineset):
-
-	addi   r10,r9,-1
-
-	cmpw   cr5,r5,r10       /* Less than a cacheline to go? */
-
-	neg     r7,r6           /* How far to next cacheline bdy? */
-
-	addi    r6,r6,-8        /* prepare for stdu  */
-	cmpwi   cr0,r9,128
-	addi    r4,r4,-8        /* prepare for ldu  */
-
-
-	ble+    cr5,L(lessthancacheline)
-
-	beq-    cr0,L(big_lines) /* 128 byte line code */
-
-
-
-
-	/* More than a cacheline left to go, and using 64 byte cachelines */
-
-	clrlwi  r7,r7,32-6      /* How far to next cacheline bdy? */
-
-	cmplwi  cr6,r7,0        /* Are we on a cacheline bdy already? */
-
-	/* Reduce total len by what it takes to get to the next cache line */
-	subf    r5,r7,r5
-	srwi    r7,r7,4         /* How many qws to get to the line bdy? */
-
-	/* How many full cache lines to copy after getting to a line bdy? */
-	srwi    r10,r5,6
-
-	cmplwi  r10,0           /* If no full cache lines to copy ... */
-	li      r11,0           /* number cachelines to copy with prefetch  */
-	beq     L(nocacheprefetch)
-
-
-	/* We are here because we have at least one full cache line to copy,
-	   and therefore some pre-touching to do. */
-
-	cmplwi  r10,PREFETCH_AHEAD
-	li      r12,64+8        /* prefetch distance  */
-	ble     L(lessthanmaxprefetch)
-
-	/* We can only do so much pre-fetching.  R11 will have the count of
-	   lines left to prefetch after the initial batch of prefetches
-	   are executed. */
-
-	subi    r11,r10,PREFETCH_AHEAD
-	li      r10,PREFETCH_AHEAD
-
-L(lessthanmaxprefetch):
-	mtctr   r10
-
-	/* At this point r10/ctr hold the number of lines to prefetch in this
-	   initial batch, and r11 holds any remainder. */
-
-L(prefetchSRC):
-	dcbt    r12,r4
-	addi    r12,r12,64
-	bdnz    L(prefetchSRC)
-
-
-	/* Prefetching is done, or was not needed.
-
-	   cr6 - are we on a cacheline boundary already?
-	   r7  - number of quadwords to the next cacheline boundary
-	*/
-
-L(nocacheprefetch):
-	mtctr   r7
-
-	cmplwi  cr1,r5,64   /* Less than a cache line to copy? */
-
-	/* How many bytes are left after we copy whatever full
-	   cache lines we can get? */
-	clrlwi  r5,r5,32-6
-
-	beq     cr6,L(cachelinealigned)
-
-
-	/* Copy quadwords up to the next cacheline boundary */
-
-L(aligntocacheline):
-	lfd     fp9,0x08(r4)
-	lfdu    fp10,0x10(r4)
-	stfd    fp9,0x08(r6)
-	stfdu   fp10,0x10(r6)
-	bdnz    L(aligntocacheline)
-
-
-	.align 4
-L(cachelinealigned):            /* copy while cache lines  */
-
-	blt-    cr1,L(lessthancacheline) /* size <64  */
-
-L(outerloop):
-	cmpwi   r11,0
-	mtctr   r11
-	beq-    L(endloop)
-
-	li      r11,64*ZERO_AHEAD +8    /* DCBZ dist  */
-
-	.align  4
-	/* Copy whole cachelines, optimized by prefetching SRC cacheline  */
-L(loop):                        /* Copy aligned body  */
-	dcbt    r12,r4          /* PREFETCH SOURCE some cache lines ahead  */
-	lfd     fp9,  0x08(r4)
-	dcbz    r11,r6
-	lfd     fp10, 0x10(r4)
-	lfd     fp11, 0x18(r4)
-	lfd     fp12, 0x20(r4)
-	stfd    fp9,  0x08(r6)
-	stfd    fp10, 0x10(r6)
-	stfd    fp11, 0x18(r6)
-	stfd    fp12, 0x20(r6)
-	lfd     fp9,  0x28(r4)
-	lfd     fp10, 0x30(r4)
-	lfd     fp11, 0x38(r4)
-	lfdu    fp12, 0x40(r4)
-	stfd    fp9,  0x28(r6)
-	stfd    fp10, 0x30(r6)
-	stfd    fp11, 0x38(r6)
-	stfdu   fp12, 0x40(r6)
-
-	bdnz    L(loop)
-
-
-L(endloop):
-	cmpwi   r10,0
-	beq-    L(endloop2)
-	mtctr   r10
-
-L(loop2):                       /* Copy aligned body  */
-	lfd     fp9,  0x08(r4)
-	lfd     fp10, 0x10(r4)
-	lfd     fp11, 0x18(r4)
-	lfd     fp12, 0x20(r4)
-	stfd    fp9,  0x08(r6)
-	stfd    fp10, 0x10(r6)
-	stfd    fp11, 0x18(r6)
-	stfd    fp12, 0x20(r6)
-	lfd     fp9,  0x28(r4)
-	lfd     fp10, 0x30(r4)
-	lfd     fp11, 0x38(r4)
-	lfdu    fp12, 0x40(r4)
-	stfd    fp9,  0x28(r6)
-	stfd    fp10, 0x30(r6)
-	stfd    fp11, 0x38(r6)
-	stfdu   fp12, 0x40(r6)
-
-	bdnz    L(loop2)
-L(endloop2):
-
-
-	.align  4
-L(lessthancacheline):           /* Was there less than cache to do ?  */
-	cmplwi  cr0,r5,16
-	srwi    r7,r5,4         /* divide size by 16  */
-	blt-    L(do_lt16)
-	mtctr   r7
-
-L(copy_remaining):
-	lfd     fp9,  0x08(r4)
-	lfdu    fp10, 0x10(r4)
-	stfd    fp9,  0x08(r6)
-	stfdu   fp10, 0x10(r6)
-	bdnz    L(copy_remaining)
-
-L(do_lt16):                     /* less than 16 ?  */
-	cmplwi  cr0,r5,0        /* copy remaining bytes (0-15)  */
-	beqlr+                  /* no rest to copy  */
-	addi    r4,r4,8
-	addi    r6,r6,8
-
-L(shortcopy):                   /* SIMPLE COPY to handle size =< 15 bytes  */
-	mtcrf   0x01,r5
-	sub     r7,r4,r6
-	bf-     cr7*4+0,8f
-	lfdx    fp9,r7,r6       /* copy 8 byte  */
-	stfd    fp9,0(r6)
-	addi    r6,r6,8
-8:
-	bf      cr7*4+1,4f
-	lwzx    r0,r7,r6        /* copy 4 byte  */
-	stw     r0,0(r6)
-	addi    r6,r6,4
-4:
-	bf      cr7*4+2,2f
-	lhzx    r0,r7,r6        /* copy 2 byte  */
-	sth     r0,0(r6)
-	addi    r6,r6,2
-2:
-	bf      cr7*4+3,1f
-	lbzx    r0,r7,r6        /* copy 1 byte  */
-	stb     r0,0(r6)
-1:
-	blr
-
-
-
-
-
-	/* Similar to above, but for use with 128 byte lines. */
-
-
-L(big_lines):
-
-	clrlwi  r7,r7,32-7      /* How far to next cacheline bdy? */
-
-	cmplwi  cr6,r7,0        /* Are we on a cacheline bdy already? */
-
-	/* Reduce total len by what it takes to get to the next cache line */
-	subf    r5,r7,r5
-	srwi    r7,r7,4         /* How many qw to get to the line bdy? */
-
-	/* How many full cache lines to copy after getting to a line bdy? */
-	srwi    r10,r5,7
-
-	cmplwi  r10,0           /* If no full cache lines to copy ... */
-	li      r11,0           /* number cachelines to copy with prefetch  */
-	beq     L(nocacheprefetch_128)
-
-
-	/* We are here because we have at least one full cache line to copy,
-	   and therefore some pre-touching to do. */
-
-	cmplwi  r10,PREFETCH_AHEAD
-	li      r12,128+8       /* prefetch distance  */
-	ble     L(lessthanmaxprefetch_128)
-
-	/* We can only do so much pre-fetching.  R11 will have the count of
-	   lines left to prefetch after the initial batch of prefetches
-	   are executed. */
-
-	subi    r11,r10,PREFETCH_AHEAD
-	li      r10,PREFETCH_AHEAD
-
-L(lessthanmaxprefetch_128):
-	mtctr   r10
-
-	/* At this point r10/ctr hold the number of lines to prefetch in this
-	   initial batch, and r11 holds any remainder. */
-
-L(prefetchSRC_128):
-	dcbt    r12,r4
-	addi    r12,r12,128
-	bdnz    L(prefetchSRC_128)
-
-
-	/* Prefetching is done, or was not needed.
-
-	   cr6 - are we on a cacheline boundary already?
-	   r7  - number of quadwords to the next cacheline boundary
-	*/
-
-L(nocacheprefetch_128):
-	mtctr   r7
-
-	cmplwi  cr1,r5,128  /* Less than a cache line to copy? */
-
-	/* How many bytes are left after we copy whatever full
-	   cache lines we can get? */
-	clrlwi  r5,r5,32-7
-
-	beq     cr6,L(cachelinealigned_128)
-
-
-	/* Copy quadwords up to the next cacheline boundary */
-
-L(aligntocacheline_128):
-	lfd     fp9,0x08(r4)
-	lfdu    fp10,0x10(r4)
-	stfd    fp9,0x08(r6)
-	stfdu   fp10,0x10(r6)
-	bdnz    L(aligntocacheline_128)
-
-
-L(cachelinealigned_128):        /* copy while cache lines  */
-
-	blt-    cr1,L(lessthancacheline) /* size <128  */
-
-L(outerloop_128):
-	cmpwi   r11,0
-	mtctr   r11
-	beq-    L(endloop_128)
-
-	li      r11,128*ZERO_AHEAD +8    /* DCBZ dist  */
-
-	.align  4
-	/* Copy whole cachelines, optimized by prefetching SRC cacheline  */
-L(loop_128):                    /* Copy aligned body  */
-	dcbt    r12,r4          /* PREFETCH SOURCE some cache lines ahead  */
-	lfd     fp9,  0x08(r4)
-	dcbz    r11,r6
-	lfd     fp10, 0x10(r4)
-	lfd     fp11, 0x18(r4)
-	lfd     fp12, 0x20(r4)
-	stfd    fp9,  0x08(r6)
-	stfd    fp10, 0x10(r6)
-	stfd    fp11, 0x18(r6)
-	stfd    fp12, 0x20(r6)
-	lfd     fp9,  0x28(r4)
-	lfd     fp10, 0x30(r4)
-	lfd     fp11, 0x38(r4)
-	lfd     fp12, 0x40(r4)
-	stfd    fp9,  0x28(r6)
-	stfd    fp10, 0x30(r6)
-	stfd    fp11, 0x38(r6)
-	stfd    fp12, 0x40(r6)
-	lfd     fp9,  0x48(r4)
-	lfd     fp10, 0x50(r4)
-	lfd     fp11, 0x58(r4)
-	lfd     fp12, 0x60(r4)
-	stfd    fp9,  0x48(r6)
-	stfd    fp10, 0x50(r6)
-	stfd    fp11, 0x58(r6)
-	stfd    fp12, 0x60(r6)
-	lfd     fp9,  0x68(r4)
-	lfd     fp10, 0x70(r4)
-	lfd     fp11, 0x78(r4)
-	lfdu    fp12, 0x80(r4)
-	stfd    fp9,  0x68(r6)
-	stfd    fp10, 0x70(r6)
-	stfd    fp11, 0x78(r6)
-	stfdu   fp12, 0x80(r6)
-
-	bdnz    L(loop_128)
-
-
-L(endloop_128):
-	cmpwi   r10,0
-	beq-    L(endloop2_128)
-	mtctr   r10
-
-L(loop2_128):                   /* Copy aligned body  */
-	lfd     fp9,  0x08(r4)
-	lfd     fp10, 0x10(r4)
-	lfd     fp11, 0x18(r4)
-	lfd     fp12, 0x20(r4)
-	stfd    fp9,  0x08(r6)
-	stfd    fp10, 0x10(r6)
-	stfd    fp11, 0x18(r6)
-	stfd    fp12, 0x20(r6)
-	lfd     fp9,  0x28(r4)
-	lfd     fp10, 0x30(r4)
-	lfd     fp11, 0x38(r4)
-	lfd     fp12, 0x40(r4)
-	stfd    fp9,  0x28(r6)
-	stfd    fp10, 0x30(r6)
-	stfd    fp11, 0x38(r6)
-	stfd    fp12, 0x40(r6)
-	lfd     fp9,  0x48(r4)
-	lfd     fp10, 0x50(r4)
-	lfd     fp11, 0x58(r4)
-	lfd     fp12, 0x60(r4)
-	stfd    fp9,  0x48(r6)
-	stfd    fp10, 0x50(r6)
-	stfd    fp11, 0x58(r6)
-	stfd    fp12, 0x60(r6)
-	lfd     fp9,  0x68(r4)
-	lfd     fp10, 0x70(r4)
-	lfd     fp11, 0x78(r4)
-	lfdu    fp12, 0x80(r4)
-	stfd    fp9,  0x68(r6)
-	stfd    fp10, 0x70(r6)
-	stfd    fp11, 0x78(r6)
-	stfdu   fp12, 0x80(r6)
-	bdnz    L(loop2_128)
-L(endloop2_128):
-
-	b       L(lessthancacheline)
-
-
-END (memcpy)
-libc_hidden_builtin_def (memcpy)
diff --git a/sysdeps/powerpc/powerpc32/cell/memcpy.S b/sysdeps/powerpc/powerpc32/cell/memcpy.S
deleted file mode 100644
index 484c0dc..0000000
--- a/sysdeps/powerpc/powerpc32/cell/memcpy.S
+++ /dev/null
@@ -1,242 +0,0 @@
-/* Optimized memcpy implementation for CELL BE PowerPC.
-   Copyright (C) 2010-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-#define PREFETCH_AHEAD 6	/* no cache lines SRC prefetching ahead  */
-#define ZERO_AHEAD 4		/* no cache lines DST zeroing ahead  */
-
-/* memcpy routine optimized for CELL-BE-PPC	v2.0
- *
- * The CELL PPC core has 1 integer unit and 1 load/store unit
- * CELL:
- * 1st level data cache = 32K
- * 2nd level data cache = 512K
- * 3rd level data cache = 0K
- * With 3.2 GHz clockrate the latency to 2nd level cache is >36 clocks,
- * latency to memory is >400 clocks
- * To improve copy performance we need to prefetch source data
- * far ahead to hide this latency
- * For best performance instruction forms ending in "." like "andi."
- * should be avoided as the are implemented in microcode on CELL.
- * The below code is loop unrolled for the CELL cache line of 128 bytes
- */
-
-.align  7
-
-EALIGN (memcpy, 5, 0)
-	CALL_MCOUNT
-
-	dcbt	0,r4		/* Prefetch ONE SRC cacheline  */
-	cmplwi	cr1,r5,16	/* is size < 16 ?  */
-	mr	r6,r3
-	blt+	cr1,.Lshortcopy
-
-.Lbigcopy:
-	neg	r8,r3		/* LS 3 bits = # bytes to 8-byte dest bdry  */
-	clrlwi  r8,r8,32-4	/* align to 16byte boundary  */
-	sub     r7,r4,r3
-	cmplwi	cr0,r8,0
-	beq+	.Ldst_aligned
-
-.Ldst_unaligned:
-	mtcrf	0x01,r8		/* put #bytes to boundary into cr7  */
-	subf	r5,r8,r5
-
-	bf	cr7*4+3,1f
-	lbzx	r0,r7,r6	/* copy 1 byte  */
-	stb	r0,0(r6)
-	addi	r6,r6,1
-1:	bf	cr7*4+2,2f
-	lhzx	r0,r7,r6	/* copy 2 byte  */
-	sth	r0,0(r6)
-	addi	r6,r6,2
-2:	bf	cr7*4+1,4f
-	lwzx	r0,r7,r6	/* copy 4 byte  */
-	stw	r0,0(r6)
-	addi	r6,r6,4
-4:	bf	cr7*4+0,8f
-	lfdx	fp9,r7,r6	/* copy 8 byte  */
-	stfd	fp9,0(r6)
-	addi	r6,r6,8
-8:
-	add	r4,r7,r6
-
-.Ldst_aligned:
-
-	cmpwi	cr5,r5,128-1
-
-	neg	r7,r6
-	addi	r6,r6,-8	/* prepare for stfdu  */
-	addi	r4,r4,-8	/* prepare for lfdu  */
-
-	clrlwi  r7,r7,32-7	/* align to cacheline boundary  */
-	ble+	cr5,.Llessthancacheline
-
-	cmplwi	cr6,r7,0
-	subf	r5,r7,r5
-	srwi	r7,r7,4		/* divide size by 16  */
-	srwi	r10,r5,7	/* number of cache lines to copy  */
-
-	cmplwi	r10,0
-	li	r11,0		/* number cachelines to copy with prefetch  */
-	beq	.Lnocacheprefetch
-
-	cmplwi	r10,PREFETCH_AHEAD
-	li	r12,128+8	/* prefetch distance  */
-	ble	.Llessthanmaxprefetch
-
-	subi	r11,r10,PREFETCH_AHEAD
-	li	r10,PREFETCH_AHEAD
-
-.Llessthanmaxprefetch:
-	mtctr	r10
-
-.LprefetchSRC:
-	dcbt    r12,r4
-	addi    r12,r12,128
-	bdnz    .LprefetchSRC
-
-.Lnocacheprefetch:
-	mtctr	r7
-	cmplwi	cr1,r5,128
-	clrlwi  r5,r5,32-7
-	beq	cr6,.Lcachelinealigned
-
-.Laligntocacheline:
-	lfd	fp9,0x08(r4)
-	lfdu	fp10,0x10(r4)
-	stfd	fp9,0x08(r6)
-	stfdu	fp10,0x10(r6)
-	bdnz	.Laligntocacheline
-
-
-.Lcachelinealigned:		/* copy while cache lines  */
-
-	blt-	cr1,.Llessthancacheline	/* size <128  */
-
-.Louterloop:
-	cmpwi   r11,0
-	mtctr	r11
-	beq-	.Lendloop
-
-	li	r11,128*ZERO_AHEAD +8	/* DCBZ dist  */
-
-.align	4
-	/* Copy whole cachelines, optimized by prefetching SRC cacheline  */
-.Lloop:				/* Copy aligned body  */
-	dcbt	r12,r4		/* PREFETCH SOURCE some cache lines ahead  */
-	lfd	fp9, 0x08(r4)
-	dcbz	r11,r6
-	lfd	fp10, 0x10(r4)	/* 4 register stride copy is optimal  */
-	lfd	fp11, 0x18(r4)	/* to hide 1st level cache latency.  */
-	lfd	fp12, 0x20(r4)
-	stfd	fp9, 0x08(r6)
-	stfd	fp10, 0x10(r6)
-	stfd	fp11, 0x18(r6)
-	stfd	fp12, 0x20(r6)
-	lfd	fp9, 0x28(r4)
-	lfd	fp10, 0x30(r4)
-	lfd	fp11, 0x38(r4)
-	lfd	fp12, 0x40(r4)
-	stfd	fp9, 0x28(r6)
-	stfd	fp10, 0x30(r6)
-	stfd	fp11, 0x38(r6)
-	stfd	fp12, 0x40(r6)
-	lfd	fp9, 0x48(r4)
-	lfd	fp10, 0x50(r4)
-	lfd	fp11, 0x58(r4)
-	lfd	fp12, 0x60(r4)
-	stfd	fp9, 0x48(r6)
-	stfd	fp10, 0x50(r6)
-	stfd	fp11, 0x58(r6)
-	stfd	fp12, 0x60(r6)
-	lfd	fp9, 0x68(r4)
-	lfd	fp10, 0x70(r4)
-	lfd	fp11, 0x78(r4)
-	lfdu	fp12, 0x80(r4)
-	stfd	fp9, 0x68(r6)
-	stfd	fp10, 0x70(r6)
-	stfd	fp11, 0x78(r6)
-	stfdu	fp12, 0x80(r6)
-
-	bdnz	.Lloop
-
-.Lendloop:
-	cmpwi	r10,0
-	slwi	r10,r10,2	/* adjust from 128 to 32 byte stride  */
-	beq-	.Lendloop2
-	mtctr	r10
-
-.Lloop2:			/* Copy aligned body  */
-	lfd	fp9, 0x08(r4)
-	lfd	fp10, 0x10(r4)
-	lfd	fp11, 0x18(r4)
-	lfdu	fp12, 0x20(r4)
-	stfd	fp9, 0x08(r6)
-	stfd	fp10, 0x10(r6)
-	stfd	fp11, 0x18(r6)
-	stfdu	fp12, 0x20(r6)
-
-	bdnz	.Lloop2
-.Lendloop2:
-
-.Llessthancacheline:		/* less than cache to do ?  */
-	cmplwi	cr0,r5,16
-	srwi	r7,r5,4		/* divide size by 16  */
-	blt-	.Ldo_lt16
-	mtctr	r7
-
-.Lcopy_remaining:
-	lfd	fp9,0x08(r4)
-	lfdu	fp10,0x10(r4)
-	stfd	fp9,0x08(r6)
-	stfdu	fp10,0x10(r6)
-	bdnz	.Lcopy_remaining
-
-.Ldo_lt16:			/* less than 16 ?  */
-	cmplwi	cr0,r5,0	/* copy remaining bytes (0-15)  */
-	beqlr+			/* no rest to copy  */
-	addi	r4,r4,8
-	addi	r6,r6,8
-
-.Lshortcopy:			/* SIMPLE COPY to handle size =< 15 bytes  */
-	mtcrf	0x01,r5
-	sub	r7,r4,r6
-	bf-	cr7*4+0,8f
-	lfdx	fp9,r7,r6	/* copy 8 byte  */
-	stfd	fp9,0(r6)
-	addi	r6,r6,8
-8:
-	bf	cr7*4+1,4f
-	lwzx	r0,r7,r6	/* copy 4 byte  */
-	stw	r0,0(r6)
-	addi	r6,r6,4
-4:
-	bf	cr7*4+2,2f
-	lhzx	r0,r7,r6	/* copy 2 byte  */
-	sth	r0,0(r6)
-	addi	r6,r6,2
-2:
-	bf	cr7*4+3,1f
-	lbzx	r0,r7,r6	/* copy 1 byte  */
-	stb	r0,0(r6)
-1:	blr
-
-END (memcpy)
-libc_hidden_builtin_def (memcpy)
diff --git a/sysdeps/powerpc/powerpc32/memset.S b/sysdeps/powerpc/powerpc32/memset.S
deleted file mode 100644
index 94686f9..0000000
--- a/sysdeps/powerpc/powerpc32/memset.S
+++ /dev/null
@@ -1,307 +0,0 @@
-/* Optimized memset implementation for PowerPC.
-   Copyright (C) 1997-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* void * [r3] memset (void *s [r3], int c [r4], size_t n [r5]));
-   Returns 's'.
-
-   The memset is done in four sizes: byte (8 bits), word (32 bits),
-   32-byte blocks (256 bits) and __cache_line_size (128, 256, 1024 bits).
-   There is a special case for setting whole cache lines to 0, which
-   takes advantage of the dcbz instruction.  */
-
-	.section	".text"
-EALIGN (memset, 5, 1)
-
-#define rTMP	r0
-#define rRTN	r3	/* initial value of 1st argument */
-#define rMEMP0	r3	/* original value of 1st arg */
-#define rCHR	r4	/* char to set in each byte */
-#define rLEN	r5	/* length of region to set */
-#define rMEMP	r6	/* address at which we are storing */
-#define rALIGN	r7	/* number of bytes we are setting now (when aligning) */
-#define rMEMP2	r8
-
-#define rPOS32	r7	/* constant +32 for clearing with dcbz */
-#define rNEG64	r8	/* constant -64 for clearing with dcbz */
-#define rNEG32	r9	/* constant -32 for clearing with dcbz */
-
-#define rGOT	r9	/* Address of the Global Offset Table.  */
-#define rCLS	r8	/* Cache line size obtained from static.  */
-#define rCLM	r9	/* Cache line size mask to check for cache alignment.  */
-
-/* take care of case for size <= 4  */
-	cmplwi	cr1, rLEN, 4
-	andi.	rALIGN, rMEMP0, 3
-	mr	rMEMP, rMEMP0
-	ble-	cr1, L(small)
-/* align to word boundary  */
-	cmplwi	cr5, rLEN, 31
-	rlwimi	rCHR, rCHR, 8, 16, 23
-	beq+	L(aligned)	/* 8th instruction from .align */
-	mtcrf	0x01, rMEMP0
-	subfic	rALIGN, rALIGN, 4
-	add	rMEMP, rMEMP, rALIGN
-	sub	rLEN, rLEN, rALIGN
-	bf+	31, L(g0)
-	stb	rCHR, 0(rMEMP0)
-	bt	30, L(aligned)
-L(g0):	sth	rCHR, -2(rMEMP)	/* 16th instruction from .align */
-/* take care of case for size < 31 */
-L(aligned):
-	mtcrf	0x01, rLEN
-	rlwimi	rCHR, rCHR, 16, 0, 15
-	ble	cr5, L(medium)
-/* align to cache line boundary...  */
-	andi.	rALIGN, rMEMP, 0x1C
-	subfic	rALIGN, rALIGN, 0x20
-	beq	L(caligned)
-	mtcrf	0x01, rALIGN
-	add	rMEMP, rMEMP, rALIGN
-	sub	rLEN, rLEN, rALIGN
-	cmplwi	cr1, rALIGN, 0x10
-	mr	rMEMP2, rMEMP
-	bf	28, L(a1)
-	stw	rCHR, -4(rMEMP2)
-	stwu	rCHR, -8(rMEMP2)
-L(a1):	blt	cr1, L(a2)
-	stw	rCHR, -4(rMEMP2) /* 32nd instruction from .align */
-	stw	rCHR, -8(rMEMP2)
-	stw	rCHR, -12(rMEMP2)
-	stwu	rCHR, -16(rMEMP2)
-L(a2):	bf	29, L(caligned)
-	stw	rCHR, -4(rMEMP2)
-/* now aligned to a cache line.  */
-L(caligned):
-	cmplwi	cr1, rCHR, 0
-	clrrwi.	rALIGN, rLEN, 5
-	mtcrf	0x01, rLEN	/* 40th instruction from .align */
-
-/* Check if we can use the special case for clearing memory using dcbz.
-   This requires that we know the correct cache line size for this
-   processor.  Getting the __cache_line_size may require establishing GOT
-   addressability, so branch out of line to set this up.  */
-	beq	cr1, L(checklinesize)
-
-/* Store blocks of 32-bytes (256-bits) starting on a 32-byte boundary.
-   Can't assume that rCHR is zero or that the cache line size is either
-   32-bytes or even known.  */
-L(nondcbz):
-	srwi	rTMP, rALIGN, 5
-	mtctr	rTMP
-	beq	L(medium)	/* we may not actually get to do a full line */
-	clrlwi.	rLEN, rLEN, 27
-	add	rMEMP, rMEMP, rALIGN
-	li	rNEG64, -0x40
-	bdz	L(cloopdone)	/* 48th instruction from .align */
-
-/* We can't use dcbz here as we don't know the cache line size.  We can
-   use "data cache block touch for store", which is safe.  */
-L(c3):	dcbtst	rNEG64, rMEMP
-	stw	rCHR, -4(rMEMP)
-	stw	rCHR, -8(rMEMP)
-	stw	rCHR, -12(rMEMP)
-	stw	rCHR, -16(rMEMP)
-	nop			/* let 601 fetch last 4 instructions of loop */
-	stw	rCHR, -20(rMEMP)
-	stw	rCHR, -24(rMEMP) /* 56th instruction from .align */
-	nop			/* let 601 fetch first 8 instructions of loop */
-	stw	rCHR, -28(rMEMP)
-	stwu	rCHR, -32(rMEMP)
-	bdnz	L(c3)
-L(cloopdone):
-	stw	rCHR, -4(rMEMP)
-	stw	rCHR, -8(rMEMP)
-	stw	rCHR, -12(rMEMP)
-	stw	rCHR, -16(rMEMP) /* 64th instruction from .align */
-	stw	rCHR, -20(rMEMP)
-	cmplwi	cr1, rLEN, 16
-	stw	rCHR, -24(rMEMP)
-	stw	rCHR, -28(rMEMP)
-	stwu	rCHR, -32(rMEMP)
-	beqlr
-	add	rMEMP, rMEMP, rALIGN
-	b	L(medium_tail2)	/* 72nd instruction from .align */
-
-	.align	5
-	nop
-/* Clear cache lines of memory in 128-byte chunks.
-   This code is optimized for processors with 32-byte cache lines.
-   It is further optimized for the 601 processor, which requires
-   some care in how the code is aligned in the i-cache.  */
-L(zloopstart):
-	clrlwi	rLEN, rLEN, 27
-	mtcrf	0x02, rALIGN
-	srwi.	rTMP, rALIGN, 7
-	mtctr	rTMP
-	li	rPOS32, 0x20
-	li	rNEG64, -0x40
-	cmplwi	cr1, rLEN, 16	/* 8 */
-	bf	26, L(z0)
-	dcbz	0, rMEMP
-	addi	rMEMP, rMEMP, 0x20
-L(z0):	li	rNEG32, -0x20
-	bf	25, L(z1)
-	dcbz	0, rMEMP
-	dcbz	rPOS32, rMEMP
-	addi	rMEMP, rMEMP, 0x40 /* 16 */
-L(z1):	cmplwi	cr5, rLEN, 0
-	beq	L(medium)
-L(zloop):
-	dcbz	0, rMEMP
-	dcbz	rPOS32, rMEMP
-	addi	rMEMP, rMEMP, 0x80
-	dcbz	rNEG64, rMEMP
-	dcbz	rNEG32, rMEMP
-	bdnz	L(zloop)
-	beqlr	cr5
-	b	L(medium_tail2)
-
-	.align	5
-L(small):
-/* Memset of 4 bytes or less.  */
-	cmplwi	cr5, rLEN, 1
-	cmplwi	cr1, rLEN, 3
-	bltlr	cr5
-	stb	rCHR, 0(rMEMP)
-	beqlr	cr5
-	nop
-	stb	rCHR, 1(rMEMP)
-	bltlr	cr1
-	stb	rCHR, 2(rMEMP)
-	beqlr	cr1
-	nop
-	stb	rCHR, 3(rMEMP)
-	blr
-
-/* Memset of 0-31 bytes.  */
-	.align	5
-L(medium):
-	cmplwi	cr1, rLEN, 16
-L(medium_tail2):
-	add	rMEMP, rMEMP, rLEN
-L(medium_tail):
-	bt-	31, L(medium_31t)
-	bt-	30, L(medium_30t)
-L(medium_30f):
-	bt-	29, L(medium_29t)
-L(medium_29f):
-	bge-	cr1, L(medium_27t)
-	bflr-	28
-	stw	rCHR, -4(rMEMP)	/* 8th instruction from .align */
-	stw	rCHR, -8(rMEMP)
-	blr
-
-L(medium_31t):
-	stbu	rCHR, -1(rMEMP)
-	bf-	30, L(medium_30f)
-L(medium_30t):
-	sthu	rCHR, -2(rMEMP)
-	bf-	29, L(medium_29f)
-L(medium_29t):
-	stwu	rCHR, -4(rMEMP)
-	blt-	cr1, L(medium_27f) /* 16th instruction from .align */
-L(medium_27t):
-	stw	rCHR, -4(rMEMP)
-	stw	rCHR, -8(rMEMP)
-	stw	rCHR, -12(rMEMP)
-	stwu	rCHR, -16(rMEMP)
-L(medium_27f):
-	bflr-	28
-L(medium_28t):
-	stw	rCHR, -4(rMEMP)
-	stw	rCHR, -8(rMEMP)
-	blr
-
-L(checklinesize):
-#ifdef SHARED
-	mflr	rTMP
-/* If the remaining length is less the 32 bytes then don't bother getting
-   the cache line size.  */
-	beq	L(medium)
-/* Establishes GOT addressability so we can load __cache_line_size
-   from static. This value was set from the aux vector during startup.  */
-	SETUP_GOT_ACCESS(rGOT,got_label)
-	addis	rGOT,rGOT,__cache_line_size-got_label@ha
-	lwz	rCLS,__cache_line_size-got_label@l(rGOT)
-	mtlr	rTMP
-#else
-/* Load __cache_line_size from static. This value was set from the
-   aux vector during startup.  */
-	lis	rCLS,__cache_line_size@ha
-/* If the remaining length is less the 32 bytes then don't bother getting
-   the cache line size.  */
-	beq	L(medium)
-	lwz	rCLS,__cache_line_size@l(rCLS)
-#endif
-
-/* If the cache line size was not set then goto to L(nondcbz), which is
-   safe for any cache line size.  */
-	cmplwi	cr1,rCLS,0
-	beq	cr1,L(nondcbz)
-
-/* If the cache line size is 32 bytes then goto to L(zloopstart),
-   which is coded specifically for 32-byte lines (and 601).  */
-	cmplwi	cr1,rCLS,32
-	beq	cr1,L(zloopstart)
-
-/* Now we know the cache line size and it is not 32-bytes.  However
-   we may not yet be aligned to the cache line and may have a partial
-   line to fill.  Touch it 1st to fetch the cache line.  */
-	dcbtst	0,rMEMP
-
-	addi	rCLM,rCLS,-1
-L(getCacheAligned):
-	cmplwi	cr1,rLEN,32
-	and.	rTMP,rCLM,rMEMP
-	blt	cr1,L(handletail32)
-	beq	L(cacheAligned)
-/* We are not aligned to start of a cache line yet.  Store 32-byte
-   of data and test again.  */
-	addi	rMEMP,rMEMP,32
-	addi	rLEN,rLEN,-32
-	stw	rCHR,-32(rMEMP)
-	stw	rCHR,-28(rMEMP)
-	stw	rCHR,-24(rMEMP)
-	stw	rCHR,-20(rMEMP)
-	stw	rCHR,-16(rMEMP)
-	stw	rCHR,-12(rMEMP)
-	stw	rCHR,-8(rMEMP)
-	stw	rCHR,-4(rMEMP)
-	b	L(getCacheAligned)
-
-/* Now we are aligned to the cache line and can use dcbz.  */
-L(cacheAligned):
-	cmplw	cr1,rLEN,rCLS
-	blt	cr1,L(handletail32)
-	dcbz	0,rMEMP
-	subf	rLEN,rCLS,rLEN
-	add	rMEMP,rMEMP,rCLS
-	b	L(cacheAligned)
-
-/* We are here because; the cache line size was set, it was not
-   32-bytes, and the remainder (rLEN) is now less than the actual cache
-   line size.  Set up the preconditions for L(nondcbz) and go there to
-   store the remaining bytes.  */
-L(handletail32):
-	clrrwi.	rALIGN, rLEN, 5
-	b	L(nondcbz)
-
-END (memset)
-libc_hidden_builtin_def (memset)
diff --git a/sysdeps/powerpc/powerpc32/power4/memcmp.S b/sysdeps/powerpc/powerpc32/power4/memcmp.S
deleted file mode 100644
index cc4bd32..0000000
--- a/sysdeps/powerpc/powerpc32/power4/memcmp.S
+++ /dev/null
@@ -1,1375 +0,0 @@
-/* Optimized strcmp implementation for PowerPC32.
-   Copyright (C) 2003-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* int [r3] memcmp (const char *s1 [r3],
-		    const char *s2 [r4],
-		    size_t size [r5])  */
-
-	.machine power4
-EALIGN (memcmp, 4, 0)
-	CALL_MCOUNT
-
-#define rRTN	r3
-#define rSTR1	r3	/* first string arg */
-#define rSTR2	r4	/* second string arg */
-#define rN	r5	/* max string length */
-#define rWORD1	r6	/* current word in s1 */
-#define rWORD2	r7	/* current word in s2 */
-#define rWORD3	r8	/* next word in s1 */
-#define rWORD4	r9	/* next word in s2 */
-#define rWORD5	r10	/* next word in s1 */
-#define rWORD6	r11	/* next word in s2 */
-#define rWORD7	r30	/* next word in s1 */
-#define rWORD8	r31	/* next word in s2 */
-
-	xor	r0, rSTR2, rSTR1
-	cmplwi	cr6, rN, 0
-	cmplwi	cr1, rN, 12
-	clrlwi.	r0, r0, 30
-	clrlwi	r12, rSTR1, 30
-	cmplwi	cr5, r12, 0
-	beq-	cr6, L(zeroLength)
-	dcbt	0, rSTR1
-	dcbt	0, rSTR2
-/* If less than 8 bytes or not aligned, use the unaligned
-   byte loop.  */
-	blt	cr1, L(bytealigned)
-	stwu	1, -64(r1)
-	cfi_adjust_cfa_offset(64)
-	stw	rWORD8, 48(r1)
-	stw	rWORD7, 44(r1)
-	cfi_offset(rWORD8, (48-64))
-	cfi_offset(rWORD7, (44-64))
-	bne	L(unaligned)
-/* At this point we know both strings have the same alignment and the
-   compare length is at least 8 bytes.  r12 contains the low order
-   2 bits of rSTR1 and cr5 contains the result of the logical compare
-   of r12 to 0.  If r12 == 0 then we are already word
-   aligned and can perform the word aligned loop.
-
-   Otherwise we know the two strings have the same alignment (but not
-   yet word aligned).  So we force the string addresses to the next lower
-   word boundary and special case this first word using shift left to
-   eliminate bits preceding the first byte.  Since we want to join the
-   normal (word aligned) compare loop, starting at the second word,
-   we need to adjust the length (rN) and special case the loop
-   versioning for the first word. This ensures that the loop count is
-   correct and the first word (shifted) is in the expected register pair. */
-	.align	4
-L(samealignment):
-	clrrwi	rSTR1, rSTR1, 2
-	clrrwi	rSTR2, rSTR2, 2
-	beq	cr5, L(Waligned)
-	add	rN, rN, r12
-	slwi	rWORD6, r12, 3
-	srwi	r0, rN, 4	/* Divide by 16 */
-	andi.	r12, rN, 12	/* Get the word remainder */
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD1, 0, rSTR1
-	lwbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD1, 0(rSTR1)
-	lwz	rWORD2, 0(rSTR2)
-#endif
-	cmplwi	cr1, r12, 8
-	cmplwi	cr7, rN, 16
-	clrlwi	rN, rN, 30
-	beq	L(dPs4)
-	mtctr	r0	/* Power4 wants mtctr 1st in dispatch group */
-	bgt	cr1, L(dPs3)
-	beq	cr1, L(dPs2)
-
-/* Remainder is 4 */
-	.align	3
-L(dsP1):
-	slw	rWORD5, rWORD1, rWORD6
-	slw	rWORD6, rWORD2, rWORD6
-	cmplw	cr5, rWORD5, rWORD6
-	blt	cr7, L(dP1x)
-/* Do something useful in this cycle since we have to branch anyway.  */
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD1, 0, rSTR1
-	lwbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD1, 4(rSTR1)
-	lwz	rWORD2, 4(rSTR2)
-#endif
-	cmplw	cr7, rWORD1, rWORD2
-	b	L(dP1e)
-/* Remainder is 8 */
-	.align	4
-L(dPs2):
-	slw	rWORD5, rWORD1, rWORD6
-	slw	rWORD6, rWORD2, rWORD6
-	cmplw	cr6, rWORD5, rWORD6
-	blt	cr7, L(dP2x)
-/* Do something useful in this cycle since we have to branch anyway.  */
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD7, 0, rSTR1
-	lwbrx	rWORD8, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD7, 4(rSTR1)
-	lwz	rWORD8, 4(rSTR2)
-#endif
-	cmplw	cr5, rWORD7, rWORD8
-	b	L(dP2e)
-/* Remainder is 12 */
-	.align	4
-L(dPs3):
-	slw	rWORD3, rWORD1, rWORD6
-	slw	rWORD4, rWORD2, rWORD6
-	cmplw	cr1, rWORD3, rWORD4
-	b	L(dP3e)
-/* Count is a multiple of 16, remainder is 0 */
-	.align	4
-L(dPs4):
-	mtctr	r0	/* Power4 wants mtctr 1st in dispatch group */
-	slw	rWORD1, rWORD1, rWORD6
-	slw	rWORD2, rWORD2, rWORD6
-	cmplw	cr7, rWORD1, rWORD2
-	b	L(dP4e)
-
-/* At this point we know both strings are word aligned and the
-   compare length is at least 8 bytes.  */
-	.align	4
-L(Waligned):
-	andi.	r12, rN, 12	/* Get the word remainder */
-	srwi	r0, rN, 4	/* Divide by 16 */
-	cmplwi	cr1, r12, 8
-	cmplwi	cr7, rN, 16
-	clrlwi	rN, rN, 30
-	beq	L(dP4)
-	bgt	cr1, L(dP3)
-	beq	cr1, L(dP2)
-
-/* Remainder is 4 */
-	.align	4
-L(dP1):
-	mtctr	r0	/* Power4 wants mtctr 1st in dispatch group */
-/* Normally we'd use rWORD7/rWORD8 here, but since we might exit early
-   (8-15 byte compare), we want to use only volatile registers.  This
-   means we can avoid restoring non-volatile registers since we did not
-   change any on the early exit path.  The key here is the non-early
-   exit path only cares about the condition code (cr5), not about which
-   register pair was used.  */
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD5, 0, rSTR1
-	lwbrx	rWORD6, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD5, 0(rSTR1)
-	lwz	rWORD6, 0(rSTR2)
-#endif
-	cmplw	cr5, rWORD5, rWORD6
-	blt	cr7, L(dP1x)
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD1, 0, rSTR1
-	lwbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD1, 4(rSTR1)
-	lwz	rWORD2, 4(rSTR2)
-#endif
-	cmplw	cr7, rWORD1, rWORD2
-L(dP1e):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD3, 0, rSTR1
-	lwbrx	rWORD4, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD3, 8(rSTR1)
-	lwz	rWORD4, 8(rSTR2)
-#endif
-	cmplw	cr1, rWORD3, rWORD4
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD5, 0, rSTR1
-	lwbrx	rWORD6, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD5, 12(rSTR1)
-	lwz	rWORD6, 12(rSTR2)
-#endif
-	cmplw	cr6, rWORD5, rWORD6
-	bne	cr5, L(dLcr5x)
-	bne	cr7, L(dLcr7x)
-
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD7, 0, rSTR1
-	lwbrx	rWORD8, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwzu	rWORD7, 16(rSTR1)
-	lwzu	rWORD8, 16(rSTR2)
-#endif
-	bne	cr1, L(dLcr1)
-	cmplw	cr5, rWORD7, rWORD8
-	bdnz	L(dLoop)
-	bne	cr6, L(dLcr6)
-	lwz	rWORD7, 44(r1)
-	lwz	rWORD8, 48(r1)
-	.align	3
-L(dP1x):
-	slwi.	r12, rN, 3
-	bne	cr5, L(dLcr5x)
-	subfic	rN, r12, 32	/* Shift count is 32 - (rN * 8).  */
-	addi	1, 1, 64
-	cfi_adjust_cfa_offset(-64)
-	bne	L(d00)
-	li	rRTN, 0
-	blr
-
-/* Remainder is 8 */
-	.align	4
-	cfi_adjust_cfa_offset(64)
-L(dP2):
-	mtctr	r0	/* Power4 wants mtctr 1st in dispatch group */
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD5, 0, rSTR1
-	lwbrx	rWORD6, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD5, 0(rSTR1)
-	lwz	rWORD6, 0(rSTR2)
-#endif
-	cmplw	cr6, rWORD5, rWORD6
-	blt	cr7, L(dP2x)
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD7, 0, rSTR1
-	lwbrx	rWORD8, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD7, 4(rSTR1)
-	lwz	rWORD8, 4(rSTR2)
-#endif
-	cmplw	cr5, rWORD7, rWORD8
-L(dP2e):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD1, 0, rSTR1
-	lwbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD1, 8(rSTR1)
-	lwz	rWORD2, 8(rSTR2)
-#endif
-	cmplw	cr7, rWORD1, rWORD2
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD3, 0, rSTR1
-	lwbrx	rWORD4, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD3, 12(rSTR1)
-	lwz	rWORD4, 12(rSTR2)
-#endif
-	cmplw	cr1, rWORD3, rWORD4
-#ifndef __LITTLE_ENDIAN__
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#endif
-	bne	cr6, L(dLcr6)
-	bne	cr5, L(dLcr5)
-	b	L(dLoop2)
-/* Again we are on a early exit path (16-23 byte compare), we want to
-   only use volatile registers and avoid restoring non-volatile
-   registers.  */
-	.align	4
-L(dP2x):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD3, 0, rSTR1
-	lwbrx	rWORD4, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD3, 4(rSTR1)
-	lwz	rWORD4, 4(rSTR2)
-#endif
-	cmplw	cr1, rWORD3, rWORD4
-	slwi.	r12, rN, 3
-	bne	cr6, L(dLcr6x)
-#ifndef __LITTLE_ENDIAN__
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#endif
-	bne	cr1, L(dLcr1x)
-	subfic	rN, r12, 32	/* Shift count is 32 - (rN * 8).  */
-	addi	1, 1, 64
-	cfi_adjust_cfa_offset(-64)
-	bne	L(d00)
-	li	rRTN, 0
-	blr
-
-/* Remainder is 12 */
-	.align	4
-	cfi_adjust_cfa_offset(64)
-L(dP3):
-	mtctr	r0	/* Power4 wants mtctr 1st in dispatch group */
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD3, 0, rSTR1
-	lwbrx	rWORD4, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD3, 0(rSTR1)
-	lwz	rWORD4, 0(rSTR2)
-#endif
-	cmplw	cr1, rWORD3, rWORD4
-L(dP3e):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD5, 0, rSTR1
-	lwbrx	rWORD6, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD5, 4(rSTR1)
-	lwz	rWORD6, 4(rSTR2)
-#endif
-	cmplw	cr6, rWORD5, rWORD6
-	blt	cr7, L(dP3x)
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD7, 0, rSTR1
-	lwbrx	rWORD8, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD7, 8(rSTR1)
-	lwz	rWORD8, 8(rSTR2)
-#endif
-	cmplw	cr5, rWORD7, rWORD8
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD1, 0, rSTR1
-	lwbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD1, 12(rSTR1)
-	lwz	rWORD2, 12(rSTR2)
-#endif
-	cmplw	cr7, rWORD1, rWORD2
-#ifndef __LITTLE_ENDIAN__
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#endif
-	bne	cr1, L(dLcr1)
-	bne	cr6, L(dLcr6)
-	b	L(dLoop1)
-/* Again we are on a early exit path (24-31 byte compare), we want to
-   only use volatile registers and avoid restoring non-volatile
-   registers.  */
-	.align	4
-L(dP3x):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD1, 0, rSTR1
-	lwbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD1, 8(rSTR1)
-	lwz	rWORD2, 8(rSTR2)
-#endif
-	cmplw	cr7, rWORD1, rWORD2
-	slwi.	r12, rN, 3
-	bne	cr1, L(dLcr1x)
-#ifndef __LITTLE_ENDIAN__
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#endif
-	bne	cr6, L(dLcr6x)
-	subfic	rN, r12, 32	/* Shift count is 32 - (rN * 8).  */
-	bne	cr7, L(dLcr7x)
-	addi	1, 1, 64
-	cfi_adjust_cfa_offset(-64)
-	bne	L(d00)
-	li	rRTN, 0
-	blr
-
-/* Count is a multiple of 16, remainder is 0 */
-	.align	4
-	cfi_adjust_cfa_offset(64)
-L(dP4):
-	mtctr	r0	/* Power4 wants mtctr 1st in dispatch group */
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD1, 0, rSTR1
-	lwbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD1, 0(rSTR1)
-	lwz	rWORD2, 0(rSTR2)
-#endif
-	cmplw	cr7, rWORD1, rWORD2
-L(dP4e):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD3, 0, rSTR1
-	lwbrx	rWORD4, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD3, 4(rSTR1)
-	lwz	rWORD4, 4(rSTR2)
-#endif
-	cmplw	cr1, rWORD3, rWORD4
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD5, 0, rSTR1
-	lwbrx	rWORD6, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD5, 8(rSTR1)
-	lwz	rWORD6, 8(rSTR2)
-#endif
-	cmplw	cr6, rWORD5, rWORD6
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD7, 0, rSTR1
-	lwbrx	rWORD8, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwzu	rWORD7, 12(rSTR1)
-	lwzu	rWORD8, 12(rSTR2)
-#endif
-	cmplw	cr5, rWORD7, rWORD8
-	bne	cr7, L(dLcr7)
-	bne	cr1, L(dLcr1)
-	bdz-	L(d24)		/* Adjust CTR as we start with +4 */
-/* This is the primary loop */
-	.align	4
-L(dLoop):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD1, 0, rSTR1
-	lwbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD1, 4(rSTR1)
-	lwz	rWORD2, 4(rSTR2)
-#endif
-	cmplw	cr1, rWORD3, rWORD4
-	bne	cr6, L(dLcr6)
-L(dLoop1):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD3, 0, rSTR1
-	lwbrx	rWORD4, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD3, 8(rSTR1)
-	lwz	rWORD4, 8(rSTR2)
-#endif
-	cmplw	cr6, rWORD5, rWORD6
-	bne	cr5, L(dLcr5)
-L(dLoop2):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD5, 0, rSTR1
-	lwbrx	rWORD6, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD5, 12(rSTR1)
-	lwz	rWORD6, 12(rSTR2)
-#endif
-	cmplw	cr5, rWORD7, rWORD8
-	bne	cr7, L(dLcr7)
-L(dLoop3):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD7, 0, rSTR1
-	lwbrx	rWORD8, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwzu	rWORD7, 16(rSTR1)
-	lwzu	rWORD8, 16(rSTR2)
-#endif
-	bne-	cr1, L(dLcr1)
-	cmplw	cr7, rWORD1, rWORD2
-	bdnz+	L(dLoop)
-
-L(dL4):
-	cmplw	cr1, rWORD3, rWORD4
-	bne	cr6, L(dLcr6)
-	cmplw	cr6, rWORD5, rWORD6
-	bne	cr5, L(dLcr5)
-	cmplw	cr5, rWORD7, rWORD8
-L(d44):
-	bne	cr7, L(dLcr7)
-L(d34):
-	bne	cr1, L(dLcr1)
-L(d24):
-	bne	cr6, L(dLcr6)
-L(d14):
-	slwi.	r12, rN, 3
-	bne	cr5, L(dLcr5)
-L(d04):
-	lwz	rWORD7, 44(r1)
-	lwz	rWORD8, 48(r1)
-	addi	1, 1, 64
-	cfi_adjust_cfa_offset(-64)
-	subfic	rN, r12, 32	/* Shift count is 32 - (rN * 8).  */
-	beq	L(zeroLength)
-/* At this point we have a remainder of 1 to 3 bytes to compare.  Since
-   we are aligned it is safe to load the whole word, and use
-   shift right to eliminate bits beyond the compare length.  */
-L(d00):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD1, 0, rSTR1
-	lwbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD1, 4(rSTR1)
-	lwz	rWORD2, 4(rSTR2)
-#endif
-	srw	rWORD1, rWORD1, rN
-	srw	rWORD2, rWORD2, rN
-	sub	rRTN, rWORD1, rWORD2
-	blr
-
-	.align	4
-	cfi_adjust_cfa_offset(64)
-L(dLcr7):
-	lwz	rWORD7, 44(r1)
-	lwz	rWORD8, 48(r1)
-L(dLcr7x):
-	li	rRTN, 1
-	addi	1, 1, 64
-	cfi_adjust_cfa_offset(-64)
-	bgtlr	cr7
-	li	rRTN, -1
-	blr
-	.align	4
-	cfi_adjust_cfa_offset(64)
-L(dLcr1):
-	lwz	rWORD7, 44(r1)
-	lwz	rWORD8, 48(r1)
-L(dLcr1x):
-	li	rRTN, 1
-	addi	1, 1, 64
-	cfi_adjust_cfa_offset(-64)
-	bgtlr	cr1
-	li	rRTN, -1
-	blr
-	.align	4
-	cfi_adjust_cfa_offset(64)
-L(dLcr6):
-	lwz	rWORD7, 44(r1)
-	lwz	rWORD8, 48(r1)
-L(dLcr6x):
-	li	rRTN, 1
-	addi	1, 1, 64
-	cfi_adjust_cfa_offset(-64)
-	bgtlr	cr6
-	li	rRTN, -1
-	blr
-	.align	4
-	cfi_adjust_cfa_offset(64)
-L(dLcr5):
-	lwz	rWORD7, 44(r1)
-	lwz	rWORD8, 48(r1)
-L(dLcr5x):
-	li	rRTN, 1
-	addi	1, 1, 64
-	cfi_adjust_cfa_offset(-64)
-	bgtlr	cr5
-	li	rRTN, -1
-	blr
-
-	.align	4
-L(bytealigned):
-	mtctr	rN	/* Power4 wants mtctr 1st in dispatch group */
-
-/* We need to prime this loop.  This loop is swing modulo scheduled
-   to avoid pipe delays.  The dependent instruction latencies (load to
-   compare to conditional branch) is 2 to 3 cycles.  In this loop each
-   dispatch group ends in a branch and takes 1 cycle.  Effectively
-   the first iteration of the loop only serves to load operands and
-   branches based on compares are delayed until the next loop.
-
-   So we must precondition some registers and condition codes so that
-   we don't exit the loop early on the first iteration.  */
-
-	lbz	rWORD1, 0(rSTR1)
-	lbz	rWORD2, 0(rSTR2)
-	bdz-	L(b11)
-	cmplw	cr7, rWORD1, rWORD2
-	lbz	rWORD3, 1(rSTR1)
-	lbz	rWORD4, 1(rSTR2)
-	bdz-	L(b12)
-	cmplw	cr1, rWORD3, rWORD4
-	lbzu	rWORD5, 2(rSTR1)
-	lbzu	rWORD6, 2(rSTR2)
-	bdz-	L(b13)
-	.align	4
-L(bLoop):
-	lbzu	rWORD1, 1(rSTR1)
-	lbzu	rWORD2, 1(rSTR2)
-	bne-	cr7, L(bLcr7)
-
-	cmplw	cr6, rWORD5, rWORD6
-	bdz-	L(b3i)
-
-	lbzu	rWORD3, 1(rSTR1)
-	lbzu	rWORD4, 1(rSTR2)
-	bne-	cr1, L(bLcr1)
-
-	cmplw	cr7, rWORD1, rWORD2
-	bdz-	L(b2i)
-
-	lbzu	rWORD5, 1(rSTR1)
-	lbzu	rWORD6, 1(rSTR2)
-	bne-	cr6, L(bLcr6)
-
-	cmplw	cr1, rWORD3, rWORD4
-	bdnz+	L(bLoop)
-
-/* We speculatively loading bytes before we have tested the previous
-   bytes.  But we must avoid overrunning the length (in the ctr) to
-   prevent these speculative loads from causing a segfault.  In this
-   case the loop will exit early (before the all pending bytes are
-   tested.  In this case we must complete the pending operations
-   before returning.  */
-L(b1i):
-	bne-	cr7, L(bLcr7)
-	bne-	cr1, L(bLcr1)
-	b	L(bx56)
-	.align	4
-L(b2i):
-	bne-	cr6, L(bLcr6)
-	bne-	cr7, L(bLcr7)
-	b	L(bx34)
-	.align	4
-L(b3i):
-	bne-	cr1, L(bLcr1)
-	bne-	cr6, L(bLcr6)
-	b	L(bx12)
-	.align	4
-L(bLcr7):
-	li	rRTN, 1
-	bgtlr	cr7
-	li	rRTN, -1
-	blr
-L(bLcr1):
-	li	rRTN, 1
-	bgtlr	cr1
-	li	rRTN, -1
-	blr
-L(bLcr6):
-	li	rRTN, 1
-	bgtlr	cr6
-	li	rRTN, -1
-	blr
-
-L(b13):
-	bne-	cr7, L(bx12)
-	bne-	cr1, L(bx34)
-L(bx56):
-	sub	rRTN, rWORD5, rWORD6
-	blr
-	nop
-L(b12):
-	bne-	cr7, L(bx12)
-L(bx34):
-	sub	rRTN, rWORD3, rWORD4
-	blr
-L(b11):
-L(bx12):
-	sub	rRTN, rWORD1, rWORD2
-	blr
-	.align	4
-L(zeroLength):
-	li	rRTN, 0
-	blr
-
-	.align	4
-/* At this point we know the strings have different alignment and the
-   compare length is at least 8 bytes.  r12 contains the low order
-   2 bits of rSTR1 and cr5 contains the result of the logical compare
-   of r12 to 0.  If r12 == 0 then rStr1 is word aligned and can
-   perform the Wunaligned loop.
-
-   Otherwise we know that rSTR1 is not already word aligned yet.
-   So we can force the string addresses to the next lower word
-   boundary and special case this first word using shift left to
-   eliminate bits preceding the first byte.  Since we want to join the
-   normal (Wualigned) compare loop, starting at the second word,
-   we need to adjust the length (rN) and special case the loop
-   versioning for the first W. This ensures that the loop count is
-   correct and the first W (shifted) is in the expected resister pair.  */
-#define rSHL		r29	/* Unaligned shift left count.  */
-#define rSHR		r28	/* Unaligned shift right count.  */
-#define rWORD8_SHIFT	r27	/* Left rotation temp for rWORD2.  */
-#define rWORD2_SHIFT	r26	/* Left rotation temp for rWORD4.  */
-#define rWORD4_SHIFT	r25	/* Left rotation temp for rWORD6.  */
-#define rWORD6_SHIFT	r24	/* Left rotation temp for rWORD8.  */
-	cfi_adjust_cfa_offset(64)
-L(unaligned):
-	stw	rSHL, 40(r1)
-	cfi_offset(rSHL, (40-64))
-	clrlwi	rSHL, rSTR2, 30
-	stw	rSHR, 36(r1)
-	cfi_offset(rSHR, (36-64))
-	beq	cr5, L(Wunaligned)
-	stw	rWORD8_SHIFT, 32(r1)
-	cfi_offset(rWORD8_SHIFT, (32-64))
-/* Adjust the logical start of rSTR2 to compensate for the extra bits
-   in the 1st rSTR1 W.  */
-	sub	rWORD8_SHIFT, rSTR2, r12
-/* But do not attempt to address the W before that W that contains
-   the actual start of rSTR2.  */
-	clrrwi	rSTR2, rSTR2, 2
-	stw	rWORD2_SHIFT, 28(r1)
-/* Compute the left/right shift counts for the unaligned rSTR2,
-   compensating for the logical (W aligned) start of rSTR1.  */
-	clrlwi	rSHL, rWORD8_SHIFT, 30
-	clrrwi	rSTR1, rSTR1, 2
-	stw	rWORD4_SHIFT, 24(r1)
-	slwi	rSHL, rSHL, 3
-	cmplw	cr5, rWORD8_SHIFT, rSTR2
-	add	rN, rN, r12
-	slwi	rWORD6, r12, 3
-	stw	rWORD6_SHIFT, 20(r1)
-	cfi_offset(rWORD2_SHIFT, (28-64))
-	cfi_offset(rWORD4_SHIFT, (24-64))
-	cfi_offset(rWORD6_SHIFT, (20-64))
-	subfic	rSHR, rSHL, 32
-	srwi	r0, rN, 4	/* Divide by 16 */
-	andi.	r12, rN, 12	/* Get the W remainder */
-/* We normally need to load 2 Ws to start the unaligned rSTR2, but in
-   this special case those bits may be discarded anyway.  Also we
-   must avoid loading a W where none of the bits are part of rSTR2 as
-   this may cross a page boundary and cause a page fault.  */
-	li	rWORD8, 0
-	blt	cr5, L(dus0)
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD8, 0, rSTR2
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD8, 0(rSTR2)
-	addi	rSTR2, rSTR2, 4
-#endif
-	slw	rWORD8, rWORD8, rSHL
-
-L(dus0):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD1, 0, rSTR1
-	lwbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD1, 0(rSTR1)
-	lwz	rWORD2, 0(rSTR2)
-#endif
-	cmplwi	cr1, r12, 8
-	cmplwi	cr7, rN, 16
-	srw	r12, rWORD2, rSHR
-	clrlwi	rN, rN, 30
-	beq	L(duPs4)
-	mtctr	r0	/* Power4 wants mtctr 1st in dispatch group */
-	or	rWORD8, r12, rWORD8
-	bgt	cr1, L(duPs3)
-	beq	cr1, L(duPs2)
-
-/* Remainder is 4 */
-	.align	4
-L(dusP1):
-	slw	rWORD8_SHIFT, rWORD2, rSHL
-	slw	rWORD7, rWORD1, rWORD6
-	slw	rWORD8, rWORD8, rWORD6
-	bge	cr7, L(duP1e)
-/* At this point we exit early with the first word compare
-   complete and remainder of 0 to 3 bytes.  See L(du14) for details on
-   how we handle the remaining bytes.  */
-	cmplw	cr5, rWORD7, rWORD8
-	slwi.	rN, rN, 3
-	bne	cr5, L(duLcr5)
-	cmplw	cr7, rN, rSHR
-	beq	L(duZeroReturn)
-	li	r0, 0
-	ble	cr7, L(dutrim)
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD2, 0, rSTR2
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD2, 4(rSTR2)
-#endif
-	srw	r0, rWORD2, rSHR
-	b	L(dutrim)
-/* Remainder is 8 */
-	.align	4
-L(duPs2):
-	slw	rWORD6_SHIFT, rWORD2, rSHL
-	slw	rWORD5, rWORD1, rWORD6
-	slw	rWORD6, rWORD8, rWORD6
-	b	L(duP2e)
-/* Remainder is 12 */
-	.align	4
-L(duPs3):
-	slw	rWORD4_SHIFT, rWORD2, rSHL
-	slw	rWORD3, rWORD1, rWORD6
-	slw	rWORD4, rWORD8, rWORD6
-	b	L(duP3e)
-/* Count is a multiple of 16, remainder is 0 */
-	.align	4
-L(duPs4):
-	mtctr	r0	/* Power4 wants mtctr 1st in dispatch group */
-	or	rWORD8, r12, rWORD8
-	slw	rWORD2_SHIFT, rWORD2, rSHL
-	slw	rWORD1, rWORD1, rWORD6
-	slw	rWORD2, rWORD8, rWORD6
-	b	L(duP4e)
-
-/* At this point we know rSTR1 is word aligned and the
-   compare length is at least 8 bytes.  */
-	.align	4
-L(Wunaligned):
-	stw	rWORD8_SHIFT, 32(r1)
-	clrrwi	rSTR2, rSTR2, 2
-	stw	rWORD2_SHIFT, 28(r1)
-	srwi	r0, rN, 4	/* Divide by 16 */
-	stw	rWORD4_SHIFT, 24(r1)
-	andi.	r12, rN, 12	/* Get the W remainder */
-	stw	rWORD6_SHIFT, 20(r1)
-	cfi_offset(rWORD8_SHIFT, (32-64))
-	cfi_offset(rWORD2_SHIFT, (28-64))
-	cfi_offset(rWORD4_SHIFT, (24-64))
-	cfi_offset(rWORD6_SHIFT, (20-64))
-	slwi	rSHL, rSHL, 3
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD6, 0, rSTR2
-	addi	rSTR2, rSTR2, 4
-	lwbrx	rWORD8, 0, rSTR2
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD6, 0(rSTR2)
-	lwzu	rWORD8, 4(rSTR2)
-#endif
-	cmplwi	cr1, r12, 8
-	cmplwi	cr7, rN, 16
-	clrlwi	rN, rN, 30
-	subfic	rSHR, rSHL, 32
-	slw	rWORD6_SHIFT, rWORD6, rSHL
-	beq	L(duP4)
-	mtctr	r0	/* Power4 wants mtctr 1st in dispatch group */
-	bgt	cr1, L(duP3)
-	beq	cr1, L(duP2)
-
-/* Remainder is 4 */
-	.align	4
-L(duP1):
-	srw	r12, rWORD8, rSHR
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD7, 0, rSTR1
-	addi	rSTR1, rSTR1, 4
-#else
-	lwz	rWORD7, 0(rSTR1)
-#endif
-	slw	rWORD8_SHIFT, rWORD8, rSHL
-	or	rWORD8, r12, rWORD6_SHIFT
-	blt	cr7, L(duP1x)
-L(duP1e):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD1, 0, rSTR1
-	lwbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD1, 4(rSTR1)
-	lwz	rWORD2, 4(rSTR2)
-#endif
-	cmplw	cr5, rWORD7, rWORD8
-	srw	r0, rWORD2, rSHR
-	slw	rWORD2_SHIFT, rWORD2, rSHL
-	or	rWORD2, r0, rWORD8_SHIFT
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD3, 0, rSTR1
-	lwbrx	rWORD4, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD3, 8(rSTR1)
-	lwz	rWORD4, 8(rSTR2)
-#endif
-	cmplw	cr7, rWORD1, rWORD2
-	srw	r12, rWORD4, rSHR
-	slw	rWORD4_SHIFT, rWORD4, rSHL
-	bne	cr5, L(duLcr5)
-	or	rWORD4, r12, rWORD2_SHIFT
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD5, 0, rSTR1
-	lwbrx	rWORD6, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD5, 12(rSTR1)
-	lwz	rWORD6, 12(rSTR2)
-#endif
-	cmplw	cr1, rWORD3, rWORD4
-	srw	r0, rWORD6, rSHR
-	slw	rWORD6_SHIFT, rWORD6, rSHL
-	bne	cr7, L(duLcr7)
-	or	rWORD6, r0, rWORD4_SHIFT
-	cmplw	cr6, rWORD5, rWORD6
-	b	L(duLoop3)
-	.align	4
-/* At this point we exit early with the first word compare
-   complete and remainder of 0 to 3 bytes.  See L(du14) for details on
-   how we handle the remaining bytes.  */
-L(duP1x):
-	cmplw	cr5, rWORD7, rWORD8
-	slwi.	rN, rN, 3
-	bne	cr5, L(duLcr5)
-	cmplw	cr7, rN, rSHR
-	beq	L(duZeroReturn)
-	li	r0, 0
-	ble	cr7, L(dutrim)
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD2, 0, rSTR2
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD2, 8(rSTR2)
-#endif
-	srw	r0, rWORD2, rSHR
-	b	L(dutrim)
-/* Remainder is 8 */
-	.align	4
-L(duP2):
-	srw	r0, rWORD8, rSHR
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD5, 0, rSTR1
-	addi	rSTR1, rSTR1, 4
-#else
-	lwz	rWORD5, 0(rSTR1)
-#endif
-	or	rWORD6, r0, rWORD6_SHIFT
-	slw	rWORD6_SHIFT, rWORD8, rSHL
-L(duP2e):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD7, 0, rSTR1
-	lwbrx	rWORD8, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD7, 4(rSTR1)
-	lwz	rWORD8, 4(rSTR2)
-#endif
-	cmplw	cr6, rWORD5, rWORD6
-	srw	r12, rWORD8, rSHR
-	slw	rWORD8_SHIFT, rWORD8, rSHL
-	or	rWORD8, r12, rWORD6_SHIFT
-	blt	cr7, L(duP2x)
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD1, 0, rSTR1
-	lwbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD1, 8(rSTR1)
-	lwz	rWORD2, 8(rSTR2)
-#endif
-	cmplw	cr5, rWORD7, rWORD8
-	bne	cr6, L(duLcr6)
-	srw	r0, rWORD2, rSHR
-	slw	rWORD2_SHIFT, rWORD2, rSHL
-	or	rWORD2, r0, rWORD8_SHIFT
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD3, 0, rSTR1
-	lwbrx	rWORD4, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD3, 12(rSTR1)
-	lwz	rWORD4, 12(rSTR2)
-#endif
-	cmplw	cr7, rWORD1, rWORD2
-	bne	cr5, L(duLcr5)
-	srw	r12, rWORD4, rSHR
-	slw	rWORD4_SHIFT, rWORD4, rSHL
-	or	rWORD4, r12, rWORD2_SHIFT
-#ifndef __LITTLE_ENDIAN__
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#endif
-	cmplw	cr1, rWORD3, rWORD4
-	b	L(duLoop2)
-	.align	4
-L(duP2x):
-	cmplw	cr5, rWORD7, rWORD8
-#ifndef __LITTLE_ENDIAN__
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#endif
-	bne	cr6, L(duLcr6)
-	slwi.	rN, rN, 3
-	bne	cr5, L(duLcr5)
-	cmplw	cr7, rN, rSHR
-	beq	L(duZeroReturn)
-	li	r0, 0
-	ble	cr7, L(dutrim)
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD2, 0, rSTR2
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD2, 4(rSTR2)
-#endif
-	srw	r0, rWORD2, rSHR
-	b	L(dutrim)
-
-/* Remainder is 12 */
-	.align	4
-L(duP3):
-	srw	r12, rWORD8, rSHR
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD3, 0, rSTR1
-	addi	rSTR1, rSTR1, 4
-#else
-	lwz	rWORD3, 0(rSTR1)
-#endif
-	slw	rWORD4_SHIFT, rWORD8, rSHL
-	or	rWORD4, r12, rWORD6_SHIFT
-L(duP3e):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD5, 0, rSTR1
-	lwbrx	rWORD6, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD5, 4(rSTR1)
-	lwz	rWORD6, 4(rSTR2)
-#endif
-	cmplw	cr1, rWORD3, rWORD4
-	srw	r0, rWORD6, rSHR
-	slw	rWORD6_SHIFT, rWORD6, rSHL
-	or	rWORD6, r0, rWORD4_SHIFT
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD7, 0, rSTR1
-	lwbrx	rWORD8, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD7, 8(rSTR1)
-	lwz	rWORD8, 8(rSTR2)
-#endif
-	cmplw	cr6, rWORD5, rWORD6
-	bne	cr1, L(duLcr1)
-	srw	r12, rWORD8, rSHR
-	slw	rWORD8_SHIFT, rWORD8, rSHL
-	or	rWORD8, r12, rWORD6_SHIFT
-	blt	cr7, L(duP3x)
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD1, 0, rSTR1
-	lwbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD1, 12(rSTR1)
-	lwz	rWORD2, 12(rSTR2)
-#endif
-	cmplw	cr5, rWORD7, rWORD8
-	bne	cr6, L(duLcr6)
-	srw	r0, rWORD2, rSHR
-	slw	rWORD2_SHIFT, rWORD2, rSHL
-	or	rWORD2, r0, rWORD8_SHIFT
-#ifndef __LITTLE_ENDIAN__
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#endif
-	cmplw	cr7, rWORD1, rWORD2
-	b	L(duLoop1)
-	.align	4
-L(duP3x):
-#ifndef __LITTLE_ENDIAN__
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#endif
-#if 0
-/* Huh?  We've already branched on cr1!  */
-	bne	cr1, L(duLcr1)
-#endif
-	cmplw	cr5, rWORD7, rWORD8
-	bne	cr6, L(duLcr6)
-	slwi.	rN, rN, 3
-	bne	cr5, L(duLcr5)
-	cmplw	cr7, rN, rSHR
-	beq	L(duZeroReturn)
-	li	r0, 0
-	ble	cr7, L(dutrim)
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD2, 0, rSTR2
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD2, 4(rSTR2)
-#endif
-	srw	r0, rWORD2, rSHR
-	b	L(dutrim)
-
-/* Count is a multiple of 16, remainder is 0 */
-	.align	4
-L(duP4):
-	mtctr	r0	/* Power4 wants mtctr 1st in dispatch group */
-	srw	r0, rWORD8, rSHR
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD1, 0, rSTR1
-	addi	rSTR1, rSTR1, 4
-#else
-	lwz	rWORD1, 0(rSTR1)
-#endif
-	slw	rWORD2_SHIFT, rWORD8, rSHL
-	or	rWORD2, r0, rWORD6_SHIFT
-L(duP4e):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD3, 0, rSTR1
-	lwbrx	rWORD4, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD3, 4(rSTR1)
-	lwz	rWORD4, 4(rSTR2)
-#endif
-	cmplw	cr7, rWORD1, rWORD2
-	srw	r12, rWORD4, rSHR
-	slw	rWORD4_SHIFT, rWORD4, rSHL
-	or	rWORD4, r12, rWORD2_SHIFT
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD5, 0, rSTR1
-	lwbrx	rWORD6, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD5, 8(rSTR1)
-	lwz	rWORD6, 8(rSTR2)
-#endif
-	cmplw	cr1, rWORD3, rWORD4
-	bne	cr7, L(duLcr7)
-	srw	r0, rWORD6, rSHR
-	slw	rWORD6_SHIFT, rWORD6, rSHL
-	or	rWORD6, r0, rWORD4_SHIFT
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD7, 0, rSTR1
-	lwbrx	rWORD8, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwzu	rWORD7, 12(rSTR1)
-	lwzu	rWORD8, 12(rSTR2)
-#endif
-	cmplw	cr6, rWORD5, rWORD6
-	bne	cr1, L(duLcr1)
-	srw	r12, rWORD8, rSHR
-	slw	rWORD8_SHIFT, rWORD8, rSHL
-	or	rWORD8, r12, rWORD6_SHIFT
-	cmplw	cr5, rWORD7, rWORD8
-	bdz-	L(du24)		/* Adjust CTR as we start with +4 */
-/* This is the primary loop */
-	.align	4
-L(duLoop):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD1, 0, rSTR1
-	lwbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD1, 4(rSTR1)
-	lwz	rWORD2, 4(rSTR2)
-#endif
-	cmplw	cr1, rWORD3, rWORD4
-	bne	cr6, L(duLcr6)
-	srw	r0, rWORD2, rSHR
-	slw	rWORD2_SHIFT, rWORD2, rSHL
-	or	rWORD2, r0, rWORD8_SHIFT
-L(duLoop1):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD3, 0, rSTR1
-	lwbrx	rWORD4, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD3, 8(rSTR1)
-	lwz	rWORD4, 8(rSTR2)
-#endif
-	cmplw	cr6, rWORD5, rWORD6
-	bne	cr5, L(duLcr5)
-	srw	r12, rWORD4, rSHR
-	slw	rWORD4_SHIFT, rWORD4, rSHL
-	or	rWORD4, r12, rWORD2_SHIFT
-L(duLoop2):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD5, 0, rSTR1
-	lwbrx	rWORD6, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD5, 12(rSTR1)
-	lwz	rWORD6, 12(rSTR2)
-#endif
-	cmplw	cr5, rWORD7, rWORD8
-	bne	cr7, L(duLcr7)
-	srw	r0, rWORD6, rSHR
-	slw	rWORD6_SHIFT, rWORD6, rSHL
-	or	rWORD6, r0, rWORD4_SHIFT
-L(duLoop3):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD7, 0, rSTR1
-	lwbrx	rWORD8, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwzu	rWORD7, 16(rSTR1)
-	lwzu	rWORD8, 16(rSTR2)
-#endif
-	cmplw	cr7, rWORD1, rWORD2
-	bne-	cr1, L(duLcr1)
-	srw	r12, rWORD8, rSHR
-	slw	rWORD8_SHIFT, rWORD8, rSHL
-	or	rWORD8, r12, rWORD6_SHIFT
-	bdnz+	L(duLoop)
-
-L(duL4):
-#if 0
-/* Huh?  We've already branched on cr1!  */
-	bne	cr1, L(duLcr1)
-#endif
-	cmplw	cr1, rWORD3, rWORD4
-	bne	cr6, L(duLcr6)
-	cmplw	cr6, rWORD5, rWORD6
-	bne	cr5, L(duLcr5)
-	cmplw	cr5, rWORD7, rWORD8
-L(du44):
-	bne	cr7, L(duLcr7)
-L(du34):
-	bne	cr1, L(duLcr1)
-L(du24):
-	bne	cr6, L(duLcr6)
-L(du14):
-	slwi.	rN, rN, 3
-	bne	cr5, L(duLcr5)
-/* At this point we have a remainder of 1 to 3 bytes to compare.  We use
-   shift right to eliminate bits beyond the compare length.
-   This allows the use of word subtract to compute the final result.
-
-   However it may not be safe to load rWORD2 which may be beyond the
-   string length. So we compare the bit length of the remainder to
-   the right shift count (rSHR). If the bit count is less than or equal
-   we do not need to load rWORD2 (all significant bits are already in
-   rWORD8_SHIFT).  */
-	cmplw	cr7, rN, rSHR
-	beq	L(duZeroReturn)
-	li	r0, 0
-	ble	cr7, L(dutrim)
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD2, 0, rSTR2
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD2, 4(rSTR2)
-#endif
-	srw	r0, rWORD2, rSHR
-	.align	4
-L(dutrim):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD1, 0, rSTR1
-#else
-	lwz	rWORD1, 4(rSTR1)
-#endif
-	lwz	rWORD8, 48(r1)
-	subfic	rN, rN, 32	/* Shift count is 32 - (rN * 8).  */
-	or	rWORD2, r0, rWORD8_SHIFT
-	lwz	rWORD7, 44(r1)
-	lwz	rSHL, 40(r1)
-	srw	rWORD1, rWORD1, rN
-	srw	rWORD2, rWORD2, rN
-	lwz	rSHR, 36(r1)
-	lwz	rWORD8_SHIFT, 32(r1)
-	sub	rRTN, rWORD1, rWORD2
-	b	L(dureturn26)
-	.align	4
-L(duLcr7):
-	lwz	rWORD8, 48(r1)
-	lwz	rWORD7, 44(r1)
-	li	rRTN, 1
-	bgt	cr7, L(dureturn29)
-	lwz	rSHL, 40(r1)
-	lwz	rSHR, 36(r1)
-	li	rRTN, -1
-	b	L(dureturn27)
-	.align	4
-L(duLcr1):
-	lwz	rWORD8, 48(r1)
-	lwz	rWORD7, 44(r1)
-	li	rRTN, 1
-	bgt	cr1, L(dureturn29)
-	lwz	rSHL, 40(r1)
-	lwz	rSHR, 36(r1)
-	li	rRTN, -1
-	b	L(dureturn27)
-	.align	4
-L(duLcr6):
-	lwz	rWORD8, 48(r1)
-	lwz	rWORD7, 44(r1)
-	li	rRTN, 1
-	bgt	cr6, L(dureturn29)
-	lwz	rSHL, 40(r1)
-	lwz	rSHR, 36(r1)
-	li	rRTN, -1
-	b	L(dureturn27)
-	.align	4
-L(duLcr5):
-	lwz	rWORD8, 48(r1)
-	lwz	rWORD7, 44(r1)
-	li	rRTN, 1
-	bgt	cr5, L(dureturn29)
-	lwz	rSHL, 40(r1)
-	lwz	rSHR, 36(r1)
-	li	rRTN, -1
-	b	L(dureturn27)
-	.align	3
-L(duZeroReturn):
-	li	rRTN, 0
-	.align	4
-L(dureturn):
-	lwz	rWORD8, 48(r1)
-	lwz	rWORD7, 44(r1)
-L(dureturn29):
-	lwz	rSHL, 40(r1)
-	lwz	rSHR, 36(r1)
-L(dureturn27):
-	lwz	rWORD8_SHIFT, 32(r1)
-L(dureturn26):
-	lwz	rWORD2_SHIFT, 28(r1)
-L(dureturn25):
-	lwz	rWORD4_SHIFT, 24(r1)
-	lwz	rWORD6_SHIFT, 20(r1)
-	addi	1, 1, 64
-	cfi_adjust_cfa_offset(-64)
-	blr
-END (memcmp)
-
-libc_hidden_builtin_def (memcmp)
-weak_alias (memcmp, bcmp)
diff --git a/sysdeps/powerpc/powerpc32/power4/memcopy.h b/sysdeps/powerpc/powerpc32/power4/memcopy.h
deleted file mode 100644
index 8050abc..0000000
--- a/sysdeps/powerpc/powerpc32/power4/memcopy.h
+++ /dev/null
@@ -1,116 +0,0 @@
-/* memcopy.h -- definitions for memory copy functions.  Generic C version.
-   Copyright (C) 1991-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-   Contributed by Torbjorn Granlund (tege@sics.se).
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-/* The strategy of the memory functions is:
-
-     1. Copy bytes until the destination pointer is aligned.
-
-     2. Copy words in unrolled loops.  If the source and destination
-     are not aligned in the same way, use word memory operations,
-     but shift and merge two read words before writing.
-
-     3. Copy the few remaining bytes.
-
-   This is fast on processors that have at least 10 registers for
-   allocation by GCC, and that can access memory at reg+const in one
-   instruction.
-
-   I made an "exhaustive" test of this memmove when I wrote it,
-   exhaustive in the sense that I tried all alignment and length
-   combinations, with and without overlap.  */
-
-#include <sysdeps/generic/memcopy.h>
-
-/* The macros defined in this file are:
-
-   BYTE_COPY_FWD(dst_beg_ptr, src_beg_ptr, nbytes_to_copy)
-
-   BYTE_COPY_BWD(dst_end_ptr, src_end_ptr, nbytes_to_copy)
-
-   WORD_COPY_FWD(dst_beg_ptr, src_beg_ptr, nbytes_remaining, nbytes_to_copy)
-
-   WORD_COPY_BWD(dst_end_ptr, src_end_ptr, nbytes_remaining, nbytes_to_copy)
-
-   MERGE(old_word, sh_1, new_word, sh_2)
-     [I fail to understand.  I feel stupid.  --roland]
-*/
-
-
-/* Threshold value for when to enter the unrolled loops.  */
-#undef	OP_T_THRES
-#define OP_T_THRES 16
-
-/* Copy exactly NBYTES bytes from SRC_BP to DST_BP,
-   without any assumptions about alignment of the pointers.  */
-#undef BYTE_COPY_FWD
-#define BYTE_COPY_FWD(dst_bp, src_bp, nbytes)				      \
-  do									      \
-    {									      \
-      size_t __nbytes = (nbytes);					      \
-      if (__nbytes & 1)							      \
-        {								      \
-	  ((byte *) dst_bp)[0] =  ((byte *) src_bp)[0];			      \
-	  src_bp += 1;							      \
-	  dst_bp += 1;							      \
-	  __nbytes -= 1;						      \
-        }								      \
-      while (__nbytes > 0)						      \
-	{								      \
-	  byte __x = ((byte *) src_bp)[0];				      \
-	  byte __y = ((byte *) src_bp)[1];				      \
-	  src_bp += 2;							      \
-	  __nbytes -= 2;						      \
-	  ((byte *) dst_bp)[0] = __x;					      \
-	  ((byte *) dst_bp)[1] = __y;					      \
-	  dst_bp += 2;							      \
-	}								      \
-    } while (0)
-
-/* Copy exactly NBYTES_TO_COPY bytes from SRC_END_PTR to DST_END_PTR,
-   beginning at the bytes right before the pointers and continuing towards
-   smaller addresses.  Don't assume anything about alignment of the
-   pointers.  */
-#undef BYTE_COPY_BWD
-#define BYTE_COPY_BWD(dst_ep, src_ep, nbytes)				      \
-  do									      \
-    {									      \
-      size_t __nbytes = (nbytes);					      \
-      if (__nbytes & 1)							      \
-        {								      \
-	  src_ep -= 1;							      \
-	  dst_ep -= 1;							      \
-	  ((byte *) dst_ep)[0] =  ((byte *) src_ep)[0];			      \
-	  __nbytes -= 1;						      \
-        }								      \
-      while (__nbytes > 0)						      \
-	{								      \
-	  byte __x, __y;						      \
-	  src_ep -= 2;							      \
-	  __y = ((byte *) src_ep)[1];					      \
-	  __x = ((byte *) src_ep)[0];					      \
-	  dst_ep -= 2;							      \
-	  __nbytes -= 2;						      \
-	  ((byte *) dst_ep)[1] = __y;					      \
-	  ((byte *) dst_ep)[0] = __x;					      \
-	}								      \
-    } while (0)
-
-/* The powerpc memcpy implementation is safe to use for memmove.  */
-#undef MEMCPY_OK_FOR_FWD_MEMMOVE
-#define MEMCPY_OK_FOR_FWD_MEMMOVE 1
diff --git a/sysdeps/powerpc/powerpc32/power4/memcpy.S b/sysdeps/powerpc/powerpc32/power4/memcpy.S
deleted file mode 100644
index 44866d6..0000000
--- a/sysdeps/powerpc/powerpc32/power4/memcpy.S
+++ /dev/null
@@ -1,481 +0,0 @@
-/* Optimized memcpy implementation for PowerPC32 on PowerPC64.
-   Copyright (C) 2003-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* void * [r3] memcpy (void *dst [r3], void *src [r4], size_t len [r5]);
-   Returns 'dst'.
-
-   Memcpy handles short copies (< 32-bytes) using a binary move blocks
-   (no loops) of lwz/stw.  The tail (remaining 1-3) bytes is handled
-   with the appropriate combination of byte and halfword load/stores.
-   There is minimal effort to optimize the alignment of short moves.
-
-   Longer moves (>= 32-bytes) justify the effort to get at least the
-   destination word (4-byte) aligned.  Further optimization is
-   possible when both source and destination are word aligned.
-   Each case has an optimized unrolled loop.   */
-
-	.machine power4
-EALIGN (memcpy, 5, 0)
-	CALL_MCOUNT
-
-    stwu  1,-32(1)
-    cfi_adjust_cfa_offset(32)
-    stw   30,20(1)
-    cfi_offset(30,(20-32))
-    mr    30,3
-    cmplwi cr1,5,31
-    stw   31,24(1)
-    cfi_offset(31,(24-32))
-    neg   0,3
-    andi. 11,3,3	/* check alignment of dst.  */
-    clrlwi 0,0,30	/* Number of bytes until the 1st word of dst.  */
-    clrlwi 10,4,30	/* check alignment of src.  */
-    cmplwi cr6,5,8
-    ble-  cr1,.L2	/* If move < 32 bytes use short move code.  */
-    cmplw cr6,10,11
-    mr    12,4
-    srwi  9,5,2		/* Number of full words remaining.  */
-    mtcrf 0x01,0
-    mr    31,5
-    beq   .L0
-
-    subf  31,0,5
-  /* Move 0-3 bytes as needed to get the destination word aligned.  */
-1:  bf    31,2f
-    lbz   6,0(12)
-    addi  12,12,1
-    stb   6,0(3)
-    addi  3,3,1
-2:  bf    30,0f
-    lhz   6,0(12)
-    addi  12,12,2
-    sth   6,0(3)
-    addi  3,3,2
-0:
-    clrlwi 10,12,30	/* check alignment of src again.  */
-    srwi  9,31,2	/* Number of full words remaining.  */
-
-  /* Copy words from source to destination, assuming the destination is
-     aligned on a word boundary.
-
-     At this point we know there are at least 25 bytes left (32-7) to copy.
-     The next step is to determine if the source is also word aligned.
-     If not branch to the unaligned move code at .L6. which uses
-     a load, shift, store strategy.
-
-     Otherwise source and destination are word aligned, and we can use
-     the optimized word copy loop.  */
-.L0:
-    clrlwi	11,31,30  /* calculate the number of tail bytes */
-    mtcrf 0x01,9
-    bne-  cr6,.L6   /* If source is not word aligned.  */
-
-  /* Move words where destination and source are word aligned.
-     Use an unrolled loop to copy 4 words (16-bytes) per iteration.
-     If the copy is not an exact multiple of 16 bytes, 1-3
-     words are copied as needed to set up the main loop.  After
-     the main loop exits there may be a tail of 1-3 bytes. These bytes are
-     copied a halfword/byte at a time as needed to preserve alignment.  */
-
-    srwi  8,31,4    /* calculate the 16 byte loop count */
-    cmplwi	cr1,9,4
-    cmplwi	cr6,11,0
-    mr    11,12
-
-    bf    30,1f
-    lwz   6,0(12)
-    lwz   7,4(12)
-    addi  11,12,8
-    mtctr 8
-    stw   6,0(3)
-    stw   7,4(3)
-    addi  10,3,8
-    bf    31,4f
-    lwz   0,8(12)
-    stw   0,8(3)
-    blt   cr1,3f
-    addi  11,12,12
-    addi  10,3,12
-    b     4f
-    .align  4
-1:
-    mr    10,3
-    mtctr 8
-    bf    31,4f
-    lwz   6,0(12)
-    addi  11,12,4
-    stw   6,0(3)
-    addi  10,3,4
-
-    .align  4
-4:
-    lwz   6,0(11)
-    lwz   7,4(11)
-    lwz   8,8(11)
-    lwz   0,12(11)
-    stw   6,0(10)
-    stw   7,4(10)
-    stw   8,8(10)
-    stw   0,12(10)
-    addi  11,11,16
-    addi  10,10,16
-    bdnz  4b
-3:
-    clrrwi 0,31,2
-    mtcrf 0x01,31
-    beq   cr6,0f
-.L9:
-    add   3,3,0
-    add   12,12,0
-
-/*  At this point we have a tail of 0-3 bytes and we know that the
-    destination is word aligned.  */
-2:  bf    30,1f
-    lhz   6,0(12)
-    addi  12,12,2
-    sth   6,0(3)
-    addi  3,3,2
-1:  bf    31,0f
-    lbz   6,0(12)
-    stb   6,0(3)
-0:
-  /* Return original dst pointer.  */
-    mr  3,30
-    lwz 30,20(1)
-    lwz 31,24(1)
-    addi 1,1,32
-    blr
-
-/* Copy up to 31 bytes.  This is divided into two cases 0-8 bytes and
-   9-31 bytes.  Each case is handled without loops, using binary
-   (1,2,4,8) tests.
-
-   In the short (0-8 byte) case no attempt is made to force alignment
-   of either source or destination.  The hardware will handle the
-   unaligned load/stores with small delays for crossing 32- 64-byte, and
-   4096-byte boundaries. Since these short moves are unlikely to be
-   unaligned or cross these boundaries, the overhead to force
-   alignment is not justified.
-
-   The longer (9-31 byte) move is more likely to cross 32- or 64-byte
-   boundaries.  Since only loads are sensitive to the 32-/64-byte
-   boundaries it is more important to align the source than the
-   destination.  If the source is not already word aligned, we first
-   move 1-3 bytes as needed.  While the destination and stores may
-   still be unaligned, this is only an issue for page (4096 byte
-   boundary) crossing, which should be rare for these short moves.
-   The hardware handles this case automatically with a small delay.  */
-
-    .align  4
-.L2:
-    mtcrf 0x01,5
-    neg   8,4
-    clrrwi 11,4,2
-    andi. 0,8,3
-    ble   cr6,.LE8	/* Handle moves of 0-8 bytes.  */
-/* At least 9 bytes left.  Get the source word aligned.  */
-    cmplwi	cr1,5,16
-    mr    10,5
-    mr    12,4
-    cmplwi	cr6,0,2
-    beq   .L3	/* If the source is already word aligned skip this.  */
-/* Copy 1-3 bytes to get source address word aligned.  */
-    lwz   6,0(11)
-    subf  10,0,5
-    add   12,4,0
-    blt   cr6,5f
-    srwi  7,6,16
-    bgt	  cr6,3f
-#ifdef __LITTLE_ENDIAN__
-    sth   7,0(3)
-#else
-    sth   6,0(3)
-#endif
-    b     7f
-    .align  4
-3:
-#ifdef __LITTLE_ENDIAN__
-    rotlwi 6,6,24
-    stb   6,0(3)
-    sth   7,1(3)
-#else
-    stb   7,0(3)
-    sth   6,1(3)
-#endif
-    b     7f
-    .align  4
-5:
-#ifdef __LITTLE_ENDIAN__
-    rotlwi 6,6,8
-#endif
-    stb   6,0(3)
-7:
-    cmplwi	cr1,10,16
-    add   3,3,0
-    mtcrf 0x01,10
-    .align  4
-.L3:
-/* At least 6 bytes left and the source is word aligned.  */
-    blt   cr1,8f
-16: /* Move 16 bytes.  */
-    lwz   6,0(12)
-    lwz   7,4(12)
-    stw   6,0(3)
-    lwz   6,8(12)
-    stw   7,4(3)
-    lwz   7,12(12)
-    addi  12,12,16
-    stw   6,8(3)
-    stw   7,12(3)
-    addi  3,3,16
-8:  /* Move 8 bytes.  */
-    bf    28,4f
-    lwz   6,0(12)
-    lwz   7,4(12)
-    addi  12,12,8
-    stw   6,0(3)
-    stw   7,4(3)
-    addi  3,3,8
-4:  /* Move 4 bytes.  */
-    bf    29,2f
-    lwz   6,0(12)
-    addi  12,12,4
-    stw   6,0(3)
-    addi  3,3,4
-2:  /* Move 2-3 bytes.  */
-    bf    30,1f
-    lhz   6,0(12)
-    sth   6,0(3)
-    bf    31,0f
-    lbz   7,2(12)
-    stb   7,2(3)
-    mr    3,30
-    lwz   30,20(1)
-    addi  1,1,32
-    blr
-1:  /* Move 1 byte.  */
-    bf    31,0f
-    lbz   6,0(12)
-    stb   6,0(3)
-0:
-  /* Return original dst pointer.  */
-    mr   3,30
-    lwz  30,20(1)
-    addi 1,1,32
-    blr
-
-/* Special case to copy 0-8 bytes.  */
-    .align  4
-.LE8:
-    mr    12,4
-    bne   cr6,4f
-    lwz   6,0(4)
-    lwz   7,4(4)
-    stw   6,0(3)
-    stw   7,4(3)
-  /* Return original dst pointer.  */
-    mr    3,30
-    lwz   30,20(1)
-    addi  1,1,32
-    blr
-    .align  4
-4:  bf    29,2b
-    lwz   6,0(4)
-    stw   6,0(3)
-6:
-    bf    30,5f
-    lhz   7,4(4)
-    sth   7,4(3)
-    bf    31,0f
-    lbz   8,6(4)
-    stb   8,6(3)
-    mr    3,30
-    lwz   30,20(1)
-    addi  1,1,32
-    blr
-    .align  4
-5:
-    bf    31,0f
-    lbz   6,4(4)
-    stb   6,4(3)
-    .align  4
-0:
-  /* Return original dst pointer.  */
-    mr   3,30
-    lwz  30,20(1)
-    addi 1,1,32
-    blr
-
-    .align  4
-.L6:
-
-  /* Copy words where the destination is aligned but the source is
-     not.  Use aligned word loads from the source, shifted to realign
-     the data, to allow aligned destination stores.
-     Use an unrolled loop to copy 4 words (16-bytes) per iteration.
-     A single word is retained for storing at loop exit to avoid walking
-     off the end of a page within the loop.
-     If the copy is not an exact multiple of 16 bytes, 1-3
-     words are copied as needed to set up the main loop.  After
-     the main loop exits there may be a tail of 1-3 bytes. These bytes are
-     copied a halfword/byte at a time as needed to preserve alignment.  */
-
-
-    cmplwi  cr6,11,0  /* are there tail bytes left ? */
-    subf    5,10,12   /* back up src pointer to prev word alignment */
-    slwi    10,10,3   /* calculate number of bits to shift 1st word left */
-    addi    11,9,-1   /* we move one word after the loop */
-    srwi    8,11,2    /* calculate the 16 byte loop count */
-    lwz     6,0(5)    /* load 1st src word into R6 */
-    mr      4,3
-    lwz     7,4(5)    /* load 2nd src word into R7 */
-    mtcrf   0x01,11
-    subfic  9,10,32   /* number of bits to shift 2nd word right */
-    mtctr   8
-    bf      30,1f
-
-    /* there are at least two words to copy, so copy them */
-#ifdef __LITTLE_ENDIAN__
-    srw   0,6,10
-    slw   8,7,9
-#else
-    slw   0,6,10  /* shift 1st src word to left align it in R0 */
-    srw   8,7,9   /* shift 2nd src word to right align it in R8 */
-#endif
-    or    0,0,8   /* or them to get word to store */
-    lwz   6,8(5)  /* load the 3rd src word */
-    stw   0,0(4)  /* store the 1st dst word */
-#ifdef __LITTLE_ENDIAN__
-    srw   0,7,10
-    slw   8,6,9
-#else
-    slw   0,7,10  /* now left align 2nd src word into R0 */
-    srw   8,6,9   /* shift 3rd src word to right align it in R8 */
-#endif
-    or    0,0,8   /* or them to get word to store */
-    lwz   7,12(5)
-    stw   0,4(4)  /* store the 2nd dst word */
-    addi  4,4,8
-    addi  5,5,16
-    bf    31,4f
-    /* there is a third word to copy, so copy it */
-#ifdef __LITTLE_ENDIAN__
-    srw   0,6,10
-    slw   8,7,9
-#else
-    slw   0,6,10  /* shift 3rd src word to left align it in R0 */
-    srw   8,7,9   /* shift 4th src word to right align it in R8 */
-#endif
-    or    0,0,8   /* or them to get word to store */
-    stw   0,0(4)  /* store 3rd dst word */
-    mr    6,7
-    lwz   7,0(5)
-    addi  5,5,4
-    addi  4,4,4
-    b     4f
-    .align 4
-1:
-#ifdef __LITTLE_ENDIAN__
-    srw     0,6,10
-    slw     8,7,9
-#else
-    slw     0,6,10  /* shift 1st src word to left align it in R0 */
-    srw     8,7,9   /* shift 2nd src word to right align it in R8 */
-#endif
-    addi  5,5,8
-    or    0,0,8   /* or them to get word to store */
-    bf    31,4f
-    mr    6,7
-    lwz   7,0(5)
-    addi  5,5,4
-    stw   0,0(4)  /* store the 1st dst word */
-    addi  4,4,4
-
-    .align  4
-4:
-    /* copy 16 bytes at a time */
-#ifdef __LITTLE_ENDIAN__
-    srw   0,6,10
-    slw   8,7,9
-#else
-    slw   0,6,10
-    srw   8,7,9
-#endif
-    or    0,0,8
-    lwz   6,0(5)
-    stw   0,0(4)
-#ifdef __LITTLE_ENDIAN__
-    srw   0,7,10
-    slw   8,6,9
-#else
-    slw   0,7,10
-    srw   8,6,9
-#endif
-    or    0,0,8
-    lwz   7,4(5)
-    stw   0,4(4)
-#ifdef __LITTLE_ENDIAN__
-    srw   0,6,10
-    slw   8,7,9
-#else
-    slw   0,6,10
-    srw   8,7,9
-#endif
-    or    0,0,8
-    lwz   6,8(5)
-    stw   0,8(4)
-#ifdef __LITTLE_ENDIAN__
-    srw   0,7,10
-    slw   8,6,9
-#else
-    slw   0,7,10
-    srw   8,6,9
-#endif
-    or    0,0,8
-    lwz   7,12(5)
-    stw   0,12(4)
-    addi  5,5,16
-    addi  4,4,16
-    bdnz+ 4b
-8:
-    /* calculate and store the final word */
-#ifdef __LITTLE_ENDIAN__
-    srw   0,6,10
-    slw   8,7,9
-#else
-    slw   0,6,10
-    srw   8,7,9
-#endif
-    or    0,0,8
-    stw   0,0(4)
-3:
-    clrrwi 0,31,2
-    mtcrf 0x01,31
-    bne   cr6,.L9	/* If the tail is 0 bytes we are done!  */
-
-  /* Return original dst pointer.  */
-    mr   3,30
-    lwz  30,20(1)
-    lwz  31,24(1)
-    addi 1,1,32
-    blr
-END (memcpy)
-
-libc_hidden_builtin_def (memcpy)
diff --git a/sysdeps/powerpc/powerpc32/power4/memset.S b/sysdeps/powerpc/powerpc32/power4/memset.S
deleted file mode 100644
index 7e8249e..0000000
--- a/sysdeps/powerpc/powerpc32/power4/memset.S
+++ /dev/null
@@ -1,226 +0,0 @@
-/* Optimized memset implementation for PowerPC64.
-   Copyright (C) 1997-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* void * [r3] memset (void *s [r3], int c [r4], size_t n [r5]));
-   Returns 's'.
-
-   The memset is done in three sizes: byte (8 bits), word (32 bits),
-   cache line (1024 bits). There is a special case for setting cache lines
-   to 0, to take advantage of the dcbz instruction.  */
-
-	.machine power4
-EALIGN (memset, 5, 0)
-	CALL_MCOUNT
-
-#define rTMP	r0
-#define rRTN	r3	/* Initial value of 1st argument.  */
-#define rMEMP0	r3	/* Original value of 1st arg.  */
-#define rCHR	r4	/* Char to set in each byte.  */
-#define rLEN	r5	/* Length of region to set.  */
-#define rMEMP	r6	/* Address at which we are storing.  */
-#define rALIGN	r7	/* Number of bytes we are setting now (when aligning). */
-#define rMEMP2	r8
-
-#define rNEG64	r8	/* Constant -64 for clearing with dcbz.  */
-#define rCLS	r8	/* Cache line size (known to be 128).  */
-#define rCLM	r9	/* Cache line size mask to check for cache alignment.  */
-L(_memset):
-/* Take care of case for size <= 4.  */
-	cmplwi	cr1, rLEN, 4
-	andi.	rALIGN, rMEMP0, 3
-	mr	rMEMP, rMEMP0
-	ble-	cr1, L(small)
-
-/* Align to word boundary.  */
-	cmplwi	cr5, rLEN, 31
-	insrwi	rCHR, rCHR, 8, 16     /* Replicate byte to halfword.  */
-	beq+	L(aligned)
-	mtcrf	0x01, rMEMP0
-	subfic	rALIGN, rALIGN, 4
-	add	rMEMP, rMEMP, rALIGN
-	sub	rLEN, rLEN, rALIGN
-	bf+	31, L(g0)
-	stb	rCHR, 0(rMEMP0)
-	bt	30, L(aligned)
-L(g0):
-	sth	rCHR, -2(rMEMP)
-
-/* Handle the case of size < 31.  */
-L(aligned):
-	mtcrf	0x01, rLEN
-	insrwi	rCHR, rCHR, 16, 0    /* Replicate halfword to word.  */
-	ble	cr5, L(medium)
-/* Align to 32-byte boundary.  */
-	andi.	rALIGN, rMEMP, 0x1C
-	subfic	rALIGN, rALIGN, 0x20
-	beq	L(caligned)
-	mtcrf	0x01, rALIGN
-	add	rMEMP, rMEMP, rALIGN
-	sub	rLEN, rLEN, rALIGN
-	cmplwi	cr1, rALIGN, 0x10
-	mr	rMEMP2, rMEMP
-	bf	28, L(a1)
-        stw     rCHR, -4(rMEMP2)
-	stwu	rCHR, -8(rMEMP2)
-L(a1):	blt	cr1, L(a2)
-        stw     rCHR, -4(rMEMP2)
-	stw	rCHR, -8(rMEMP2)
-	stw	rCHR, -12(rMEMP2)
-	stwu	rCHR, -16(rMEMP2)
-L(a2):  bf      29, L(caligned)
-        stw     rCHR, -4(rMEMP2)
-
-/* Now aligned to a 32 byte boundary.  */
-L(caligned):
-	cmplwi	cr1, rCHR, 0
-	clrrwi.	rALIGN, rLEN, 5
-	mtcrf	0x01, rLEN
-	beq	cr1, L(zloopstart) /* Special case for clearing memory using dcbz.  */
-L(nondcbz):
-	srwi	rTMP, rALIGN, 5
-	mtctr	rTMP
-	beq	L(medium)	/* We may not actually get to do a full line.  */
-	clrlwi.	rLEN, rLEN, 27
-	add	rMEMP, rMEMP, rALIGN
-	li	rNEG64, -0x40
-	bdz	L(cloopdone)
-
-        .align 4
-L(c3): 	dcbtst	rNEG64, rMEMP
-        stw     rCHR, -4(rMEMP)
-	stw	rCHR, -8(rMEMP)
-        stw     rCHR, -12(rMEMP)
-	stw	rCHR, -16(rMEMP)
-        stw     rCHR, -20(rMEMP)
-	stw	rCHR, -24(rMEMP)
-        stw     rCHR, -28(rMEMP)
-	stwu	rCHR, -32(rMEMP)
-	bdnz	L(c3)
-L(cloopdone):
-        stw     rCHR, -4(rMEMP)
-	stw	rCHR, -8(rMEMP)
-        stw     rCHR, -12(rMEMP)
-	stw	rCHR, -16(rMEMP)
-	cmplwi	cr1, rLEN, 16
-        stw     rCHR, -20(rMEMP)
-	stw	rCHR, -24(rMEMP)
-        stw     rCHR, -28(rMEMP)
-	stwu	rCHR, -32(rMEMP)
-	beqlr
-	add	rMEMP, rMEMP, rALIGN
-	b	L(medium_tail2)
-
-	.align 5
-/* Clear lines of memory in 128-byte chunks.  */
-L(zloopstart):
-/* If the remaining length is less the 32 bytes, don't bother getting
-	 the cache line size.  */
-	beq	L(medium)
-	li      rCLS,128  /* cache line size is 128 */
-	dcbt	0,rMEMP
-L(getCacheAligned):
-	cmplwi	cr1,rLEN,32
-	andi.	rTMP,rMEMP,127
-	blt	cr1,L(handletail32)
-	beq	L(cacheAligned)
-	addi	rMEMP,rMEMP,32
-	addi	rLEN,rLEN,-32
-	stw	rCHR,-32(rMEMP)
-        stw     rCHR,-28(rMEMP)
-	stw	rCHR,-24(rMEMP)
-	stw     rCHR,-20(rMEMP)
-	stw	rCHR,-16(rMEMP)
-        stw     rCHR,-12(rMEMP)
-	stw	rCHR,-8(rMEMP)
-        stw     rCHR,-4(rMEMP)
-	b	L(getCacheAligned)
-
-/* Now we are aligned to the cache line and can use dcbz.  */
-        .align 4
-L(cacheAligned):
-	cmplw	cr1,rLEN,rCLS
-	blt	cr1,L(handletail32)
-	dcbz	0,rMEMP
-	subf	rLEN,rCLS,rLEN
-	add	rMEMP,rMEMP,rCLS
-	b	L(cacheAligned)
-
-/* We are here because the cache line size was set and the remainder
-  (rLEN) is less than the actual cache line size.
-   So set up the preconditions for L(nondcbz) and go there.  */
-L(handletail32):
-	clrrwi.	rALIGN, rLEN, 5
-	b		L(nondcbz)
-
-	.align 5
-L(small):
-/* Memset of 4 bytes or less.  */
-	cmplwi	cr5, rLEN, 1
-	cmplwi	cr1, rLEN, 3
-	bltlr	cr5
-	stb	rCHR, 0(rMEMP)
-	beqlr	cr5
-	stb	rCHR, 1(rMEMP)
-	bltlr	cr1
-	stb	rCHR, 2(rMEMP)
-	beqlr	cr1
-	stb	rCHR, 3(rMEMP)
-	blr
-
-/* Memset of 0-31 bytes.  */
-	.align 5
-L(medium):
-	cmplwi	cr1, rLEN, 16
-L(medium_tail2):
-	add	rMEMP, rMEMP, rLEN
-L(medium_tail):
-	bt-	31, L(medium_31t)
-	bt-	30, L(medium_30t)
-L(medium_30f):
-	bt-	29, L(medium_29t)
-L(medium_29f):
-	bge-	cr1, L(medium_27t)
-	bflr-	28
-        stw     rCHR, -4(rMEMP)
-	stw	rCHR, -8(rMEMP)
-	blr
-
-L(medium_31t):
-	stbu	rCHR, -1(rMEMP)
-	bf-	30, L(medium_30f)
-L(medium_30t):
-	sthu	rCHR, -2(rMEMP)
-	bf-	29, L(medium_29f)
-L(medium_29t):
-	stwu	rCHR, -4(rMEMP)
-	blt-	cr1, L(medium_27f)
-L(medium_27t):
-        stw     rCHR, -4(rMEMP)
-	stw	rCHR, -8(rMEMP)
-        stw     rCHR, -12(rMEMP)
-	stwu	rCHR, -16(rMEMP)
-L(medium_27f):
-	bflr-	28
-L(medium_28t):
-        stw     rCHR, -4(rMEMP)
-	stw	rCHR, -8(rMEMP)
-	blr
-END (memset)
-libc_hidden_builtin_def (memset)
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/ifunc-impl-list.c b/sysdeps/powerpc/powerpc32/power4/multiarch/ifunc-impl-list.c
index 3ddc33f..bd8f037 100644
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/ifunc-impl-list.c
+++ b/sysdeps/powerpc/powerpc32/power4/multiarch/ifunc-impl-list.c
@@ -46,179 +46,5 @@ __libc_ifunc_impl_list (const char *name, struct libc_ifunc_impl *array,
   else if (hwcap & PPC_FEATURE_POWER5)
     hwcap |= PPC_FEATURE_POWER4;
 
-#ifdef SHARED
-  /* Support sysdeps/powerpc/powerpc32/power4/multiarch/memcpy.c.  */
-  IFUNC_IMPL (i, name, memcpy,
-	      IFUNC_IMPL_ADD (array, i, memcpy, hwcap & PPC_FEATURE_HAS_VSX,
-			      __memcpy_power7)
-	      IFUNC_IMPL_ADD (array, i, memcpy, hwcap & PPC_FEATURE_ARCH_2_06,
-			      __memcpy_a2)
-	      IFUNC_IMPL_ADD (array, i, memcpy, hwcap & PPC_FEATURE_ARCH_2_05,
-			      __memcpy_power6)
-	      IFUNC_IMPL_ADD (array, i, memcpy, hwcap & PPC_FEATURE_CELL_BE,
-			      __memcpy_cell)
-	      IFUNC_IMPL_ADD (array, i, memcpy, 1, __memcpy_ppc))
-
-  /* Support sysdeps/powerpc/powerpc32/power4/multiarch/memmove.c.  */
-  IFUNC_IMPL (i, name, memmove,
-	      IFUNC_IMPL_ADD (array, i, memmove, hwcap & PPC_FEATURE_HAS_VSX,
-			      __memmove_power7)
-	      IFUNC_IMPL_ADD (array, i, memmove, 1, __memmove_ppc))
-
-  /* Support sysdeps/powerpc/powerpc32/power4/multiarch/memset.c.  */
-  IFUNC_IMPL (i, name, memset,
-	      IFUNC_IMPL_ADD (array, i, memset, hwcap & PPC_FEATURE_HAS_VSX,
-			      __memset_power7)
-	      IFUNC_IMPL_ADD (array, i, memset, hwcap & PPC_FEATURE_ARCH_2_05,
-			      __memset_power6)
-	      IFUNC_IMPL_ADD (array, i, memset, 1, __memset_ppc))
-
-  /* Support sysdeps/powerpc/powerpc32/power4/multiarch/bzero.c.  */
-  IFUNC_IMPL (i, name, bzero,
-	      IFUNC_IMPL_ADD (array, i, bzero, hwcap & PPC_FEATURE_HAS_VSX,
-			      __bzero_power7)
-	      IFUNC_IMPL_ADD (array, i, bzero, hwcap & PPC_FEATURE_ARCH_2_05,
-			      __bzero_power6)
-	      IFUNC_IMPL_ADD (array, i, bzero, 1, __bzero_ppc))
-
-  /* Support sysdeps/powerpc/powerpc32/power4/multiarch/strlen.c.  */
-  IFUNC_IMPL (i, name, strlen,
-	      IFUNC_IMPL_ADD (array, i, strlen, hwcap & PPC_FEATURE_HAS_VSX,
-			      __strlen_power7)
-	      IFUNC_IMPL_ADD (array, i, strlen, 1,
-			      __strlen_ppc))
-
-  /* Support sysdeps/powerpc/powerpc32/power4/multiarch/strnlen.c.  */
-  IFUNC_IMPL (i, name, strnlen,
-	      IFUNC_IMPL_ADD (array, i, strnlen, hwcap & PPC_FEATURE_HAS_VSX,
-			      __strnlen_power7)
-	      IFUNC_IMPL_ADD (array, i, strnlen, 1,
-			      __strnlen_ppc))
-
-  /* Support sysdeps/powerpc/powerpc32/multiarch/strncmp.c.  */
-  IFUNC_IMPL (i, name, strncmp,
-	      IFUNC_IMPL_ADD (array, i, strncmp, hwcap & PPC_FEATURE_HAS_VSX,
-			      __strncmp_power7)
-	      IFUNC_IMPL_ADD (array, i, strncmp, 1,
-			      __strncmp_ppc))
-#endif
-
-  /* Support sysdeps/powerpc/powerpc32/power4/multiarch/memcmp.c.  */
-  IFUNC_IMPL (i, name, memcmp,
-	      IFUNC_IMPL_ADD (array, i, memcmp, hwcap & PPC_FEATURE_HAS_VSX,
-			      __memcmp_power7)
-	      IFUNC_IMPL_ADD (array, i, memcmp, 1, __memcmp_ppc))
-
-  /* Support sysdeps/powerpc/powerpc32/power4/multiarch/mempcpy.c.  */
-  IFUNC_IMPL (i, name, mempcpy,
-	      IFUNC_IMPL_ADD (array, i, mempcpy,
-			      hwcap & PPC_FEATURE_HAS_VSX,
-			      __mempcpy_power7)
-	      IFUNC_IMPL_ADD (array, i, mempcpy, 1,
-			      __mempcpy_ppc))
-
-  /* Support sysdeps/powerpc/powerpc32/power4/multiarch/memchr.c.  */
-  IFUNC_IMPL (i, name, memchr,
-	      IFUNC_IMPL_ADD (array, i, memchr,
-			      hwcap & PPC_FEATURE_HAS_VSX,
-			      __memchr_power7)
-	      IFUNC_IMPL_ADD (array, i, memchr, 1,
-			      __memchr_ppc))
-
-  /* Support sysdeps/powerpc/powerpc32/power4/multiarch/memrchr.c.  */
-  IFUNC_IMPL (i, name, memrchr,
-	      IFUNC_IMPL_ADD (array, i, memrchr,
-			      hwcap & PPC_FEATURE_HAS_VSX,
-			      __memrchr_power7)
-	      IFUNC_IMPL_ADD (array, i, memrchr, 1,
-			      __memrchr_ppc))
-
-  /* Support sysdeps/powerpc/powerpc32/power4/multiarch/rawmemchr.c.  */
-  IFUNC_IMPL (i, name, rawmemchr,
-	      IFUNC_IMPL_ADD (array, i, rawmemchr,
-			      hwcap & PPC_FEATURE_HAS_VSX,
-			      __rawmemchr_power7)
-	      IFUNC_IMPL_ADD (array, i, rawmemchr, 1,
-			      __rawmemchr_ppc))
-
-  /* Support sysdeps/powerpc/powerpc32/power4/multiarch/strcasecmp.c.  */
-  IFUNC_IMPL (i, name, strcasecmp,
-	      IFUNC_IMPL_ADD (array, i, strcasecmp,
-			      hwcap & PPC_FEATURE_HAS_VSX,
-			      __strcasecmp_power7)
-	      IFUNC_IMPL_ADD (array, i, strcasecmp, 1, __strcasecmp_ppc))
-
-  /* Support sysdeps/powerpc/powerpc32/power4/multiarch/strcasecmp_l.c.  */
-  IFUNC_IMPL (i, name, strcasecmp_l,
-	      IFUNC_IMPL_ADD (array, i, strcasecmp_l,
-			      hwcap & PPC_FEATURE_HAS_VSX,
-			      __strcasecmp_l_power7)
-	      IFUNC_IMPL_ADD (array, i, strcasecmp_l, 1,
-			      __strcasecmp_l_ppc))
-
-  /* Support sysdeps/powerpc/powerpc32/power4/multiarch/strncase.c.  */
-  IFUNC_IMPL (i, name, strncasecmp,
-	      IFUNC_IMPL_ADD (array, i, strncasecmp,
-			      hwcap & PPC_FEATURE_HAS_VSX,
-			      __strncasecmp_power7)
-	      IFUNC_IMPL_ADD (array, i, strncasecmp, 1, __strncasecmp_ppc))
-
-  /* Support sysdeps/powerpc/powerpc32/power4/multiarch/strncase_l.c.  */
-  IFUNC_IMPL (i, name, strncasecmp_l,
-	      IFUNC_IMPL_ADD (array, i, strncasecmp_l,
-			      hwcap & PPC_FEATURE_HAS_VSX,
-			      __strncasecmp_l_power7)
-	      IFUNC_IMPL_ADD (array, i, strncasecmp_l, 1,
-			      __strncasecmp_l_ppc))
-
-  /* Support sysdeps/powerpc/powerpc32/power4/multiarch/strchrnul.c.  */
-  IFUNC_IMPL (i, name, strchrnul,
-	      IFUNC_IMPL_ADD (array, i, strchrnul,
-			      hwcap & PPC_FEATURE_HAS_VSX,
-			      __strchrnul_power7)
-	      IFUNC_IMPL_ADD (array, i, strchrnul, 1,
-			      __strchrnul_ppc))
-
-  /* Support sysdeps/powerpc/powerpc32/power4/multiarch/strchr.c.  */
-  IFUNC_IMPL (i, name, strchr,
-	      IFUNC_IMPL_ADD (array, i, strchr,
-			      hwcap & PPC_FEATURE_HAS_VSX,
-			      __strchr_power7)
-	      IFUNC_IMPL_ADD (array, i, strchr, 1,
-			      __strchr_ppc))
-
-  /* Support sysdeps/powerpc/powerpc32/power4/multiarch/wcschr.c.  */
-  IFUNC_IMPL (i, name, wcschr,
-	      IFUNC_IMPL_ADD (array, i, wcschr,
-			      hwcap & PPC_FEATURE_HAS_VSX,
-			      __wcschr_power7)
-	      IFUNC_IMPL_ADD (array, i, wcschr,
-			      hwcap & PPC_FEATURE_ARCH_2_05,
-			      __wcschr_power6)
-	      IFUNC_IMPL_ADD (array, i, wcschr, 1,
-			      __wcschr_ppc))
-
-  /* Support sysdeps/powerpc/powerpc32/power4/multiarch/wcsrchr.c.  */
-  IFUNC_IMPL (i, name, wcsrchr,
-	      IFUNC_IMPL_ADD (array, i, wcsrchr,
-			      hwcap & PPC_FEATURE_HAS_VSX,
-			      __wcsrchr_power7)
-	      IFUNC_IMPL_ADD (array, i, wcsrchr,
-			      hwcap & PPC_FEATURE_ARCH_2_05,
-			      __wcsrchr_power6)
-	      IFUNC_IMPL_ADD (array, i, wcsrchr, 1,
-			      __wcsrchr_ppc))
-
-  /* Support sysdeps/powerpc/powerpc32/power4/multiarch/wcscpy.c.  */
-  IFUNC_IMPL (i, name, wcscpy,
-	      IFUNC_IMPL_ADD (array, i, wcscpy,
-			      hwcap & PPC_FEATURE_HAS_VSX,
-			      __wcscpy_power7)
-	      IFUNC_IMPL_ADD (array, i, wcscpy,
-			      hwcap & PPC_FEATURE_ARCH_2_05,
-			      __wcscpy_power6)
-	      IFUNC_IMPL_ADD (array, i, wcscpy, 1,
-			      __wcscpy_ppc))
-
   return i;
 }
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/memchr-power7.S b/sysdeps/powerpc/powerpc32/power4/multiarch/memchr-power7.S
deleted file mode 100644
index e8e5f38..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/memchr-power7.S
+++ /dev/null
@@ -1,40 +0,0 @@
-/* Optimized memchr implementation for PowerPC32/POWER7 using cmpb insn.
-   Copyright (C) 2010-2018 Free Software Foundation, Inc.
-   Contributed by Luis Machado <luisgpm@br.ibm.com>.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-#undef ENTRY
-#define ENTRY(name)						\
- .globl C_SYMBOL_NAME(__memchr_power7);				\
- .type C_SYMBOL_NAME(__memchr_power7),@function;		\
- C_LABEL(__memchr_power7)					\
- cfi_startproc;
-
-#undef END
-#define END(name)						\
- cfi_endproc;							\
- ASM_SIZE_DIRECTIVE(__memchr_power7)
-
-#undef weak_alias
-#define weak_alias(name, alias)
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc32/power7/memchr.S>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/memchr-ppc32.c b/sysdeps/powerpc/powerpc32/power4/multiarch/memchr-ppc32.c
deleted file mode 100644
index 9333b54..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/memchr-ppc32.c
+++ /dev/null
@@ -1,34 +0,0 @@
-/* PowerPC32 default implementation of memchr.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <string.h>
-
-#define MEMCHR  __memchr_ppc
-
-#undef weak_alias
-#define weak_alias(a, b)
-
-#ifdef SHARED
-# undef libc_hidden_builtin_def
-# define libc_hidden_builtin_def(name) \
-  __hidden_ver1(__memchr_ppc, __GI_memchr, __memchr_ppc);
-#endif
-
-extern __typeof (memchr) __memchr_ppc attribute_hidden;
-
-#include <string/memchr.c>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/memchr.c b/sysdeps/powerpc/powerpc32/power4/multiarch/memchr.c
deleted file mode 100644
index ac3d01e..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/memchr.c
+++ /dev/null
@@ -1,41 +0,0 @@
-/* Multiple versions of memchr.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if IS_IN (libc)
-# undef memchr
-/* Redefine memchr so that the compiler won't make the weak_alias point
-   to internal hidden definition (__GI_memchr), since PPC32 does not
-   support local IFUNC calls.  */
-# define memchr __redirect_memchr
-# include <string.h>
-# include "init-arch.h"
-
-extern __typeof (__redirect_memchr) __memchr_ppc attribute_hidden;
-extern __typeof (__redirect_memchr) __memchr_power7 attribute_hidden;
-
-extern __typeof (__redirect_memchr) __libc_memchr;
-
-libc_ifunc (__libc_memchr,
-	    (hwcap & PPC_FEATURE_HAS_VSX)
-            ? __memchr_power7
-            : __memchr_ppc);
-#undef memchr
-weak_alias (__libc_memchr, memchr)
-#else
-#include <string/memchr.c>
-#endif
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/memcmp-power7.S b/sysdeps/powerpc/powerpc32/power4/multiarch/memcmp-power7.S
deleted file mode 100644
index 0fcb0e8..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/memcmp-power7.S
+++ /dev/null
@@ -1,41 +0,0 @@
-/* Optimized memcmp implementation for POWER7/PowerPC32.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-#undef EALIGN
-#define EALIGN(name, alignt, words)				\
- .globl C_SYMBOL_NAME(__memcmp_power7);				\
- .type C_SYMBOL_NAME(__memcmp_power7),@function;		\
- .align ALIGNARG(alignt);					\
- EALIGN_W_##words;						\
- C_LABEL(__memcmp_power7)					\
- cfi_startproc;
-
-#undef END
-#define END(name)						\
- cfi_endproc;							\
- ASM_SIZE_DIRECTIVE(__memcmp_power7)
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#undef weak_alias
-#define weak_alias(a, b)
-
-#include <sysdeps/powerpc/powerpc32/power7/memcmp.S>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/memcmp-ppc32.S b/sysdeps/powerpc/powerpc32/power4/multiarch/memcmp-ppc32.S
deleted file mode 100644
index a58c6b8..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/memcmp-ppc32.S
+++ /dev/null
@@ -1,45 +0,0 @@
-/* Default memcmp implementation for PowerPC32.
-   Copyright (C) 1997-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-#if IS_IN (libc)
-# undef EALIGN
-# define EALIGN(name, alignt, words)				\
-  .globl C_SYMBOL_NAME(__memcmp_ppc);				\
-  .type C_SYMBOL_NAME(__memcmp_ppc),@function;		\
-  .align ALIGNARG(alignt);					\
-  EALIGN_W_##words;						\
-  C_LABEL(__memcmp_ppc)					\
-  cfi_startproc;
-
-# undef END
-# define END(name)						\
-  cfi_endproc;							\
-  ASM_SIZE_DIRECTIVE(__memcmp_ppc)
-
-# undef libc_hidden_builtin_def
-# define libc_hidden_builtin_def(name)				\
-  .globl __GI_memcmp; __GI_memcmp = __memcmp_ppc
-
-# undef weak_alias
-# define weak_alias(a, b)					\
-  .weak b ; b = __memcmp_ppc
-#endif
-
-#include <sysdeps/powerpc/powerpc32/power4/memcmp.S>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/memcmp.c b/sysdeps/powerpc/powerpc32/power4/multiarch/memcmp.c
deleted file mode 100644
index 00e7e7d..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/memcmp.c
+++ /dev/null
@@ -1,36 +0,0 @@
-/* Multiple versions of memcmp.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-/* Define multiple versions only for definition in libc.  */
-#if IS_IN (libc)
-# define memcmp __redirect_memcmp
-# include <string.h>
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-extern __typeof (memcmp) __memcmp_ppc attribute_hidden;
-extern __typeof (memcmp) __memcmp_power7 attribute_hidden;
-# undef memcmp
-
-/* Avoid DWARF definition DIE on ifunc symbol so that GDB can handle
-   ifunc symbol properly.  */
-libc_ifunc_redirected (__redirect_memcmp, memcmp,
-		       (hwcap & PPC_FEATURE_HAS_VSX)
-		       ? __memcmp_power7
-		       : __memcmp_ppc);
-#endif
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/memcpy-a2.S b/sysdeps/powerpc/powerpc32/power4/multiarch/memcpy-a2.S
deleted file mode 100644
index 539e260..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/memcpy-a2.S
+++ /dev/null
@@ -1,38 +0,0 @@
-/* Optimized memcpy implementation for PowerPC A2.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-#undef EALIGN
-#define EALIGN(name, alignt, words)				\
- .globl C_SYMBOL_NAME(__memcpy_a2);				\
- .type C_SYMBOL_NAME(__memcpy_a2),@function;			\
- .align ALIGNARG(alignt);					\
- EALIGN_W_##words;						\
- C_LABEL(__memcpy_a2)						\
- cfi_startproc;
-
-#undef END
-#define END(name)						\
- cfi_endproc;							\
- ASM_SIZE_DIRECTIVE(__memcpy_a2)
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc32/a2/memcpy.S>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/memcpy-cell.S b/sysdeps/powerpc/powerpc32/power4/multiarch/memcpy-cell.S
deleted file mode 100644
index cbf7ff5..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/memcpy-cell.S
+++ /dev/null
@@ -1,38 +0,0 @@
-/* Optimized memcpy implementation for CELL BE PowerPC.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-#undef EALIGN
-#define EALIGN(name, alignt, words)				\
- .globl C_SYMBOL_NAME(__memcpy_cell);				\
- .type C_SYMBOL_NAME(__memcpy_cell),@function;			\
- .align ALIGNARG(alignt);					\
- EALIGN_W_##words;						\
- C_LABEL(__memcpy_cell)						\
- cfi_startproc;
-
-#undef END
-#define END(name)						\
- cfi_endproc;							\
- ASM_SIZE_DIRECTIVE(__memcpy_cell)
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc32/cell/memcpy.S>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/memcpy-power6.S b/sysdeps/powerpc/powerpc32/power4/multiarch/memcpy-power6.S
deleted file mode 100644
index 16f05bf..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/memcpy-power6.S
+++ /dev/null
@@ -1,38 +0,0 @@
-/* Optimized memcpy implementation for PowerPC32 on POWER6.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-#undef EALIGN
-#define EALIGN(name, alignt, words)				\
- .globl C_SYMBOL_NAME(__memcpy_power6);				\
- .type C_SYMBOL_NAME(__memcpy_power6),@function;		\
- .align ALIGNARG(alignt);					\
- EALIGN_W_##words;						\
- C_LABEL(__memcpy_power6)					\
- cfi_startproc;
-
-#undef END
-#define END(name)						\
- cfi_endproc;							\
- ASM_SIZE_DIRECTIVE(__memcpy_power6)
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc32/power6/memcpy.S>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/memcpy-power7.S b/sysdeps/powerpc/powerpc32/power4/multiarch/memcpy-power7.S
deleted file mode 100644
index a35b02a..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/memcpy-power7.S
+++ /dev/null
@@ -1,38 +0,0 @@
-/* Optimized memcpy implementation for PowerPC32/POWER7.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-#undef EALIGN
-#define EALIGN(name, alignt, words)				\
- .globl C_SYMBOL_NAME(__memcpy_power7);				\
- .type C_SYMBOL_NAME(__memcpy_power7),@function;		\
- .align ALIGNARG(alignt);					\
- EALIGN_W_##words;						\
- C_LABEL(__memcpy_power7)					\
- cfi_startproc;
-
-#undef END
-#define END(name)						\
- cfi_endproc;							\
- ASM_SIZE_DIRECTIVE(__memcpy_power7)
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc32/power7/memcpy.S>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/memcpy-ppc32.S b/sysdeps/powerpc/powerpc32/power4/multiarch/memcpy-ppc32.S
deleted file mode 100644
index 7c11b12..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/memcpy-ppc32.S
+++ /dev/null
@@ -1,41 +0,0 @@
-/* Default memcpy implementation for PowerPC32.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-#if defined SHARED && IS_IN (libc)
-# undef EALIGN
-# define EALIGN(name, alignt, words)				\
-  .globl C_SYMBOL_NAME(__memcpy_ppc);				\
-  .type C_SYMBOL_NAME(__memcpy_ppc),@function;		\
-  .align ALIGNARG(alignt);					\
-  EALIGN_W_##words;						\
-  C_LABEL(__memcpy_ppc)					\
-  cfi_startproc;
-
-# undef END
-# define END(name)						\
-  cfi_endproc;							\
-  ASM_SIZE_DIRECTIVE(__memcpy_ppc)
-
-# undef libc_hidden_builtin_def
-# define libc_hidden_builtin_def(name)				\
-    .globl __GI_memcpy; __GI_memcpy = __memcpy_ppc
-#endif
-
-#include <sysdeps/powerpc/powerpc32/power4/memcpy.S>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/memcpy.c b/sysdeps/powerpc/powerpc32/power4/multiarch/memcpy.c
deleted file mode 100644
index 7db588f..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/memcpy.c
+++ /dev/null
@@ -1,48 +0,0 @@
-/* Multiple versions of memcpy.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-/* Define multiple versions only for the definition in lib and for
-   DSO.  In static binaries we need memcpy before the initialization
-   happened.  */
-#if defined SHARED && IS_IN (libc)
-# undef memcpy
-# define memcpy __redirect_memcpy
-# include <string.h>
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-extern __typeof (memcpy) __memcpy_ppc attribute_hidden;
-extern __typeof (memcpy) __memcpy_cell attribute_hidden;
-extern __typeof (memcpy) __memcpy_power6 attribute_hidden;
-extern __typeof (memcpy) __memcpy_a2 attribute_hidden;
-extern __typeof (memcpy) __memcpy_power7 attribute_hidden;
-# undef memcpy
-
-/* Avoid DWARF definition DIE on ifunc symbol so that GDB can handle
-   ifunc symbol properly.  */
-libc_ifunc_redirected (__redirect_memcpy, memcpy,
-		       (hwcap & PPC_FEATURE_HAS_VSX)
-		       ? __memcpy_power7
-		       : (hwcap & PPC_FEATURE_ARCH_2_06)
-			 ? __memcpy_a2
-			 : (hwcap & PPC_FEATURE_ARCH_2_05)
-			   ? __memcpy_power6
-			   : (hwcap & PPC_FEATURE_CELL_BE)
-			     ? __memcpy_cell
-			     : __memcpy_ppc);
-#endif
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/memmove-power7.c b/sysdeps/powerpc/powerpc32/power4/multiarch/memmove-power7.c
deleted file mode 100644
index 1b9d70e..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/memmove-power7.c
+++ /dev/null
@@ -1,41 +0,0 @@
-/* Power7 multiarch memmove.
-   Copyright (C) 2014-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; see the file COPYING.LIB.  If
-   not, see <http://www.gnu.org/licenses/>.  */
-
-#include <string.h>
-#include <memcopy.h>
-
-extern __typeof (_wordcopy_fwd_aligned) _wordcopy_fwd_aligned_power7;
-extern __typeof (_wordcopy_fwd_dest_aligned) _wordcopy_fwd_dest_aligned_power7;
-extern __typeof (_wordcopy_bwd_aligned) _wordcopy_bwd_aligned_power7;
-extern __typeof (_wordcopy_bwd_dest_aligned) _wordcopy_bwd_dest_aligned_power7;
-
-#define _wordcopy_fwd_aligned       _wordcopy_fwd_aligned_power7
-#define _wordcopy_fwd_dest_aligned  _wordcopy_fwd_dest_aligned_power7
-#define _wordcopy_bwd_aligned       _wordcopy_bwd_aligned_power7
-#define _wordcopy_bwd_dest_aligned  _wordcopy_bwd_dest_aligned_power7
-
-extern __typeof (memcpy) __memcpy_power7;
-#define memcpy __memcpy_power7
-
-extern __typeof (memmove) __memmove_power7;
-#define MEMMOVE __memmove_power7
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <string/memmove.c>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/memmove-ppc.c b/sysdeps/powerpc/powerpc32/power4/multiarch/memmove-ppc.c
deleted file mode 100644
index 3f300a7..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/memmove-ppc.c
+++ /dev/null
@@ -1,44 +0,0 @@
-/* Power7 multiarch memmove.
-   Copyright (C) 2014-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; see the file COPYING.LIB.  If
-   not, see <http://www.gnu.org/licenses/>.  */
-
-#include <string.h>
-#include <memcopy.h>
-
-extern __typeof (_wordcopy_fwd_aligned) _wordcopy_fwd_aligned_ppc;
-extern __typeof (_wordcopy_fwd_dest_aligned) _wordcopy_fwd_dest_aligned_ppc;
-extern __typeof (_wordcopy_bwd_aligned) _wordcopy_bwd_aligned_ppc;
-extern __typeof (_wordcopy_bwd_dest_aligned) _wordcopy_bwd_dest_aligned_ppc;
-
-#define _wordcopy_fwd_aligned       _wordcopy_fwd_aligned_ppc
-#define _wordcopy_fwd_dest_aligned  _wordcopy_fwd_dest_aligned_ppc
-#define _wordcopy_bwd_aligned       _wordcopy_bwd_aligned_ppc
-#define _wordcopy_bwd_dest_aligned  _wordcopy_bwd_dest_aligned_ppc
-
-extern __typeof (memcpy) __memcpy_ppc;
-#define memcpy __memcpy_ppc
-
-extern __typeof (memmove) __memmove_ppc;
-#define MEMMOVE __memmove_ppc
-
-#if defined SHARED
-# undef libc_hidden_builtin_def
-# define libc_hidden_builtin_def(name)  \
-  __hidden_ver1 (__memmove_ppc, __GI_memmove, __memmove_ppc);
-#endif
-
-#include <string/memmove.c>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/memmove.c b/sysdeps/powerpc/powerpc32/power4/multiarch/memmove.c
deleted file mode 100644
index 3634f3f..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/memmove.c
+++ /dev/null
@@ -1,36 +0,0 @@
-/* Multiple versions of memmove. PowerPC32 version.
-   Copyright (C) 2014-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if defined SHARED && IS_IN (libc)
-/* Redefine memmove so that the compiler won't complain about the type
-   mismatch with the IFUNC selector in strong_alias, below.  */
-# define memmove __redirect_memmove
-# include <string.h>
-# include "init-arch.h"
-
-extern __typeof (memmove) __memmove_ppc attribute_hidden;
-extern __typeof (memmove) __memmove_power7 attribute_hidden;
-# undef memmove
-
-libc_ifunc_redirected (__redirect_memmove, memmove,
-		       (hwcap & PPC_FEATURE_HAS_VSX)
-		       ? __memmove_power7
-		       : __memmove_ppc);
-#else
-# include <string/memmove.c>
-#endif
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/mempcpy-power7.S b/sysdeps/powerpc/powerpc32/power4/multiarch/mempcpy-power7.S
deleted file mode 100644
index 05f0271..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/mempcpy-power7.S
+++ /dev/null
@@ -1,35 +0,0 @@
-/* Optimized mempcpy implementation for POWER7.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-#undef EALIGN
-#define EALIGN(name, alignt, words)				\
- .globl C_SYMBOL_NAME(__mempcpy_power7);			\
- .type C_SYMBOL_NAME(__mempcpy_power7),@function;		\
- .align ALIGNARG(alignt);					\
- EALIGN_W_##words;						\
- C_LABEL(__mempcpy_power7)					\
- cfi_startproc;
-
-#undef END
-#define END(name)						\
- cfi_endproc;							\
- ASM_SIZE_DIRECTIVE(__mempcpy_power7)
-
-#include <sysdeps/powerpc/powerpc32/power7/mempcpy.S>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/mempcpy-ppc32.c b/sysdeps/powerpc/powerpc32/power4/multiarch/mempcpy-ppc32.c
deleted file mode 100644
index 441f7db..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/mempcpy-ppc32.c
+++ /dev/null
@@ -1,32 +0,0 @@
-/* PowerPC32 default implementation of mempcpy.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define MEMPCPY  __mempcpy_ppc
-
-#undef libc_hidden_def
-#define libc_hidden_def(name)
-#undef weak_alias
-#define weak_alias(a, b)
-
-#if defined SHARED
-# undef libc_hidden_builtin_def
-# define libc_hidden_builtin_def(name)  \
-  __hidden_ver1 (__mempcpy_ppc, __GI_mempcpy, __mempcpy_ppc);
-#endif
-
-#include <string/mempcpy.c>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/mempcpy.c b/sysdeps/powerpc/powerpc32/power4/multiarch/mempcpy.c
deleted file mode 100644
index caa77de..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/mempcpy.c
+++ /dev/null
@@ -1,43 +0,0 @@
-/* Multiple versions of mempcpy.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if IS_IN (libc)
-# define mempcpy __redirect_mempcpy
-# define __mempcpy __redirect___mempcpy
-# define NO_MEMPCPY_STPCPY_REDIRECT
-# define __NO_STRING_INLINES
-# include <string.h>
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-extern __typeof (__mempcpy) __mempcpy_ppc attribute_hidden;
-extern __typeof (__mempcpy) __mempcpy_power7 attribute_hidden;
-# undef mempcpy
-# undef __mempcpy
-
-/* Avoid DWARF definition DIE on ifunc symbol so that GDB can handle
-   ifunc symbol properly.  */
-libc_ifunc_redirected (__redirect___mempcpy,  __mempcpy,
-		       (hwcap & PPC_FEATURE_HAS_VSX)
-		       ? __mempcpy_power7
-		       : __mempcpy_ppc);
-
-weak_alias (__mempcpy, mempcpy)
-#else
-# include <string/mempcpy.c>
-#endif
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/memrchr-power7.S b/sysdeps/powerpc/powerpc32/power4/multiarch/memrchr-power7.S
deleted file mode 100644
index faf7e86..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/memrchr-power7.S
+++ /dev/null
@@ -1,40 +0,0 @@
-/* Optimized memrchr implementation for PowerPC32/POWER7 using cmpb insn.
-   Copyright (C) 2010-2018 Free Software Foundation, Inc.
-   Contributed by Luis Machado <luisgpm@br.ibm.com>.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-#undef ENTRY
-#define ENTRY(name)						\
- .globl C_SYMBOL_NAME(__memrchr_power7);			\
- .type C_SYMBOL_NAME(__memrchr_power7),@function;		\
- C_LABEL(__memrchr_power7)					\
- cfi_startproc;
-
-#undef END
-#define END(name)						\
- cfi_endproc;							\
- ASM_SIZE_DIRECTIVE(__memrchr_power7)
-
-#undef weak_alias
-#define weak_alias(name, alias)
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc32/power7/memrchr.S>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/memrchr-ppc32.c b/sysdeps/powerpc/powerpc32/power4/multiarch/memrchr-ppc32.c
deleted file mode 100644
index 8f9f279..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/memrchr-ppc32.c
+++ /dev/null
@@ -1,25 +0,0 @@
-/* PowerPC32 default implementation of memrchr.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if IS_IN (libc)
-# define MEMRCHR  __memrchr_ppc
-# include <string.h>
-extern void *__memrchr_ppc (const void *, int, size_t);
-#endif
-
-#include <string/memrchr.c>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/memrchr.c b/sysdeps/powerpc/powerpc32/power4/multiarch/memrchr.c
deleted file mode 100644
index 46e20df..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/memrchr.c
+++ /dev/null
@@ -1,37 +0,0 @@
-/* Multiple versions of memrchr.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if IS_IN (libc)
-# include <string.h>
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-extern __typeof (__memrchr) __memrchr_ppc attribute_hidden;
-extern __typeof (__memrchr) __memrchr_power7 attribute_hidden;
-
-/* Avoid DWARF definition DIE on ifunc symbol so that GDB can handle
-   ifunc symbol properly.  */
-libc_ifunc (__memrchr,
-	    (hwcap & PPC_FEATURE_HAS_VSX)
-            ? __memrchr_power7
-            : __memrchr_ppc);
-
-weak_alias (__memrchr, memrchr)
-#else
-#include <string/memrchr.c>
-#endif
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/memset-power6.S b/sysdeps/powerpc/powerpc32/power4/multiarch/memset-power6.S
deleted file mode 100644
index f1cd354..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/memset-power6.S
+++ /dev/null
@@ -1,38 +0,0 @@
-/* Optimized 32-bit memset implementation for POWER6.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-#undef EALIGN
-#define EALIGN(name, alignt, words)				\
- .globl C_SYMBOL_NAME(__memset_power6);				\
- .type C_SYMBOL_NAME(__memset_power6),@function;		\
- .align ALIGNARG(alignt);					\
- EALIGN_W_##words;						\
- C_LABEL(__memset_power6)					\
- cfi_startproc;
-
-#undef END
-#define END(name)						\
- cfi_endproc;							\
- ASM_SIZE_DIRECTIVE(__memset_power6)
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc32/power6/memset.S>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/memset-power7.S b/sysdeps/powerpc/powerpc32/power4/multiarch/memset-power7.S
deleted file mode 100644
index 8c488ee..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/memset-power7.S
+++ /dev/null
@@ -1,38 +0,0 @@
-/* Optimized memset implementation for PowerPC32/POWER7.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-#undef EALIGN
-#define EALIGN(name, alignt, words)				\
- .globl C_SYMBOL_NAME(__memset_power7);				\
- .type C_SYMBOL_NAME(__memset_power7),@function;		\
- .align ALIGNARG(alignt);					\
- EALIGN_W_##words;						\
- C_LABEL(__memset_power7)					\
- cfi_startproc;
-
-#undef END
-#define END(name)						\
- cfi_endproc;							\
- ASM_SIZE_DIRECTIVE(__memset_power7)
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc32/power7/memset.S>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/memset-ppc32.S b/sysdeps/powerpc/powerpc32/power4/multiarch/memset-ppc32.S
deleted file mode 100644
index f2278b4..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/memset-ppc32.S
+++ /dev/null
@@ -1,41 +0,0 @@
-/* Default memset implementation for PowerPC32.
-   Copyright (C) 1997-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-#if defined SHARED && IS_IN (libc)
-# undef EALIGN
-# define EALIGN(name, alignt, words)				\
-  .globl C_SYMBOL_NAME(__memset_ppc);				\
-  .type C_SYMBOL_NAME(__memset_ppc),@function;		\
-  .align ALIGNARG(alignt);					\
-  EALIGN_W_##words;						\
-  C_LABEL(__memset_ppc)					\
-  cfi_startproc;
-
-# undef END
-# define END(name)						\
-  cfi_endproc;							\
-  ASM_SIZE_DIRECTIVE(__memset_ppc)
-
-# undef libc_hidden_builtin_def
-# define libc_hidden_builtin_def(name)				\
-    .globl __GI_memset; __GI_memset = __memset_ppc
-#endif
-
-#include <sysdeps/powerpc/powerpc32/power4/memset.S>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/memset.c b/sysdeps/powerpc/powerpc32/power4/multiarch/memset.c
deleted file mode 100644
index 3a2eb17..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/memset.c
+++ /dev/null
@@ -1,39 +0,0 @@
-/* Multiple versions of memset.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-/* Define multiple versions only for definition in libc.  */
-#if defined SHARED && IS_IN (libc)
-# define memset __redirect_memset
-# include <string.h>
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-extern __typeof (memset) __memset_ppc attribute_hidden;
-extern __typeof (memset) __memset_power6 attribute_hidden;
-extern __typeof (memset) __memset_power7 attribute_hidden;
-# undef memset
-
-/* Avoid DWARF definition DIE on ifunc symbol so that GDB can handle
-   ifunc symbol properly.  */
-libc_ifunc_redirected (__redirect_memset, memset,
-		       (hwcap & PPC_FEATURE_HAS_VSX)
-		       ? __memset_power7
-		       : (hwcap & PPC_FEATURE_ARCH_2_05)
-			 ? __memset_power6
-			 : __memset_ppc);
-#endif
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/rawmemchr-power7.S b/sysdeps/powerpc/powerpc32/power4/multiarch/rawmemchr-power7.S
deleted file mode 100644
index 494084f..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/rawmemchr-power7.S
+++ /dev/null
@@ -1,40 +0,0 @@
-/* Optimized rawrawmemchr implementation for PowerPC32/POWER7 using cmpb insn.
-   Copyright (C) 2010-2018 Free Software Foundation, Inc.
-   Contributed by Luis Machado <luisgpm@br.ibm.com>.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-#undef ENTRY
-#define ENTRY(name)						\
- .globl C_SYMBOL_NAME(__rawmemchr_power7);			\
- .type C_SYMBOL_NAME(__rawmemchr_power7),@function;		\
- C_LABEL(__rawmemchr_power7)					\
- cfi_startproc;
-
-#undef END
-#define END(name)						\
- cfi_endproc;							\
- ASM_SIZE_DIRECTIVE(__rawmemchr_power7)
-
-#undef weak_alias
-#define weak_alias(name, alias)
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc32/power7/rawmemchr.S>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/rawmemchr-ppc32.c b/sysdeps/powerpc/powerpc32/power4/multiarch/rawmemchr-ppc32.c
deleted file mode 100644
index 8ebd039..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/rawmemchr-ppc32.c
+++ /dev/null
@@ -1,32 +0,0 @@
-/* PowerPC32 default implementation of rawmemchr.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <string.h>
-
-#define RAWMEMCHR  __rawmemchr_ppc
-#undef weak_alias
-#define weak_alias(a, b)
-#ifdef SHARED
-# undef libc_hidden_def
-# define libc_hidden_def(name)  \
-  __hidden_ver1 (__rawmemchr_ppc, __GI___rawmemchr, __rawmemchr_ppc);
-#endif
-
-extern __typeof (rawmemchr) __rawmemchr_ppc attribute_hidden;
-
-#include <string/rawmemchr.c>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/rawmemchr.c b/sysdeps/powerpc/powerpc32/power4/multiarch/rawmemchr.c
deleted file mode 100644
index 14aaf8e..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/rawmemchr.c
+++ /dev/null
@@ -1,38 +0,0 @@
-/* Multiple versions of rawmemchr.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if IS_IN (libc)
-# define __rawmemchr __redirect___rawmemchr
-# include <string.h>
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-extern __typeof (__rawmemchr) __rawmemchr_ppc attribute_hidden;
-extern __typeof (__rawmemchr) __rawmemchr_power7 attribute_hidden;
-# undef __rawmemchr
-
-/* Avoid DWARF definition DIE on ifunc symbol so that GDB can handle
-   ifunc symbol properly.  */
-libc_ifunc_redirected (__redirect___rawmemchr, __rawmemchr,
-		       (hwcap & PPC_FEATURE_HAS_VSX)
-		       ? __rawmemchr_power7
-		       : __rawmemchr_ppc);
-weak_alias (__rawmemchr, rawmemchr)
-#else
-#include <string/rawmemchr.c>
-#endif
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/rtld-memcmp.S b/sysdeps/powerpc/powerpc32/power4/multiarch/rtld-memcmp.S
deleted file mode 100644
index 2ffce4b..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/rtld-memcmp.S
+++ /dev/null
@@ -1,19 +0,0 @@
-/* Loader memcmp implementation for PowerPC32.
-   Copyright (C) 1997-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdeps/powerpc/powerpc32/power4/memcmp.S>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/rtld-memset.S b/sysdeps/powerpc/powerpc32/power4/multiarch/rtld-memset.S
deleted file mode 100644
index 3db95ad..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/rtld-memset.S
+++ /dev/null
@@ -1,18 +0,0 @@
-/* Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdeps/powerpc/powerpc32/power4/memset.S>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/rtld-strchr.S b/sysdeps/powerpc/powerpc32/power4/multiarch/rtld-strchr.S
deleted file mode 100644
index bc7eaed..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/rtld-strchr.S
+++ /dev/null
@@ -1,18 +0,0 @@
-/* Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdeps/powerpc/powerpc32/strchr.S>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/rtld-strnlen.c b/sysdeps/powerpc/powerpc32/power4/multiarch/rtld-strnlen.c
deleted file mode 100644
index fd8aed4..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/rtld-strnlen.c
+++ /dev/null
@@ -1,18 +0,0 @@
-/* Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <string/strnlen.c>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/strcasecmp-power7.S b/sysdeps/powerpc/powerpc32/power4/multiarch/strcasecmp-power7.S
deleted file mode 100644
index 18695a0..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/strcasecmp-power7.S
+++ /dev/null
@@ -1,39 +0,0 @@
-/* Optimized strcasecmp implementation for PowerPC32.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-#undef ENTRY
-#define ENTRY(name)						\
- .globl C_SYMBOL_NAME(__strcasecmp_power7);			\
- .type C_SYMBOL_NAME(__strcasecmp_power7),@function;		\
- C_LABEL(__strcasecmp_power7)					\
- cfi_startproc;
-
-#undef END
-#define END(name)						\
- cfi_endproc;							\
- ASM_SIZE_DIRECTIVE(__strcasecmp_power7)
-
-#undef weak_alias
-#define weak_alias(name, alias)
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc32/power7/strcasecmp.S>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/strcasecmp.c b/sysdeps/powerpc/powerpc32/power4/multiarch/strcasecmp.c
deleted file mode 100644
index e059759..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/strcasecmp.c
+++ /dev/null
@@ -1,41 +0,0 @@
-/* Multiple versions of strcasecmp.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if IS_IN (libc)
-# include <string.h>
-# define strcasecmp __strcasecmp_ppc
-
-extern __typeof (__strcasecmp) __strcasecmp_ppc attribute_hidden;
-extern __typeof (__strcasecmp) __strcasecmp_power7 attribute_hidden;
-#endif
-
-#include <string/strcasecmp.c>
-#undef strcasecmp
-
-#if IS_IN (libc)
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-extern __typeof (__strcasecmp) __libc_strcasecmp;
-libc_ifunc (__libc_strcasecmp,
-	    (hwcap & PPC_FEATURE_HAS_VSX)
-            ? __strcasecmp_power7
-            : __strcasecmp_ppc);
-
-weak_alias (__libc_strcasecmp, strcasecmp)
-#endif
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/strcasecmp_l-power7.S b/sysdeps/powerpc/powerpc32/power4/multiarch/strcasecmp_l-power7.S
deleted file mode 100644
index 8d00d28..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/strcasecmp_l-power7.S
+++ /dev/null
@@ -1,41 +0,0 @@
-/* Default strcasecmp implementation for PowerPC32.
-   Copyright (C) 2011-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-#undef ENTRY
-#define ENTRY(name)						\
- .globl C_SYMBOL_NAME(__strcasecmp_l_power7);			\
- .type C_SYMBOL_NAME(__strcasecmp_l_power7),@function;		\
- C_LABEL(__strcasecmp_l_power7)					\
- cfi_startproc;
-
-#undef END
-#define END(name)						\
- cfi_endproc;							\
- ASM_SIZE_DIRECTIVE(__strcasecmp_l_power7)
-
-#undef weak_alias
-#define weak_alias(name, alias)
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#define USE_IN_EXTENDED_LOCALE_MODEL
-
-#include <sysdeps/powerpc/powerpc32/power7/strcasecmp.S>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/strcasecmp_l.c b/sysdeps/powerpc/powerpc32/power4/multiarch/strcasecmp_l.c
deleted file mode 100644
index 3a1a847..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/strcasecmp_l.c
+++ /dev/null
@@ -1,41 +0,0 @@
-/* Multiple versions of strcasecmp.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if IS_IN (libc)
-# include <string.h>
-# define strcasecmp_l __strcasecmp_l_ppc
-
-extern __typeof (__strcasecmp_l) __strcasecmp_l_ppc attribute_hidden;
-extern __typeof (__strcasecmp_l) __strcasecmp_l_power7 attribute_hidden;
-#endif
-
-#include <string/strcasecmp_l.c>
-#undef strcasecmp_l
-
-#if IS_IN (libc)
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-extern __typeof (__strcasecmp_l) __libc_strcasecmp_l;
-libc_ifunc (__libc_strcasecmp_l,
-	    (hwcap & PPC_FEATURE_HAS_VSX)
-            ? __strcasecmp_l_power7
-            : __strcasecmp_l_ppc);
-
-weak_alias (__libc_strcasecmp_l, strcasecmp_l)
-#endif
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/strchr-power7.S b/sysdeps/powerpc/powerpc32/power4/multiarch/strchr-power7.S
deleted file mode 100644
index bfa7a7f..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/strchr-power7.S
+++ /dev/null
@@ -1,39 +0,0 @@
-/* Optimized strchr implementation for PowerPC32/POWER7 using cmpb insn.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-#undef ENTRY
-#define ENTRY(name)						\
- .globl C_SYMBOL_NAME(__strchr_power7);			\
- .type C_SYMBOL_NAME(__strchr_power7),@function;		\
- C_LABEL(__strchr_power7)					\
- cfi_startproc;
-
-#undef END
-#define END(name)						\
- cfi_endproc;							\
- ASM_SIZE_DIRECTIVE(__strchr_power7)
-
-#undef weak_alias
-#define weak_alias(name, alias)
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc32/power7/strchr.S>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/strchr-ppc32.S b/sysdeps/powerpc/powerpc32/power4/multiarch/strchr-ppc32.S
deleted file mode 100644
index 7acf902..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/strchr-ppc32.S
+++ /dev/null
@@ -1,41 +0,0 @@
-/* PowerPC32 default implementation of strchr.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-#ifdef SHARED
-# undef ENTRY
-# define ENTRY(name)						\
-    .globl C_SYMBOL_NAME(__strchr_ppc);			\
-    .type C_SYMBOL_NAME(__strchr_ppc),@function;		\
-    .align ALIGNARG(2);						\
-    C_LABEL(__strchr_ppc)					\
-    cfi_startproc;						\
-    CALL_MCOUNT
-
-# undef END
-# define END(name)						\
-    cfi_endproc;						\
-    ASM_SIZE_DIRECTIVE(__strchr_ppc)				\
-
-# undef libc_hidden_builtin_def
-# define libc_hidden_builtin_def(name)				\
-    .globl __GI_strchr; __GI_strchr = __strchr_ppc
-#endif
-
-#include <sysdeps/powerpc/powerpc32/strchr.S>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/strchr.c b/sysdeps/powerpc/powerpc32/power4/multiarch/strchr.c
deleted file mode 100644
index 8329149..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/strchr.c
+++ /dev/null
@@ -1,39 +0,0 @@
-/* Multiple versions of strchr.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-/* Define multiple versions only for definition in libc.  */
-#if defined SHARED && IS_IN (libc)
-# define strchr __redirect_strchr
-/* Omit the strchr inline definitions because it would redefine strchr.  */
-# define __NO_STRING_INLINES
-# include <string.h>
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-extern __typeof (strchr) __strchr_ppc attribute_hidden;
-extern __typeof (strchr) __strchr_power7 attribute_hidden;
-# undef strchr
-
-/* Avoid DWARF definition DIE on ifunc symbol so that GDB can handle
-   ifunc symbol properly.  */
-libc_ifunc_redirected (__redirect_strchr,  strchr,
-		       (hwcap & PPC_FEATURE_HAS_VSX)
-		       ? __strchr_power7
-		       : __strchr_ppc);
-weak_alias (strchr, index)
-#endif
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/strchrnul-power7.S b/sysdeps/powerpc/powerpc32/power4/multiarch/strchrnul-power7.S
deleted file mode 100644
index 5851294..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/strchrnul-power7.S
+++ /dev/null
@@ -1,39 +0,0 @@
-/* Optimized strchrnul implementation for PowerPC32/POWER7 using cmpb insn.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-#undef ENTRY
-#define ENTRY(name)						\
- .globl C_SYMBOL_NAME(__strchrnul_power7);			\
- .type C_SYMBOL_NAME(__strchrnul_power7),@function;		\
- C_LABEL(__strchrnul_power7)					\
- cfi_startproc;
-
-#undef END
-#define END(name)						\
- cfi_endproc;							\
- ASM_SIZE_DIRECTIVE(__strchrnul_power7)
-
-#undef weak_alias
-#define weak_alias(name, alias)
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc32/power7/strchrnul.S>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/strchrnul-ppc32.c b/sysdeps/powerpc/powerpc32/power4/multiarch/strchrnul-ppc32.c
deleted file mode 100644
index 7ae631f..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/strchrnul-ppc32.c
+++ /dev/null
@@ -1,28 +0,0 @@
-/* PowerPC32 default implementation of strchrnul.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <string.h>
-
-#define STRCHRNUL  __strchrnul_ppc
-
-#undef weak_alias
-#define weak_alias(a,b )
-
-extern __typeof (strchrnul) __strchrnul_ppc attribute_hidden;
-
-#include <string/strchrnul.c>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/strchrnul.c b/sysdeps/powerpc/powerpc32/power4/multiarch/strchrnul.c
deleted file mode 100644
index 527160f..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/strchrnul.c
+++ /dev/null
@@ -1,37 +0,0 @@
-/* Multiple versions of strchrnul.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if IS_IN (libc)
-# include <string.h>
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-extern __typeof (__strchrnul) __strchrnul_ppc attribute_hidden;
-extern __typeof (__strchrnul) __strchrnul_power7 attribute_hidden;
-
-/* Avoid DWARF definition DIE on ifunc symbol so that GDB can handle
-   ifunc symbol properly.  */
-libc_ifunc (__strchrnul,
-	    (hwcap & PPC_FEATURE_HAS_VSX)
-            ? __strchrnul_power7
-            : __strchrnul_ppc);
-
-weak_alias (__strchrnul, strchrnul)
-#else
-#include <string/strchrnul.c>
-#endif
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/strlen-power7.S b/sysdeps/powerpc/powerpc32/power4/multiarch/strlen-power7.S
deleted file mode 100644
index d7b0dfa..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/strlen-power7.S
+++ /dev/null
@@ -1,36 +0,0 @@
-/* Optimized strlen implementation for PowerPC32/POWER7 using cmpb insn.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-#undef ENTRY
-#define ENTRY(name)						\
- .globl C_SYMBOL_NAME(__strlen_power7);				\
- .type C_SYMBOL_NAME(__strlen_power7),@function;		\
- C_LABEL(__strlen_power7)					\
- cfi_startproc;
-
-#undef END
-#define END(name)						\
- cfi_endproc;							\
- ASM_SIZE_DIRECTIVE(__strlen_power7)
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc32/power7/strlen.S>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/strlen-ppc32.S b/sysdeps/powerpc/powerpc32/power4/multiarch/strlen-ppc32.S
deleted file mode 100644
index 99de9ca..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/strlen-ppc32.S
+++ /dev/null
@@ -1,41 +0,0 @@
-/* Default strlen implementation for PowerPC32.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if defined SHARED && IS_IN (libc)
-
-#include <sysdep.h>
-
-# undef ENTRY
-# define ENTRY(name)						\
-  .globl C_SYMBOL_NAME(__strlen_ppc);				\
-  .type C_SYMBOL_NAME(__strlen_ppc),@function;		\
-  C_LABEL(__strlen_ppc)					\
-  cfi_startproc;
-
-# undef END
-# define END(name)						\
-  cfi_endproc;							\
-  ASM_SIZE_DIRECTIVE(__strlen_ppc)
-
-# undef libc_hidden_builtin_def
-# define libc_hidden_builtin_def(name)				\
-  .globl __GI_strlen; __GI_strlen = __strlen_ppc
-
-#endif
-
-#include <sysdeps/powerpc/powerpc32/strlen.S>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/strlen.c b/sysdeps/powerpc/powerpc32/power4/multiarch/strlen.c
deleted file mode 100644
index 3ce050b..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/strlen.c
+++ /dev/null
@@ -1,33 +0,0 @@
-/* Multiple versions of strlen.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if defined SHARED && IS_IN (libc)
-# define strlen __redirect_strlen
-# include <string.h>
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-extern __typeof (strlen) __strlen_ppc attribute_hidden;
-extern __typeof (strlen) __strlen_power7 attribute_hidden;
-# undef strlen
-
-libc_ifunc_redirected (__redirect_strlen, strlen,
-		       (hwcap & PPC_FEATURE_HAS_VSX)
-		       ? __strlen_power7
-		       : __strlen_ppc);
-#endif
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/strncase-power7.c b/sysdeps/powerpc/powerpc32/power4/multiarch/strncase-power7.c
deleted file mode 100644
index d29fb55..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/strncase-power7.c
+++ /dev/null
@@ -1,26 +0,0 @@
-/* Optimized strcasecmp_l implememtation for POWER7.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-
-#include <string.h>
-
-#define __strncasecmp __strncasecmp_power7
-
-extern __typeof (strncasecmp) __strncasecmp_power7 attribute_hidden;
-
-#include <string/strncase.c>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/strncase.c b/sysdeps/powerpc/powerpc32/power4/multiarch/strncase.c
deleted file mode 100644
index a286a7b..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/strncase.c
+++ /dev/null
@@ -1,41 +0,0 @@
-/* Multiple versions of strncasecmp.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if IS_IN (libc)
-# include <string.h>
-# define strncasecmp __strncasecmp_ppc
-extern __typeof (__strncasecmp) __strncasecmp_ppc attribute_hidden;
-extern __typeof (__strncasecmp) __strncasecmp_power7 attribute_hidden;
-#endif
-
-#include <string/strncase.c>
-#undef strncasecmp
-
-#if IS_IN (libc)
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-/* Avoid DWARF definition DIE on ifunc symbol so that GDB can handle
-   ifunc symbol properly.  */
-extern __typeof (__strncasecmp) __libc_strncasecmp;
-libc_ifunc (__libc_strncasecmp,
-	     (hwcap & PPC_FEATURE_HAS_VSX)
-             ? __strncasecmp_power7
-             : __strncasecmp_ppc);
-weak_alias (__libc_strncasecmp, strncasecmp)
-#endif
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/strncase_l-power7.c b/sysdeps/powerpc/powerpc32/power4/multiarch/strncase_l-power7.c
deleted file mode 100644
index 5540a44..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/strncase_l-power7.c
+++ /dev/null
@@ -1,26 +0,0 @@
-/* Optimized strcasecmp_l implememtation for POWER7.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <string.h>
-
-#define __strncasecmp_l __strncasecmp_l_power7
-#define USE_IN_EXTENDED_LOCALE_MODEL    1
-
-extern __typeof (strncasecmp_l) __strncasecmp_l_power7 attribute_hidden;
-
-#include <string/strncase.c>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/strncase_l.c b/sysdeps/powerpc/powerpc32/power4/multiarch/strncase_l.c
deleted file mode 100644
index 21ce9ec..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/strncase_l.c
+++ /dev/null
@@ -1,42 +0,0 @@
-/* Multiple versions of strncasecmp_l.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if IS_IN (libc)
-# include <string.h>
-# define strncasecmp_l __strncasecmp_l_ppc
-extern __typeof (__strncasecmp_l) __strncasecmp_l_ppc attribute_hidden;
-extern __typeof (__strncasecmp_l) __strncasecmp_l_power7 attribute_hidden;
-#endif
-
-#include <string/strncase_l.c>
-#undef strncasecmp_l
-
-#if IS_IN (libc)
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-/* Avoid DWARF definition DIE on ifunc symbol so that GDB can handle
-   ifunc symbol properly.  */
-extern __typeof (__strncasecmp_l) __libc_strncasecmp_l;
-libc_ifunc (__libc_strncasecmp_l,
-	     (hwcap & PPC_FEATURE_HAS_VSX)
-             ? __strncasecmp_l_power7
-             : __strncasecmp_l_ppc);
-
-weak_alias (__libc_strncasecmp_l, strncasecmp_l)
-#endif
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/strncmp-power7.S b/sysdeps/powerpc/powerpc32/power4/multiarch/strncmp-power7.S
deleted file mode 100644
index f1df407..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/strncmp-power7.S
+++ /dev/null
@@ -1,38 +0,0 @@
-/* Optimized strcmp implementation for POWER7/PowerPC32.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-#undef EALIGN
-#define EALIGN(name, alignt, words)				\
- .globl C_SYMBOL_NAME(__strncmp_power7);			\
- .type C_SYMBOL_NAME(__strncmp_power7),@function;		\
- .align ALIGNARG(alignt);					\
- EALIGN_W_##words;						\
- C_LABEL(__strncmp_power7)					\
- cfi_startproc;
-
-#undef END
-#define END(name)						\
- cfi_endproc;							\
- ASM_SIZE_DIRECTIVE(__strncmp_power7)
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc32/power7/strncmp.S>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/strncmp-ppc32.S b/sysdeps/powerpc/powerpc32/power4/multiarch/strncmp-ppc32.S
deleted file mode 100644
index 59dd36d..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/strncmp-ppc32.S
+++ /dev/null
@@ -1,40 +0,0 @@
-/* Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-#if defined SHARED && IS_IN (libc)
-# undef EALIGN
-# define EALIGN(name, alignt, words)				\
-  .globl C_SYMBOL_NAME(__strncmp_ppc);			\
-  .type C_SYMBOL_NAME(__strncmp_ppc),@function;		\
-  .align ALIGNARG(alignt);					\
-  EALIGN_W_##words;						\
-  C_LABEL(__strncmp_ppc)					\
-  cfi_startproc;
-
-# undef END
-# define END(name)						\
-  cfi_endproc;							\
-  ASM_SIZE_DIRECTIVE(__strncmp_ppc)
-
-# undef libc_hidden_builtin_def
-# define libc_hidden_builtin_def(name)				\
-    .globl __GI_strncmp; __GI_strncmp = __strncmp_ppc
-#endif
-
-#include <sysdeps/powerpc/powerpc32/power4/strncmp.S>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/strncmp.c b/sysdeps/powerpc/powerpc32/power4/multiarch/strncmp.c
deleted file mode 100644
index cb1cbe7..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/strncmp.c
+++ /dev/null
@@ -1,39 +0,0 @@
-/* Multiple versions of strncmp.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-/* Define multiple versions only for definition in libc.  */
-#if defined SHARED && IS_IN (libc)
-# define strncmp __redirect_strncmp
-/* Omit the strncmp inline definitions because it would redefine strncmp.  */
-# define __NO_STRING_INLINES
-# include <string.h>
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-extern __typeof (strncmp) __strncmp_ppc attribute_hidden;
-extern __typeof (strncmp) __strncmp_power4 attribute_hidden;
-extern __typeof (strncmp) __strncmp_power7 attribute_hidden;
-# undef strncmp
-
-/* Avoid DWARF definition DIE on ifunc symbol so that GDB can handle
-   ifunc symbol properly.  */
-libc_ifunc_redirected (__redirect_strncmp, strncmp,
-		       (hwcap & PPC_FEATURE_HAS_VSX)
-		       ? __strncmp_power7
-		       : __strncmp_ppc);
-#endif
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/strnlen-power7.S b/sysdeps/powerpc/powerpc32/power4/multiarch/strnlen-power7.S
deleted file mode 100644
index d5137f6..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/strnlen-power7.S
+++ /dev/null
@@ -1,40 +0,0 @@
-/* Optimized strnlen implementation for PowerPC32/POWER7 using cmpb insn.
-   Copyright (C) 2010-2018 Free Software Foundation, Inc.
-   Contributed by Luis Machado <luisgpm@br.ibm.com>.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-#undef ENTRY
-#define ENTRY(name)						\
- .globl C_SYMBOL_NAME(__strnlen_power7);			\
- .type C_SYMBOL_NAME(__strnlen_power7),@function;		\
- C_LABEL(__strnlen_power7)					\
- cfi_startproc;
-
-#undef END
-#define END(name)						\
- cfi_endproc;							\
- ASM_SIZE_DIRECTIVE(__strnlen_power7)
-
-#undef libc_hidden_def
-#define libc_hidden_def(name)
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc32/power7/strnlen.S>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/strnlen-ppc32.c b/sysdeps/powerpc/powerpc32/power4/multiarch/strnlen-ppc32.c
deleted file mode 100644
index df940d3..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/strnlen-ppc32.c
+++ /dev/null
@@ -1,28 +0,0 @@
-/* Default strnlen implementation for PowerPC32.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define STRNLEN  __strnlen_ppc
-#ifdef SHARED
-# undef libc_hidden_def
-# define libc_hidden_def(name)  \
-    __hidden_ver1 (__strnlen_ppc, __GI_strnlen, __strnlen_ppc); \
-    strong_alias (__strnlen_ppc, __strnlen_ppc_1); \
-    __hidden_ver1 (__strnlen_ppc_1, __GI___strnlen, __strnlen_ppc_1);
-#endif
-
-#include <string/strnlen.c>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/strnlen.c b/sysdeps/powerpc/powerpc32/power4/multiarch/strnlen.c
deleted file mode 100644
index d056b74..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/strnlen.c
+++ /dev/null
@@ -1,36 +0,0 @@
-/* Multiple versions of strnlen.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if IS_IN (libc)
-# define strnlen __redirect_strnlen
-# define __strnlen __redirect___strnlen
-# include <string.h>
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-extern __typeof (__strnlen) __strnlen_ppc attribute_hidden;
-extern __typeof (__strnlen) __strnlen_power7 attribute_hidden;
-# undef strnlen
-# undef __strnlen
-
-libc_ifunc_redirected (__redirect___strnlen, __strnlen,
-		       (hwcap & PPC_FEATURE_HAS_VSX)
-		       ? __strnlen_power7
-		       : __strnlen_ppc);
-weak_alias (__strnlen, strnlen)
-#endif
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/wcschr-power6.c b/sysdeps/powerpc/powerpc32/power4/multiarch/wcschr-power6.c
deleted file mode 100644
index dacc8af..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/wcschr-power6.c
+++ /dev/null
@@ -1,26 +0,0 @@
-/* wcschr.c - Wide Character Search for powerpc32/power6.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; see the file COPYING.LIB.  If
-   not, see <http://www.gnu.org/licenses/>.  */
-
-#include <wchar.h>
-
-#define WCSCHR __wcschr_power6
-
-#undef libc_hidden_def
-#define libc_hidden_def(name)
-
-#include <sysdeps/powerpc/power6/wcschr.c>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/wcschr-power7.c b/sysdeps/powerpc/powerpc32/power4/multiarch/wcschr-power7.c
deleted file mode 100644
index 2c28407..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/wcschr-power7.c
+++ /dev/null
@@ -1,26 +0,0 @@
-/* wcschr.c - Wide Character Search for powerpc32/power7.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; see the file COPYING.LIB.  If
-   not, see <http://www.gnu.org/licenses/>.  */
-
-#include <wchar.h>
-
-#define WCSCHR __wcschr_power7
-
-#undef libc_hidden_def
-#define libc_hidden_def(name)
-
-#include <sysdeps/powerpc/power6/wcschr.c>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/wcschr-ppc32.c b/sysdeps/powerpc/powerpc32/power4/multiarch/wcschr-ppc32.c
deleted file mode 100644
index 340d4f1..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/wcschr-ppc32.c
+++ /dev/null
@@ -1,43 +0,0 @@
-/* Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <wchar.h>
-
-#if IS_IN (libc)
-# undef libc_hidden_weak
-# define libc_hidden_weak(name)
-
-# undef weak_alias
-# undef libc_hidden_def
-
-# ifdef SHARED
-#  define libc_hidden_def(name)  \
-    __hidden_ver1 (__wcschr_ppc, __GI_wcschr, __wcschr_ppc); \
-    strong_alias (__wcschr_ppc, __wcschr_ppc_1); \
-    __hidden_ver1 (__wcschr_ppc_1, __GI___wcschr, __wcschr_ppc_1);
-#  define weak_alias(name,alias)
-# else
-#  define weak_alias(name, alias) \
-    _weak_alias(__wcschr_ppc, __wcschr)
-#  define libc_hidden_def(name)
-# endif /* SHARED  */
-#endif
-
-extern __typeof (wcschr) __wcschr_ppc;
-
-#define WCSCHR  __wcschr_ppc
-#include <wcsmbs/wcschr.c>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/wcschr.c b/sysdeps/powerpc/powerpc32/power4/multiarch/wcschr.c
deleted file mode 100644
index 97d55dc..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/wcschr.c
+++ /dev/null
@@ -1,41 +0,0 @@
-/* Multiple versions of wcschr
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if IS_IN (libc)
-# define wcschr __redirect_wcschr
-# include <wchar.h>
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-extern __typeof (__redirect_wcschr) __wcschr_ppc attribute_hidden;
-extern __typeof (__redirect_wcschr) __wcschr_power6 attribute_hidden;
-extern __typeof (__redirect_wcschr) __wcschr_power7 attribute_hidden;
-
-extern __typeof (__redirect_wcschr) __libc_wcschr;
-
-libc_ifunc (__libc_wcschr,
-	     (hwcap & PPC_FEATURE_HAS_VSX)
-             ? __wcschr_power7 :
-	       (hwcap & PPC_FEATURE_ARCH_2_05)
-	       ? __wcschr_power6
-             : __wcschr_ppc);
-#undef wcschr
-weak_alias (__libc_wcschr, wcschr)
-#else
-#include <wcsmbs/wcschr.c>
-#endif
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/wcscpy-power6.c b/sysdeps/powerpc/powerpc32/power4/multiarch/wcscpy-power6.c
deleted file mode 100644
index 9f0ae48..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/wcscpy-power6.c
+++ /dev/null
@@ -1,22 +0,0 @@
-/* Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <wchar.h>
-
-#define WCSCPY __wcscpy_power6
-
-#include <sysdeps/powerpc/power6/wcscpy.c>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/wcscpy-power7.c b/sysdeps/powerpc/powerpc32/power4/multiarch/wcscpy-power7.c
deleted file mode 100644
index c4d6da5..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/wcscpy-power7.c
+++ /dev/null
@@ -1,22 +0,0 @@
-/* Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <wchar.h>
-
-#define WCSCPY __wcscpy_power7
-
-#include <sysdeps/powerpc/power6/wcscpy.c>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/wcscpy-ppc32.c b/sysdeps/powerpc/powerpc32/power4/multiarch/wcscpy-ppc32.c
deleted file mode 100644
index b5d27ac..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/wcscpy-ppc32.c
+++ /dev/null
@@ -1,26 +0,0 @@
-/* Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <wchar.h>
-
-#if IS_IN (libc)
-# define WCSCPY  __wcscpy_ppc
-#endif
-
-extern __typeof (wcscpy) __wcscpy_ppc;
-
-#include <wcsmbs/wcscpy.c>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/wcscpy.c b/sysdeps/powerpc/powerpc32/power4/multiarch/wcscpy.c
deleted file mode 100644
index 85bb8da..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/wcscpy.c
+++ /dev/null
@@ -1,36 +0,0 @@
-/* Multiple versions of wcscpy
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if IS_IN (libc)
-# include <wchar.h>
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-extern __typeof (wcscpy) __wcscpy_ppc attribute_hidden;
-extern __typeof (wcscpy) __wcscpy_power6 attribute_hidden;
-extern __typeof (wcscpy) __wcscpy_power7 attribute_hidden;
-
-libc_ifunc (wcscpy,
-	     (hwcap & PPC_FEATURE_HAS_VSX)
-             ? __wcscpy_power7 :
-	       (hwcap & PPC_FEATURE_ARCH_2_05)
-	       ? __wcscpy_power6
-             : __wcscpy_ppc);
-#else
-#include <wcsmbs/wcscpy.c>
-#endif
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/wcsrchr-power6.c b/sysdeps/powerpc/powerpc32/power4/multiarch/wcsrchr-power6.c
deleted file mode 100644
index 2302793..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/wcsrchr-power6.c
+++ /dev/null
@@ -1,20 +0,0 @@
-/* Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define WCSRCHR      __wcsrchr_power6
-
-#include <sysdeps/powerpc/power6/wcsrchr.c>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/wcsrchr-power7.c b/sysdeps/powerpc/powerpc32/power4/multiarch/wcsrchr-power7.c
deleted file mode 100644
index f6f79b8..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/wcsrchr-power7.c
+++ /dev/null
@@ -1,20 +0,0 @@
-/* Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define WCSRCHR      __wcsrchr_power7
-
-#include <sysdeps/powerpc/power6/wcsrchr.c>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/wcsrchr-ppc32.c b/sysdeps/powerpc/powerpc32/power4/multiarch/wcsrchr-ppc32.c
deleted file mode 100644
index 86d1efe..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/wcsrchr-ppc32.c
+++ /dev/null
@@ -1,26 +0,0 @@
-/* Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <wchar.h>
-
-#if IS_IN (libc)
-# define WCSRCHR  __wcsrchr_ppc
-#endif
-
-extern __typeof (wcsrchr) __wcsrchr_ppc;
-
-#include <wcsmbs/wcsrchr.c>
diff --git a/sysdeps/powerpc/powerpc32/power4/multiarch/wcsrchr.c b/sysdeps/powerpc/powerpc32/power4/multiarch/wcsrchr.c
deleted file mode 100644
index b0a82bb..0000000
--- a/sysdeps/powerpc/powerpc32/power4/multiarch/wcsrchr.c
+++ /dev/null
@@ -1,36 +0,0 @@
-/* Multiple versions of wcsrchr
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if IS_IN (libc)
-# include <wchar.h>
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-extern __typeof (wcsrchr) __wcsrchr_ppc attribute_hidden;
-extern __typeof (wcsrchr) __wcsrchr_power6 attribute_hidden;
-extern __typeof (wcsrchr) __wcsrchr_power7 attribute_hidden;
-
-libc_ifunc (wcsrchr,
-	     (hwcap & PPC_FEATURE_HAS_VSX)
-             ? __wcsrchr_power7 :
-	       (hwcap & PPC_FEATURE_ARCH_2_05)
-	       ? __wcsrchr_power6
-             : __wcsrchr_ppc);
-#else
-#include <wcsmbs/wcsrchr.c>
-#endif
diff --git a/sysdeps/powerpc/powerpc32/power4/strncmp.S b/sysdeps/powerpc/powerpc32/power4/strncmp.S
deleted file mode 100644
index ac80674..0000000
--- a/sysdeps/powerpc/powerpc32/power4/strncmp.S
+++ /dev/null
@@ -1,196 +0,0 @@
-/* Optimized strcmp implementation for PowerPC32.
-   Copyright (C) 2003-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* See strlen.s for comments on how the end-of-string testing works.  */
-
-/* int [r3] strncmp (const char *s1 [r3], const char *s2 [r4], size_t size [r5])  */
-
-EALIGN (strncmp, 4, 0)
-
-#define rTMP2	r0
-#define rRTN	r3
-#define rSTR1	r3	/* first string arg */
-#define rSTR2	r4	/* second string arg */
-#define rN	r5	/* max string length */
-#define rWORD1	r6	/* current word in s1 */
-#define rWORD2	r7	/* current word in s2 */
-#define rWORD3  r10
-#define rWORD4  r11
-#define rFEFE	r8	/* constant 0xfefefeff (-0x01010101) */
-#define r7F7F	r9	/* constant 0x7f7f7f7f */
-#define rNEG	r10	/* ~(word in s1 | 0x7f7f7f7f) */
-#define rBITDIF	r11	/* bits that differ in s1 & s2 words */
-#define rTMP	r12
-
-	dcbt	0,rSTR1
-	or	rTMP, rSTR2, rSTR1
-	lis	r7F7F, 0x7f7f
-	dcbt	0,rSTR2
-	clrlwi.	rTMP, rTMP, 30
-	cmplwi	cr1, rN, 0
-	lis	rFEFE, -0x101
-	bne	L(unaligned)
-/* We are word aligned so set up for two loops.  first a word
-   loop, then fall into the byte loop if any residual.  */
-	srwi.	rTMP, rN, 2
-	clrlwi	rN, rN, 30
-	addi	rFEFE, rFEFE, -0x101
-	addi	r7F7F, r7F7F, 0x7f7f
-	cmplwi	cr1, rN, 0
-	beq	L(unaligned)
-
-	mtctr	rTMP	/* Power4 wants mtctr 1st in dispatch group.  */
-	lwz	rWORD1, 0(rSTR1)
-	lwz	rWORD2, 0(rSTR2)
-	b	L(g1)
-
-L(g0):
-	lwzu	rWORD1, 4(rSTR1)
-	bne-	cr1, L(different)
-	lwzu	rWORD2, 4(rSTR2)
-L(g1):	add	rTMP, rFEFE, rWORD1
-	nor	rNEG, r7F7F, rWORD1
-	bdz	L(tail)
-	and.	rTMP, rTMP, rNEG
-	cmpw	cr1, rWORD1, rWORD2
-	beq+	L(g0)
-
-/* OK. We've hit the end of the string. We need to be careful that
-   we don't compare two strings as different because of gunk beyond
-   the end of the strings...  */
-
-#ifdef __LITTLE_ENDIAN__
-L(endstring):
-	slwi	rTMP, rTMP, 1
-	addi    rTMP2, rTMP, -1
-	andc    rTMP2, rTMP2, rTMP
-	and	rWORD2, rWORD2, rTMP2		/* Mask off gunk.  */
-	and	rWORD1, rWORD1, rTMP2
-	rlwinm	rTMP2, rWORD2, 8, 0xffffffff	/* Byte reverse word.  */
-	rlwinm	rTMP, rWORD1, 8, 0xffffffff
-	rldimi	rTMP2, rWORD2, 24, 32
-	rldimi	rTMP, rWORD1, 24, 32
-	rlwimi	rTMP2, rWORD2, 24, 16, 23
-	rlwimi	rTMP, rWORD1, 24, 16, 23
-	xor.	rBITDIF, rTMP, rTMP2
-	sub	rRTN, rTMP, rTMP2
-	bgelr+
-	ori	rRTN, rTMP2, 1
-	blr
-
-L(different):
-	lwz	rWORD1, -4(rSTR1)
-	rlwinm	rTMP2, rWORD2, 8, 0xffffffff	/* Byte reverse word.  */
-	rlwinm	rTMP, rWORD1, 8, 0xffffffff
-	rldimi	rTMP2, rWORD2, 24, 32
-	rldimi	rTMP, rWORD1, 24, 32
-	rlwimi	rTMP2, rWORD2, 24, 16, 23
-	rlwimi	rTMP, rWORD1, 24, 16, 23
-	xor.	rBITDIF, rTMP, rTMP2
-	sub	rRTN, rTMP, rTMP2
-	bgelr+
-	ori	rRTN, rTMP2, 1
-	blr
-
-#else
-L(endstring):
-	and	rTMP, r7F7F, rWORD1
-	beq	cr1, L(equal)
-	add	rTMP, rTMP, r7F7F
-	xor.	rBITDIF, rWORD1, rWORD2
-	andc	rNEG, rNEG, rTMP
-	blt-	L(highbit)
-	cntlzw	rBITDIF, rBITDIF
-	cntlzw	rNEG, rNEG
-	addi	rNEG, rNEG, 7
-	cmpw	cr1, rNEG, rBITDIF
-	sub	rRTN, rWORD1, rWORD2
-	bgelr+	cr1
-L(equal):
-	li	rRTN, 0
-	blr
-
-L(different):
-	lwz	rWORD1, -4(rSTR1)
-	xor.	rBITDIF, rWORD1, rWORD2
-	sub	rRTN, rWORD1, rWORD2
-	bgelr+
-L(highbit):
-	ori	rRTN, rWORD2, 1
-	blr
-#endif
-
-/* Oh well.  In this case, we just do a byte-by-byte comparison.  */
-	.align 4
-L(tail):
-	and.	rTMP, rTMP, rNEG
-	cmpw	cr1, rWORD1, rWORD2
-	bne-	L(endstring)
-	addi	rSTR1, rSTR1, 4
-	bne-	cr1, L(different)
-	addi	rSTR2, rSTR2, 4
-	cmplwi	cr1, rN, 0
-L(unaligned):
-	mtctr   rN	/* Power4 wants mtctr 1st in dispatch group */
-	ble	cr1, L(ux)
-L(uz):
-	lbz	rWORD1, 0(rSTR1)
-	lbz	rWORD2, 0(rSTR2)
-	.align 4
-L(u1):
-	cmpwi	cr1, rWORD1, 0
-	bdz	L(u4)
-	cmpw	rWORD1, rWORD2
-	beq-	cr1, L(u4)
-	bne-	L(u4)
-	lbzu    rWORD3, 1(rSTR1)
-	lbzu	rWORD4, 1(rSTR2)
-	cmpwi	cr1, rWORD3, 0
-	bdz	L(u3)
-	cmpw	rWORD3, rWORD4
-	beq-    cr1, L(u3)
-	bne-    L(u3)
-	lbzu	rWORD1, 1(rSTR1)
-	lbzu	rWORD2, 1(rSTR2)
-	cmpwi	cr1, rWORD1, 0
-	bdz	L(u4)
-	cmpw	rWORD1, rWORD2
-	beq-	cr1, L(u4)
-	bne-	L(u4)
-	lbzu	rWORD3, 1(rSTR1)
-	lbzu	rWORD4, 1(rSTR2)
-	cmpwi	cr1, rWORD3, 0
-	bdz	L(u3)
-	cmpw	rWORD3, rWORD4
-	beq-    cr1, L(u3)
-	bne-	L(u3)
-	lbzu	rWORD1, 1(rSTR1)
-	lbzu	rWORD2, 1(rSTR2)
-	b       L(u1)
-
-L(u3):  sub     rRTN, rWORD3, rWORD4
-	blr
-L(u4):	sub	rRTN, rWORD1, rWORD2
-	blr
-L(ux):
-	li	rRTN, 0
-	blr
-END (strncmp)
-libc_hidden_builtin_def (strncmp)
diff --git a/sysdeps/powerpc/powerpc32/power6/memcpy.S b/sysdeps/powerpc/powerpc32/power6/memcpy.S
deleted file mode 100644
index 3ca26a2..0000000
--- a/sysdeps/powerpc/powerpc32/power6/memcpy.S
+++ /dev/null
@@ -1,907 +0,0 @@
-/* Optimized memcpy implementation for PowerPC32 on POWER6.
-   Copyright (C) 2003-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* void * [r3] memcpy (void *dst [r3], void *src [r4], size_t len [r5]);
-   Returns 'dst'.
-
-   Memcpy handles short copies (< 32-bytes) using a binary move blocks
-   (no loops) of lwz/stw.  The tail (remaining 1-3) bytes is handled
-   with the appropriate combination of byte and halfword load/stores.
-   There is minimal effort to optimize the alignment of short moves.
-
-   Longer moves (>= 32-bytes) justify the effort to get at least the
-   destination word (4-byte) aligned.  Further optimization is
-   possible when both source and destination are word aligned.
-   Each case has an optimized unrolled loop.   */
-
-	.machine power6
-EALIGN (memcpy, 5, 0)
-	CALL_MCOUNT
-
-    stwu   1,-32(1)
-    cfi_adjust_cfa_offset(32)
-    cmplwi cr1,5,31     /* check for short move.  */
-    neg    0,3
-    cmplwi cr1,5,31
-    clrlwi 10,4,30	/* check alignment of src.  */
-    andi.  11,3,3	/* check alignment of dst.  */
-    clrlwi 0,0,30	/* Number of bytes until the 1st word of dst.  */
-    ble-   cr1,L(word_unaligned_short)	/* If move < 32 bytes.  */
-    cmplw  cr6,10,11
-    stw    31,24(1)
-    stw    30,20(1)
-    cfi_offset(31,(24-32))
-    cfi_offset(30,(20-32))
-    mr     30,3
-    beq    .L0
-    mtcrf  0x01,0
-    subf  31,0,5        /* Length after alignment.  */
-    add   12,4,0        /* Compute src addr after alignment.  */
-  /* Move 0-3 bytes as needed to get the destination word aligned.  */
-1:  bf    31,2f
-    lbz   6,0(4)
-    bf    30,3f
-    lhz   7,1(4)
-    stb   6,0(3)
-    sth   7,1(3)
-    addi  3,3,3
-    b     0f
-3:
-    stb   6,0(3)
-    addi  3,3,1
-    b     0f
-2:  bf    30,0f
-    lhz   6,0(4)
-    sth   6,0(3)
-    addi  3,3,2
-0:
-    clrlwi 10,12,30	/* check alignment of src again.  */
-    srwi   9,31,2	/* Number of full words remaining.  */
-    bne-   cr6,L(wdu)   /* If source is not word aligned. .L6 */
-    clrlwi 11,31,30  /* calculate the number of tail bytes */
-    b      L(word_aligned)
-  /* Copy words from source to destination, assuming the destination is
-     aligned on a word boundary.
-
-     At this point we know there are at least 29 bytes left (32-3) to copy.
-     The next step is to determine if the source is also word aligned.
-     If not branch to the unaligned move code at .L6. which uses
-     a load, shift, store strategy.
-
-     Otherwise source and destination are word aligned, and we can use
-     the optimized word copy loop.  */
-    .align  4
-.L0:
-    mr     31,5
-    mr     12,4
-    bne-   cr6,L(wdu)   /* If source is not word aligned. .L6 */
-    srwi   9,5,2	/* Number of full words remaining.  */
-    clrlwi 11,5,30      /* calculate the number of tail bytes */
-
-  /* Move words where destination and source are word aligned.
-     Use an unrolled loop to copy 4 words (16-bytes) per iteration.
-     If the copy is not an exact multiple of 16 bytes, 1-3
-     words are copied as needed to set up the main loop.  After
-     the main loop exits there may be a tail of 1-3 bytes. These bytes are
-     copied a halfword/byte at a time as needed to preserve alignment.  */
-L(word_aligned):
-    mtcrf 0x01,9
-    srwi  8,31,4    /* calculate the 16 byte loop count */
-    cmplwi	cr1,9,4
-    cmplwi	cr6,11,0
-    mr    11,12
-
-    bf    30,1f
-    lwz   6,0(12)
-    lwz   7,4(12)
-    addi  11,12,8
-    mtctr 8
-    stw   6,0(3)
-    stw   7,4(3)
-    addi  10,3,8
-    bf    31,4f
-    lwz   0,8(12)
-    stw   0,8(3)
-    blt   cr1,3f
-    addi  11,12,12
-    addi  10,3,12
-    b     4f
-    .align  4
-1:
-    mr    10,3
-    mtctr 8
-    bf    31,4f
-    lwz   6,0(12)
-    addi  11,12,4
-    stw   6,0(3)
-    addi  10,3,4
-
-    .align  4
-4:
-    lwz   6,0(11)
-    lwz   7,4(11)
-    lwz   8,8(11)
-    lwz   0,12(11)
-    stw   6,0(10)
-    stw   7,4(10)
-    stw   8,8(10)
-    stw   0,12(10)
-    addi  11,11,16
-    addi  10,10,16
-    bdnz  4b
-3:
-    clrrwi 0,31,2
-    mtcrf 0x01,31
-    beq   cr6,0f
-.L9:
-    add   3,3,0
-    add   12,12,0
-
-/*  At this point we have a tail of 0-3 bytes and we know that the
-    destination is word aligned.  */
-2:  bf    30,1f
-    lhz   6,0(12)
-    addi  12,12,2
-    sth   6,0(3)
-    addi  3,3,2
-1:  bf    31,0f
-    lbz   6,0(12)
-    stb   6,0(3)
-0:
-  /* Return original dst pointer.  */
-    mr  3,30
-    lwz 30,20(1)
-    lwz 31,24(1)
-    addi 1,1,32
-    blr
-
-/* Copy up to 31 bytes.  This divided into two cases 0-8 bytes and 9-31
-   bytes.  Each case is handled without loops, using binary (1,2,4,8)
-   tests.
-
-   In the short (0-8 byte) case no attempt is made to force alignment
-   of either source or destination.  The hardware will handle the
-   unaligned load/stores with small delays for crossing 32- 128-byte,
-   and 4096-byte boundaries. Since these short moves are unlikely to be
-   unaligned or cross these boundaries, the overhead to force
-   alignment is not justified.
-
-   The longer (9-31 byte) move is more likely to cross 32- or 128-byte
-   boundaries.  Since only loads are sensitive to the 32-/128-byte
-   boundaries it is more important to align the source then the
-   destination.  If the source is not already word aligned, we first
-   move 1-3 bytes as needed.  Since we are only word aligned we don't
-   use double word load/stores to insure that all loads are aligned.
-   While the destination and stores may still be unaligned, this
-   is only an issue for page (4096 byte boundary) crossing, which
-   should be rare for these short moves.  The hardware handles this
-   case automatically with a small (~20 cycle) delay.  */
-    .align  4
-
-    cfi_same_value (31)
-    cfi_same_value (30)
-L(word_unaligned_short):
-    mtcrf 0x01,5
-    cmplwi cr6,5,8
-    neg   8,4
-    clrrwi	9,4,2
-    andi. 0,8,3
-    beq   cr6,L(wus_8)	/* Handle moves of 8 bytes.  */
-/* At least 9 bytes left.  Get the source word aligned.  */
-    cmplwi	cr1,5,16
-    mr    12,4
-    ble   cr6,L(wus_4)  /* Handle moves of 0-8 bytes.  */
-    mr    11,3
-    mr    10,5
-    cmplwi	cr6,0,2
-    beq   L(wus_tail)	/* If the source is already word aligned skip this.  */
-/* Copy 1-3 bytes to get source address word aligned.  */
-    lwz   6,0(9)
-    subf  10,0,5
-    add   12,4,0
-    blt   cr6,5f
-    srwi  7,6,16
-    bgt	  cr6,3f
-#ifdef __LITTLE_ENDIAN__
-    sth   7,0(3)
-#else
-    sth   6,0(3)
-#endif
-    b     7f
-    .align  4
-3:
-#ifdef __LITTLE_ENDIAN__
-    rotlwi 6,6,24
-    stb   6,0(3)
-    sth   7,1(3)
-#else
-    stb   7,0(3)
-    sth   6,1(3)
-#endif
-    b     7f
-    .align  4
-5:
-#ifdef __LITTLE_ENDIAN__
-    rotlwi 6,6,8
-#endif
-    stb   6,0(3)
-7:
-    cmplwi	cr1,10,16
-    add   11,3,0
-    mtcrf 0x01,10
-    .align  4
-L(wus_tail):
-/* At least 6 bytes left and the source is word aligned.  This allows
-   some speculative loads up front.  */
-/* We need to special case the fall-through because the biggest delays
-   are due to address computation not being ready in time for the
-   AGEN.  */
-    lwz   6,0(12)
-    lwz   7,4(12)
-    blt   cr1,L(wus_tail8)
-    cmplwi	cr0,10,24
-L(wus_tail16): /* Move 16 bytes.  */
-    stw   6,0(11)
-    stw   7,4(11)
-    lwz   6,8(12)
-    lwz   7,12(12)
-    stw   6,8(11)
-    stw   7,12(11)
-/* Move 8 bytes more.  */
-    bf    28,L(wus_tail16p8)
-    cmplwi	cr1,10,28
-    lwz   6,16(12)
-    lwz   7,20(12)
-    stw   6,16(11)
-    stw   7,20(11)
-/* Move 4 bytes more.  */
-    bf    29,L(wus_tail16p4)
-    lwz   6,24(12)
-    stw   6,24(11)
-    addi  12,12,28
-    addi  11,11,28
-    bgt   cr1,L(wus_tail2)
- /* exactly 28 bytes.  Return original dst pointer and exit.  */
-    addi  1,1,32
-    blr
-    .align  4
-L(wus_tail16p8):  /* less than 8 bytes left.  */
-    beq   cr1,L(wus_tailX) /* exactly 16 bytes, early exit.  */
-    cmplwi	cr1,10,20
-    bf    29,L(wus_tail16p2)
-/* Move 4 bytes more.  */
-    lwz   6,16(12)
-    stw   6,16(11)
-    addi  12,12,20
-    addi  11,11,20
-    bgt   cr1,L(wus_tail2)
- /* exactly 20 bytes.  Return original dst pointer and exit.  */
-    addi  1,1,32
-    blr
-    .align  4
-L(wus_tail16p4):  /* less than 4 bytes left.  */
-    addi  12,12,24
-    addi  11,11,24
-    bgt   cr0,L(wus_tail2)
- /* exactly 24 bytes.  Return original dst pointer and exit.  */
-    addi  1,1,32
-    blr
-    .align  4
-L(wus_tail16p2):  /* 16 bytes moved, less than 4 bytes left.  */
-    addi  12,12,16
-    addi  11,11,16
-    b     L(wus_tail2)
-
-    .align  4
-L(wus_tail8):  /* Move 8 bytes.  */
-/*  r6, r7 already loaded speculatively.  */
-    cmplwi	cr1,10,8
-    cmplwi	cr0,10,12
-    bf    28,L(wus_tail4)
-    stw   6,0(11)
-    stw   7,4(11)
-/* Move 4 bytes more.  */
-    bf    29,L(wus_tail8p4)
-    lwz   6,8(12)
-    stw   6,8(11)
-    addi  12,12,12
-    addi  11,11,12
-    bgt   cr0,L(wus_tail2)
- /* exactly 12 bytes.  Return original dst pointer and exit.  */
-    addi  1,1,32
-    blr
-    .align  4
-L(wus_tail8p4):  /* less than 4 bytes left.  */
-    addi  12,12,8
-    addi  11,11,8
-    bgt   cr1,L(wus_tail2)
- /* exactly 8 bytes.  Return original dst pointer and exit.  */
-    addi  1,1,32
-    blr
-
-    .align  4
-L(wus_tail4):  /* Move 4 bytes.  */
-/*  r6 already loaded speculatively.  If we are here we know there is
-    more than 4 bytes left.  So there is no need to test.  */
-    addi  12,12,4
-    stw   6,0(11)
-    addi  11,11,4
-L(wus_tail2):  /* Move 2-3 bytes.  */
-    bf    30,L(wus_tail1)
-    lhz   6,0(12)
-    sth   6,0(11)
-    bf    31,L(wus_tailX)
-    lbz   7,2(12)
-    stb   7,2(11)
-    addi  1,1,32
-    blr
-L(wus_tail1):  /* Move 1 byte.  */
-    bf    31,L(wus_tailX)
-    lbz   6,0(12)
-    stb   6,0(11)
-L(wus_tailX):
-  /* Return original dst pointer.  */
-    addi  1,1,32
-    blr
-
-/* Special case to copy 0-8 bytes.  */
-    .align  4
-L(wus_8):
-    lwz   6,0(4)
-    lwz   7,4(4)
-    stw   6,0(3)
-    stw   7,4(3)
-  /* Return original dst pointer.  */
-    addi  1,1,32
-    blr
-    .align  4
-L(wus_4):
-    bf    29,L(wus_2)
-    lwz   6,0(4)
-    stw   6,0(3)
-    bf    30,L(wus_5)
-    lhz   7,4(4)
-    sth   7,4(3)
-    bf    31,L(wus_0)
-    lbz   8,6(4)
-    stb   8,6(3)
-    addi  1,1,32
-    blr
-    .align  4
-L(wus_5):
-    bf    31,L(wus_0)
-    lbz   6,4(4)
-    stb   6,4(3)
-  /* Return original dst pointer.  */
-    addi 1,1,32
-    blr
-    .align  4
-L(wus_2):  /* Move 2-3 bytes.  */
-    bf    30,L(wus_1)
-    lhz   6,0(4)
-    sth   6,0(3)
-    bf    31,L(wus_0)
-    lbz   7,2(4)
-    stb   7,2(3)
-    addi  1,1,32
-    blr
-    .align  4
-L(wus_1):  /* Move 1 byte.  */
-    bf    31,L(wus_0)
-    lbz   6,0(4)
-    stb   6,0(3)
-    .align  3
-L(wus_0):
-  /* Return original dst pointer.  */
-    addi  1,1,32
-    blr
-
-    .align  4
-    cfi_offset(31,(24-32))
-    cfi_offset(30,(20-32))
-L(wdu):
-
-  /* Copy words where the destination is aligned but the source is
-     not.  For power4, power5 and power6 machines there is penalty for
-     unaligned loads (src) that cross 32-byte, cacheline, or page
-     boundaries. So we want to use simple (unaligned) loads where
-     possible but avoid them where we know the load would span a 32-byte
-     boundary.
-
-     At this point we know we have at least 29 (32-3) bytes to copy
-     the src is unaligned. and we may cross at least one 32-byte
-     boundary. Also we have the following register values:
-     r3 == adjusted dst, word aligned
-     r4 == unadjusted src
-     r5 == unadjusted len
-     r9 == adjusted Word length
-     r10 == src alignment (1-3)
-     r12 == adjusted src, not aligned
-     r31 == adjusted len
-
-     First we need to copy word up to but not crossing the next 32-byte
-     boundary. Then perform aligned loads just before and just after
-     the boundary and use shifts and or to generate the next aligned
-     word for dst. If more than 32 bytes remain we copy (unaligned src)
-     the next 7 words and repeat the loop until less than 32-bytes
-     remain.
-
-     Then if more than 4 bytes remain we again use aligned loads,
-     shifts and or to generate the next dst word. We then process the
-     remaining words using unaligned loads as needed. Finally we check
-     if there are more than 0 bytes (1-3) bytes remaining and use
-     halfword and or byte load/stores to complete the copy.
-*/
-    mr      4,12      /* restore unaligned adjusted src ptr */
-    clrlwi  0,12,27   /* Find dist from previous 32-byte boundary.  */
-    slwi    10,10,3   /* calculate number of bits to shift 1st word left */
-    cmplwi  cr5,0,16
-    subfic  8,0,32   /* Number of bytes to next 32-byte boundary.  */
-
-    mtcrf   0x01,8
-    cmplwi  cr1,10,16
-    subfic  9,10,32  /* number of bits to shift 2nd word right */
-/*  This test is reversed because the timing to compare the bytes to
-    32-byte boundary could not be meet.  So we compare the bytes from
-    previous 32-byte boundary and invert the test.  */
-    bge     cr5,L(wdu_h32_8)
-    .align  4
-    lwz   6,0(4)
-    lwz   7,4(4)
-    addi  12,4,16    /* generate alternate pointers to avoid agen */
-    addi  11,3,16    /* timing issues downstream.  */
-    stw   6,0(3)
-    stw   7,4(3)
-    subi  31,31,16
-    lwz   6,8(4)
-    lwz   7,12(4)
-    addi  4,4,16
-    stw   6,8(3)
-    stw   7,12(3)
-    addi  3,3,16
-    bf    28,L(wdu_h32_4)
-    lwz   6,0(12)
-    lwz   7,4(12)
-    subi  31,31,8
-    addi  4,4,8
-    stw   6,0(11)
-    stw   7,4(11)
-    addi  3,3,8
-    bf    29,L(wdu_h32_0)
-    lwz   6,8(12)
-    addi  4,4,4
-    subi  31,31,4
-    stw   6,8(11)
-    addi  3,3,4
-    b     L(wdu_h32_0)
-    .align  4
-L(wdu_h32_8):
-    bf    28,L(wdu_h32_4)
-    lwz   6,0(4)
-    lwz   7,4(4)
-    subi  31,31,8
-    bf    29,L(wdu_h32_8x)
-    stw   6,0(3)
-    stw   7,4(3)
-    lwz   6,8(4)
-    addi  4,4,12
-    subi  31,31,4
-    stw   6,8(3)
-    addi  3,3,12
-    b     L(wdu_h32_0)
-    .align  4
-L(wdu_h32_8x):
-    addi  4,4,8
-    stw   6,0(3)
-    stw   7,4(3)
-    addi  3,3,8
-    b     L(wdu_h32_0)
-    .align  4
-L(wdu_h32_4):
-    bf    29,L(wdu_h32_0)
-    lwz   6,0(4)
-    subi  31,31,4
-    addi  4,4,4
-    stw   6,0(3)
-    addi  3,3,4
-    .align  4
-L(wdu_h32_0):
-/*  set up for 32-byte boundary crossing word move and possibly 32-byte
-    move loop.  */
-    clrrwi  12,4,2
-    cmplwi  cr5,31,32
-    bge     cr1,L(wdu2_32)
-#if 0
-    b       L(wdu1_32)
-/*
-    cmplwi  cr1,10,8
-    beq     cr1,L(wdu1_32)
-    cmplwi  cr1,10,16
-    beq     cr1,L(wdu2_32)
-    cmplwi  cr1,10,24
-    beq     cr1,L(wdu3_32)
-*/
-L(wdu_32):
-    lwz     6,0(12)
-    cmplwi  cr6,31,4
-    srwi    8,31,5    /* calculate the 32 byte loop count */
-    slw     0,6,10
-    clrlwi  31,31,27   /* The remaining bytes, < 32.  */
-    blt     cr5,L(wdu_32tail)
-    mtctr   8
-    cmplwi  cr6,31,4
-    .align  4
-L(wdu_loop32):
-    /* copy 32 bytes at a time */
-    lwz   8,4(12)
-    addi  12,12,32
-    lwz   7,4(4)
-    srw   8,8,9
-    or    0,0,8
-    stw   0,0(3)
-    stw   7,4(3)
-    lwz   6,8(4)
-    lwz   7,12(4)
-    stw   6,8(3)
-    stw   7,12(3)
-    lwz   6,16(4)
-    lwz   7,20(4)
-    stw   6,16(3)
-    stw   7,20(3)
-    lwz   6,24(4)
-    lwz   7,28(4)
-    lwz   8,0(12)
-    addi  4,4,32
-    stw   6,24(3)
-    stw   7,28(3)
-    addi  3,3,32
-    slw   0,8,10
-    bdnz+ L(wdu_loop32)
-
-L(wdu_32tail):
-    mtcrf   0x01,31
-    cmplwi  cr5,31,16
-    blt     cr6,L(wdu_4tail)
-    /* calculate and store the final word */
-    lwz   8,4(12)
-    srw   8,8,9
-    or    6,0,8
-    b     L(wdu_32tailx)
-#endif
-    .align  4
-L(wdu1_32):
-    lwz     6,-1(4)
-    cmplwi  cr6,31,4
-    srwi    8,31,5    /* calculate the 32 byte loop count */
-#ifdef __LITTLE_ENDIAN__
-    srwi    6,6,8
-#else
-    slwi    6,6,8
-#endif
-    clrlwi  31,31,27   /* The remaining bytes, < 32.  */
-    blt     cr5,L(wdu1_32tail)
-    mtctr   8
-    cmplwi  cr6,31,4
-
-    lwz   8,3(4)
-    lwz   7,4(4)
-#ifdef __LITTLE_ENDIAN__
-    rldimi 6,8,24,32
-#else
-/*  Equivalent to: srwi   8,8,32-8;  or    6,6,8 */
-    rlwimi 6,8,8,(32-8),31
-#endif
-    b      L(wdu1_loop32x)
-    .align  4
-L(wdu1_loop32):
-    /* copy 32 bytes at a time */
-    lwz   8,3(4)
-    lwz   7,4(4)
-    stw   10,-8(3)
-    stw   11,-4(3)
-#ifdef __LITTLE_ENDIAN__
-    rldimi 6,8,24,32
-#else
-/*  Equivalent to  srwi   8,8,32-8; or    6,6,8 */
-    rlwimi 6,8,8,(32-8),31
-#endif
-L(wdu1_loop32x):
-    lwz   10,8(4)
-    lwz   11,12(4)
-    stw   6,0(3)
-    stw   7,4(3)
-    lwz   6,16(4)
-    lwz   7,20(4)
-    stw   10,8(3)
-    stw   11,12(3)
-    lwz   10,24(4)
-    lwz   11,28(4)
-    lwz   8,32-1(4)
-    addi  4,4,32
-    stw   6,16(3)
-    stw   7,20(3)
-    addi  3,3,32
-#ifdef __LITTLE_ENDIAN__
-    srwi  6,8,8
-#else
-    slwi  6,8,8
-#endif
-    bdnz+ L(wdu1_loop32)
-    stw   10,-8(3)
-    stw   11,-4(3)
-
-L(wdu1_32tail):
-    mtcrf   0x01,31
-    cmplwi  cr5,31,16
-    blt     cr6,L(wdu_4tail)
-    /* calculate and store the final word */
-    lwz   8,3(4)
-#ifdef __LITTLE_ENDIAN__
-    rldimi 6,8,24,32
-#else
-/*  Equivalent to: srwi   8,8,32-8;  or    6,6,8  */
-    rlwimi 6,8,8,(32-8),31
-#endif
-    b     L(wdu_32tailx)
-
-L(wdu2_32):
-    bgt     cr1,L(wdu3_32)
-    lwz     6,-2(4)
-    cmplwi  cr6,31,4
-    srwi    8,31,5    /* calculate the 32 byte loop count */
-#ifdef __LITTLE_ENDIAN__
-    srwi    6,6,16
-#else
-    slwi    6,6,16
-#endif
-    clrlwi  31,31,27   /* The remaining bytes, < 32.  */
-    blt     cr5,L(wdu2_32tail)
-    mtctr   8
-    cmplwi  cr6,31,4
-
-    lwz   8,2(4)
-    lwz   7,4(4)
-#ifdef __LITTLE_ENDIAN__
-    rldimi 6,8,16,32
-#else
-    rlwimi 6,8,16,(32-16),31
-#endif
-    b      L(wdu2_loop32x)
-    .align  4
-L(wdu2_loop32):
-    /* copy 32 bytes at a time */
-    lwz   8,2(4)
-    lwz   7,4(4)
-    stw   10,-8(3)
-    stw   11,-4(3)
-#ifdef __LITTLE_ENDIAN__
-    rldimi 6,8,16,32
-#else
-    rlwimi 6,8,16,(32-16),31
-#endif
-L(wdu2_loop32x):
-    lwz   10,8(4)
-    lwz   11,12(4)
-    stw   6,0(3)
-    stw   7,4(3)
-    lwz   6,16(4)
-    lwz   7,20(4)
-    stw   10,8(3)
-    stw   11,12(3)
-    lwz   10,24(4)
-    lwz   11,28(4)
-/*    lwz   8,0(12) */
-    lwz   8,32-2(4)
-    addi  4,4,32
-    stw   6,16(3)
-    stw   7,20(3)
-    addi  3,3,32
-#ifdef __LITTLE_ENDIAN__
-    srwi  6,8,16
-#else
-    slwi  6,8,16
-#endif
-    bdnz+ L(wdu2_loop32)
-    stw   10,-8(3)
-    stw   11,-4(3)
-
-L(wdu2_32tail):
-    mtcrf   0x01,31
-    cmplwi  cr5,31,16
-    blt     cr6,L(wdu_4tail)
-    /* calculate and store the final word */
-    lwz   8,2(4)
-#ifdef __LITTLE_ENDIAN__
-    rldimi 6,8,16,32
-#else
-    rlwimi 6,8,16,(32-16),31
-#endif
-    b     L(wdu_32tailx)
-
-L(wdu3_32):
-/*    lwz     6,0(12) */
-    lwz     6,-3(4)
-    cmplwi  cr6,31,4
-    srwi    8,31,5    /* calculate the 32 byte loop count */
-#ifdef __LITTLE_ENDIAN__
-    srwi    6,6,24
-#else
-    slwi    6,6,24
-#endif
-    clrlwi  31,31,27   /* The remaining bytes, < 32.  */
-    blt     cr5,L(wdu3_32tail)
-    mtctr   8
-    cmplwi  cr6,31,4
-
-    lwz   8,1(4)
-    lwz   7,4(4)
-#ifdef __LITTLE_ENDIAN__
-    rldimi 6,8,8,32
-#else
-    rlwimi 6,8,24,(32-24),31
-#endif
-    b      L(wdu3_loop32x)
-    .align  4
-L(wdu3_loop32):
-    /* copy 32 bytes at a time */
-    lwz   8,1(4)
-    lwz   7,4(4)
-    stw   10,-8(3)
-    stw   11,-4(3)
-#ifdef __LITTLE_ENDIAN__
-    rldimi 6,8,8,32
-#else
-    rlwimi 6,8,24,(32-24),31
-#endif
-L(wdu3_loop32x):
-    lwz   10,8(4)
-    lwz   11,12(4)
-    stw   6,0(3)
-    stw   7,4(3)
-    lwz   6,16(4)
-    lwz   7,20(4)
-    stw   10,8(3)
-    stw   11,12(3)
-    lwz   10,24(4)
-    lwz   11,28(4)
-    lwz   8,32-3(4)
-    addi  4,4,32
-    stw   6,16(3)
-    stw   7,20(3)
-    addi  3,3,32
-#ifdef __LITTLE_ENDIAN__
-    srwi  6,8,24
-#else
-    slwi  6,8,24
-#endif
-    bdnz+ L(wdu3_loop32)
-    stw   10,-8(3)
-    stw   11,-4(3)
-
-L(wdu3_32tail):
-    mtcrf   0x01,31
-    cmplwi  cr5,31,16
-    blt     cr6,L(wdu_4tail)
-    /* calculate and store the final word */
-    lwz   8,1(4)
-#ifdef __LITTLE_ENDIAN__
-    rldimi 6,8,8,32
-#else
-    rlwimi 6,8,24,(32-24),31
-#endif
-    b     L(wdu_32tailx)
-    .align  4
-L(wdu_32tailx):
-    blt     cr5,L(wdu_t32_8)
-    lwz   7,4(4)
-    addi  12,4,16    /* generate alternate pointers to avoid agen */
-    addi  11,3,16    /* timing issues downstream.  */
-    stw   6,0(3)
-    stw   7,4(3)
-    subi  31,31,16
-    lwz   6,8(4)
-    lwz   7,12(4)
-    addi  4,4,16
-    stw   6,8(3)
-    stw   7,12(3)
-    addi  3,3,16
-    bf    28,L(wdu_t32_4x)
-    lwz   6,0(12)
-    lwz   7,4(12)
-    addi  4,4,8
-    subi  31,31,8
-    stw   6,0(11)
-    stw   7,4(11)
-    addi  3,3,8
-    bf    29,L(wdu_t32_0)
-    lwz   6,8(12)
-    addi  4,4,4
-    subi  31,31,4
-    stw   6,8(11)
-    addi  3,3,4
-    b     L(wdu_t32_0)
-    .align  4
-L(wdu_t32_4x):
-    bf    29,L(wdu_t32_0)
-    lwz   6,0(4)
-    addi  4,4,4
-    subi  31,31,4
-    stw   6,0(3)
-    addi  3,3,4
-    b     L(wdu_t32_0)
-    .align  4
-L(wdu_t32_8):
-    bf    28,L(wdu_t32_4)
-    lwz   7,4(4)
-    subi  31,31,8
-    bf    29,L(wdu_t32_8x)
-    stw   6,0(3)
-    stw   7,4(3)
-    lwz   6,8(4)
-    subi  31,31,4
-    addi  4,4,12
-    stw   6,8(3)
-    addi  3,3,12
-    b     L(wdu_t32_0)
-    .align  4
-L(wdu_t32_8x):
-    addi  4,4,8
-    stw   6,0(3)
-    stw   7,4(3)
-    addi  3,3,8
-    b     L(wdu_t32_0)
-    .align  4
-L(wdu_t32_4):
-    subi  31,31,4
-    stw   6,0(3)
-    addi  4,4,4
-    addi  3,3,4
-    .align  4
-L(wdu_t32_0):
-L(wdu_4tail):
-    cmplwi  cr6,31,0
-    beq   cr6,L(wdus_0)	/* If the tail is 0 bytes we are done!  */
-    bf    30,L(wdus_3)
-    lhz   7,0(4)
-    sth   7,0(3)
-    bf    31,L(wdus_0)
-    lbz   8,2(4)
-    stb   8,2(3)
-    mr    3,30
-    lwz   30,20(1)
-    lwz   31,24(1)
-    addi  1,1,32
-    blr
-    .align  4
-L(wdus_3):
-    bf    31,L(wus_0)
-    lbz   6,0(4)
-    stb   6,0(3)
-    .align  4
-L(wdus_0):
-  /* Return original dst pointer.  */
-    mr   3,30
-    lwz  30,20(1)
-    lwz  31,24(1)
-    addi 1,1,32
-    blr
-END (memcpy)
-
-libc_hidden_builtin_def (memcpy)
diff --git a/sysdeps/powerpc/powerpc32/power6/memset.S b/sysdeps/powerpc/powerpc32/power6/memset.S
deleted file mode 100644
index 8f5e862..0000000
--- a/sysdeps/powerpc/powerpc32/power6/memset.S
+++ /dev/null
@@ -1,539 +0,0 @@
-/* Optimized 32-bit memset implementation for POWER6.
-   Copyright (C) 1997-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* void * [r3] memset (void *s [r3], int c [r4], size_t n [r5]));
-   Returns 's'.
-
-   The memset is done in three sizes: byte (8 bits), word (32 bits),
-   cache line (1024 bits). There is a special case for setting cache lines
-   to 0, to take advantage of the dcbz instruction.  */
-
-	.machine power6
-EALIGN (memset, 7, 0)
-	CALL_MCOUNT
-
-#define rTMP	r0
-#define rRTN	r3	/* Initial value of 1st argument.  */
-#define rMEMP0	r3	/* Original value of 1st arg.  */
-#define rCHR	r4	/* Char to set in each byte.  */
-#define rLEN	r5	/* Length of region to set.  */
-#define rMEMP	r6	/* Address at which we are storing.  */
-#define rALIGN	r7	/* Number of bytes we are setting now (when aligning). */
-#define rMEMP2	r8
-
-#define rNEG64	r8	/* Constant -64 for clearing with dcbz.  */
-#define rMEMP3	r9	/* Alt mem pointer.  */
-L(_memset):
-/* Take care of case for size <= 4.  */
-	cmplwi	cr1, rLEN, 4
-	andi.	rALIGN, rMEMP0, 3
-	mr	rMEMP, rMEMP0
-	ble-	cr1, L(small)
-/* Align to word boundary.  */
-	cmplwi	cr5, rLEN, 31
-	insrwi	rCHR, rCHR, 8, 16	/* Replicate byte to halfword.  */
-	beq+	L(aligned)
-	mtcrf	0x01, rMEMP0
-	subfic	rALIGN, rALIGN, 4
-	add	rMEMP, rMEMP, rALIGN
-	sub	rLEN, rLEN, rALIGN
-	bf+	31, L(g0)
-	stb	rCHR, 0(rMEMP0)
-	bt	30, L(aligned)
-L(g0):
-	sth	rCHR, -2(rMEMP)
-
-        .align 4
-/* Handle the case of size < 31.  */
-L(aligned):
-	mtcrf	0x01, rLEN
-	insrwi	rCHR, rCHR, 16, 0	/* Replicate halfword to word.  */
-	ble	cr5, L(medium)
-/* Align to 32-byte boundary.  */
-	andi.	rALIGN, rMEMP, 0x1C
-	subfic	rALIGN, rALIGN, 0x20
-	beq	L(caligned)
-	mtcrf	0x01, rALIGN
-	add	rMEMP, rMEMP, rALIGN
-	sub	rLEN, rLEN, rALIGN
-	cmplwi	cr1, rALIGN, 0x10
-	mr	rMEMP2, rMEMP
-	bf	28, L(a1)
-        stw     rCHR, -4(rMEMP2)
-	stwu	rCHR, -8(rMEMP2)
-	nop
-L(a1):	blt	cr1, L(a2)
-        stw     rCHR, -4(rMEMP2)
-	stw	rCHR, -8(rMEMP2)
-	stw	rCHR, -12(rMEMP2)
-	stwu	rCHR, -16(rMEMP2)
-L(a2):  bf      29, L(caligned)
-        stw     rCHR, -4(rMEMP2)
-
-        .align 3
-/* Now aligned to a 32 byte boundary.  */
-L(caligned):
-	cmplwi	cr1, rCHR, 0
-	clrrwi.	rALIGN, rLEN, 5
-	mtcrf	0x01, rLEN
-	beq	cr1, L(zloopstart) /* Special case for clearing memory using dcbz.  */
-L(nondcbz):
-	beq	L(medium)	/* We may not actually get to do a full line.  */
-	nop
-/* Storing a non-zero "c" value. We are aligned at a sector (32-byte)
-   boundary may not be at cache line (128-byte) boundary.  */
-L(nzloopstart):
-/* memset in 32-byte chunks until we get to a cache line boundary.
-   If rLEN is less than the distance to the next cache-line boundary use
-   cacheAligned1 code to finish the tail.  */
-	cmplwi	cr1,rLEN,128
-
-	andi.	rTMP,rMEMP,127
-	blt	cr1,L(cacheAligned1)
-	addi	rMEMP3,rMEMP,32
-	beq	L(nzCacheAligned)
-	addi	rLEN,rLEN,-32
-	stw	rCHR,0(rMEMP)
-        stw     rCHR,4(rMEMP)
-	stw	rCHR,8(rMEMP)
-	stw     rCHR,12(rMEMP)
-	stw	rCHR,16(rMEMP)
-        stw     rCHR,20(rMEMP)
-	addi	rMEMP,rMEMP,32
-	andi.	rTMP,rMEMP3,127
-	stw	rCHR,-8(rMEMP3)
-        stw     rCHR,-4(rMEMP3)
-
-	beq	L(nzCacheAligned)
-	addi	rLEN,rLEN,-32
-	stw	rCHR,0(rMEMP3)
-        stw     rCHR,4(rMEMP3)
-	addi	rMEMP,rMEMP,32
-	stw	rCHR,8(rMEMP3)
-	stw     rCHR,12(rMEMP3)
-	andi.	rTMP,rMEMP,127
-	stw	rCHR,16(rMEMP3)
-        stw     rCHR,20(rMEMP3)
-	stw	rCHR,24(rMEMP3)
-        stw     rCHR,28(rMEMP3)
-
-	beq	L(nzCacheAligned)
-	addi	rLEN,rLEN,-32
-/* At this point we can overrun the store queue (pipe reject) so it is
-   time to slow things down. The store queue can merge two adjacent
-   stores into a single L1/L2 op, but the L2 is clocked at 1/2 the CPU.
-   So we add "group ending nops" to guarantee that we dispatch only two
-   stores every other cycle. */
-	ori	r1,r1,0
-	ori	r1,r1,0
-	stw	rCHR,32(rMEMP3)
-        stw     rCHR,36(rMEMP3)
-	addi	rMEMP,rMEMP,32
-	cmplwi	cr1,rLEN,128
-	ori	r1,r1,0
-	ori	r1,r1,0
-	stw	rCHR,40(rMEMP3)
-	stw     rCHR,44(rMEMP3)
-	ori	r1,r1,0
-	ori	r1,r1,0
-	stw	rCHR,48(rMEMP3)
-        stw     rCHR,52(rMEMP3)
-	ori	r1,r1,0
-	ori	r1,r1,0
-	stw	rCHR,56(rMEMP3)
-        stw     rCHR,60(rMEMP3)
-	blt	cr1,L(cacheAligned1)
-	b	L(nzCacheAligned)
-
-/* Now we are aligned to the cache line and can use dcbtst.  */
-        .align 5
-L(nzCacheAligned):
-	cmplwi	cr1,rLEN,128
-	cmplwi	cr6,rLEN,256
-	blt	cr1,L(cacheAligned1)
-	blt	cr6,L(nzCacheAligned128)
-        .align 4
-L(nzCacheAligned128):
-	nop
-	addi	rMEMP3,rMEMP,64
-	stw	rCHR,0(rMEMP)
-        stw     rCHR,4(rMEMP)
-	stw	rCHR,8(rMEMP)
-	stw     rCHR,12(rMEMP)
-	stw	rCHR,16(rMEMP)
-        stw     rCHR,20(rMEMP)
-	stw	rCHR,24(rMEMP)
-        stw     rCHR,28(rMEMP)
-	stw	rCHR,32(rMEMP)
-        stw     rCHR,36(rMEMP)
-	stw	rCHR,40(rMEMP)
-	stw     rCHR,44(rMEMP)
-	stw	rCHR,48(rMEMP)
-        stw     rCHR,52(rMEMP)
-	stw	rCHR,56(rMEMP)
-        stw     rCHR,60(rMEMP)
-	addi	rMEMP,rMEMP3,64
-	addi	rLEN,rLEN,-128
-/* At this point we can overrun the store queue (pipe reject) so it is
-   time to slow things down. The store queue can merge two adjacent
-   stores into a single L1/L2 op, but the L2 is clocked at 1/2 the CPU.
-   So we add "group ending nops" to guarantee that we dispatch only one
-   store per cycle. */
-	stw	rCHR,0(rMEMP3)
-	ori	r1,r1,0
-        stw     rCHR,4(rMEMP3)
-	ori	r1,r1,0
-	stw	rCHR,8(rMEMP3)
-	ori	r1,r1,0
-	stw     rCHR,12(rMEMP3)
-	ori	r1,r1,0
-	stw	rCHR,16(rMEMP3)
-	ori	r1,r1,0
-        stw     rCHR,20(rMEMP3)
-	ori	r1,r1,0
-	stw	rCHR,24(rMEMP3)
-	ori	r1,r1,0
-        stw     rCHR,28(rMEMP3)
-	ori	r1,r1,0
-	stw	rCHR,32(rMEMP3)
-	ori	r1,r1,0
-        stw     rCHR,36(rMEMP3)
-	ori	r1,r1,0
-	stw	rCHR,40(rMEMP3)
-	ori	r1,r1,0
-	stw     rCHR,44(rMEMP3)
-	ori	r1,r1,0
-	stw	rCHR,48(rMEMP3)
-	ori	r1,r1,0
-        stw     rCHR,52(rMEMP3)
-	ori	r1,r1,0
-	stw	rCHR,56(rMEMP3)
-	ori	r1,r1,0
-        stw     rCHR,60(rMEMP3)
-	blt	cr6,L(cacheAligned1)
-#if IS_IN (libc)
-	lfd	0,-128(rMEMP)
-#endif
-	b	L(nzCacheAligned256)
-        .align 5
-L(nzCacheAligned256):
-	cmplwi	cr1,rLEN,256
-	addi	rMEMP3,rMEMP,64
-#if !IS_IN (libc)
-/* When we are not in libc we should use only GPRs to avoid the FPU lock
-   interrupt.  */
-	stw	rCHR,0(rMEMP)
-        stw     rCHR,4(rMEMP)
-	stw	rCHR,8(rMEMP)
-	stw     rCHR,12(rMEMP)
-	stw	rCHR,16(rMEMP)
-        stw     rCHR,20(rMEMP)
-	stw	rCHR,24(rMEMP)
-        stw     rCHR,28(rMEMP)
-	stw	rCHR,32(rMEMP)
-        stw     rCHR,36(rMEMP)
-	stw	rCHR,40(rMEMP)
-	stw     rCHR,44(rMEMP)
-	stw	rCHR,48(rMEMP)
-        stw     rCHR,52(rMEMP)
-	stw	rCHR,56(rMEMP)
-        stw     rCHR,60(rMEMP)
-	addi	rMEMP,rMEMP3,64
-	addi	rLEN,rLEN,-128
-	stw	rCHR,0(rMEMP3)
-        stw     rCHR,4(rMEMP3)
-	stw	rCHR,8(rMEMP3)
-	stw     rCHR,12(rMEMP3)
-	stw	rCHR,16(rMEMP3)
-        stw     rCHR,20(rMEMP3)
-	stw	rCHR,24(rMEMP3)
-        stw     rCHR,28(rMEMP3)
-	stw	rCHR,32(rMEMP3)
-        stw     rCHR,36(rMEMP3)
-	stw	rCHR,40(rMEMP3)
-	stw     rCHR,44(rMEMP3)
-	stw	rCHR,48(rMEMP3)
-        stw     rCHR,52(rMEMP3)
-	stw	rCHR,56(rMEMP3)
-        stw     rCHR,60(rMEMP3)
-#else
-/* We are in libc and this is a long memset so we can use FPRs and can afford
-   occasional FPU locked interrupts.  */
-	stfd	0,0(rMEMP)
-	stfd	0,8(rMEMP)
-	stfd	0,16(rMEMP)
-	stfd	0,24(rMEMP)
-	stfd	0,32(rMEMP)
-	stfd	0,40(rMEMP)
-	stfd	0,48(rMEMP)
-	stfd	0,56(rMEMP)
-	addi	rMEMP,rMEMP3,64
-	addi	rLEN,rLEN,-128
-	stfd	0,0(rMEMP3)
-	stfd	0,8(rMEMP3)
-	stfd	0,16(rMEMP3)
-	stfd	0,24(rMEMP3)
-	stfd	0,32(rMEMP3)
-	stfd	0,40(rMEMP3)
-	stfd	0,48(rMEMP3)
-	stfd	0,56(rMEMP3)
-#endif
-	bge	cr1,L(nzCacheAligned256)
-	dcbtst	0,rMEMP
-	b	L(cacheAligned1)
-
-	.align 4
-/* Storing a zero "c" value. We are aligned at a sector (32-byte)
-   boundary but may not be at cache line (128-byte) boundary.  If the
-   remaining length spans a full cache line we can use the Data cache
-   block zero instruction. */
-L(zloopstart):
-/* memset in 32-byte chunks until we get to a cache line boundary.
-   If rLEN is less than the distance to the next cache-line boundary use
-   cacheAligned1 code to finish the tail.  */
-	cmplwi	cr1,rLEN,128
-	beq	L(medium)
-L(getCacheAligned):
-	andi.	rTMP,rMEMP,127
-	blt	cr1,L(cacheAligned1)
-	addi	rMEMP3,rMEMP,32
-	beq	L(cacheAligned)
-	addi	rLEN,rLEN,-32
-	stw	rCHR,0(rMEMP)
-        stw     rCHR,4(rMEMP)
-	stw	rCHR,8(rMEMP)
-	stw     rCHR,12(rMEMP)
-	stw	rCHR,16(rMEMP)
-        stw     rCHR,20(rMEMP)
-	addi	rMEMP,rMEMP,32
-	andi.	rTMP,rMEMP3,127
-	stw	rCHR,-8(rMEMP3)
-        stw     rCHR,-4(rMEMP3)
-L(getCacheAligned2):
-	beq	L(cacheAligned)
-	addi	rLEN,rLEN,-32
-	addi	rMEMP,rMEMP,32
-	stw	rCHR,0(rMEMP3)
-        stw     rCHR,4(rMEMP3)
-	stw	rCHR,8(rMEMP3)
-	stw     rCHR,12(rMEMP3)
-	andi.	rTMP,rMEMP,127
-	nop
-	stw	rCHR,16(rMEMP3)
-        stw     rCHR,20(rMEMP3)
-	stw	rCHR,24(rMEMP3)
-        stw     rCHR,28(rMEMP3)
-L(getCacheAligned3):
-	beq	L(cacheAligned)
-/* At this point we can overrun the store queue (pipe reject) so it is
-   time to slow things down. The store queue can merge two adjacent
-   stores into a single L1/L2 op, but the L2 is clocked at 1/2 the CPU.
-   So we add "group ending nops" to guarantee that we dispatch only two
-   stores every other cycle. */
-	addi	rLEN,rLEN,-32
-	ori	r1,r1,0
-	ori	r1,r1,0
-	stw	rCHR,32(rMEMP3)
-        stw     rCHR,36(rMEMP3)
-	addi	rMEMP,rMEMP,32
-	cmplwi	cr1,rLEN,128
-	ori	r1,r1,0
-	stw	rCHR,40(rMEMP3)
-	stw     rCHR,44(rMEMP3)
-	cmplwi	cr6,rLEN,256
-	li	rMEMP2,128
-	ori	r1,r1,0
-	stw	rCHR,48(rMEMP3)
-        stw     rCHR,52(rMEMP3)
-	ori	r1,r1,0
-	ori	r1,r1,0
-	stw	rCHR,56(rMEMP3)
-        stw     rCHR,60(rMEMP3)
-	blt	cr1,L(cacheAligned1)
-	blt	cr6,L(cacheAligned128)
-	b	L(cacheAlignedx)
-
-/* Now we are aligned to the cache line and can use dcbz.  */
-        .align 4
-L(cacheAligned):
-	cmplwi	cr1,rLEN,128
-	cmplwi	cr6,rLEN,256
-	blt	cr1,L(cacheAligned1)
-	li	rMEMP2,128
-L(cacheAlignedx):
-	cmplwi	cr5,rLEN,640
-	blt	cr6,L(cacheAligned128)
-	bgt	cr5,L(cacheAligned512)
-	cmplwi	cr6,rLEN,512
-	dcbz	0,rMEMP
-	cmplwi	cr1,rLEN,384
-	dcbz	rMEMP2,rMEMP
-	addi	rMEMP,rMEMP,256
-	addi	rLEN,rLEN,-256
-	blt	cr1,L(cacheAligned1)
-	blt	cr6,L(cacheAligned128)
-	b	L(cacheAligned256)
-	.align 5
-/* A simple loop for the longer (>640 bytes) lengths.  This form limits
-   the branch miss-predicted to exactly 1 at loop exit.*/
-L(cacheAligned512):
-	cmplwi	cr1,rLEN,128
-	blt	cr1,L(cacheAligned1)
-	dcbz	0,rMEMP
-	addi	rLEN,rLEN,-128
-	addi	rMEMP,rMEMP,128
-	b	L(cacheAligned512)
-        .align 5
-L(cacheAligned256):
-	cmplwi	cr6,rLEN,512
-	dcbz	0,rMEMP
-	cmplwi	cr1,rLEN,384
-	dcbz	rMEMP2,rMEMP
-	addi	rMEMP,rMEMP,256
-	addi	rLEN,rLEN,-256
-	bge	cr6,L(cacheAligned256)
-	blt	cr1,L(cacheAligned1)
-        .align 4
-L(cacheAligned128):
-	dcbz	0,rMEMP
-	addi	rMEMP,rMEMP,128
-	addi	rLEN,rLEN,-128
-        .align 4
-L(cacheAligned1):
-	cmplwi	cr1,rLEN,32
-	blt	cr1,L(handletail32)
-	addi	rMEMP3,rMEMP,32
-	addi	rLEN,rLEN,-32
-	stw	rCHR,0(rMEMP)
-        stw     rCHR,4(rMEMP)
-	stw	rCHR,8(rMEMP)
-	stw     rCHR,12(rMEMP)
-	stw	rCHR,16(rMEMP)
-        stw     rCHR,20(rMEMP)
-	addi	rMEMP,rMEMP,32
-	cmplwi	cr1,rLEN,32
-	stw	rCHR,-8(rMEMP3)
-        stw     rCHR,-4(rMEMP3)
-L(cacheAligned2):
-	blt	cr1,L(handletail32)
-	addi	rLEN,rLEN,-32
-	stw	rCHR,0(rMEMP3)
-        stw     rCHR,4(rMEMP3)
-	stw	rCHR,8(rMEMP3)
-	stw     rCHR,12(rMEMP3)
-	addi	rMEMP,rMEMP,32
-	cmplwi	cr1,rLEN,32
-	stw	rCHR,16(rMEMP3)
-        stw     rCHR,20(rMEMP3)
-	stw	rCHR,24(rMEMP3)
-        stw     rCHR,28(rMEMP3)
-	nop
-L(cacheAligned3):
-	blt	cr1,L(handletail32)
-/* At this point we can overrun the store queue (pipe reject) so it is
-   time to slow things down. The store queue can merge two adjacent
-   stores into a single L1/L2 op, but the L2 is clocked at 1/2 the CPU.
-   So we add "group ending nops" to guarantee that we dispatch only two
-   stores every other cycle. */
-	ori	r1,r1,0
-	ori	r1,r1,0
-	addi	rMEMP,rMEMP,32
-	addi	rLEN,rLEN,-32
-	ori	r1,r1,0
-	ori	r1,r1,0
-	stw	rCHR,32(rMEMP3)
-        stw     rCHR,36(rMEMP3)
-	ori	r1,r1,0
-	ori	r1,r1,0
-	stw	rCHR,40(rMEMP3)
-	stw     rCHR,44(rMEMP3)
-	ori	r1,r1,0
-	ori	r1,r1,0
-	stw	rCHR,48(rMEMP3)
-        stw     rCHR,52(rMEMP3)
-	ori	r1,r1,0
-	ori	r1,r1,0
-	stw	rCHR,56(rMEMP3)
-        stw     rCHR,60(rMEMP3)
-
-/* We are here because the length or remainder (rLEN) is less than the
-   cache line/sector size and does not justify aggressive loop unrolling.
-   So set up the preconditions for L(medium) and go there.  */
-        .align 3
-L(handletail32):
-	cmplwi	cr1,rLEN,0
-	beqlr   cr1
-	b	L(medium)
-
-	.align 4
-L(small):
-/* Memset of 4 bytes or less.  */
-	cmplwi	cr5, rLEN, 1
-	cmplwi	cr1, rLEN, 3
-	bltlr	cr5
-	stb	rCHR, 0(rMEMP)
-	beqlr	cr5
-	stb	rCHR, 1(rMEMP)
-	bltlr	cr1
-	stb	rCHR, 2(rMEMP)
-	beqlr	cr1
-	stb	rCHR, 3(rMEMP)
-	blr
-
-/* Memset of 0-31 bytes.  */
-	.align 5
-L(medium):
-	cmplwi	cr1, rLEN, 16
-L(medium_tail2):
-	add	rMEMP, rMEMP, rLEN
-L(medium_tail):
-	bt-	31, L(medium_31t)
-	bt-	30, L(medium_30t)
-L(medium_30f):
-	bt	29, L(medium_29t)
-L(medium_29f):
-	bge	cr1, L(medium_27t)
-	bflr	28
-        stw     rCHR, -4(rMEMP)
-	stw	rCHR, -8(rMEMP)
-	blr
-
-L(medium_31t):
-	stbu	rCHR, -1(rMEMP)
-	bf-	30, L(medium_30f)
-L(medium_30t):
-	sthu	rCHR, -2(rMEMP)
-	bf-	29, L(medium_29f)
-L(medium_29t):
-	stwu	rCHR, -4(rMEMP)
-	blt	cr1, L(medium_27f)
-L(medium_27t):
-        stw     rCHR, -4(rMEMP)
-	stw	rCHR, -8(rMEMP)
-        stw     rCHR, -12(rMEMP)
-	stwu	rCHR, -16(rMEMP)
-L(medium_27f):
-	bflr	28
-L(medium_28t):
-        stw     rCHR, -4(rMEMP)
-	stw	rCHR, -8(rMEMP)
-	blr
-END (memset)
-libc_hidden_builtin_def (memset)
diff --git a/sysdeps/powerpc/powerpc32/power7/memchr.S b/sysdeps/powerpc/powerpc32/power7/memchr.S
deleted file mode 100644
index ec78709..0000000
--- a/sysdeps/powerpc/powerpc32/power7/memchr.S
+++ /dev/null
@@ -1,193 +0,0 @@
-/* Optimized memchr implementation for PowerPC32/POWER7 using cmpb insn.
-   Copyright (C) 2010-2018 Free Software Foundation, Inc.
-   Contributed by Luis Machado <luisgpm@br.ibm.com>.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* int [r3] memchr (char *s [r3], int byte [r4], int size [r5])  */
-	.machine  power7
-ENTRY (__memchr)
-	CALL_MCOUNT
-	dcbt	0,r3
-	clrrwi  r8,r3,2
-	insrwi	r4,r4,8,16    /* Replicate byte to word.  */
-
-	/* Calculate the last acceptable address and check for possible
-	   addition overflow by using satured math:
-	   r7 = r3 + r5
-	   r7 |= -(r7 < x)  */
-	add     r7,r3,r5
-	subfc   r6,r3,r7
-	subfe   r9,r9,r9
-	or      r7,r7,r9
-
-	insrwi	r4,r4,16,0
-	cmplwi	r5,16
-	li	r9, -1
-	rlwinm	r6,r3,3,27,28 /* Calculate padding.  */
-	addi	r7,r7,-1
-#ifdef __LITTLE_ENDIAN__
-	slw	r9,r9,r6
-#else
-	srw	r9,r9,r6
-#endif
-	ble	L(small_range)
-
-	lwz	r12,0(r8)     /* Load word from memory.  */
-	cmpb	r3,r12,r4     /* Check for BYTEs in WORD1.  */
-	and	r3,r3,r9
-	clrlwi	r5,r7,30      /* Byte count - 1 in last word.  */
-	clrrwi	r7,r7,2       /* Address of last word.  */
-	cmplwi	cr7,r3,0      /* If r3 == 0, no BYTEs have been found.  */
-	bne	cr7,L(done)
-
-	mtcrf   0x01,r8
-	/* Are we now aligned to a doubleword boundary?  If so, skip to
-	   the main loop.  Otherwise, go through the alignment code.  */
-	bt	29,L(loop_setup)
-
-	/* Handle WORD2 of pair.  */
-	lwzu	r12,4(r8)
-	cmpb	r3,r12,r4
-	cmplwi	cr7,r3,0
-	bne	cr7,L(done)
-
-L(loop_setup):
-	/* The last word we want to read in the loop below is the one
-	   containing the last byte of the string, ie. the word at
-	   (s + size - 1) & ~3, or r7.  The first word read is at
-	   r8 + 4, we read 2 * cnt words, so the last word read will
-	   be at r8 + 4 + 8 * cnt - 4.  Solving for cnt gives
-	   cnt = (r7 - r8) / 8  */
-	sub	r6,r7,r8
-	srwi	r6,r6,3	      /* Number of loop iterations.  */
-	mtctr	r6            /* Setup the counter.  */
-
-	/* Main loop to look for BYTE in the string.  Since
-	   it's a small loop (8 instructions), align it to 32-bytes.  */
-	.align	5
-L(loop):
-	/* Load two words, compare and merge in a
-	   single register for speed.  This is an attempt
-	   to speed up the byte-checking process for bigger strings.  */
-	lwz	r12,4(r8)
-	lwzu	r11,8(r8)
-	cmpb	r3,r12,r4
-	cmpb	r9,r11,r4
-	or	r6,r9,r3      /* Merge everything in one word.  */
-	cmplwi	cr7,r6,0
-	bne	cr7,L(found)
-	bdnz	L(loop)
-
-	/* We may have one more dword to read.  */
-	cmplw	r8,r7
-	beqlr
-
-	lwzu	r12,4(r8)
-	cmpb	r3,r12,r4
-	cmplwi	cr6,r3,0
-	bne	cr6,L(done)
-	blr
-
-	.align	4
-L(found):
-	/* OK, one (or both) of the words contains BYTE.  Check
-	   the first word and decrement the address in case the first
-	   word really contains BYTE.  */
-	cmplwi	cr6,r3,0
-	addi	r8,r8,-4
-	bne	cr6,L(done)
-
-	/* BYTE must be in the second word.  Adjust the address
-	   again and move the result of cmpb to r3 so we can calculate the
-	   pointer.  */
-
-	mr	r3,r9
-	addi	r8,r8,4
-
-	/* r3 has the output of the cmpb instruction, that is, it contains
-	   0xff in the same position as BYTE in the original
-	   word from the string.  Use that to calculate the pointer.
-	   We need to make sure BYTE is *before* the end of the range.  */
-L(done):
-#ifdef __LITTLE_ENDIAN__
-	addi    r0,r3,-1
-	andc    r0,r0,r3
-	popcntw	r0,r0	      /* Count trailing zeros.  */
-#else
-	cntlzw	r0,r3	      /* Count leading zeros before the match.  */
-#endif
-	cmplw	r8,r7         /* Are we on the last word?  */
-	srwi	r0,r0,3	      /* Convert leading/trailing zeros to bytes.  */
-	add	r3,r8,r0
-	cmplw	cr7,r0,r5     /* If on the last dword, check byte offset.  */
-	bnelr
-	blelr	cr7
-	li	r3,0
-	blr
-
-	.align	4
-L(null):
-	li	r3,0
-	blr
-
-/* Deals with size <= 16.  */
-	.align	4
-L(small_range):
-	cmplwi	r5,0
-	beq	L(null)
-	lwz	r12,0(r8)     /* Load word from memory.  */
-	cmpb	r3,r12,r4     /* Check for BYTE in DWORD1.  */
-	and	r3,r3,r9
-	cmplwi	cr7,r3,0
-	clrlwi	r5,r7,30      /* Byte count - 1 in last word.  */
-	clrrwi	r7,r7,2       /* Address of last word.  */
-	cmplw	r8,r7         /* Are we done already?  */
-	bne	cr7,L(done)
-	beqlr
-
-	lwzu	r12,4(r8)
-	cmpb	r3,r12,r4
-	cmplwi	cr6,r3,0
-	cmplw	r8,r7
-	bne	cr6,L(done)
-	beqlr
-
-	lwzu	r12,4(r8)
-	cmpb	r3,r12,r4
-	cmplwi	cr6,r3,0
-	cmplw	r8,r7
-	bne	cr6,L(done)
-	beqlr
-
-	lwzu	r12,4(r8)
-	cmpb	r3,r12,r4
-	cmplwi	cr6,r3,0
-	cmplw	r8,r7
-	bne	cr6,L(done)
-	beqlr
-
-	lwzu	r12,4(r8)
-	cmpb	r3,r12,r4
-	cmplwi	cr6,r3,0
-	bne	cr6,L(done)
-	blr
-
-END (__memchr)
-weak_alias (__memchr, memchr)
-libc_hidden_builtin_def (memchr)
diff --git a/sysdeps/powerpc/powerpc32/power7/memcmp.S b/sysdeps/powerpc/powerpc32/power7/memcmp.S
deleted file mode 100644
index 8c1a00d..0000000
--- a/sysdeps/powerpc/powerpc32/power7/memcmp.S
+++ /dev/null
@@ -1,1375 +0,0 @@
-/* Optimized memcmp implementation for POWER7/PowerPC32.
-   Copyright (C) 2010-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* int [r3] memcmp (const char *s1 [r3],
-		    const char *s2 [r4],
-		    size_t size [r5])  */
-
-	.machine power7
-EALIGN (memcmp, 4, 0)
-	CALL_MCOUNT
-
-#define rRTN	r3
-#define rSTR1	r3	/* first string arg */
-#define rSTR2	r4	/* second string arg */
-#define rN	r5	/* max string length */
-#define rWORD1	r6	/* current word in s1 */
-#define rWORD2	r7	/* current word in s2 */
-#define rWORD3	r8	/* next word in s1 */
-#define rWORD4	r9	/* next word in s2 */
-#define rWORD5	r10	/* next word in s1 */
-#define rWORD6	r11	/* next word in s2 */
-#define rWORD7	r30	/* next word in s1 */
-#define rWORD8	r31	/* next word in s2 */
-
-	xor	r0, rSTR2, rSTR1
-	cmplwi	cr6, rN, 0
-	cmplwi	cr1, rN, 12
-	clrlwi.	r0, r0, 30
-	clrlwi	r12, rSTR1, 30
-	cmplwi	cr5, r12, 0
-	beq-	cr6, L(zeroLength)
-	dcbt	0, rSTR1
-	dcbt	0, rSTR2
-/* If less than 8 bytes or not aligned, use the unaligned
-   byte loop.  */
-	blt	cr1, L(bytealigned)
-	stwu	1, -64(r1)
-	cfi_adjust_cfa_offset(64)
-	stw	rWORD8, 48(r1)
-	stw	rWORD7, 44(r1)
-	cfi_offset(rWORD8, (48-64))
-	cfi_offset(rWORD7, (44-64))
-	bne	L(unaligned)
-/* At this point we know both strings have the same alignment and the
-   compare length is at least 8 bytes.  r12 contains the low order
-   2 bits of rSTR1 and cr5 contains the result of the logical compare
-   of r12 to 0.  If r12 == 0 then we are already word
-   aligned and can perform the word aligned loop.
-
-   Otherwise we know the two strings have the same alignment (but not
-   yet word aligned).  So we force the string addresses to the next lower
-   word boundary and special case this first word using shift left to
-   eliminate bits preceding the first byte.  Since we want to join the
-   normal (word aligned) compare loop, starting at the second word,
-   we need to adjust the length (rN) and special case the loop
-   versioning for the first word. This ensures that the loop count is
-   correct and the first word (shifted) is in the expected register pair. */
-	.align	4
-L(samealignment):
-	clrrwi	rSTR1, rSTR1, 2
-	clrrwi	rSTR2, rSTR2, 2
-	beq	cr5, L(Waligned)
-	add	rN, rN, r12
-	slwi	rWORD6, r12, 3
-	srwi	r0, rN, 4	/* Divide by 16 */
-	andi.	r12, rN, 12	/* Get the word remainder */
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD1, 0, rSTR1
-	lwbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD1, 0(rSTR1)
-	lwz	rWORD2, 0(rSTR2)
-#endif
-	cmplwi	cr1, r12, 8
-	cmplwi	cr7, rN, 16
-	clrlwi	rN, rN, 30
-	beq	L(dPs4)
-	mtctr	r0
-	bgt	cr1, L(dPs3)
-	beq	cr1, L(dPs2)
-
-/* Remainder is 4 */
-	.align	3
-L(dsP1):
-	slw	rWORD5, rWORD1, rWORD6
-	slw	rWORD6, rWORD2, rWORD6
-	cmplw	cr5, rWORD5, rWORD6
-	blt	cr7, L(dP1x)
-/* Do something useful in this cycle since we have to branch anyway.  */
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD1, 0, rSTR1
-	lwbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD1, 4(rSTR1)
-	lwz	rWORD2, 4(rSTR2)
-#endif
-	cmplw	cr7, rWORD1, rWORD2
-	b	L(dP1e)
-/* Remainder is 8 */
-	.align	4
-L(dPs2):
-	slw	rWORD5, rWORD1, rWORD6
-	slw	rWORD6, rWORD2, rWORD6
-	cmplw	cr6, rWORD5, rWORD6
-	blt	cr7, L(dP2x)
-/* Do something useful in this cycle since we have to branch anyway.  */
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD7, 0, rSTR1
-	lwbrx	rWORD8, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD7, 4(rSTR1)
-	lwz	rWORD8, 4(rSTR2)
-#endif
-	cmplw	cr5, rWORD7, rWORD8
-	b	L(dP2e)
-/* Remainder is 12 */
-	.align	4
-L(dPs3):
-	slw	rWORD3, rWORD1, rWORD6
-	slw	rWORD4, rWORD2, rWORD6
-	cmplw	cr1, rWORD3, rWORD4
-	b	L(dP3e)
-/* Count is a multiple of 16, remainder is 0 */
-	.align	4
-L(dPs4):
-	mtctr	r0
-	slw	rWORD1, rWORD1, rWORD6
-	slw	rWORD2, rWORD2, rWORD6
-	cmplw	cr7, rWORD1, rWORD2
-	b	L(dP4e)
-
-/* At this point we know both strings are word aligned and the
-   compare length is at least 8 bytes.  */
-	.align	4
-L(Waligned):
-	andi.	r12, rN, 12	/* Get the word remainder */
-	srwi	r0, rN, 4	/* Divide by 16 */
-	cmplwi	cr1, r12, 8
-	cmplwi	cr7, rN, 16
-	clrlwi	rN, rN, 30
-	beq	L(dP4)
-	bgt	cr1, L(dP3)
-	beq	cr1, L(dP2)
-
-/* Remainder is 4 */
-	.align	4
-L(dP1):
-	mtctr	r0
-/* Normally we'd use rWORD7/rWORD8 here, but since we might exit early
-   (8-15 byte compare), we want to use only volatile registers.  This
-   means we can avoid restoring non-volatile registers since we did not
-   change any on the early exit path.  The key here is the non-early
-   exit path only cares about the condition code (cr5), not about which
-   register pair was used.  */
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD5, 0, rSTR1
-	lwbrx	rWORD6, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD5, 0(rSTR1)
-	lwz	rWORD6, 0(rSTR2)
-#endif
-	cmplw	cr5, rWORD5, rWORD6
-	blt	cr7, L(dP1x)
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD1, 0, rSTR1
-	lwbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD1, 4(rSTR1)
-	lwz	rWORD2, 4(rSTR2)
-#endif
-	cmplw	cr7, rWORD1, rWORD2
-L(dP1e):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD3, 0, rSTR1
-	lwbrx	rWORD4, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD3, 8(rSTR1)
-	lwz	rWORD4, 8(rSTR2)
-#endif
-	cmplw	cr1, rWORD3, rWORD4
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD5, 0, rSTR1
-	lwbrx	rWORD6, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD5, 12(rSTR1)
-	lwz	rWORD6, 12(rSTR2)
-#endif
-	cmplw	cr6, rWORD5, rWORD6
-	bne	cr5, L(dLcr5x)
-	bne	cr7, L(dLcr7x)
-
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD7, 0, rSTR1
-	lwbrx	rWORD8, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwzu	rWORD7, 16(rSTR1)
-	lwzu	rWORD8, 16(rSTR2)
-#endif
-	bne	cr1, L(dLcr1)
-	cmplw	cr5, rWORD7, rWORD8
-	bdnz	L(dLoop)
-	bne	cr6, L(dLcr6)
-	lwz	rWORD7, 44(r1)
-	lwz	rWORD8, 48(r1)
-	.align	3
-L(dP1x):
-	slwi.	r12, rN, 3
-	bne	cr5, L(dLcr5x)
-	subfic	rN, r12, 32	/* Shift count is 32 - (rN * 8).  */
-	addi	r1, r1, 64
-	cfi_adjust_cfa_offset(-64)
-	bne	L(d00)
-	li	rRTN, 0
-	blr
-
-/* Remainder is 8 */
-	.align	4
-	cfi_adjust_cfa_offset(64)
-L(dP2):
-	mtctr	r0
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD5, 0, rSTR1
-	lwbrx	rWORD6, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD5, 0(rSTR1)
-	lwz	rWORD6, 0(rSTR2)
-#endif
-	cmplw	cr6, rWORD5, rWORD6
-	blt	cr7, L(dP2x)
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD7, 0, rSTR1
-	lwbrx	rWORD8, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD7, 4(rSTR1)
-	lwz	rWORD8, 4(rSTR2)
-#endif
-	cmplw	cr5, rWORD7, rWORD8
-L(dP2e):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD1, 0, rSTR1
-	lwbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD1, 8(rSTR1)
-	lwz	rWORD2, 8(rSTR2)
-#endif
-	cmplw	cr7, rWORD1, rWORD2
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD3, 0, rSTR1
-	lwbrx	rWORD4, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD3, 12(rSTR1)
-	lwz	rWORD4, 12(rSTR2)
-#endif
-	cmplw	cr1, rWORD3, rWORD4
-#ifndef __LITTLE_ENDIAN__
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#endif
-	bne	cr6, L(dLcr6)
-	bne	cr5, L(dLcr5)
-	b	L(dLoop2)
-/* Again we are on a early exit path (16-23 byte compare), we want to
-   only use volatile registers and avoid restoring non-volatile
-   registers.  */
-	.align	4
-L(dP2x):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD3, 0, rSTR1
-	lwbrx	rWORD4, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD3, 4(rSTR1)
-	lwz	rWORD4, 4(rSTR2)
-#endif
-	cmplw	cr1, rWORD3, rWORD4
-	slwi.	r12, rN, 3
-	bne	cr6, L(dLcr6x)
-#ifndef __LITTLE_ENDIAN__
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#endif
-	bne	cr1, L(dLcr1x)
-	subfic	rN, r12, 32	/* Shift count is 32 - (rN * 8).  */
-	addi	r1, r1, 64
-	cfi_adjust_cfa_offset(-64)
-	bne	L(d00)
-	li	rRTN, 0
-	blr
-
-/* Remainder is 12 */
-	.align	4
-	cfi_adjust_cfa_offset(64)
-L(dP3):
-	mtctr	r0
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD3, 0, rSTR1
-	lwbrx	rWORD4, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD3, 0(rSTR1)
-	lwz	rWORD4, 0(rSTR2)
-#endif
-	cmplw	cr1, rWORD3, rWORD4
-L(dP3e):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD5, 0, rSTR1
-	lwbrx	rWORD6, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD5, 4(rSTR1)
-	lwz	rWORD6, 4(rSTR2)
-#endif
-	cmplw	cr6, rWORD5, rWORD6
-	blt	cr7, L(dP3x)
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD7, 0, rSTR1
-	lwbrx	rWORD8, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD7, 8(rSTR1)
-	lwz	rWORD8, 8(rSTR2)
-#endif
-	cmplw	cr5, rWORD7, rWORD8
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD1, 0, rSTR1
-	lwbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD1, 12(rSTR1)
-	lwz	rWORD2, 12(rSTR2)
-#endif
-	cmplw	cr7, rWORD1, rWORD2
-#ifndef __LITTLE_ENDIAN__
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#endif
-	bne	cr1, L(dLcr1)
-	bne	cr6, L(dLcr6)
-	b	L(dLoop1)
-/* Again we are on a early exit path (24-31 byte compare), we want to
-   only use volatile registers and avoid restoring non-volatile
-   registers.  */
-	.align	4
-L(dP3x):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD1, 0, rSTR1
-	lwbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD1, 8(rSTR1)
-	lwz	rWORD2, 8(rSTR2)
-#endif
-	cmplw	cr7, rWORD1, rWORD2
-	slwi.	r12, rN, 3
-	bne	cr1, L(dLcr1x)
-#ifndef __LITTLE_ENDIAN__
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#endif
-	bne	cr6, L(dLcr6x)
-	subfic	rN, r12, 32	/* Shift count is 32 - (rN * 8).  */
-	bne	cr7, L(dLcr7x)
-	addi	r1, r1, 64
-	cfi_adjust_cfa_offset(-64)
-	bne	L(d00)
-	li	rRTN, 0
-	blr
-
-/* Count is a multiple of 16, remainder is 0 */
-	.align	4
-	cfi_adjust_cfa_offset(64)
-L(dP4):
-	mtctr	r0
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD1, 0, rSTR1
-	lwbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD1, 0(rSTR1)
-	lwz	rWORD2, 0(rSTR2)
-#endif
-	cmplw	cr7, rWORD1, rWORD2
-L(dP4e):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD3, 0, rSTR1
-	lwbrx	rWORD4, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD3, 4(rSTR1)
-	lwz	rWORD4, 4(rSTR2)
-#endif
-	cmplw	cr1, rWORD3, rWORD4
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD5, 0, rSTR1
-	lwbrx	rWORD6, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD5, 8(rSTR1)
-	lwz	rWORD6, 8(rSTR2)
-#endif
-	cmplw	cr6, rWORD5, rWORD6
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD7, 0, rSTR1
-	lwbrx	rWORD8, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwzu	rWORD7, 12(rSTR1)
-	lwzu	rWORD8, 12(rSTR2)
-#endif
-	cmplw	cr5, rWORD7, rWORD8
-	bne	cr7, L(dLcr7)
-	bne	cr1, L(dLcr1)
-	bdz-	L(d24)		/* Adjust CTR as we start with +4 */
-/* This is the primary loop */
-	.align	4
-L(dLoop):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD1, 0, rSTR1
-	lwbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD1, 4(rSTR1)
-	lwz	rWORD2, 4(rSTR2)
-#endif
-	cmplw	cr1, rWORD3, rWORD4
-	bne	cr6, L(dLcr6)
-L(dLoop1):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD3, 0, rSTR1
-	lwbrx	rWORD4, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD3, 8(rSTR1)
-	lwz	rWORD4, 8(rSTR2)
-#endif
-	cmplw	cr6, rWORD5, rWORD6
-	bne	cr5, L(dLcr5)
-L(dLoop2):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD5, 0, rSTR1
-	lwbrx	rWORD6, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD5, 12(rSTR1)
-	lwz	rWORD6, 12(rSTR2)
-#endif
-	cmplw	cr5, rWORD7, rWORD8
-	bne	cr7, L(dLcr7)
-L(dLoop3):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD7, 0, rSTR1
-	lwbrx	rWORD8, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwzu	rWORD7, 16(rSTR1)
-	lwzu	rWORD8, 16(rSTR2)
-#endif
-	bne	cr1, L(dLcr1)
-	cmplw	cr7, rWORD1, rWORD2
-	bdnz	L(dLoop)
-
-L(dL4):
-	cmplw	cr1, rWORD3, rWORD4
-	bne	cr6, L(dLcr6)
-	cmplw	cr6, rWORD5, rWORD6
-	bne	cr5, L(dLcr5)
-	cmplw	cr5, rWORD7, rWORD8
-L(d44):
-	bne	cr7, L(dLcr7)
-L(d34):
-	bne	cr1, L(dLcr1)
-L(d24):
-	bne	cr6, L(dLcr6)
-L(d14):
-	slwi.	r12, rN, 3
-	bne	cr5, L(dLcr5)
-L(d04):
-	lwz	rWORD7, 44(r1)
-	lwz	rWORD8, 48(r1)
-	addi	r1, r1, 64
-	cfi_adjust_cfa_offset(-64)
-	subfic	rN, r12, 32	/* Shift count is 32 - (rN * 8).  */
-	beq	L(zeroLength)
-/* At this point we have a remainder of 1 to 3 bytes to compare.  Since
-   we are aligned it is safe to load the whole word, and use
-   shift right to eliminate bits beyond the compare length.  */
-L(d00):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD1, 0, rSTR1
-	lwbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD1, 4(rSTR1)
-	lwz	rWORD2, 4(rSTR2)
-#endif
-	srw	rWORD1, rWORD1, rN
-	srw	rWORD2, rWORD2, rN
-	sub	rRTN, rWORD1, rWORD2
-	blr
-
-	.align	4
-	cfi_adjust_cfa_offset(64)
-L(dLcr7):
-	lwz	rWORD7, 44(r1)
-	lwz	rWORD8, 48(r1)
-L(dLcr7x):
-	li	rRTN, 1
-	addi	r1, r1, 64
-	cfi_adjust_cfa_offset(-64)
-	bgtlr	cr7
-	li	rRTN, -1
-	blr
-	.align	4
-	cfi_adjust_cfa_offset(64)
-L(dLcr1):
-	lwz	rWORD7, 44(r1)
-	lwz	rWORD8, 48(r1)
-L(dLcr1x):
-	li	rRTN, 1
-	addi	r1, r1, 64
-	cfi_adjust_cfa_offset(-64)
-	bgtlr	cr1
-	li	rRTN, -1
-	blr
-	.align	4
-	cfi_adjust_cfa_offset(64)
-L(dLcr6):
-	lwz	rWORD7, 44(r1)
-	lwz	rWORD8, 48(r1)
-L(dLcr6x):
-	li	rRTN, 1
-	addi	r1, r1, 64
-	cfi_adjust_cfa_offset(-64)
-	bgtlr	cr6
-	li	rRTN, -1
-	blr
-	.align	4
-	cfi_adjust_cfa_offset(64)
-L(dLcr5):
-	lwz	rWORD7, 44(r1)
-	lwz	rWORD8, 48(r1)
-L(dLcr5x):
-	li	rRTN, 1
-	addi	r1, r1, 64
-	cfi_adjust_cfa_offset(-64)
-	bgtlr	cr5
-	li	rRTN, -1
-	blr
-
-	.align	4
-L(bytealigned):
-	mtctr	rN
-
-/* We need to prime this loop.  This loop is swing modulo scheduled
-   to avoid pipe delays.  The dependent instruction latencies (load to
-   compare to conditional branch) is 2 to 3 cycles.  In this loop each
-   dispatch group ends in a branch and takes 1 cycle.  Effectively
-   the first iteration of the loop only serves to load operands and
-   branches based on compares are delayed until the next loop.
-
-   So we must precondition some registers and condition codes so that
-   we don't exit the loop early on the first iteration.  */
-
-	lbz	rWORD1, 0(rSTR1)
-	lbz	rWORD2, 0(rSTR2)
-	bdz	L(b11)
-	cmplw	cr7, rWORD1, rWORD2
-	lbz	rWORD3, 1(rSTR1)
-	lbz	rWORD4, 1(rSTR2)
-	bdz	L(b12)
-	cmplw	cr1, rWORD3, rWORD4
-	lbzu	rWORD5, 2(rSTR1)
-	lbzu	rWORD6, 2(rSTR2)
-	bdz	L(b13)
-	.align	4
-L(bLoop):
-	lbzu	rWORD1, 1(rSTR1)
-	lbzu	rWORD2, 1(rSTR2)
-	bne	cr7, L(bLcr7)
-
-	cmplw	cr6, rWORD5, rWORD6
-	bdz	L(b3i)
-
-	lbzu	rWORD3, 1(rSTR1)
-	lbzu	rWORD4, 1(rSTR2)
-	bne	cr1, L(bLcr1)
-
-	cmplw	cr7, rWORD1, rWORD2
-	bdz	L(b2i)
-
-	lbzu	rWORD5, 1(rSTR1)
-	lbzu	rWORD6, 1(rSTR2)
-	bne	cr6, L(bLcr6)
-
-	cmplw	cr1, rWORD3, rWORD4
-	bdnz	L(bLoop)
-
-/* We speculatively loading bytes before we have tested the previous
-   bytes.  But we must avoid overrunning the length (in the ctr) to
-   prevent these speculative loads from causing a segfault.  In this
-   case the loop will exit early (before the all pending bytes are
-   tested.  In this case we must complete the pending operations
-   before returning.  */
-L(b1i):
-	bne	cr7, L(bLcr7)
-	bne	cr1, L(bLcr1)
-	b	L(bx56)
-	.align	4
-L(b2i):
-	bne	cr6, L(bLcr6)
-	bne	cr7, L(bLcr7)
-	b	L(bx34)
-	.align	4
-L(b3i):
-	bne	cr1, L(bLcr1)
-	bne	cr6, L(bLcr6)
-	b	L(bx12)
-	.align	4
-L(bLcr7):
-	li	rRTN, 1
-	bgtlr	cr7
-	li	rRTN, -1
-	blr
-L(bLcr1):
-	li	rRTN, 1
-	bgtlr	cr1
-	li	rRTN, -1
-	blr
-L(bLcr6):
-	li	rRTN, 1
-	bgtlr	cr6
-	li	rRTN, -1
-	blr
-
-L(b13):
-	bne	cr7, L(bx12)
-	bne	cr1, L(bx34)
-L(bx56):
-	sub	rRTN, rWORD5, rWORD6
-	blr
-	nop
-L(b12):
-	bne	cr7, L(bx12)
-L(bx34):
-	sub	rRTN, rWORD3, rWORD4
-	blr
-L(b11):
-L(bx12):
-	sub	rRTN, rWORD1, rWORD2
-	blr
-	.align	4
-L(zeroLength):
-	li	rRTN, 0
-	blr
-
-	.align	4
-/* At this point we know the strings have different alignment and the
-   compare length is at least 8 bytes.  r12 contains the low order
-   2 bits of rSTR1 and cr5 contains the result of the logical compare
-   of r12 to 0.  If r12 == 0 then rStr1 is word aligned and can
-   perform the Wunaligned loop.
-
-   Otherwise we know that rSTR1 is not already word aligned yet.
-   So we can force the string addresses to the next lower word
-   boundary and special case this first word using shift left to
-   eliminate bits preceding the first byte.  Since we want to join the
-   normal (Wualigned) compare loop, starting at the second word,
-   we need to adjust the length (rN) and special case the loop
-   versioning for the first W. This ensures that the loop count is
-   correct and the first W (shifted) is in the expected resister pair.  */
-#define rSHL		r29	/* Unaligned shift left count.  */
-#define rSHR		r28	/* Unaligned shift right count.  */
-#define rWORD8_SHIFT	r27	/* Left rotation temp for rWORD2.  */
-#define rWORD2_SHIFT	r26	/* Left rotation temp for rWORD4.  */
-#define rWORD4_SHIFT	r25	/* Left rotation temp for rWORD6.  */
-#define rWORD6_SHIFT	r24	/* Left rotation temp for rWORD8.  */
-	cfi_adjust_cfa_offset(64)
-L(unaligned):
-	stw	rSHL, 40(r1)
-	cfi_offset(rSHL, (40-64))
-	clrlwi	rSHL, rSTR2, 30
-	stw	rSHR, 36(r1)
-	cfi_offset(rSHR, (36-64))
-	beq	cr5, L(Wunaligned)
-	stw	rWORD8_SHIFT, 32(r1)
-	cfi_offset(rWORD8_SHIFT, (32-64))
-/* Adjust the logical start of rSTR2 to compensate for the extra bits
-   in the 1st rSTR1 W.  */
-	sub	rWORD8_SHIFT, rSTR2, r12
-/* But do not attempt to address the W before that W that contains
-   the actual start of rSTR2.  */
-	clrrwi	rSTR2, rSTR2, 2
-	stw	rWORD2_SHIFT, 28(r1)
-/* Compute the left/right shift counts for the unaligned rSTR2,
-   compensating for the logical (W aligned) start of rSTR1.  */
-	clrlwi	rSHL, rWORD8_SHIFT, 30
-	clrrwi	rSTR1, rSTR1, 2
-	stw	rWORD4_SHIFT, 24(r1)
-	slwi	rSHL, rSHL, 3
-	cmplw	cr5, rWORD8_SHIFT, rSTR2
-	add	rN, rN, r12
-	slwi	rWORD6, r12, 3
-	stw	rWORD6_SHIFT, 20(r1)
-	cfi_offset(rWORD2_SHIFT, (28-64))
-	cfi_offset(rWORD4_SHIFT, (24-64))
-	cfi_offset(rWORD6_SHIFT, (20-64))
-	subfic	rSHR, rSHL, 32
-	srwi	r0, rN, 4	/* Divide by 16 */
-	andi.	r12, rN, 12	/* Get the W remainder */
-/* We normally need to load 2 Ws to start the unaligned rSTR2, but in
-   this special case those bits may be discarded anyway.  Also we
-   must avoid loading a W where none of the bits are part of rSTR2 as
-   this may cross a page boundary and cause a page fault.  */
-	li	rWORD8, 0
-	blt	cr5, L(dus0)
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD8, 0, rSTR2
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD8, 0(rSTR2)
-	addi	rSTR2, rSTR2, 4
-#endif
-	slw	rWORD8, rWORD8, rSHL
-
-L(dus0):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD1, 0, rSTR1
-	lwbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD1, 0(rSTR1)
-	lwz	rWORD2, 0(rSTR2)
-#endif
-	cmplwi	cr1, r12, 8
-	cmplwi	cr7, rN, 16
-	srw	r12, rWORD2, rSHR
-	clrlwi	rN, rN, 30
-	beq	L(duPs4)
-	mtctr	r0
-	or	rWORD8, r12, rWORD8
-	bgt	cr1, L(duPs3)
-	beq	cr1, L(duPs2)
-
-/* Remainder is 4 */
-	.align	4
-L(dusP1):
-	slw	rWORD8_SHIFT, rWORD2, rSHL
-	slw	rWORD7, rWORD1, rWORD6
-	slw	rWORD8, rWORD8, rWORD6
-	bge	cr7, L(duP1e)
-/* At this point we exit early with the first word compare
-   complete and remainder of 0 to 3 bytes.  See L(du14) for details on
-   how we handle the remaining bytes.  */
-	cmplw	cr5, rWORD7, rWORD8
-	slwi.	rN, rN, 3
-	bne	cr5, L(duLcr5)
-	cmplw	cr7, rN, rSHR
-	beq	L(duZeroReturn)
-	li	r0, 0
-	ble	cr7, L(dutrim)
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD2, 0, rSTR2
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD2, 4(rSTR2)
-#endif
-	srw	r0, rWORD2, rSHR
-	b	L(dutrim)
-/* Remainder is 8 */
-	.align	4
-L(duPs2):
-	slw	rWORD6_SHIFT, rWORD2, rSHL
-	slw	rWORD5, rWORD1, rWORD6
-	slw	rWORD6, rWORD8, rWORD6
-	b	L(duP2e)
-/* Remainder is 12 */
-	.align	4
-L(duPs3):
-	slw	rWORD4_SHIFT, rWORD2, rSHL
-	slw	rWORD3, rWORD1, rWORD6
-	slw	rWORD4, rWORD8, rWORD6
-	b	L(duP3e)
-/* Count is a multiple of 16, remainder is 0 */
-	.align	4
-L(duPs4):
-	mtctr	r0
-	or	rWORD8, r12, rWORD8
-	slw	rWORD2_SHIFT, rWORD2, rSHL
-	slw	rWORD1, rWORD1, rWORD6
-	slw	rWORD2, rWORD8, rWORD6
-	b	L(duP4e)
-
-/* At this point we know rSTR1 is word aligned and the
-   compare length is at least 8 bytes.  */
-	.align	4
-L(Wunaligned):
-	stw	rWORD8_SHIFT, 32(r1)
-	clrrwi	rSTR2, rSTR2, 2
-	stw	rWORD2_SHIFT, 28(r1)
-	srwi	r0, rN, 4	/* Divide by 16 */
-	stw	rWORD4_SHIFT, 24(r1)
-	andi.	r12, rN, 12	/* Get the W remainder */
-	stw	rWORD6_SHIFT, 20(r1)
-	cfi_offset(rWORD8_SHIFT, (32-64))
-	cfi_offset(rWORD2_SHIFT, (28-64))
-	cfi_offset(rWORD4_SHIFT, (24-64))
-	cfi_offset(rWORD6_SHIFT, (20-64))
-	slwi	rSHL, rSHL, 3
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD6, 0, rSTR2
-	addi	rSTR2, rSTR2, 4
-	lwbrx	rWORD8, 0, rSTR2
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD6, 0(rSTR2)
-	lwzu	rWORD8, 4(rSTR2)
-#endif
-	cmplwi	cr1, r12, 8
-	cmplwi	cr7, rN, 16
-	clrlwi	rN, rN, 30
-	subfic	rSHR, rSHL, 32
-	slw	rWORD6_SHIFT, rWORD6, rSHL
-	beq	L(duP4)
-	mtctr	r0
-	bgt	cr1, L(duP3)
-	beq	cr1, L(duP2)
-
-/* Remainder is 4 */
-	.align	4
-L(duP1):
-	srw	r12, rWORD8, rSHR
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD7, 0, rSTR1
-	addi	rSTR1, rSTR1, 4
-#else
-	lwz	rWORD7, 0(rSTR1)
-#endif
-	slw	rWORD8_SHIFT, rWORD8, rSHL
-	or	rWORD8, r12, rWORD6_SHIFT
-	blt	cr7, L(duP1x)
-L(duP1e):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD1, 0, rSTR1
-	lwbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD1, 4(rSTR1)
-	lwz	rWORD2, 4(rSTR2)
-#endif
-	cmplw	cr5, rWORD7, rWORD8
-	srw	r0, rWORD2, rSHR
-	slw	rWORD2_SHIFT, rWORD2, rSHL
-	or	rWORD2, r0, rWORD8_SHIFT
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD3, 0, rSTR1
-	lwbrx	rWORD4, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD3, 8(rSTR1)
-	lwz	rWORD4, 8(rSTR2)
-#endif
-	cmplw	cr7, rWORD1, rWORD2
-	srw	r12, rWORD4, rSHR
-	slw	rWORD4_SHIFT, rWORD4, rSHL
-	bne	cr5, L(duLcr5)
-	or	rWORD4, r12, rWORD2_SHIFT
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD5, 0, rSTR1
-	lwbrx	rWORD6, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD5, 12(rSTR1)
-	lwz	rWORD6, 12(rSTR2)
-#endif
-	cmplw	cr1, rWORD3, rWORD4
-	srw	r0, rWORD6, rSHR
-	slw	rWORD6_SHIFT, rWORD6, rSHL
-	bne	cr7, L(duLcr7)
-	or	rWORD6, r0, rWORD4_SHIFT
-	cmplw	cr6, rWORD5, rWORD6
-	b	L(duLoop3)
-	.align	4
-/* At this point we exit early with the first word compare
-   complete and remainder of 0 to 3 bytes.  See L(du14) for details on
-   how we handle the remaining bytes.  */
-L(duP1x):
-	cmplw	cr5, rWORD7, rWORD8
-	slwi.	rN, rN, 3
-	bne	cr5, L(duLcr5)
-	cmplw	cr7, rN, rSHR
-	beq	L(duZeroReturn)
-	li	r0, 0
-	ble	cr7, L(dutrim)
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD2, 0, rSTR2
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD2, 8(rSTR2)
-#endif
-	srw	r0, rWORD2, rSHR
-	b	L(dutrim)
-/* Remainder is 8 */
-	.align	4
-L(duP2):
-	srw	r0, rWORD8, rSHR
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD5, 0, rSTR1
-	addi	rSTR1, rSTR1, 4
-#else
-	lwz	rWORD5, 0(rSTR1)
-#endif
-	or	rWORD6, r0, rWORD6_SHIFT
-	slw	rWORD6_SHIFT, rWORD8, rSHL
-L(duP2e):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD7, 0, rSTR1
-	lwbrx	rWORD8, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD7, 4(rSTR1)
-	lwz	rWORD8, 4(rSTR2)
-#endif
-	cmplw	cr6, rWORD5, rWORD6
-	srw	r12, rWORD8, rSHR
-	slw	rWORD8_SHIFT, rWORD8, rSHL
-	or	rWORD8, r12, rWORD6_SHIFT
-	blt	cr7, L(duP2x)
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD1, 0, rSTR1
-	lwbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD1, 8(rSTR1)
-	lwz	rWORD2, 8(rSTR2)
-#endif
-	cmplw	cr5, rWORD7, rWORD8
-	bne	cr6, L(duLcr6)
-	srw	r0, rWORD2, rSHR
-	slw	rWORD2_SHIFT, rWORD2, rSHL
-	or	rWORD2, r0, rWORD8_SHIFT
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD3, 0, rSTR1
-	lwbrx	rWORD4, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD3, 12(rSTR1)
-	lwz	rWORD4, 12(rSTR2)
-#endif
-	cmplw	cr7, rWORD1, rWORD2
-	bne	cr5, L(duLcr5)
-	srw	r12, rWORD4, rSHR
-	slw	rWORD4_SHIFT, rWORD4, rSHL
-	or	rWORD4, r12, rWORD2_SHIFT
-#ifndef __LITTLE_ENDIAN__
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#endif
-	cmplw	cr1, rWORD3, rWORD4
-	b	L(duLoop2)
-	.align	4
-L(duP2x):
-	cmplw	cr5, rWORD7, rWORD8
-#ifndef __LITTLE_ENDIAN__
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#endif
-	bne	cr6, L(duLcr6)
-	slwi.	rN, rN, 3
-	bne	cr5, L(duLcr5)
-	cmplw	cr7, rN, rSHR
-	beq	L(duZeroReturn)
-	li	r0, 0
-	ble	cr7, L(dutrim)
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD2, 0, rSTR2
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD2, 4(rSTR2)
-#endif
-	srw	r0, rWORD2, rSHR
-	b	L(dutrim)
-
-/* Remainder is 12 */
-	.align	4
-L(duP3):
-	srw	r12, rWORD8, rSHR
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD3, 0, rSTR1
-	addi	rSTR1, rSTR1, 4
-#else
-	lwz	rWORD3, 0(rSTR1)
-#endif
-	slw	rWORD4_SHIFT, rWORD8, rSHL
-	or	rWORD4, r12, rWORD6_SHIFT
-L(duP3e):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD5, 0, rSTR1
-	lwbrx	rWORD6, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD5, 4(rSTR1)
-	lwz	rWORD6, 4(rSTR2)
-#endif
-	cmplw	cr1, rWORD3, rWORD4
-	srw	r0, rWORD6, rSHR
-	slw	rWORD6_SHIFT, rWORD6, rSHL
-	or	rWORD6, r0, rWORD4_SHIFT
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD7, 0, rSTR1
-	lwbrx	rWORD8, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD7, 8(rSTR1)
-	lwz	rWORD8, 8(rSTR2)
-#endif
-	cmplw	cr6, rWORD5, rWORD6
-	bne	cr1, L(duLcr1)
-	srw	r12, rWORD8, rSHR
-	slw	rWORD8_SHIFT, rWORD8, rSHL
-	or	rWORD8, r12, rWORD6_SHIFT
-	blt	cr7, L(duP3x)
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD1, 0, rSTR1
-	lwbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD1, 12(rSTR1)
-	lwz	rWORD2, 12(rSTR2)
-#endif
-	cmplw	cr5, rWORD7, rWORD8
-	bne	cr6, L(duLcr6)
-	srw	r0, rWORD2, rSHR
-	slw	rWORD2_SHIFT, rWORD2, rSHL
-	or	rWORD2, r0, rWORD8_SHIFT
-#ifndef __LITTLE_ENDIAN__
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#endif
-	cmplw	cr7, rWORD1, rWORD2
-	b	L(duLoop1)
-	.align	4
-L(duP3x):
-#ifndef __LITTLE_ENDIAN__
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#endif
-#if 0
-/* Huh?  We've already branched on cr1!  */
-	bne	cr1, L(duLcr1)
-#endif
-	cmplw	cr5, rWORD7, rWORD8
-	bne	cr6, L(duLcr6)
-	slwi.	rN, rN, 3
-	bne	cr5, L(duLcr5)
-	cmplw	cr7, rN, rSHR
-	beq	L(duZeroReturn)
-	li	r0, 0
-	ble	cr7, L(dutrim)
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD2, 0, rSTR2
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD2, 4(rSTR2)
-#endif
-	srw	r0, rWORD2, rSHR
-	b	L(dutrim)
-
-/* Count is a multiple of 16, remainder is 0 */
-	.align	4
-L(duP4):
-	mtctr	r0
-	srw	r0, rWORD8, rSHR
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD1, 0, rSTR1
-	addi	rSTR1, rSTR1, 4
-#else
-	lwz	rWORD1, 0(rSTR1)
-#endif
-	slw	rWORD2_SHIFT, rWORD8, rSHL
-	or	rWORD2, r0, rWORD6_SHIFT
-L(duP4e):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD3, 0, rSTR1
-	lwbrx	rWORD4, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD3, 4(rSTR1)
-	lwz	rWORD4, 4(rSTR2)
-#endif
-	cmplw	cr7, rWORD1, rWORD2
-	srw	r12, rWORD4, rSHR
-	slw	rWORD4_SHIFT, rWORD4, rSHL
-	or	rWORD4, r12, rWORD2_SHIFT
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD5, 0, rSTR1
-	lwbrx	rWORD6, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD5, 8(rSTR1)
-	lwz	rWORD6, 8(rSTR2)
-#endif
-	cmplw	cr1, rWORD3, rWORD4
-	bne	cr7, L(duLcr7)
-	srw	r0, rWORD6, rSHR
-	slw	rWORD6_SHIFT, rWORD6, rSHL
-	or	rWORD6, r0, rWORD4_SHIFT
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD7, 0, rSTR1
-	lwbrx	rWORD8, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwzu	rWORD7, 12(rSTR1)
-	lwzu	rWORD8, 12(rSTR2)
-#endif
-	cmplw	cr6, rWORD5, rWORD6
-	bne	cr1, L(duLcr1)
-	srw	r12, rWORD8, rSHR
-	slw	rWORD8_SHIFT, rWORD8, rSHL
-	or	rWORD8, r12, rWORD6_SHIFT
-	cmplw	cr5, rWORD7, rWORD8
-	bdz	L(du24)		/* Adjust CTR as we start with +4 */
-/* This is the primary loop */
-	.align	4
-L(duLoop):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD1, 0, rSTR1
-	lwbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD1, 4(rSTR1)
-	lwz	rWORD2, 4(rSTR2)
-#endif
-	cmplw	cr1, rWORD3, rWORD4
-	bne	cr6, L(duLcr6)
-	srw	r0, rWORD2, rSHR
-	slw	rWORD2_SHIFT, rWORD2, rSHL
-	or	rWORD2, r0, rWORD8_SHIFT
-L(duLoop1):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD3, 0, rSTR1
-	lwbrx	rWORD4, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD3, 8(rSTR1)
-	lwz	rWORD4, 8(rSTR2)
-#endif
-	cmplw	cr6, rWORD5, rWORD6
-	bne	cr5, L(duLcr5)
-	srw	r12, rWORD4, rSHR
-	slw	rWORD4_SHIFT, rWORD4, rSHL
-	or	rWORD4, r12, rWORD2_SHIFT
-L(duLoop2):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD5, 0, rSTR1
-	lwbrx	rWORD6, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD5, 12(rSTR1)
-	lwz	rWORD6, 12(rSTR2)
-#endif
-	cmplw	cr5, rWORD7, rWORD8
-	bne	cr7, L(duLcr7)
-	srw	r0, rWORD6, rSHR
-	slw	rWORD6_SHIFT, rWORD6, rSHL
-	or	rWORD6, r0, rWORD4_SHIFT
-L(duLoop3):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD7, 0, rSTR1
-	lwbrx	rWORD8, 0, rSTR2
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-#else
-	lwzu	rWORD7, 16(rSTR1)
-	lwzu	rWORD8, 16(rSTR2)
-#endif
-	cmplw	cr7, rWORD1, rWORD2
-	bne	cr1, L(duLcr1)
-	srw	r12, rWORD8, rSHR
-	slw	rWORD8_SHIFT, rWORD8, rSHL
-	or	rWORD8, r12, rWORD6_SHIFT
-	bdnz	L(duLoop)
-
-L(duL4):
-#if 0
-/* Huh?  We've already branched on cr1!  */
-	bne	cr1, L(duLcr1)
-#endif
-	cmplw	cr1, rWORD3, rWORD4
-	bne	cr6, L(duLcr6)
-	cmplw	cr6, rWORD5, rWORD6
-	bne	cr5, L(duLcr5)
-	cmplw	cr5, rWORD7, rWORD8
-L(du44):
-	bne	cr7, L(duLcr7)
-L(du34):
-	bne	cr1, L(duLcr1)
-L(du24):
-	bne	cr6, L(duLcr6)
-L(du14):
-	slwi.	rN, rN, 3
-	bne	cr5, L(duLcr5)
-/* At this point we have a remainder of 1 to 3 bytes to compare.  We use
-   shift right to eliminate bits beyond the compare length.
-   This allows the use of word subtract to compute the final result.
-
-   However it may not be safe to load rWORD2 which may be beyond the
-   string length. So we compare the bit length of the remainder to
-   the right shift count (rSHR). If the bit count is less than or equal
-   we do not need to load rWORD2 (all significant bits are already in
-   rWORD8_SHIFT).  */
-	cmplw	cr7, rN, rSHR
-	beq	L(duZeroReturn)
-	li	r0, 0
-	ble	cr7, L(dutrim)
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD2, 0, rSTR2
-	addi	rSTR2, rSTR2, 4
-#else
-	lwz	rWORD2, 4(rSTR2)
-#endif
-	srw	r0, rWORD2, rSHR
-	.align	4
-L(dutrim):
-#ifdef __LITTLE_ENDIAN__
-	lwbrx	rWORD1, 0, rSTR1
-#else
-	lwz	rWORD1, 4(rSTR1)
-#endif
-	lwz	rWORD8, 48(r1)
-	subfic	rN, rN, 32	/* Shift count is 32 - (rN * 8).  */
-	or	rWORD2, r0, rWORD8_SHIFT
-	lwz	rWORD7, 44(r1)
-	lwz	rSHL, 40(r1)
-	srw	rWORD1, rWORD1, rN
-	srw	rWORD2, rWORD2, rN
-	lwz	rSHR, 36(r1)
-	lwz	rWORD8_SHIFT, 32(r1)
-	sub	rRTN, rWORD1, rWORD2
-	b	L(dureturn26)
-	.align	4
-L(duLcr7):
-	lwz	rWORD8, 48(r1)
-	lwz	rWORD7, 44(r1)
-	li	rRTN, 1
-	bgt	cr7, L(dureturn29)
-	lwz	rSHL, 40(r1)
-	lwz	rSHR, 36(r1)
-	li	rRTN, -1
-	b	L(dureturn27)
-	.align	4
-L(duLcr1):
-	lwz	rWORD8, 48(r1)
-	lwz	rWORD7, 44(r1)
-	li	rRTN, 1
-	bgt	cr1, L(dureturn29)
-	lwz	rSHL, 40(r1)
-	lwz	rSHR, 36(r1)
-	li	rRTN, -1
-	b	L(dureturn27)
-	.align	4
-L(duLcr6):
-	lwz	rWORD8, 48(r1)
-	lwz	rWORD7, 44(r1)
-	li	rRTN, 1
-	bgt	cr6, L(dureturn29)
-	lwz	rSHL, 40(r1)
-	lwz	rSHR, 36(r1)
-	li	rRTN, -1
-	b	L(dureturn27)
-	.align	4
-L(duLcr5):
-	lwz	rWORD8, 48(r1)
-	lwz	rWORD7, 44(r1)
-	li	rRTN, 1
-	bgt	cr5, L(dureturn29)
-	lwz	rSHL, 40(r1)
-	lwz	rSHR, 36(r1)
-	li	rRTN, -1
-	b	L(dureturn27)
-	.align	3
-L(duZeroReturn):
-	li	rRTN, 0
-	.align	4
-L(dureturn):
-	lwz	rWORD8, 48(r1)
-	lwz	rWORD7, 44(r1)
-L(dureturn29):
-	lwz	rSHL, 40(r1)
-	lwz	rSHR, 36(r1)
-L(dureturn27):
-	lwz	rWORD8_SHIFT, 32(r1)
-L(dureturn26):
-	lwz	rWORD2_SHIFT, 28(r1)
-L(dureturn25):
-	lwz	rWORD4_SHIFT, 24(r1)
-	lwz	rWORD6_SHIFT, 20(r1)
-	addi	r1, r1, 64
-	cfi_adjust_cfa_offset(-64)
-	blr
-END (memcmp)
-
-libc_hidden_builtin_def (memcmp)
-weak_alias (memcmp, bcmp)
diff --git a/sysdeps/powerpc/powerpc32/power7/memcpy.S b/sysdeps/powerpc/powerpc32/power7/memcpy.S
deleted file mode 100644
index 76b1c53..0000000
--- a/sysdeps/powerpc/powerpc32/power7/memcpy.S
+++ /dev/null
@@ -1,538 +0,0 @@
-/* Optimized memcpy implementation for PowerPC32/POWER7.
-   Copyright (C) 2010-2018 Free Software Foundation, Inc.
-   Contributed by Luis Machado <luisgpm@br.ibm.com>.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* void * [r3] memcpy (void *dst [r3], void *src [r4], size_t len [r5]);
-   Returns 'dst'.  */
-
-	.machine  power7
-EALIGN (memcpy, 5, 0)
-	CALL_MCOUNT
-
-	stwu    1,-32(1)
-	cfi_adjust_cfa_offset(32)
-	stw	30,20(1)
-	cfi_offset(30,(20-32))
-	stw	31,24(1)
-	mr      30,3
-	cmplwi  cr1,5,31
-	neg	0,3
-	cfi_offset(31,-8)
-	ble	cr1, L(copy_LT_32)  /* If move < 32 bytes use short move
-				    code.  */
-
-	andi.   11,3,15	      /* Check alignment of DST.  */
-	clrlwi  10,4,28	      /* Check alignment of SRC.  */
-	cmplw   cr6,10,11     /* SRC and DST alignments match?  */
-	mr	12,4
-	mr	31,5
-	bne	cr6,L(copy_GE_32_unaligned)
-
-	srwi    9,5,3	      /* Number of full quadwords remaining.  */
-
-	beq	L(copy_GE_32_aligned_cont)
-
-	clrlwi  0,0,29
-	mtcrf   0x01,0
-	subf    31,0,5
-
-	/* Get the SRC aligned to 8 bytes.  */
-
-1:	bf	31,2f
-	lbz	6,0(12)
-	addi    12,12,1
-	stb	6,0(3)
-	addi    3,3,1
-2:	bf      30,4f
-	lhz     6,0(12)
-	addi    12,12,2
-	sth     6,0(3)
-	addi    3,3,2
-4:	bf      29,0f
-	lwz     6,0(12)
-	addi    12,12,4
-	stw     6,0(3)
-	addi    3,3,4
-0:
-	clrlwi  10,12,29      /* Check alignment of SRC again.  */
-	srwi    9,31,3	      /* Number of full doublewords remaining.  */
-
-L(copy_GE_32_aligned_cont):
-
-	clrlwi  11,31,29
-	mtcrf   0x01,9
-
-	srwi    8,31,5
-	cmplwi  cr1,9,4
-	cmplwi  cr6,11,0
-	mr	11,12
-
-	/* Copy 1~3 doublewords so the main loop starts
-	at a multiple of 32 bytes.  */
-
-	bf	30,1f
-	lfd     6,0(12)
-	lfd     7,8(12)
-	addi    11,12,16
-	mtctr   8
-	stfd    6,0(3)
-	stfd    7,8(3)
-	addi    10,3,16
-	bf      31,4f
-	lfd     0,16(12)
-	stfd    0,16(3)
-	blt     cr1,3f
-	addi    11,12,24
-	addi    10,3,24
-	b       4f
-
-	.align  4
-1:	/* Copy 1 doubleword and set the counter.  */
-	mr	10,3
-	mtctr   8
-	bf      31,4f
-	lfd     6,0(12)
-	addi    11,12,8
-	stfd    6,0(3)
-	addi    10,3,8
-
-L(aligned_copy):
-	/* Main aligned copy loop. Copies up to 128-bytes at a time. */
-	.align  4
-4:
-	/* check for any 32-byte or 64-byte lumps that are outside of a
-	   nice 128-byte range.  R8 contains the number of 32-byte
-	   lumps, so drop this into the CR, and use the SO/EQ bits to help
-	   handle the 32- or 64- byte lumps.  Then handle the rest with an
-	   unrolled 128-bytes-at-a-time copy loop. */
-	mtocrf	1,8
-	li	6,16	# 16() index
-	li	7,32	# 32() index
-	li	8,48	# 48() index
-
-L(aligned_32byte):
-	/* if the SO bit (indicating a 32-byte lump) is not set, move along. */
-	bns	cr7,L(aligned_64byte)
-	lxvd2x	6,0,11
-	lxvd2x	7,11,6
-	addi	11,11,32
-	stxvd2x	6,0,10
-	stxvd2x	7,10,6
-	addi	10,10,32
-
-L(aligned_64byte):
-	/* if the EQ bit (indicating a 64-byte lump) is not set, move along. */
-	bne	cr7,L(aligned_128setup)
-	lxvd2x	6,0,11
-	lxvd2x	7,11,6
-	lxvd2x	8,11,7
-	lxvd2x	9,11,8
-	addi	11,11,64
-	stxvd2x	6,0,10
-	stxvd2x	7,10,6
-	stxvd2x	8,10,7
-	stxvd2x	9,10,8
-	addi	10,10,64
-
-L(aligned_128setup):
-	/* Set up for the 128-byte at a time copy loop.  */
-	srwi	8,31,7
-	cmpwi	8,0	# Any 4x lumps left?
-	beq	3f	# if not, move along.
-	lxvd2x	6,0,11
-	lxvd2x	7,11,6
-	mtctr	8	# otherwise, load the ctr and begin.
-	li	8,48	# 48() index
-	b	L(aligned_128loop)
-
-L(aligned_128head):
-	/* for the 2nd + iteration of this loop. */
-	lxvd2x	6,0,11
-	lxvd2x	7,11,6
-L(aligned_128loop):
-	lxvd2x	8,11,7
-	lxvd2x	9,11,8
-	stxvd2x	6,0,10
-	addi	11,11,64
-	stxvd2x	7,10,6
-	stxvd2x	8,10,7
-	stxvd2x	9,10,8
-	lxvd2x	6,0,11
-	lxvd2x	7,11,6
-	addi	10,10,64
-	lxvd2x	8,11,7
-	lxvd2x	9,11,8
-	addi	11,11,64
-	stxvd2x	6,0,10
-	stxvd2x	7,10,6
-	stxvd2x	8,10,7
-	stxvd2x	9,10,8
-	addi	10,10,64
-	bdnz	L(aligned_128head)
-
-3:
-	/* Check for tail bytes.  */
-	clrrwi  0,31,3
-	mtcrf   0x01,31
-	beq	cr6,0f
-
-.L9:
-	add	3,3,0
-	add	12,12,0
-
-	/*  At this point we have a tail of 0-7 bytes and we know that the
-	destination is doubleword-aligned.  */
-4:	/* Copy 4 bytes.  */
-	bf	29,2f
-
-	lwz     6,0(12)
-	addi    12,12,4
-	stw     6,0(3)
-	addi    3,3,4
-2:	/* Copy 2 bytes.  */
-	bf	30,1f
-
-	lhz     6,0(12)
-	addi    12,12,2
-	sth     6,0(3)
-	addi    3,3,2
-1:	/* Copy 1 byte.  */
-	bf	31,0f
-
-	lbz	6,0(12)
-	stb	6,0(3)
-0:	/* Return original DST pointer.  */
-	mr	3,30
-	lwz	30,20(1)
-	lwz     31,24(1)
-	addi    1,1,32
-	blr
-
-	/* Handle copies of 0~31 bytes.  */
-	.align  4
-L(copy_LT_32):
-	cmplwi  cr6,5,8
-	mr	12,4
-	mtcrf   0x01,5
-	ble	cr6,L(copy_LE_8)
-
-	/* At least 9 bytes to go.  */
-	neg	8,4
-	clrrwi  11,4,2
-	andi.   0,8,3
-	cmplwi  cr1,5,16
-	mr	10,5
-	beq	L(copy_LT_32_aligned)
-
-	/* Force 4-bytes alignment for SRC.  */
-	mtocrf  0x01,0
-	subf    10,0,5
-2:	bf	30,1f
-
-	lhz	6,0(12)
-	addi    12,12,2
-	sth	6,0(3)
-	addi    3,3,2
-1:	bf	31,L(end_4bytes_alignment)
-
-	lbz	6,0(12)
-	addi    12,12,1
-	stb	6,0(3)
-	addi    3,3,1
-
-	.align  4
-L(end_4bytes_alignment):
-	cmplwi  cr1,10,16
-	mtcrf   0x01,10
-
-L(copy_LT_32_aligned):
-	/* At least 6 bytes to go, and SRC is word-aligned.  */
-	blt	cr1,8f
-
-	/* Copy 16 bytes.  */
-	lwz	6,0(12)
-	lwz     7,4(12)
-	stw     6,0(3)
-	lwz     8,8(12)
-	stw     7,4(3)
-	lwz     6,12(12)
-	addi    12,12,16
-	stw     8,8(3)
-	stw     6,12(3)
-	addi    3,3,16
-8:	/* Copy 8 bytes.  */
-	bf	28,4f
-
-	lwz     6,0(12)
-	lwz     7,4(12)
-	addi    12,12,8
-	stw     6,0(3)
-	stw     7,4(3)
-	addi    3,3,8
-4:	/* Copy 4 bytes.  */
-	bf	29,2f
-
-	lwz     6,0(12)
-	addi    12,12,4
-	stw     6,0(3)
-	addi    3,3,4
-2:	/* Copy 2-3 bytes.  */
-	bf	30,1f
-
-	lhz     6,0(12)
-	sth     6,0(3)
-	bf      31,0f
-	lbz     7,2(12)
-	stb     7,2(3)
-
-	/* Return original DST pointer.  */
-	mr      3,30
-	lwz     30,20(1)
-	addi    1,1,32
-	blr
-
-	.align  4
-1:	/* Copy 1 byte.  */
-	bf	31,0f
-
-	lbz	6,0(12)
-	stb	6,0(3)
-0:	/* Return original DST pointer.  */
-	mr	3,30
-	lwz	30,20(1)
-	addi    1,1,32
-	blr
-
-	/* Handles copies of 0~8 bytes.  */
-	.align  4
-L(copy_LE_8):
-	bne	cr6,4f
-
-	/* Though we could've used lfd/stfd here, they are still
-	slow for unaligned cases.  */
-
-	lwz	6,0(4)
-	lwz     7,4(4)
-	stw     6,0(3)
-	stw     7,4(3)
-
-	/* Return original DST pointer.  */
-	mr      3,30
-	lwz     30,20(1)
-	addi    1,1,32
-	blr
-
-	.align  4
-4:	/* Copies 4~7 bytes.  */
-	bf	29,2b
-
-	lwz	6,0(4)
-	stw     6,0(3)
-	bf      30,5f
-	lhz     7,4(4)
-	sth     7,4(3)
-	bf      31,0f
-	lbz     8,6(4)
-	stb     8,6(3)
-
-	/* Return original DST pointer.  */
-	mr      3,30
-	lwz     30,20(1)
-	addi    1,1,32
-	blr
-
-	.align  4
-5:	/* Copy 1 byte.  */
-	bf	31,0f
-
-	lbz	6,4(4)
-	stb	6,4(3)
-
-0:	/* Return original DST pointer.  */
-	mr	3,30
-	lwz     30,20(1)
-	addi    1,1,32
-	blr
-
-	/* Handle copies of 32+ bytes where DST is aligned (to quadword) but
-	SRC is not. Use aligned quadword loads from SRC, shifted to realign
-	the data, allowing for aligned DST stores.  */
-	.align  4
-L(copy_GE_32_unaligned):
-	andi.   11,3,15	      /* Check alignment of DST.  */
-	clrlwi  0,0,28	      /* Number of bytes until the 1st
-			      quadword of DST.  */
-	srwi    9,5,4	      /* Number of full quadwords remaining.  */
-
-	beq    L(copy_GE_32_unaligned_cont)
-
-	/* DST is not quadword aligned, get it aligned.  */
-
-	mtcrf   0x01,0
-	subf    31,0,5
-
-	/* Vector instructions work best when proper alignment (16-bytes)
-	is present.  Move 0~15 bytes as needed to get DST quadword-aligned.  */
-1:	/* Copy 1 byte.  */
-	bf	31,2f
-
-	lbz	6,0(12)
-	addi    12,12,1
-	stb	6,0(3)
-	addi    3,3,1
-2:	/* Copy 2 bytes.  */
-	bf	    30,4f
-
-	lhz     6,0(12)
-	addi    12,12,2
-	sth     6,0(3)
-	addi    3,3,2
-4:	/* Copy 4 bytes.  */
-	bf	29,8f
-
-	lwz     6,0(12)
-	addi    12,12,4
-	stw     6,0(3)
-	addi    3,3,4
-8:	/* Copy 8 bytes.  */
-	bf	28,0f
-
-	lfd	6,0(12)
-	addi    12,12,8
-	stfd    6,0(3)
-	addi    3,3,8
-0:
-	clrlwi  10,12,28      /* Check alignment of SRC.  */
-	srwi    9,31,4	      /* Number of full quadwords remaining.  */
-
-	/* The proper alignment is present, it is OK to copy the bytes now.  */
-L(copy_GE_32_unaligned_cont):
-
-	/* Setup two indexes to speed up the indexed vector operations.  */
-	clrlwi  11,31,28
-	li      6,16	      /* Index for 16-bytes offsets.  */
-	li	7,32	      /* Index for 32-bytes offsets.  */
-	cmplwi  cr1,11,0
-	srwi    8,31,5	      /* Setup the loop counter.  */
-	mr      10,3
-	mr      11,12
-	mtcrf   0x01,9
-	cmplwi  cr6,9,1
-#ifdef __LITTLE_ENDIAN__
-	lvsr    5,0,12
-#else
-	lvsl    5,0,12
-#endif
-	lvx     3,0,12
-	bf      31,L(setup_unaligned_loop)
-
-	/* Copy another 16 bytes to align to 32-bytes due to the loop .  */
-	lvx     4,12,6
-#ifdef __LITTLE_ENDIAN__
-	vperm   6,4,3,5
-#else
-	vperm   6,3,4,5
-#endif
-	addi    11,12,16
-	addi    10,3,16
-	stvx    6,0,3
-	vor	3,4,4
-
-L(setup_unaligned_loop):
-	mtctr   8
-	ble     cr6,L(end_unaligned_loop)
-
-	/* Copy 32 bytes at a time using vector instructions.  */
-	.align  4
-L(unaligned_loop):
-
-	/* Note: vr6/vr10 may contain data that was already copied,
-	but in order to get proper alignment, we may have to copy
-	some portions again. This is faster than having unaligned
-	vector instructions though.  */
-
-	lvx	4,11,6	      /* vr4 = r11+16.  */
-#ifdef __LITTLE_ENDIAN__
-	vperm   6,4,3,5
-#else
-	vperm   6,3,4,5
-#endif
-	lvx	3,11,7	      /* vr3 = r11+32.  */
-#ifdef __LITTLE_ENDIAN__
-	vperm   10,3,4,5
-#else
-	vperm   10,4,3,5
-#endif
-	addi    11,11,32
-	stvx    6,0,10
-	stvx    10,10,6
-	addi    10,10,32
-
-	bdnz    L(unaligned_loop)
-
-	.align  4
-L(end_unaligned_loop):
-
-	/* Check for tail bytes.  */
-	clrrwi  0,31,4
-	mtcrf   0x01,31
-	beq	cr1,0f
-
-	add	3,3,0
-	add	12,12,0
-
-	/*  We have 1~15 tail bytes to copy, and DST is quadword aligned.  */
-8:	/* Copy 8 bytes.  */
-	bf	28,4f
-
-	lwz	6,0(12)
-	lwz	7,4(12)
-	addi    12,12,8
-	stw	6,0(3)
-	stw	7,4(3)
-	addi    3,3,8
-4:	/* Copy 4 bytes.  */
-	bf	29,2f
-
-	lwz	6,0(12)
-	addi    12,12,4
-	stw	6,0(3)
-	addi    3,3,4
-2:	/* Copy 2~3 bytes.  */
-	bf	30,1f
-
-	lhz	6,0(12)
-	addi    12,12,2
-	sth	6,0(3)
-	addi    3,3,2
-1:	/* Copy 1 byte.  */
-	bf	31,0f
-
-	lbz	6,0(12)
-	stb	6,0(3)
-0:	/* Return original DST pointer.  */
-	mr	3,30
-	lwz     30,20(1)
-	lwz	31,24(1)
-	addi    1,1,32
-	blr
-
-END (memcpy)
-libc_hidden_builtin_def (memcpy)
diff --git a/sysdeps/powerpc/powerpc32/power7/mempcpy.S b/sysdeps/powerpc/powerpc32/power7/mempcpy.S
deleted file mode 100644
index 1a3f4eb..0000000
--- a/sysdeps/powerpc/powerpc32/power7/mempcpy.S
+++ /dev/null
@@ -1,482 +0,0 @@
-/* Optimized mempcpy implementation for POWER7.
-   Copyright (C) 2010-2018 Free Software Foundation, Inc.
-   Contributed by Luis Machado <luisgpm@br.ibm.com>.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* void * [r3] __mempcpy (void *dst [r3], void *src [r4], size_t len [r5]);
-	Returns 'dst' + 'len'.  */
-
-	.machine  power7
-EALIGN (__mempcpy, 5, 0)
-	CALL_MCOUNT
-
-	stwu	1,-32(1)
-	cfi_adjust_cfa_offset(32)
-	stw	30,20(1)
-	cfi_offset(30,(20-32))
-	stw	31,24(1)
-	mr	30,3
-	cmplwi	cr1,5,31
-	neg	0,3
-	cfi_offset(31,-8)
-	ble	cr1,L(copy_LT_32)  /* If move < 32 bytes use short move
-					code.  */
-
-	andi.	11,3,7	      /* Check alignment of DST.  */
-	clrlwi	10,4,29	      /* Check alignment of SRC.  */
-	cmplw	cr6,10,11     /* SRC and DST alignments match?  */
-	mr	12,4
-	mr	31,5
-	bne	cr6,L(copy_GE_32_unaligned)
-
-	srwi	9,5,3	      /* Number of full quadwords remaining.  */
-
-	beq	L(copy_GE_32_aligned_cont)
-
-	clrlwi	0,0,29
-	mtcrf	0x01,0
-	subf	31,0,5
-
-	/* Get the SRC aligned to 8 bytes.  */
-
-1:	bf	31,2f
-	lbz	6,0(12)
-	addi	12,12,1
-	stb	6,0(3)
-	addi	3,3,1
-2:	bf	30,4f
-	lhz	6,0(12)
-	addi	12,12,2
-	sth	6,0(3)
-	addi	3,3,2
-4:	bf	29,0f
-	lwz	6,0(12)
-	addi	12,12,4
-	stw	6,0(3)
-	addi	3,3,4
-0:
-	clrlwi	10,12,29      /* Check alignment of SRC again.  */
-	srwi	9,31,3	      /* Number of full doublewords remaining.  */
-
-L(copy_GE_32_aligned_cont):
-
-	clrlwi	11,31,29
-	mtcrf	0x01,9
-
-	srwi	8,31,5
-	cmplwi	cr1,9,4
-	cmplwi	cr6,11,0
-	mr	11,12
-
-	/* Copy 1~3 doublewords so the main loop starts
-	at a multiple of 32 bytes.  */
-
-	bf	30,1f
-	lfd	6,0(12)
-	lfd	7,8(12)
-	addi	11,12,16
-	mtctr	8
-	stfd	6,0(3)
-	stfd	7,8(3)
-	addi	10,3,16
-	bf	31,4f
-	lfd	0,16(12)
-	stfd	0,16(3)
-	blt	cr1,3f
-	addi	11,12,24
-	addi	10,3,24
-	b	4f
-
-	.align	4
-1:	/* Copy 1 doubleword and set the counter.  */
-	mr	10,3
-	mtctr	8
-	bf	31,4f
-	lfd	6,0(12)
-	addi	11,12,8
-	stfd	6,0(3)
-	addi	10,3,8
-
-	.align	4
-4:	/* Main aligned copy loop. Copies 32-bytes at a time.  */
-	lfd	6,0(11)
-	lfd	7,8(11)
-	lfd	8,16(11)
-	lfd	0,24(11)
-	addi	11,11,32
-
-	stfd	6,0(10)
-	stfd	7,8(10)
-	stfd	8,16(10)
-	stfd	0,24(10)
-	addi	10,10,32
-	bdnz	4b
-3:
-
-	/* Check for tail bytes.  */
-
-	clrrwi	0,31,3
-	mtcrf	0x01,31
-	beq	cr6,0f
-
-.L9:
-	add	3,3,0
-	add	12,12,0
-
-	/*  At this point we have a tail of 0-7 bytes and we know that the
-	destination is doubleword-aligned.  */
-4:	/* Copy 4 bytes.  */
-	bf	29,2f
-
-	lwz	6,0(12)
-	addi	12,12,4
-	stw	6,0(3)
-	addi	3,3,4
-2:	/* Copy 2 bytes.  */
-	bf	30,1f
-
-	lhz	6,0(12)
-	addi	12,12,2
-	sth	6,0(3)
-	addi	3,3,2
-1:	/* Copy 1 byte.  */
-	bf	31,0f
-
-	lbz	6,0(12)
-	stb	6,0(3)
-0:	/* Return DST + LEN pointer.  */
-	add	3,30,5
-	lwz	30,20(1)
-	lwz	31,24(1)
-	addi	1,1,32
-	blr
-
-	/* Handle copies of 0~31 bytes.  */
-	.align	4
-L(copy_LT_32):
-	cmplwi	cr6,5,8
-	mr	12,4
-	mtcrf	0x01,5
-	ble	cr6,L(copy_LE_8)
-
-	/* At least 9 bytes to go.  */
-	neg	8,4
-	clrrwi	11,4,2
-	andi.	0,8,3
-	cmplwi	cr1,5,16
-	mr	10,5
-	beq	L(copy_LT_32_aligned)
-
-	/* Force 4-bytes alignment for SRC.  */
-	mtocrf  0x01,0
-	subf	10,0,5
-2:	bf	30,1f
-
-	lhz	6,0(12)
-	addi	12,12,2
-	sth	6,0(3)
-	addi	3,3,2
-1:	bf	31,L(end_4bytes_alignment)
-
-	lbz	6,0(12)
-	addi	12,12,1
-	stb	6,0(3)
-	addi	3,3,1
-
-	.align	4
-L(end_4bytes_alignment):
-	cmplwi	cr1,10,16
-	mtcrf	0x01,10
-
-L(copy_LT_32_aligned):
-	/* At least 6 bytes to go, and SRC is word-aligned.  */
-	blt	cr1,8f
-
-	/* Copy 16 bytes.  */
-	lwz	6,0(12)
-	lwz	7,4(12)
-	stw	6,0(3)
-	lwz	8,8(12)
-	stw	7,4(3)
-	lwz	6,12(12)
-	addi	12,12,16
-	stw	8,8(3)
-	stw	6,12(3)
-	addi	3,3,16
-8:	/* Copy 8 bytes.  */
-	bf	28,4f
-
-	lwz	6,0(12)
-	lwz	7,4(12)
-	addi	12,12,8
-	stw	6,0(3)
-	stw	7,4(3)
-	addi	3,3,8
-4:	/* Copy 4 bytes.  */
-	bf	29,2f
-
-	lwz	6,0(12)
-	addi	12,12,4
-	stw	6,0(3)
-	addi	3,3,4
-2:	/* Copy 2-3 bytes.  */
-	bf	30,1f
-
-	lhz	6,0(12)
-	sth	6,0(3)
-	bf	31,0f
-	lbz	7,2(12)
-	stb	7,2(3)
-
-	/* Return DST + LEN pointer.  */
-	add	3,30,5
-	lwz	30,20(1)
-	addi	1,1,32
-	blr
-
-	.align	4
-1:	/* Copy 1 byte.  */
-	bf	31,0f
-
-	lbz	6,0(12)
-	stb	6,0(3)
-0:	/* Return DST + LEN pointer.  */
-	add	3,30,5
-	lwz	30,20(1)
-	addi	1,1,32
-	blr
-
-	/* Handles copies of 0~8 bytes.  */
-	.align	4
-L(copy_LE_8):
-	bne	cr6,4f
-
-	/* Though we could've used lfd/stfd here, they are still
-	slow for unaligned cases.  */
-
-	lwz	6,0(4)
-	lwz	7,4(4)
-	stw	6,0(3)
-	stw	7,4(3)
-
-	/* Return DST + LEN pointer.  */
-	add	3,30,5
-	lwz	30,20(1)
-	addi	1,1,32
-	blr
-
-	.align	4
-4:	/* Copies 4~7 bytes.  */
-	bf	29,2b
-
-	lwz	6,0(4)
-	stw	6,0(3)
-	bf	30,5f
-	lhz	7,4(4)
-	sth	7,4(3)
-	bf	31,0f
-	lbz	8,6(4)
-	stb	8,6(3)
-
-	/* Return DST + LEN pointer.  */
-	add	3,30,5
-	lwz	30,20(1)
-	addi	1,1,32
-	blr
-
-	.align	4
-5:	/* Copy 1 byte.  */
-	bf	31,0f
-
-	lbz	6,4(4)
-	stb	6,4(3)
-
-0:	/* Return DST + LEN pointer.  */
-	add	3,30,5
-	lwz	30,20(1)
-	addi	1,1,32
-	blr
-
-	/* Handle copies of 32+ bytes where DST is aligned (to quadword) but
-	SRC is not. Use aligned quadword loads from SRC, shifted to realign
-	the data, allowing for aligned DST stores.  */
-	.align	4
-L(copy_GE_32_unaligned):
-	andi.	11,3,15	      /* Check alignment of DST.  */
-	clrlwi	0,0,28	      /* Number of bytes until the 1st
-				 quadword of DST.  */
-	srwi	9,5,4	      /* Number of full quadwords remaining.  */
-
-	beq	L(copy_GE_32_unaligned_cont)
-
-	/* DST is not quadword aligned, get it aligned.  */
-
-	mtcrf	0x01,0
-	subf	31,0,5
-
-	/* Vector instructions work best when proper alignment (16-bytes)
-	is present.  Move 0~15 bytes as needed to get DST quadword-aligned.  */
-1:	/* Copy 1 byte.  */
-	bf	31,2f
-
-	lbz	6,0(12)
-	addi	12,12,1
-	stb	6,0(3)
-	addi	3,3,1
-2:	/* Copy 2 bytes.  */
-	bf		30,4f
-
-	lhz	6,0(12)
-	addi	12,12,2
-	sth	6,0(3)
-	addi	3,3,2
-4:	/* Copy 4 bytes.  */
-	bf	29,8f
-
-	lwz	6,0(12)
-	addi	12,12,4
-	stw	6,0(3)
-	addi	3,3,4
-8:	/* Copy 8 bytes.  */
-	bf	28,0f
-
-	lfd	6,0(12)
-	addi	12,12,8
-	stfd	6,0(3)
-	addi	3,3,8
-0:
-	clrlwi	10,12,28      /* Check alignment of SRC.  */
-	srwi	9,31,4	      /* Number of full quadwords remaining.  */
-
-	/* The proper alignment is present, it is OK to copy the bytes now.  */
-L(copy_GE_32_unaligned_cont):
-
-	/* Setup two indexes to speed up the indexed vector operations.  */
-	clrlwi	11,31,28
-	li	6,16	      /* Index for 16-bytes offsets.  */
-	li	7,32	      /* Index for 32-bytes offsets.  */
-	cmplwi	cr1,11,0
-	srwi	8,31,5	      /* Setup the loop counter.  */
-	mr	10,3
-	mr	11,12
-	mtcrf	0x01,9
-	cmplwi	cr6,9,1
-#ifdef __LITTLE_ENDIAN__
-	lvsr    5,0,12
-#else
-	lvsl    5,0,12
-#endif
-	lvx	3,0,12
-	bf	31,L(setup_unaligned_loop)
-
-	/* Copy another 16 bytes to align to 32-bytes due to the loop .  */
-	lvx	4,12,6
-#ifdef __LITTLE_ENDIAN__
-	vperm   6,4,3,5
-#else
-	vperm   6,3,4,5
-#endif
-	addi	11,12,16
-	addi	10,3,16
-	stvx	6,0,3
-	vor	3,4,4
-
-L(setup_unaligned_loop):
-	mtctr	8
-	ble	cr6,L(end_unaligned_loop)
-
-	/* Copy 32 bytes at a time using vector instructions.  */
-	.align	4
-L(unaligned_loop):
-
-	/* Note: vr6/vr10 may contain data that was already copied,
-	but in order to get proper alignment, we may have to copy
-	some portions again. This is faster than having unaligned
-	vector instructions though.  */
-
-	lvx	4,11,6	      /* vr4 = r11+16.  */
-#ifdef __LITTLE_ENDIAN__
-	vperm   6,4,3,5
-#else
-	vperm   6,3,4,5
-#endif
-	lvx	3,11,7	      /* vr3 = r11+32.  */
-#ifdef __LITTLE_ENDIAN__
-	vperm   10,3,4,5
-#else
-	vperm   10,4,3,5
-#endif
-	addi	11,11,32
-	stvx	6,0,10
-	stvx	10,10,6
-	addi	10,10,32
-
-	bdnz	L(unaligned_loop)
-
-	.align	4
-L(end_unaligned_loop):
-
-	/* Check for tail bytes.  */
-	clrrwi	0,31,4
-	mtcrf	0x01,31
-	beq	cr1,0f
-
-	add	3,3,0
-	add	12,12,0
-
-	/*  We have 1~15 tail bytes to copy, and DST is quadword aligned.  */
-8:	/* Copy 8 bytes.  */
-	bf	28,4f
-
-	lwz	6,0(12)
-	lwz	7,4(12)
-	addi	12,12,8
-	stw	6,0(3)
-	stw	7,4(3)
-	addi	3,3,8
-4:	/* Copy 4 bytes.  */
-	bf	29,2f
-
-	lwz	6,0(12)
-	addi	12,12,4
-	stw	6,0(3)
-	addi	3,3,4
-2:	/* Copy 2~3 bytes.  */
-	bf	30,1f
-
-	lhz	6,0(12)
-	addi	12,12,2
-	sth	6,0(3)
-	addi	3,3,2
-1:	/* Copy 1 byte.  */
-	bf	31,0f
-
-	lbz	6,0(12)
-	stb	6,0(3)
-0:	/* Return DST + LEN pointer.  */
-	add	3,30,5
-	lwz	30,20(1)
-	lwz	31,24(1)
-	addi	1,1,32
-	blr
-
-END (__mempcpy)
-libc_hidden_def (__mempcpy)
-weak_alias (__mempcpy, mempcpy)
-libc_hidden_builtin_def (mempcpy)
diff --git a/sysdeps/powerpc/powerpc32/power7/memrchr.S b/sysdeps/powerpc/powerpc32/power7/memrchr.S
deleted file mode 100644
index aedae95..0000000
--- a/sysdeps/powerpc/powerpc32/power7/memrchr.S
+++ /dev/null
@@ -1,196 +0,0 @@
-/* Optimized memrchr implementation for PowerPC32/POWER7 using cmpb insn.
-   Copyright (C) 2010-2018 Free Software Foundation, Inc.
-   Contributed by Luis Machado <luisgpm@br.ibm.com>.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* int [r3] memrchr (char *s [r3], int byte [r4], int size [r5])  */
-	.machine  power7
-ENTRY (__memrchr)
-	CALL_MCOUNT
-	add	r7,r3,r5      /* Calculate the last acceptable address.  */
-	neg	r0,r7
-	addi	r7,r7,-1
-	mr	r10,r3
-	clrrwi	r6,r7,7
-	li	r9,3<<5
-	dcbt	r9,r6,16      /* Stream hint, decreasing addresses.  */
-
-	/* Replicate BYTE to word.  */
-	insrwi	r4,r4,8,16
-	insrwi	r4,r4,16,0
-	li	r6,-4
-	li	r9,-1
-	rlwinm	r0,r0,3,27,28 /* Calculate padding.  */
-	clrrwi	r8,r7,2
-	srw	r9,r9,r0
-	cmplwi	r5,16
-	clrrwi	r0,r10,2
-	ble	L(small_range)
-
-#ifdef __LITTLE_ENDIAN__
-	lwzx	r12,0,r8
-#else
-	lwbrx	r12,0,r8      /* Load reversed word from memory.  */
-#endif
-	cmpb	r3,r12,r4     /* Check for BYTE in WORD1.  */
-	and	r3,r3,r9
-	cmplwi	cr7,r3,0      /* If r3 == 0, no BYTEs have been found.  */
-	bne	cr7,L(done)
-
-	mtcrf   0x01,r8
-	/* Are we now aligned to a doubleword boundary?  If so, skip to
-	   the main loop.  Otherwise, go through the alignment code.  */
-	bf	29,L(loop_setup)
-
-	/* Handle WORD2 of pair.  */
-#ifdef __LITTLE_ENDIAN__
-	lwzx	r12,r8,r6
-#else
-	lwbrx	r12,r8,r6
-#endif
-	addi	r8,r8,-4
-	cmpb	r3,r12,r4
-	cmplwi	cr7,r3,0
-	bne	cr7,L(done)
-
-L(loop_setup):
-	/* The last word we want to read in the loop below is the one
-	   containing the first byte of the string, ie. the word at
-	   s & ~3, or r0.  The first word read is at r8 - 4, we
-	   read 2 * cnt words, so the last word read will be at
-	   r8 - 4 - 8 * cnt + 4.  Solving for cnt gives
-	   cnt = (r8 - r0) / 8  */
-	sub	r5,r8,r0
-	addi	r8,r8,-4
-	srwi	r9,r5,3       /* Number of loop iterations.  */
-	mtctr	r9	      /* Setup the counter.  */
-
-	/* Main loop to look for BYTE backwards in the string.
-	   FIXME: Investigate whether 32 byte align helps with this
-	   9 instruction loop.  */
-	.align	5
-L(loop):
-	/* Load two words, compare and merge in a
-	   single register for speed.  This is an attempt
-	   to speed up the byte-checking process for bigger strings.  */
-
-#ifdef __LITTLE_ENDIAN__
-	lwzx	r12,0,r8
-	lwzx	r11,r8,r6
-#else
-	lwbrx	r12,0,r8
-	lwbrx	r11,r8,r6
-#endif
-	cmpb	r3,r12,r4
-	cmpb	r9,r11,r4
-	or	r5,r9,r3      /* Merge everything in one word.  */
-	cmplwi	cr7,r5,0
-	bne	cr7,L(found)
-	addi	r8,r8,-8
-	bdnz	L(loop)
-
-	/* We may have one more word to read.  */
-	cmplw	r8,r0
-	bnelr
-
-#ifdef __LITTLE_ENDIAN__
-	lwzx	r12,0,r8
-#else
-	lwbrx	r12,0,r8
-#endif
-	cmpb	r3,r12,r4
-	cmplwi	cr7,r3,0
-	bne	cr7,L(done)
-	blr
-
-	.align	4
-L(found):
-	/* OK, one (or both) of the words contains BYTE.  Check
-	   the first word.  */
-	cmplwi	cr6,r3,0
-	bne	cr6,L(done)
-
-	/* BYTE must be in the second word.  Adjust the address
-	   again and move the result of cmpb to r3 so we can calculate the
-	   pointer.  */
-
-	mr	r3,r9
-	addi	r8,r8,-4
-
-	/* r3 has the output of the cmpb instruction, that is, it contains
-	   0xff in the same position as BYTE in the original
-	   word from the string.  Use that to calculate the pointer.
-	   We need to make sure BYTE is *before* the end of the
-	   range.  */
-L(done):
-	cntlzw	r9,r3	      /* Count leading zeros before the match.  */
-	cmplw	r8,r0         /* Are we on the last word?  */
-	srwi	r6,r9,3	      /* Convert leading zeros to bytes.  */
-	addi	r0,r6,-3
-	sub	r3,r8,r0
-	cmplw	cr7,r3,r10
-	bnelr
-	bgelr	cr7
-	li	r3,0
-	blr
-
-	.align	4
-L(null):
-	li	r3,0
-	blr
-
-/* Deals with size <= 16.  */
-	.align	4
-L(small_range):
-	cmplwi	r5,0
-	beq	L(null)
-
-#ifdef __LITTLE_ENDIAN__
-	lwzx	r12,0,r8
-#else
-	lwbrx	r12,0,r8      /* Load reversed word from memory.  */
-#endif
-	cmpb	r3,r12,r4     /* Check for BYTE in WORD1.  */
-	and	r3,r3,r9
-	cmplwi	cr7,r3,0
-	bne	cr7,L(done)
-
-	/* Are we done already?  */
-	cmplw	r8,r0
-	addi	r8,r8,-4
-	beqlr
-
-	.align	5
-L(loop_small):
-#ifdef __LITTLE_ENDIAN__
-	lwzx	r12,0,r8
-#else
-	lwbrx	r12,0,r8
-#endif
-	cmpb	r3,r12,r4
-	cmplw	r8,r0
-	cmplwi	cr7,r3,0
-	bne	cr7,L(done)
-	addi	r8,r8,-4
-	bne	L(loop_small)
-	blr
-
-END (__memrchr)
-weak_alias (__memrchr, memrchr)
-libc_hidden_builtin_def (memrchr)
diff --git a/sysdeps/powerpc/powerpc32/power7/memset.S b/sysdeps/powerpc/powerpc32/power7/memset.S
deleted file mode 100644
index 26fa736..0000000
--- a/sysdeps/powerpc/powerpc32/power7/memset.S
+++ /dev/null
@@ -1,431 +0,0 @@
-/* Optimized memset implementation for PowerPC32/POWER7.
-   Copyright (C) 2010-2018 Free Software Foundation, Inc.
-   Contributed by Luis Machado <luisgpm@br.ibm.com>.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* void * [r3] memset (void *s [r3], int c [r4], size_t n [r5]));
-   Returns 's'.  */
-
-	.machine  power7
-EALIGN (memset, 5, 0)
-	CALL_MCOUNT
-
-	.align	4
-L(_memset):
-	cmplwi	cr7,5,31
-	cmplwi	cr6,5,8
-	mr	10,3		/* Save original argument for later.  */
-	mr	7,1		/* Save original r1 for later.  */
-	cfi_offset(31,-8)
-
-	/* Replicate byte to word.  */
-	insrwi	4,4,8,16
-	insrwi	4,4,16,0
-
-	ble	cr6,L(small)	/* If length <= 8, use short copy code.  */
-
-	neg	0,3
-	ble	cr7,L(medium)	/* If length < 32, use medium copy code.  */
-
-	/* Save our word twice to create a doubleword that we will later
-	   copy to a FPR.  */
-	stwu	1,-32(1)
-	andi.	11,10,7		/* Check alignment of DST.  */
-	mr	12,5
-	stw	4,24(1)
-	stw	4,28(1)
-	beq	L(big_aligned)
-
-	clrlwi	0,0,29
-	mtocrf	0x01,0
-	subf	5,0,5
-
-	/* Get DST aligned to 8 bytes.  */
-1:	bf	31,2f
-
-	stb	4,0(10)
-	addi	10,10,1
-2:	bf	30,4f
-
-	sth	4,0(10)
-	addi	10,10,2
-4:	bf	29,L(big_aligned)
-
-	stw	4,0(10)
-	addi	10,10,4
-
-	.align	4
-L(big_aligned):
-	cmplwi	cr5,5,255
-	li	0,32
-	cmplwi	cr1,5,160
-	dcbtst	0,10
-	cmplwi	cr6,4,0
-	srwi	9,5,3		/* Number of full doublewords remaining.  */
-	crand	27,26,21
-	mtocrf	0x01,9
-	bt	27,L(huge)
-
-	/* From this point on, we'll copy 32+ bytes and the value
-	   isn't 0 (so we can't use dcbz).  */
-
-	srwi	8,5,5
-	clrlwi	11,5,29
-	cmplwi	cr6,11,0
-	cmplwi	cr1,9,4
-	mtctr	8
-
-	/* Copy 1~3 doublewords so the main loop starts
-	at a multiple of 32 bytes.  */
-
-	bf	30,1f
-
-	stw	4,0(10)
-	stw	4,4(10)
-	stw	4,8(10)
-	stw	4,12(10)
-	addi	10,10,16
-	bf	31,L(big_loop)
-
-	stw	4,0(10)
-	stw	4,4(10)
-	addi	10,10,8
-	mr	12,10
-	blt	cr1,L(tail_bytes)
-
-	b	L(big_loop)
-
-	.align	4
-1:	/* Copy 1 doubleword.  */
-	bf	31,L(big_loop)
-
-	stw	4,0(10)
-	stw	4,4(10)
-	addi	10,10,8
-
-	/* First use a 32-bytes loop with stw's to try and avoid the LHS due
-	   to the lfd we will do next.  Also, ping-pong through r10 and r12
-	   to avoid AGEN delays.  */
-	.align	4
-L(big_loop):
-	addi	12,10,32
-	stw	4,0(10)
-	stw	4,4(10)
-	stw	4,8(10)
-	stw	4,12(10)
-	stw	4,16(10)
-	stw	4,20(10)
-	stw	4,24(10)
-	stw	4,28(10)
-	bdz	L(tail_bytes)
-
-	addi	10,10,64
-	stw	4,0(12)
-	stw	4,4(12)
-	stw	4,8(12)
-	stw	4,12(12)
-	stw	4,16(12)
-	stw	4,20(12)
-	stw	4,24(12)
-	stw	4,28(12)
-	bdnz	L(big_loop_fast_setup)
-
-	mr	12,10
-	b	L(tail_bytes)
-
-	/* Now that we're probably past the LHS window, use the VSX to
-	   speed up the loop.  */
-L(big_loop_fast_setup):
-	li	11,24
-	li	6,16
-	lxvdsx	4,1,11
-
-	.align	4
-L(big_loop_fast):
-	addi	12,10,32
-	stxvd2x	4,0,10
-	stxvd2x	4,10,6
-	bdz	L(tail_bytes)
-
-	addi	10,10,64
-	stxvd2x	4,0,12
-	stxvd2x	4,12,6
-	bdnz	L(big_loop_fast)
-
-	mr	12,10
-
-	.align	4
-L(tail_bytes):
-
-	/* Check for tail bytes.  */
-	mr	1,7		/* Restore r1.  */
-	beqlr	cr6
-
-	clrlwi	0,5,29
-	mtocrf	0x01,0
-
-	/*  At this point we have a tail of 0-7 bytes and we know that the
-	destination is doubleword-aligned.  */
-4:	/* Copy 4 bytes.  */
-	bf	29,2f
-
-	stw	4,0(12)
-	addi	12,12,4
-2:	/* Copy 2 bytes.  */
-	bf	30,1f
-
-	sth	4,0(12)
-	addi	12,12,2
-1:	/* Copy 1 byte.  */
-	bflr	31
-
-	stb	4,0(12)
-	blr
-
-
-	/* Special case when value is 0 and we have a long length to deal
-	   with.  Use dcbz to zero out 128-bytes at a time.  Before using
-	   dcbz though, we need to get the destination 128-bytes aligned.  */
-	.align	4
-L(huge):
-	lfd	4,24(1)
-	andi.	11,10,127
-	neg	0,10
-	beq	L(huge_aligned)
-
-	clrlwi	0,0,25
-	subf	5,0,5
-	srwi	0,0,3
-	mtocrf  0x01,0
-
-	/* Get DST aligned to 128 bytes.  */
-8:	bf	28,4f
-
-	stfd	4,0(10)
-	stfd	4,8(10)
-	stfd	4,16(10)
-	stfd	4,24(10)
-	stfd	4,32(10)
-	stfd	4,40(10)
-	stfd	4,48(10)
-	stfd	4,56(10)
-	addi	10,10,64
-	.align	4
-4:	bf	29,2f
-
-	stfd	4,0(10)
-	stfd	4,8(10)
-	stfd	4,16(10)
-	stfd	4,24(10)
-	addi	10,10,32
-	.align	4
-2:	bf	30,1f
-
-	stfd	4,0(10)
-	stfd	4,8(10)
-	addi	10,10,16
-	.align	4
-1:	bf	31,L(huge_aligned)
-
-	stfd	4,0(10)
-	addi	10,10,8
-
-L(huge_aligned):
-	srwi	8,5,7
-	clrlwi	11,5,25
-	cmplwi	cr6,11,0
-	mtctr	8
-
-	/* Copies 128-bytes at a time.  */
-	.align	4
-L(huge_loop):
-	dcbz	0,10
-	addi	10,10,128
-	bdnz	L(huge_loop)
-
-	/* We have a tail of 0~127 bytes to handle.  */
-	mr	1,7		/* Restore r1.  */
-	beqlr	cr6
-
-	subf	9,3,10
-	subf	5,9,12
-	srwi	8,5,3
-	cmplwi	cr6,8,0
-	mtocrf	0x01,8
-
-	/* We have a tail o 1~127 bytes. Copy up to 15 doublewords for
-	speed.  We'll handle the resulting tail bytes later.  */
-	beq	cr6,L(tail)
-
-8:	bf	28,4f
-
-	stfd	4,0(10)
-	stfd	4,8(10)
-	stfd	4,16(10)
-	stfd	4,24(10)
-	stfd	4,32(10)
-	stfd	4,40(10)
-	stfd	4,48(10)
-	stfd	4,56(10)
-	addi	10,10,64
-	.align	4
-4:	bf	29,2f
-
-	stfd	4,0(10)
-	stfd	4,8(10)
-	stfd	4,16(10)
-	stfd	4,24(10)
-	addi	10,10,32
-	.align	4
-2:	bf	30,1f
-
-	stfd	4,0(10)
-	stfd	4,8(10)
-	addi	10,10,16
-	.align	4
-1:	bf	31,L(tail)
-
-	stfd	4,0(10)
-	addi	10,10,8
-
-	/* Handle the rest of the tail bytes here.  */
-L(tail):
-	mtocrf	0x01,5
-
-	.align	4
-4:	bf	29,2f
-
-	stw	4,0(10)
-	addi	10,10,4
-	.align	4
-2:	bf	30,1f
-
-	sth	4,0(10)
-	addi	10,10,2
-	.align	4
-1:	bflr	31
-
-	stb	4,0(10)
-	blr
-
-
-	/* Expanded tree to copy tail bytes without increments.  */
-	.align	4
-L(copy_tail):
-	bf	29,L(FXX)
-
-	stw	4,0(10)
-	bf	30,L(TFX)
-
-	sth	4,4(10)
-	bflr	31
-
-	stb	4,6(10)
-	blr
-
-	.align	4
-L(FXX):	bf	30,L(FFX)
-
-	sth	4,0(10)
-	bflr	31
-
-	stb	4,2(10)
-	blr
-
-	.align	4
-L(TFX):	bflr	31
-
-	stb	4,4(10)
-	blr
-
-	.align	4
-L(FFX):	bflr	31
-
-	stb	4,0(10)
-	blr
-
-	/* Handle copies of 9~31 bytes.  */
-	.align	4
-L(medium):
-	/* At least 9 bytes to go.  */
-	andi.	11,10,3
-	clrlwi	0,0,30
-	beq	L(medium_aligned)
-
-	/* Force 4-bytes alignment for DST.  */
-	mtocrf	0x01,0
-	subf	5,0,5
-1:	/* Copy 1 byte.  */
-	bf	31,2f
-
-	stb	4,0(10)
-	addi	10,10,1
-2:	/* Copy 2 bytes.  */
-	bf	30,L(medium_aligned)
-
-	sth	4,0(10)
-	addi	10,10,2
-
-	.align	4
-L(medium_aligned):
-	/* At least 6 bytes to go, and DST is word-aligned.  */
-	cmplwi	cr1,5,16
-	mtocrf	0x01,5
-	blt	cr1,8f
-
-	/* Copy 16 bytes.  */
-	stw	4,0(10)
-	stw	4,4(10)
-	stw	4,8(10)
-	stw	4,12(10)
-	addi	10,10,16
-8:	/* Copy 8 bytes.  */
-	bf	28,4f
-
-	stw	4,0(10)
-	stw	4,4(10)
-	addi	10,10,8
-4:	/* Copy 4 bytes.  */
-	bf	29,2f
-
-	stw	4,0(10)
-	addi	10,10,4
-2:	/* Copy 2-3 bytes.  */
-	bf	30,1f
-
-	sth	4,0(10)
-	addi	10,10,2
-1:	/* Copy 1 byte.  */
-	bflr	31
-
-	stb	4,0(10)
-	blr
-
-	/* Handles copies of 0~8 bytes.  */
-	.align	4
-L(small):
-	mtocrf	0x01,5
-	bne	cr6,L(copy_tail)
-
-	stw	4,0(10)
-	stw	4,4(10)
-	blr
-
-END (memset)
-libc_hidden_builtin_def (memset)
diff --git a/sysdeps/powerpc/powerpc32/power7/rawmemchr.S b/sysdeps/powerpc/powerpc32/power7/rawmemchr.S
deleted file mode 100644
index a886e13..0000000
--- a/sysdeps/powerpc/powerpc32/power7/rawmemchr.S
+++ /dev/null
@@ -1,110 +0,0 @@
-/* Optimized rawmemchr implementation for PowerPC32/POWER7 using cmpb insn.
-   Copyright (C) 2010-2018 Free Software Foundation, Inc.
-   Contributed by Luis Machado <luisgpm@br.ibm.com>.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* int [r3] rawmemchr (void *s [r3], int c [r4])  */
-	.machine  power7
-ENTRY (__rawmemchr)
-	CALL_MCOUNT
-	dcbt	0,r3
-	clrrwi	r8,r3,2	      /* Align the address to word boundary.  */
-
-	/* Replicate byte to word.  */
-	insrwi	r4,r4,8,16
-	insrwi	r4,r4,16,0
-
-	/* Now r4 has a word of c bytes.  */
-
-	rlwinm	r6,r3,3,27,28 /* Calculate padding.  */
-	lwz	r12,0(r8)     /* Load word from memory.  */
-	cmpb	r5,r12,r4     /* Compare each byte against c byte.  */
-#ifdef __LITTLE_ENDIAN__
-	srw	r5,r5,r6
-	slw	r5,r5,r6
-#else
-	slw	r5,r5,r6      /* Move left to discard ignored bits.  */
-	srw	r5,r5,r6      /* Bring the bits back as zeros.  */
-#endif
-	cmpwi	cr7,r5,0      /* If r5 == 0, no c bytes have been found.  */
-	bne	cr7,L(done)
-
-	mtcrf   0x01,r8
-
-	/* Are we now aligned to a doubleword boundary?  If so, skip to
-	   the main loop.  Otherwise, go through the alignment code.  */
-
-	bt	29,L(loop)
-
-	/* Handle WORD2 of pair.  */
-	lwzu	r12,4(r8)
-	cmpb	r5,r12,r4
-	cmpwi	cr7,r5,0
-	bne	cr7,L(done)
-	b	L(loop)	      /* We branch here (rather than falling through)
-				 to skip the nops due to heavy alignment
-				 of the loop below.  */
-
-	/* Main loop to look for the end of the string.  Since it's a
-	   small loop (< 8 instructions), align it to 32-bytes.  */
-	.p2align  5
-L(loop):
-	/* Load two words, compare and merge in a
-	   single register for speed.  This is an attempt
-	   to speed up the byte-checking process for bigger strings.  */
-	lwz	r12,4(r8)
-	lwzu	r11,8(r8)
-	cmpb	r5,r12,r4
-	cmpb	r6,r11,r4
-	or	r7,r5,r6
-	cmpwi	cr7,r7,0
-	beq	cr7,L(loop)
-
-	/* OK, one (or both) of the words contains a 'c' byte.  Check
-	   the first word and decrement the address in case the first
-	   word really contains a c byte.  */
-
-	cmpwi	cr6,r5,0
-	addi	r8,r8,-4
-	bne	cr6,L(done)
-
-	/* The 'c' byte must be in the second word.  Adjust the address
-	   again and move the result of cmpb to r10 so we can calculate the
-	   pointer.  */
-	mr	r5,r6
-	addi	r8,r8,4
-
-	/* r5 has the output of the cmpb instruction, that is, it contains
-	   0xff in the same position as the 'c' byte in the original
-	   word from the string.  Use that fact to find out what is
-	   the position of the byte inside the string.  */
-L(done):
-#ifdef __LITTLE_ENDIAN__
-	addi    r0,r5,-1
-	andc    r0,r0,r5
-	popcntw	r0,r0
-#else
-	cntlzw	r0,r5	      /* Count leading zeros before the match.  */
-#endif
-	srwi	r0,r0,3	      /* Convert leading zeros to bytes.  */
-	add	r3,r8,r0      /* Return address of the matching char.  */
-	blr
-END (__rawmemchr)
-weak_alias (__rawmemchr,rawmemchr)
-libc_hidden_builtin_def (__rawmemchr)
diff --git a/sysdeps/powerpc/powerpc32/power7/strcasecmp.S b/sysdeps/powerpc/powerpc32/power7/strcasecmp.S
deleted file mode 100644
index 7bd8b43..0000000
--- a/sysdeps/powerpc/powerpc32/power7/strcasecmp.S
+++ /dev/null
@@ -1,129 +0,0 @@
-/* Optimized strcasecmp implementation for PowerPC32.
-   Copyright (C) 2011-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-#include <locale-defines.h>
-
-/* int [r3] strcasecmp (const char *s1 [r3], const char *s2 [r4] )
-
-   or if defined USE_IN_EXTENDED_LOCALE_MODEL:
-
-   int [r3] strcasecmp_l (const char *s1 [r3], const char *s2 [r4],
-                          locale_t loc [r5]) */
-
-#ifndef STRCMP
-# define __STRCMP __strcasecmp
-# define STRCMP   strcasecmp
-#endif
-
-ENTRY (__STRCMP)
-
-#define rRTN	r3	/* Return value */
-#define rSTR1	r5	/* 1st string */
-#define rSTR2	r4	/* 2nd string */
-#define rLOCARG	r5	/* 3rd argument: locale_t */
-#define rCHAR1	r6	/* Byte read from 1st string */
-#define rCHAR2	r7	/* Byte read from 2nd string */
-#define rADDR1	r8	/* Address of tolower(rCHAR1) */
-#define rADDR2	r12	/* Address of tolower(rCHAR2) */
-#define rLWR1	r8	/* Byte tolower(rCHAR1) */
-#define rLWR2	r12	/* Byte tolower(rCHAR2) */
-#define rTMP	r0
-#define rGOT	r9	/* Address of the Global Offset Table */
-#define rLOC	r11	/* Default locale address */
-
-	cmpw    cr7, r3, r4
-#ifndef USE_IN_EXTENDED_LOCALE_MODEL
-# ifdef SHARED
-	mflr	rTMP
-	bcl	20,31,.L1
-.L1:	mflr	rGOT
-	addis	rGOT, rGOT, _GLOBAL_OFFSET_TABLE_-.L1@ha
-	addi 	rGOT, rGOT, _GLOBAL_OFFSET_TABLE_-.L1@l
-	lwz	rLOC, __libc_tsd_LOCALE@got@tprel(rGOT)
-	add 	rLOC, rLOC, __libc_tsd_LOCALE@tls
-	lwz	rLOC, 0(rLOC)
-	mtlr	rTMP
-# else
-	lis	rTMP,_GLOBAL_OFFSET_TABLE_@ha
-	la	rLOC,_GLOBAL_OFFSET_TABLE_@l(rTMP)
-	lwz	rLOC, __libc_tsd_LOCALE@got@tprel(rGOT)
-	add	rLOC, rLOC, __libc_tsd_LOCALE@tls
-	lwz	rLOC, 0(rLOC)
-# endif /* SHARED */
-#else
-	mr	rLOC, rLOCARG
-#endif
-	mr	rSTR1, rRTN
-	lwz	rLOC, LOCALE_CTYPE_TOLOWER(rLOC)
-	li	rRTN, 0
-	beqlr	cr7
-
-	/* Unrolling loop for POWER: loads are done with 'lbz' plus
-	offset and string descriptors are only updated in the end
-	of loop unrolling. */
-
-L(loop):
-	lbz	rCHAR1, 0(rSTR1)	/* Load char from s1 */
-	lbz	rCHAR2, 0(rSTR2)	/* Load char from s2 */
-	sldi	rADDR1, rCHAR1, 2	/* Calculate address for tolower(*s1) */
-	sldi	rADDR2, rCHAR2, 2	/* Calculate address for tolower(*s2) */
-	lwzx	rLWR1, rLOC, rADDR1	/* Load tolower(*s1) */
-	lwzx	rLWR2, rLOC, rADDR2	/* Load tolower(*s2) */
-	cmpwi	cr7, rCHAR1, 0		/* *s1 == '\0' ? */
-	subf.	r3, rLWR2, rLWR1
-	bnelr
-	beqlr	cr7
-	lbz	rCHAR1, 1(rSTR1)
-	lbz	rCHAR2, 1(rSTR2)
-	sldi	rADDR1, rCHAR1, 2
-	sldi	rADDR2, rCHAR2, 2
-	lwzx	rLWR1, rLOC, rADDR1
-	lwzx	rLWR2, rLOC, rADDR2
-	cmpwi	cr7, rCHAR1, 0
-	subf.	r3, rLWR2, rLWR1
-	bnelr
-	beqlr	cr7
-	lbz	rCHAR1, 2(rSTR1)
-	lbz	rCHAR2, 2(rSTR2)
-	sldi	rADDR1, rCHAR1, 2
-	sldi	rADDR2, rCHAR2, 2
-	lwzx	rLWR1, rLOC, rADDR1
-	lwzx	rLWR2, rLOC, rADDR2
-	cmpwi	cr7, rCHAR1, 0
-	subf.	r3, rLWR2, rLWR1
-	bnelr
-	beqlr	cr7
-	lbz	rCHAR1, 3(rSTR1)
-	lbz	rCHAR2, 3(rSTR2)
-	/* Increment both string descriptors */
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-	sldi	rADDR1, rCHAR1, 2
-	sldi	rADDR2, rCHAR2, 2
-	lwzx	rLWR1, rLOC, rADDR1
-	lwzx	rLWR2, rLOC, rADDR2
-	cmpwi	cr7, rCHAR1, 0
-	subf.	r3, rLWR2, rLWR1
-	bnelr
-	bne	cr7,L(loop)
-	blr
-END (__STRCMP)
-
-weak_alias (__STRCMP, STRCMP)
-libc_hidden_builtin_def (__STRCMP)
diff --git a/sysdeps/powerpc/powerpc32/power7/strcasecmp_l.S b/sysdeps/powerpc/powerpc32/power7/strcasecmp_l.S
deleted file mode 100644
index c13c4eb..0000000
--- a/sysdeps/powerpc/powerpc32/power7/strcasecmp_l.S
+++ /dev/null
@@ -1,5 +0,0 @@
-#define USE_IN_EXTENDED_LOCALE_MODEL
-#define STRCMP   strcasecmp_l
-#define __STRCMP __strcasecmp_l
-
-#include "strcasecmp.S"
diff --git a/sysdeps/powerpc/powerpc32/power7/strchr.S b/sysdeps/powerpc/powerpc32/power7/strchr.S
deleted file mode 100644
index 54bb4ad..0000000
--- a/sysdeps/powerpc/powerpc32/power7/strchr.S
+++ /dev/null
@@ -1,225 +0,0 @@
-/* Optimized strchr implementation for PowerPC32/POWER7 using cmpb insn.
-   Copyright (C) 2010-2018 Free Software Foundation, Inc.
-   Contributed by Luis Machado <luisgpm@br.ibm.com>.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* int [r3] strchr (char *s [r3], int c [r4])  */
-	.machine  power7
-ENTRY (strchr)
-	CALL_MCOUNT
-	dcbt	0,r3
-	clrrwi	r8,r3,2	      /* Align the address to word boundary.  */
-	cmpwi	cr7,r4,0
-	lwz	r12,0(r8)     /* Load word from memory.  */
-	li	r0,0	      /* Word with null chars to use
-				 with cmpb.  */
-
-	rlwinm	r6,r3,3,27,28 /* Calculate padding.  */
-
-	beq	cr7,L(null_match)
-
-	/* Replicate byte to word.  */
-	insrwi	r4,r4,8,16
-	insrwi	r4,r4,16,0
-
-	/* Now r4 has a word of c bytes and r0 has
-	   a word of null bytes.  */
-
-	cmpb	r10,r12,r4     /* Compare each byte against c byte.  */
-	cmpb	r11,r12,r0     /* Compare each byte against null byte.  */
-
-	/* Move the words left and right to discard the bits that are
-	   not part of the string and to bring them back as zeros.  */
-#ifdef __LITTLE_ENDIAN__
-	srw	r10,r10,r6
-	srw	r11,r11,r6
-	slw	r10,r10,r6
-	slw	r11,r11,r6
-#else
-	slw	r10,r10,r6
-	slw	r11,r11,r6
-	srw	r10,r10,r6
-	srw	r11,r11,r6
-#endif
-	or	r5,r10,r11    /* OR the results to speed things up.  */
-	cmpwi	cr7,r5,0      /* If r5 == 0, no c or null bytes
-				 have been found.  */
-	bne	cr7,L(done)
-
-	mtcrf   0x01,r8
-
-	/* Are we now aligned to a doubleword boundary?  If so, skip to
-	   the main loop.  Otherwise, go through the alignment code.  */
-
-	bt	29,L(loop)
-
-	/* Handle WORD2 of pair.  */
-	lwzu	r12,4(r8)
-	cmpb	r10,r12,r4
-	cmpb	r11,r12,r0
-	or	r5,r10,r11
-	cmpwi	cr7,r5,0
-	bne	cr7,L(done)
-	b	L(loop)	      /* We branch here (rather than falling through)
-				 to skip the nops due to heavy alignment
-				 of the loop below.  */
-
-	.p2align  5
-L(loop):
-	/* Load two words, compare and merge in a
-	   single register for speed.  This is an attempt
-	   to speed up the null-checking process for bigger strings.  */
-	lwz	r12,4(r8)
-	lwzu	r9,8(r8)
-	cmpb	r10,r12,r4
-	cmpb	r11,r12,r0
-	cmpb	r6,r9,r4
-	cmpb	r7,r9,r0
-	or	r12,r10,r11
-	or	r9,r6,r7
-	or	r5,r12,r9
-	cmpwi	cr7,r5,0
-	beq	cr7,L(loop)
-
-	/* OK, one (or both) of the words contains a c/null byte.  Check
-	   the first word and decrement the address in case the first
-	   word really contains a c/null byte.  */
-
-	cmpwi	cr6,r12,0
-	addi	r8,r8,-4
-	bne	cr6,L(done)
-
-	/* The c/null byte must be in the second word.  Adjust the address
-	   again and move the result of cmpb to r10/r11 so we can calculate
-	   the pointer.  */
-
-	mr	r10,r6
-	mr	r11,r7
-	addi	r8,r8,4
-
-	/* r10/r11 have the output of the cmpb instructions, that is,
-	   0xff in the same position as the c/null byte in the original
-	   word from the string.  Use that to calculate the pointer.  */
-L(done):
-#ifdef __LITTLE_ENDIAN__
-	addi    r3,r10,-1
-	andc    r3,r3,r10
-	popcntw	r0,r3
-	addi    r4,r11,-1
-	andc    r4,r4,r11
-	cmplw	cr7,r3,r4
-	bgt	cr7,L(no_match)
-#else
-	cntlzw	r0,r10	      /* Count leading zeros before c matches.  */
-	cmplw	cr7,r11,r10
-	bgt	cr7,L(no_match)
-#endif
-	srwi	r0,r0,3	      /* Convert leading zeros to bytes.  */
-	add	r3,r8,r0      /* Return address of the matching c byte
-				 or null in case c was not found.  */
-	blr
-
-	.align	4
-L(no_match):
-	li	r3,0
-	blr
-
-/* We are here because strchr was called with a null byte.  */
-	.align	4
-L(null_match):
-	/* r0 has a word of null bytes.  */
-
-	cmpb	r5,r12,r0     /* Compare each byte against null bytes.  */
-
-	/* Move the words left and right to discard the bits that are
-	   not part of the string and bring them back as zeros.  */
-#ifdef __LITTLE_ENDIAN__
-	srw	r5,r5,r6
-	slw	r5,r5,r6
-#else
-	slw	r5,r5,r6
-	srw	r5,r5,r6
-#endif
-	cmpwi	cr7,r5,0      /* If r10 == 0, no c or null bytes
-				 have been found.  */
-	bne	cr7,L(done_null)
-
-	mtcrf   0x01,r8
-
-	/* Are we now aligned to a doubleword boundary?  If so, skip to
-	   the main loop.  Otherwise, go through the alignment code.  */
-
-	bt	29,L(loop_null)
-
-	/* Handle WORD2 of pair.  */
-	lwzu	r12,4(r8)
-	cmpb    r5,r12,r0
-	cmpwi	cr7,r5,0
-	bne	cr7,L(done_null)
-	b	L(loop_null)  /* We branch here (rather than falling through)
-				 to skip the nops due to heavy alignment
-				 of the loop below.  */
-
-	/* Main loop to look for the end of the string.  Since it's a
-	   small loop (< 8 instructions), align it to 32-bytes.  */
-	.p2align  5
-L(loop_null):
-	/* Load two words, compare and merge in a
-	   single register for speed.  This is an attempt
-	   to speed up the null-checking process for bigger strings.  */
-	lwz	r12,4(r8)
-	lwzu    r11,8(r8)
-	cmpb	r5,r12,r0
-	cmpb	r10,r11,r0
-	or	r6,r5,r10
-	cmpwi	cr7,r6,0
-	beq	cr7,L(loop_null)
-
-	/* OK, one (or both) of the words contains a null byte.  Check
-	   the first word and decrement the address in case the first
-	   word really contains a null byte.  */
-
-	cmpwi	cr6,r5,0
-	addi	r8,r8,-4
-	bne	cr6,L(done_null)
-
-	/* The null byte must be in the second word.  Adjust the address
-	   again and move the result of cmpb to r10 so we can calculate the
-	   pointer.  */
-
-	mr	r5,r10
-	addi	r8,r8,4
-
-	/* r5 has the output of the cmpb instruction, that is, it contains
-	   0xff in the same position as the null byte in the original
-	   word from the string.  Use that to calculate the pointer.  */
-L(done_null):
-#ifdef __LITTLE_ENDIAN__
-	addi    r0,r5,-1
-	andc    r0,r0,r5
-	popcntw	r0,r0
-#else
-	cntlzw	r0,r5	      /* Count leading zeros before the match.  */
-#endif
-	srwi	r0,r0,3	      /* Convert leading zeros to bytes.  */
-	add	r3,r8,r0      /* Return address of the matching null byte.  */
-	blr
-END (strchr)
-weak_alias (strchr, index)
-libc_hidden_builtin_def (strchr)
diff --git a/sysdeps/powerpc/powerpc32/power7/strchrnul.S b/sysdeps/powerpc/powerpc32/power7/strchrnul.S
deleted file mode 100644
index 634bf56..0000000
--- a/sysdeps/powerpc/powerpc32/power7/strchrnul.S
+++ /dev/null
@@ -1,127 +0,0 @@
-/* Optimized strchrnul implementation for PowerPC32/POWER7 using cmpb insn.
-   Copyright (C) 2010-2018 Free Software Foundation, Inc.
-   Contributed by Luis Machado <luisgpm@br.ibm.com>.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* int [r3] strchrnul (char *s [r3], int c [r4])  */
-	.machine  power7
-ENTRY (__strchrnul)
-	CALL_MCOUNT
-	dcbt	0,r3
-	clrrwi	r8,r3,2	      /* Align the address to word boundary.  */
-
-	/* Replicate byte to word.  */
-	insrwi  r4,r4,8,16
-	insrwi  r4,r4,16,0
-
-	rlwinm	r6,r3,3,27,28 /* Calculate padding.  */
-	lwz	r12,0(r8)     /* Load word from memory.  */
-	li	r0,0	      /* Word with null chars to use
-				 with cmpb.  */
-
-	/* Now r4 has a word of c bytes and r0 has
-	   a word of null bytes.  */
-
-	cmpb	r10,r12,r0    /* Compare each byte against c byte.  */
-	cmpb	r9,r12,r4     /* Compare each byte against null byte.  */
-
-	/* Move the words left and right to discard the bits that are
-	   not part of the string and bring them back as zeros.  */
-#ifdef __LITTLE_ENDIAN__
-	srw	r10,r10,r6
-	srw	r9,r9,r6
-	slw	r10,r10,r6
-	slw	r9,r9,r6
-#else
-	slw	r10,r10,r6
-	slw	r9,r9,r6
-	srw	r10,r10,r6
-	srw	r9,r9,r6
-#endif
-	or	r5,r9,r10     /* OR the results to speed things up.  */
-	cmpwi	cr7,r5,0      /* If r5 == 0, no c or null bytes
-				 have been found.  */
-	bne	cr7,L(done)
-
-	mtcrf   0x01,r8
-
-	/* Are we now aligned to a doubleword boundary?  If so, skip to
-	   the main loop.  Otherwise, go through the alignment code.  */
-
-	bt	29,L(loop)
-
-	/* Handle WORD2 of pair.  */
-	lwzu	r12,4(r8)
-	cmpb	r10,r12,r0
-	cmpb	r9,r12,r4
-	or	r5,r9,r10
-	cmpwi	cr7,r5,0
-	bne	cr7,L(done)
-	b	L(loop)	      /* We branch here (rather than falling through)
-				 to skip the nops due to heavy alignment
-				 of the loop below.  */
-
-	.p2align  5
-L(loop):
-	/* Load two words, compare and merge in a
-	   single register for speed.  This is an attempt
-	   to speed up the null-checking process for bigger strings.  */
-	lwz	r12,4(r8)
-	lwzu	r11,8(r8)
-	cmpb	r10,r12,r0
-	cmpb	r9,r12,r4
-	cmpb	r6,r11,r0
-	cmpb	r7,r11,r4
-	or	r5,r9,r10
-	or	r10,r6,r7
-	or	r11,r5,r10
-	cmpwi	cr7,r11,0
-	beq	cr7,L(loop)
-
-	/* OK, one (or both) of the words contains a c/null byte.  Check
-	   the first word and decrement the address in case the first
-	   word really contains a c/null byte.  */
-
-	cmpwi	cr6,r5,0
-	addi	r8,r8,-4
-	bne	cr6,L(done)
-
-	/* The c/null byte must be in the second word.  Adjust the address
-	   again and move the result of cmpb to r5 so we can calculate the
-	   pointer.  */
-	mr	r5,r10
-	addi	r8,r8,4
-
-	/* r5 has the output of the cmpb instruction, that is, it contains
-	   0xff in the same position as the c/null byte in the original
-	   word from the string.  Use that to calculate the pointer.  */
-L(done):
-#ifdef __LITTLE_ENDIAN__
-	addi    r0,r5,-1
-	andc    r0,r0,r5
-	popcntw	r0,r0
-#else
-	cntlzw	r0,r5	      /* Count leading zeros before the match.  */
-#endif
-	srwi	r0,r0,3	      /* Convert leading zeros to bytes.  */
-	add	r3,r8,r0      /* Return address of matching c/null byte.  */
-	blr
-END (__strchrnul)
-weak_alias (__strchrnul,strchrnul)
-libc_hidden_builtin_def (__strchrnul)
diff --git a/sysdeps/powerpc/powerpc32/power7/strlen.S b/sysdeps/powerpc/powerpc32/power7/strlen.S
deleted file mode 100644
index f7d1ebb..0000000
--- a/sysdeps/powerpc/powerpc32/power7/strlen.S
+++ /dev/null
@@ -1,102 +0,0 @@
-/* Optimized strlen implementation for PowerPC32/POWER7 using cmpb insn.
-   Copyright (C) 2010-2018 Free Software Foundation, Inc.
-   Contributed by Luis Machado <luisgpm@br.ibm.com>.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* int [r3] strlen (char *s [r3])  */
-	.machine  power7
-ENTRY (strlen)
-	CALL_MCOUNT
-	dcbt	0,r3
-	clrrwi	r4,r3,2	      /* Align the address to word boundary.  */
-	rlwinm	r6,r3,3,27,28 /* Calculate padding.  */
-	li	r0,0	      /* Word with null chars to use with cmpb.  */
-	li	r5,-1	      /* MASK = 0xffffffffffffffff.  */
-	lwz	r12,0(r4)     /* Load word from memory.  */
-#ifdef __LITTLE_ENDIAN__
-	slw	r5,r5,r6
-#else
-	srw	r5,r5,r6      /* MASK = MASK >> padding.  */
-#endif
-	orc	r9,r12,r5     /* Mask bits that are not part of the string.  */
-	cmpb	r10,r9,r0     /* Check for null bytes in WORD1.  */
-	cmpwi	cr7,r10,0     /* If r10 == 0, no null's have been found.  */
-	bne	cr7,L(done)
-
-	mtcrf   0x01,r4
-
-	/* Are we now aligned to a doubleword boundary?  If so, skip to
-	   the main loop.  Otherwise, go through the alignment code.  */
-
-	bt	29,L(loop)
-
-	/* Handle WORD2 of pair.  */
-	lwzu	r12,4(r4)
-	cmpb	r10,r12,r0
-	cmpwi	cr7,r10,0
-	bne	cr7,L(done)
-
-	/* Main loop to look for the end of the string.  Since it's a
-	   small loop (< 8 instructions), align it to 32-bytes.  */
-	.p2align  5
-L(loop):
-	/* Load two words, compare and merge in a
-	   single register for speed.  This is an attempt
-	   to speed up the null-checking process for bigger strings.  */
-
-	lwz	r12, 4(r4)
-	lwzu	r11, 8(r4)
-	cmpb	r10,r12,r0
-	cmpb	r9,r11,r0
-	or	r8,r9,r10     /* Merge everything in one word.  */
-	cmpwi	cr7,r8,0
-	beq	cr7,L(loop)
-
-	/* OK, one (or both) of the words contains a null byte.  Check
-	   the first word and decrement the address in case the first
-	   word really contains a null byte.  */
-
-	cmpwi	cr6,r10,0
-	addi	r4,r4,-4
-	bne	cr6,L(done)
-
-	/* The null byte must be in the second word.  Adjust the address
-	   again and move the result of cmpb to r10 so we can calculate the
-	   length.  */
-
-	mr	r10,r9
-	addi	r4,r4,4
-
-	/* r10 has the output of the cmpb instruction, that is, it contains
-	   0xff in the same position as the null byte in the original
-	   word from the string.  Use that to calculate the length.  */
-L(done):
-#ifdef __LITTLE_ENDIAN__
-	addi	r9, r10, -1   /* Form a mask from trailing zeros.  */
-	andc	r9, r9, r10
-	popcntw r0, r9	      /* Count the bits in the mask.  */
-#else
-	cntlzw	r0,r10	      /* Count leading zeros before the match.  */
-#endif
-	subf	r5,r3,r4
-	srwi	r0,r0,3	      /* Convert leading zeros to bytes.  */
-	add	r3,r5,r0      /* Compute final length.  */
-	blr
-END (strlen)
-libc_hidden_builtin_def (strlen)
diff --git a/sysdeps/powerpc/powerpc32/power7/strncmp.S b/sysdeps/powerpc/powerpc32/power7/strncmp.S
deleted file mode 100644
index 9fe8e41..0000000
--- a/sysdeps/powerpc/powerpc32/power7/strncmp.S
+++ /dev/null
@@ -1,199 +0,0 @@
-/* Optimized strcmp implementation for POWER7/PowerPC32.
-   Copyright (C) 2010-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* See strlen.s for comments on how the end-of-string testing works.  */
-
-/* int [r3] strncmp (const char *s1 [r3],
-		     const char *s2 [r4],
-		     size_t size [r5])  */
-
-EALIGN (strncmp,5,0)
-
-#define rTMP2	r0
-#define rRTN	r3
-#define rSTR1	r3	/* first string arg */
-#define rSTR2	r4	/* second string arg */
-#define rN	r5	/* max string length */
-#define rWORD1	r6	/* current word in s1 */
-#define rWORD2	r7	/* current word in s2 */
-#define rWORD3	r10
-#define rWORD4	r11
-#define rFEFE	r8	/* constant 0xfefefeff (-0x01010101) */
-#define r7F7F	r9	/* constant 0x7f7f7f7f */
-#define rNEG	r10	/* ~(word in s1 | 0x7f7f7f7f) */
-#define rBITDIF	r11	/* bits that differ in s1 & s2 words */
-#define rTMP	r12
-
-	dcbt	0,rSTR1
-	nop
-	or	rTMP,rSTR2,rSTR1
-	lis	r7F7F,0x7f7f
-	dcbt	0,rSTR2
-	nop
-	clrlwi.	rTMP,rTMP,30
-	cmplwi	cr1,rN,0
-	lis	rFEFE,-0x101
-	bne	L(unaligned)
-/* We are word aligned so set up for two loops.  first a word
-   loop, then fall into the byte loop if any residual.  */
-	srwi.	rTMP,rN,2
-	clrlwi	rN,rN,30
-	addi	rFEFE,rFEFE,-0x101
-	addi	r7F7F,r7F7F,0x7f7f
-	cmplwi	cr1,rN,0
-	beq	L(unaligned)
-
-	mtctr	rTMP
-	lwz	rWORD1,0(rSTR1)
-	lwz	rWORD2,0(rSTR2)
-	b	L(g1)
-
-L(g0):
-	lwzu	rWORD1,4(rSTR1)
-	bne	cr1,L(different)
-	lwzu	rWORD2,4(rSTR2)
-L(g1):	add	rTMP,rFEFE,rWORD1
-	nor	rNEG,r7F7F,rWORD1
-	bdz	L(tail)
-	and.	rTMP,rTMP,rNEG
-	cmpw	cr1,rWORD1,rWORD2
-	beq	L(g0)
-
-/* OK. We've hit the end of the string. We need to be careful that
-   we don't compare two strings as different because of gunk beyond
-   the end of the strings...  */
-#ifdef __LITTLE_ENDIAN__
-L(endstring):
-	slwi	rTMP, rTMP, 1
-	addi    rTMP2, rTMP, -1
-	andc    rTMP2, rTMP2, rTMP
-	and	rWORD2, rWORD2, rTMP2		/* Mask off gunk.  */
-	and	rWORD1, rWORD1, rTMP2
-	rlwinm	rTMP2, rWORD2, 8, 0xffffffff	/* Byte reverse word.  */
-	rlwinm	rTMP, rWORD1, 8, 0xffffffff
-	rldimi	rTMP2, rWORD2, 24, 32
-	rldimi	rTMP, rWORD1, 24, 32
-	rlwimi	rTMP2, rWORD2, 24, 16, 23
-	rlwimi	rTMP, rWORD1, 24, 16, 23
-	xor.	rBITDIF, rTMP, rTMP2
-	sub	rRTN, rTMP, rTMP2
-	bgelr
-	ori	rRTN, rTMP2, 1
-	blr
-
-L(different):
-	lwz	rWORD1, -4(rSTR1)
-	rlwinm	rTMP2, rWORD2, 8, 0xffffffff	/* Byte reverse word.  */
-	rlwinm	rTMP, rWORD1, 8, 0xffffffff
-	rldimi	rTMP2, rWORD2, 24, 32
-	rldimi	rTMP, rWORD1, 24, 32
-	rlwimi	rTMP2, rWORD2, 24, 16, 23
-	rlwimi	rTMP, rWORD1, 24, 16, 23
-	xor.	rBITDIF, rTMP, rTMP2
-	sub	rRTN, rTMP, rTMP2
-	bgelr
-	ori	rRTN, rTMP2, 1
-	blr
-
-#else
-L(endstring):
-	and	rTMP,r7F7F,rWORD1
-	beq	cr1,L(equal)
-	add	rTMP,rTMP,r7F7F
-	xor.	rBITDIF,rWORD1,rWORD2
-	andc	rNEG,rNEG,rTMP
-	blt	L(highbit)
-	cntlzw	rBITDIF,rBITDIF
-	cntlzw	rNEG,rNEG
-	addi	rNEG,rNEG,7
-	cmpw	cr1,rNEG,rBITDIF
-	sub	rRTN,rWORD1,rWORD2
-	bgelr	cr1
-L(equal):
-	li	rRTN,0
-	blr
-
-L(different):
-	lwz	rWORD1,-4(rSTR1)
-	xor.	rBITDIF,rWORD1,rWORD2
-	sub	rRTN,rWORD1,rWORD2
-	bgelr
-L(highbit):
-	ori	rRTN, rWORD2, 1
-	blr
-#endif
-
-/* Oh well. In this case, we just do a byte-by-byte comparison.  */
-	.align	4
-L(tail):
-	and.	rTMP,rTMP,rNEG
-	cmpw	cr1,rWORD1,rWORD2
-	bne	L(endstring)
-	addi	rSTR1,rSTR1,4
-	bne	cr1,L(different)
-	addi	rSTR2,rSTR2,4
-	cmplwi	cr1,rN,0
-L(unaligned):
-	mtctr	rN
-	ble	cr1,L(ux)
-L(uz):
-	lbz	rWORD1,0(rSTR1)
-	lbz	rWORD2,0(rSTR2)
-	.align	4
-L(u1):
-	cmpwi	cr1,rWORD1,0
-	bdz	L(u4)
-	cmpw	rWORD1,rWORD2
-	beq	cr1,L(u4)
-	bne	L(u4)
-	lbzu	rWORD3,1(rSTR1)
-	lbzu	rWORD4,1(rSTR2)
-	cmpwi	cr1,rWORD3,0
-	bdz	L(u3)
-	cmpw	rWORD3,rWORD4
-	beq	cr1,L(u3)
-	bne	L(u3)
-	lbzu	rWORD1,1(rSTR1)
-	lbzu	rWORD2,1(rSTR2)
-	cmpwi	cr1,rWORD1,0
-	bdz	L(u4)
-	cmpw	rWORD1,rWORD2
-	beq	cr1,L(u4)
-	bne	L(u4)
-	lbzu	rWORD3,1(rSTR1)
-	lbzu	rWORD4,1(rSTR2)
-	cmpwi	cr1,rWORD3,0
-	bdz	L(u3)
-	cmpw	rWORD3,rWORD4
-	beq	cr1,L(u3)
-	bne	L(u3)
-	lbzu	rWORD1,1(rSTR1)
-	lbzu	rWORD2,1(rSTR2)
-	b	L(u1)
-
-L(u3):  sub	rRTN,rWORD3,rWORD4
-	blr
-L(u4):	sub	rRTN,rWORD1,rWORD2
-	blr
-L(ux):
-	li	rRTN,0
-	blr
-END (strncmp)
-libc_hidden_builtin_def (strncmp)
diff --git a/sysdeps/powerpc/powerpc32/power7/strnlen.S b/sysdeps/powerpc/powerpc32/power7/strnlen.S
deleted file mode 100644
index 2f28acc..0000000
--- a/sysdeps/powerpc/powerpc32/power7/strnlen.S
+++ /dev/null
@@ -1,176 +0,0 @@
-/* Optimized strnlen implementation for PowerPC32/POWER7 using cmpb insn.
-   Copyright (C) 2010-2018 Free Software Foundation, Inc.
-   Contributed by Luis Machado <luisgpm@br.ibm.com>.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* int [r3] strnlen (char *s [r3], int size [r4])  */
-	.machine  power7
-ENTRY (__strnlen)
-	CALL_MCOUNT
-	dcbt	0,r3
-	clrrwi	r8,r3,2	      /* Align the address to word boundary.  */
-	add	r7,r3,r4      /* Calculate the last acceptable address.  */
-	cmplwi	r4,16
-	li	r0,0	      /* Word with null chars.  */
-	addi	r7,r7,-1
-	ble	L(small_range)
-
-	rlwinm	r6,r3,3,27,28 /* Calculate padding.  */
-	lwz	r12,0(r8)     /* Load word from memory.  */
-	cmpb	r10,r12,r0    /* Check for null bytes in DWORD1.  */
-#ifdef __LITTLE_ENDIAN__
-	srw	r10,r10,r6
-	slw	r10,r10,r6
-#else
-	slw	r10,r10,r6
-	srw	r10,r10,r6
-#endif
-	cmplwi	cr7,r10,0     /* If r10 == 0, no null's have been found.  */
-	bne	cr7,L(done)
-
-	clrrwi	r7,r7,2       /* Address of last word.  */
-	mtcrf   0x01,r8
-	/* Are we now aligned to a doubleword boundary?  If so, skip to
-	   the main loop.  Otherwise, go through the alignment code.  */
-
-	bt	29,L(loop_setup)
-
-	/* Handle WORD2 of pair.  */
-	lwzu	r12,4(r8)
-	cmpb	r10,r12,r0
-	cmplwi	cr7,r10,0
-	bne	cr7,L(done)
-
-L(loop_setup):
-	/* The last word we want to read in the loop below is the one
-	   containing the last byte of the string, ie. the word at
-	   (s + size - 1) & ~3, or r7.  The first word read is at
-	   r8 + 4, we read 2 * cnt words, so the last word read will
-	   be at r8 + 4 + 8 * cnt - 4.  Solving for cnt gives
-	   cnt = (r7 - r8) / 8  */
-	sub	r5,r7,r8
-	srwi	r6,r5,3	      /* Number of loop iterations.  */
-	mtctr	r6	      /* Setup the counter.  */
-
-	/* Main loop to look for the null byte in the string.  Since
-	   it's a small loop (< 8 instructions), align it to 32-bytes.  */
-	.p2align  5
-L(loop):
-	/* Load two words, compare and merge in a
-	   single register for speed.  This is an attempt
-	   to speed up the null-checking process for bigger strings.  */
-
-	lwz	r12,4(r8)
-	lwzu	r11,8(r8)
-	cmpb	r10,r12,r0
-	cmpb	r9,r11,r0
-	or	r5,r9,r10     /* Merge everything in one word.  */
-	cmplwi	cr7,r5,0
-	bne	cr7,L(found)
-	bdnz	L(loop)
-
-	/* We may have one more word to read.  */
-	cmplw	cr6,r8,r7
-	beq	cr6,L(end_max)
-
-	lwzu	r12,4(r8)
-	cmpb	r10,r12,r0
-	cmplwi	cr6,r10,0
-	bne	cr6,L(done)
-
-L(end_max):
-	mr	r3,r4
-	blr
-
-	/* OK, one (or both) of the words contains a null byte.  Check
-	   the first word and decrement the address in case the first
-	   word really contains a null byte.  */
-	.align	4
-L(found):
-	cmplwi	cr6,r10,0
-	addi	r8,r8,-4
-	bne	cr6,L(done)
-
-	/* The null byte must be in the second word.  Adjust the address
-	   again and move the result of cmpb to r10 so we can calculate the
-	   length.  */
-
-	mr	r10,r9
-	addi	r8,r8,4
-
-	/* r10 has the output of the cmpb instruction, that is, it contains
-	   0xff in the same position as the null byte in the original
-	   word from the string.  Use that to calculate the length.
-	   We need to make sure the null char is *before* the end of the
-	   range.  */
-L(done):
-#ifdef __LITTLE_ENDIAN__
-	addi	r0,r10,-1
-	andc	r0,r0,r10
-	popcntw	r0,r0
-#else
-	cntlzw	r0,r10	      /* Count leading zeros before the match.  */
-#endif
-	sub	r3,r8,r3
-	srwi	r0,r0,3	      /* Convert leading/trailing zeros to bytes.  */
-	add	r3,r3,r0      /* Length until the match.  */
-	cmplw	r3,r4
-	blelr
-	mr	r3,r4
-	blr
-
-/* Deals with size <= 16.  */
-	.align	4
-L(small_range):
-	cmplwi	r4,0
-	beq	L(end_max)
-
-	clrrwi	r7,r7,2       /* Address of last word.  */
-
-	rlwinm	r6,r3,3,27,28 /* Calculate padding.  */
-	lwz	r12,0(r8)     /* Load word from memory.  */
-	cmpb	r10,r12,r0    /* Check for null bytes in WORD1.  */
-#ifdef __LITTLE_ENDIAN__
-	srw	r10,r10,r6
-	slw	r10,r10,r6
-#else
-	slw	r10,r10,r6
-	srw	r10,r10,r6
-#endif
-	cmplwi	cr7,r10,0
-	bne	cr7,L(done)
-
-	cmplw	r8,r7
-	beq	L(end_max)
-
-	.p2align  5
-L(loop_small):
-	lwzu	r12,4(r8)
-	cmpb	r10,r12,r0
-	cmplwi	cr6,r10,0
-	bne	cr6,L(done)
-	cmplw	r8,r7
-	bne	L(loop_small)
-	mr	r3,r4
-	blr
-
-END (__strnlen)
-libc_hidden_def (__strnlen)
-weak_alias (__strnlen, strnlen)
-libc_hidden_builtin_def (strnlen)
diff --git a/sysdeps/powerpc/powerpc32/rtld-memset.c b/sysdeps/powerpc/powerpc32/rtld-memset.c
deleted file mode 100644
index f3ed8ad..0000000
--- a/sysdeps/powerpc/powerpc32/rtld-memset.c
+++ /dev/null
@@ -1,4 +0,0 @@
-/* PPCA2 has a different cache-line size than the usual 128 bytes.  To avoid
-   using code that assumes cache-line size to be 128 bytes (with dcbz
-   instructions) we use the generic code instead.  */
-#include <string/memset.c>
diff --git a/sysdeps/powerpc/powerpc32/strchr.S b/sysdeps/powerpc/powerpc32/strchr.S
deleted file mode 100644
index 38983a2..0000000
--- a/sysdeps/powerpc/powerpc32/strchr.S
+++ /dev/null
@@ -1,146 +0,0 @@
-/* Optimized strchr implementation for PowerPC.
-   Copyright (C) 1997-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* See strlen.s for comments on how this works.  */
-
-/* char * [r3] strchr (const char *s [r3] , int c [r4] )  */
-
-ENTRY (strchr)
-
-#define rTMP1	r0
-#define rRTN	r3	/* outgoing result */
-#define rSTR	r8	/* current word pointer */
-#define rCHR	r4	/* byte we're looking for, spread over the whole word */
-#define rWORD	r5	/* the current word */
-#define rCLZB	rCHR	/* leading zero byte count */
-#define rFEFE	r6	/* constant 0xfefefeff (-0x01010101) */
-#define r7F7F	r7	/* constant 0x7f7f7f7f */
-#define rTMP2	r9
-#define rIGN	r10	/* number of bits we should ignore in the first word */
-#define rMASK	r11	/* mask with the bits to ignore set to 0 */
-#define rTMP3	r12
-#define rTMP4	rIGN
-#define rTMP5	rMASK
-
-
-	rlwimi	rCHR, rCHR, 8, 16, 23
-	li	rMASK, -1
-	rlwimi	rCHR, rCHR, 16, 0, 15
-	rlwinm	rIGN, rRTN, 3, 27, 28
-	lis	rFEFE, -0x101
-	lis	r7F7F, 0x7f7f
-	clrrwi	rSTR, rRTN, 2
-	addi	rFEFE, rFEFE, -0x101
-	addi	r7F7F, r7F7F, 0x7f7f
-/* Test the first (partial?) word.  */
-	lwz	rWORD, 0(rSTR)
-#ifdef __LITTLE_ENDIAN__
-	slw	rMASK, rMASK, rIGN
-#else
-	srw	rMASK, rMASK, rIGN
-#endif
-	orc	rWORD, rWORD, rMASK
-	add	rTMP1, rFEFE, rWORD
-	nor	rTMP2, r7F7F, rWORD
-	and.	rTMP4, rTMP1, rTMP2
-	xor	rTMP3, rCHR, rWORD
-	orc	rTMP3, rTMP3, rMASK
-	b	L(loopentry)
-
-/* The loop.  */
-
-L(loop):
-	lwzu	rWORD, 4(rSTR)
-	and.	rTMP5, rTMP1, rTMP2
-/* Test for 0.	*/
-	add	rTMP1, rFEFE, rWORD /* x - 0x01010101.  */
-	nor	rTMP2, r7F7F, rWORD /* ~(x | 0x7f7f7f7f) == ~x & 0x80808080.  */
-	bne	L(foundit)
-	and.	rTMP4, rTMP1, rTMP2 /* (x - 0x01010101) & ~x & 0x80808080.  */
-/* Start test for the bytes we're looking for.  */
-	xor	rTMP3, rCHR, rWORD
-L(loopentry):
-	add	rTMP1, rFEFE, rTMP3
-	nor	rTMP2, r7F7F, rTMP3
-	beq	L(loop)
-
-/* There is a zero byte in the word, but may also be a matching byte (either
-   before or after the zero byte).  In fact, we may be looking for a
-   zero byte, in which case we return a match.  */
-	and.	rTMP5, rTMP1, rTMP2
-	li	rRTN, 0
-	beqlr
-/* At this point:
-   rTMP5 bytes are 0x80 for each match of c, 0 otherwise.
-   rTMP4 bytes are 0x80 for each match of 0, 0 otherwise.
-   But there may be false matches in the next most significant byte from
-   a true match due to carries.  This means we need to recalculate the
-   matches using a longer method for big-endian.  */
-#ifdef __LITTLE_ENDIAN__
-	addi	rTMP1, rTMP5, -1
-	andc	rTMP1, rTMP1, rTMP5
-	cntlzw	rCLZB, rTMP1
-	addi	rTMP2, rTMP4, -1
-	andc	rTMP2, rTMP2, rTMP4
-	cmplw	rTMP1, rTMP2
-	bgtlr
-	subfic	rCLZB, rCLZB, 32-7
-#else
-/* I think we could reduce this by two instructions by keeping the "nor"
-   results from the loop for reuse here.  See strlen.S tail.  Similarly
-   one instruction could be pruned from L(foundit).  */
-	and	rFEFE, r7F7F, rWORD
-	or	rTMP5, r7F7F, rWORD
-	and	rTMP1, r7F7F, rTMP3
-	or	rTMP4, r7F7F, rTMP3
-	add	rFEFE, rFEFE, r7F7F
-	add	rTMP1, rTMP1, r7F7F
-	nor	rWORD, rTMP5, rFEFE
-	nor	rTMP2, rTMP4, rTMP1
-	cntlzw	rCLZB, rTMP2
-	cmplw	rWORD, rTMP2
-	bgtlr
-#endif
-	srwi	rCLZB, rCLZB, 3
-	add	rRTN, rSTR, rCLZB
-	blr
-
-L(foundit):
-#ifdef __LITTLE_ENDIAN__
-	addi	rTMP1, rTMP5, -1
-	andc	rTMP1, rTMP1, rTMP5
-	cntlzw	rCLZB, rTMP1
-	subfic	rCLZB, rCLZB, 32-7-32
-	srawi	rCLZB, rCLZB, 3
-#else
-	and	rTMP1, r7F7F, rTMP3
-	or	rTMP4, r7F7F, rTMP3
-	add	rTMP1, rTMP1, r7F7F
-	nor	rTMP2, rTMP4, rTMP1
-	cntlzw	rCLZB, rTMP2
-	subi	rSTR, rSTR, 4
-	srwi	rCLZB, rCLZB, 3
-#endif
-	add	rRTN, rSTR, rCLZB
-	blr
-END (strchr)
-
-weak_alias (strchr, index)
-libc_hidden_builtin_def (strchr)
diff --git a/sysdeps/powerpc/powerpc32/strcmp.S b/sysdeps/powerpc/powerpc32/strcmp.S
deleted file mode 100644
index bd038db..0000000
--- a/sysdeps/powerpc/powerpc32/strcmp.S
+++ /dev/null
@@ -1,150 +0,0 @@
-/* Optimized strcmp implementation for PowerPC.
-   Copyright (C) 1997-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* See strlen.s for comments on how the end-of-string testing works.  */
-
-/* int [r3] strcmp (const char *s1 [r3], const char *s2 [r4])  */
-
-EALIGN (strcmp, 4, 0)
-
-#define rTMP2	r0
-#define rRTN	r3
-#define rSTR1	r3	/* first string arg */
-#define rSTR2	r4	/* second string arg */
-#define rWORD1	r5	/* current word in s1 */
-#define rWORD2	r6	/* current word in s2 */
-#define rFEFE	r7	/* constant 0xfefefeff (-0x01010101) */
-#define r7F7F	r8	/* constant 0x7f7f7f7f */
-#define rNEG	r9	/* ~(word in s1 | 0x7f7f7f7f) */
-#define rBITDIF	r10	/* bits that differ in s1 & s2 words */
-#define rTMP	r11
-
-
-	or	rTMP, rSTR2, rSTR1
-	clrlwi.	rTMP, rTMP, 30
-	lis	rFEFE, -0x101
-	bne	L(unaligned)
-
-	lwz	rWORD1, 0(rSTR1)
-	lwz	rWORD2, 0(rSTR2)
-	lis	r7F7F, 0x7f7f
-	addi	rFEFE, rFEFE, -0x101
-	addi	r7F7F, r7F7F, 0x7f7f
-	b	L(g1)
-
-L(g0):	lwzu	rWORD1, 4(rSTR1)
-	bne	cr1, L(different)
-	lwzu	rWORD2, 4(rSTR2)
-L(g1):	add	rTMP, rFEFE, rWORD1
-	nor	rNEG, r7F7F, rWORD1
-	and.	rTMP, rTMP, rNEG
-	cmpw	cr1, rWORD1, rWORD2
-	beq+	L(g0)
-
-/* OK. We've hit the end of the string. We need to be careful that
-   we don't compare two strings as different because of gunk beyond
-   the end of the strings...  */
-#ifdef __LITTLE_ENDIAN__
-L(endstring):
-	addi    rTMP2, rTMP, -1
-	andc    rTMP2, rTMP2, rTMP
-	rlwimi	rTMP2, rTMP2, 1, 0, 30
-	and	rWORD2, rWORD2, rTMP2		/* Mask off gunk.  */
-	and	rWORD1, rWORD1, rTMP2
-	rlwinm	rTMP2, rWORD2, 8, 0xffffffff	/* Byte reverse word.  */
-	rlwinm	rTMP, rWORD1, 8, 0xffffffff
-	rlwimi	rTMP2, rWORD2, 24, 0, 7
-	rlwimi	rTMP, rWORD1, 24, 0, 7
-	rlwimi	rTMP2, rWORD2, 24, 16, 23
-	rlwimi	rTMP, rWORD1, 24, 16, 23
-	xor.	rBITDIF, rTMP, rTMP2
-	sub	rRTN, rTMP, rTMP2
-	bgelr+
-	ori	rRTN, rTMP2, 1
-	blr
-
-L(different):
-	lwz	rWORD1, -4(rSTR1)
-	rlwinm	rTMP2, rWORD2, 8, 0xffffffff	/* Byte reverse word.  */
-	rlwinm	rTMP, rWORD1, 8, 0xffffffff
-	rlwimi	rTMP2, rWORD2, 24, 0, 7
-	rlwimi	rTMP, rWORD1, 24, 0, 7
-	rlwimi	rTMP2, rWORD2, 24, 16, 23
-	rlwimi	rTMP, rWORD1, 24, 16, 23
-	xor.	rBITDIF, rTMP, rTMP2
-	sub	rRTN, rTMP, rTMP2
-	bgelr+
-	ori	rRTN, rTMP2, 1
-	blr
-
-#else
-L(endstring):
-	and	rTMP, r7F7F, rWORD1
-	beq	cr1, L(equal)
-	add	rTMP, rTMP, r7F7F
-	xor.	rBITDIF, rWORD1, rWORD2
-	andc	rNEG, rNEG, rTMP
-	blt-	L(highbit)
-	cntlzw	rBITDIF, rBITDIF
-	cntlzw	rNEG, rNEG
-	addi	rNEG, rNEG, 7
-	cmpw	cr1, rNEG, rBITDIF
-	sub	rRTN, rWORD1, rWORD2
-	bgelr+	cr1
-L(equal):
-	li	rRTN, 0
-	blr
-
-L(different):
-	lwz	rWORD1, -4(rSTR1)
-	xor.	rBITDIF, rWORD1, rWORD2
-	sub	rRTN, rWORD1, rWORD2
-	bgelr+
-L(highbit):
-	ori	rRTN, rWORD2, 1
-	blr
-#endif
-
-/* Oh well.  In this case, we just do a byte-by-byte comparison.  */
-	.align 4
-L(unaligned):
-	lbz	rWORD1, 0(rSTR1)
-	lbz	rWORD2, 0(rSTR2)
-	b	L(u1)
-
-L(u0):	lbzu	rWORD1, 1(rSTR1)
-	bne-	L(u4)
-	lbzu	rWORD2, 1(rSTR2)
-L(u1):	cmpwi	cr1, rWORD1, 0
-	beq-	cr1, L(u3)
-	cmpw	rWORD1, rWORD2
-	bne-	L(u3)
-	lbzu	rWORD1, 1(rSTR1)
-	lbzu	rWORD2, 1(rSTR2)
-	cmpwi	cr1, rWORD1, 0
-	cmpw	rWORD1, rWORD2
-	bne+	cr1, L(u0)
-L(u3):	sub	rRTN, rWORD1, rWORD2
-	blr
-L(u4):	lbz	rWORD1, -1(rSTR1)
-	sub	rRTN, rWORD1, rWORD2
-	blr
-END (strcmp)
-libc_hidden_builtin_def (strcmp)
diff --git a/sysdeps/powerpc/powerpc32/strcpy.S b/sysdeps/powerpc/powerpc32/strcpy.S
deleted file mode 100644
index 757dad9..0000000
--- a/sysdeps/powerpc/powerpc32/strcpy.S
+++ /dev/null
@@ -1,117 +0,0 @@
-/* Optimized strcpy implementation for PowerPC.
-   Copyright (C) 1997-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* See strlen.s for comments on how the end-of-string testing works.  */
-
-/* char * [r3] strcpy (char *dest [r3], const char *src [r4])  */
-
-EALIGN (strcpy, 4, 0)
-
-#define rTMP	r0
-#define rRTN	r3	/* incoming DEST arg preserved as result */
-#define rSRC	r4	/* pointer to previous word in src */
-#define rDEST	r5	/* pointer to previous word in dest */
-#define rWORD	r6	/* current word from src */
-#define rFEFE	r7	/* constant 0xfefefeff (-0x01010101) */
-#define r7F7F	r8	/* constant 0x7f7f7f7f */
-#define rNEG	r9	/* ~(word in s1 | 0x7f7f7f7f) */
-#define rALT	r10	/* alternate word from src */
-
-
-	or	rTMP, rSRC, rRTN
-	clrlwi.	rTMP, rTMP, 30
-	addi	rDEST, rRTN, -4
-	bne	L(unaligned)
-
-	lis	rFEFE, -0x101
-	lis	r7F7F, 0x7f7f
-	lwz	rWORD, 0(rSRC)
-	addi	rFEFE, rFEFE, -0x101
-	addi	r7F7F, r7F7F, 0x7f7f
-	b	L(g2)
-
-L(g0):	lwzu	rALT, 4(rSRC)
-	stwu	rWORD, 4(rDEST)
-	add	rTMP, rFEFE, rALT
-	nor	rNEG, r7F7F, rALT
-	and.	rTMP, rTMP, rNEG
-	bne-	L(g1)
-	lwzu	rWORD, 4(rSRC)
-	stwu	rALT, 4(rDEST)
-L(g2):	add	rTMP, rFEFE, rWORD
-	nor	rNEG, r7F7F, rWORD
-	and.	rTMP, rTMP, rNEG
-	beq+	L(g0)
-
-	mr	rALT, rWORD
-/* We've hit the end of the string.  Do the rest byte-by-byte.  */
-L(g1):
-#ifdef __LITTLE_ENDIAN__
-	rlwinm.	rTMP, rALT, 0, 24, 31
-	stb	rALT, 4(rDEST)
-	beqlr-
-	rlwinm.	rTMP, rALT, 24, 24, 31
-	stb	rTMP, 5(rDEST)
-	beqlr-
-	rlwinm.	rTMP, rALT, 16, 24, 31
-	stb	rTMP, 6(rDEST)
-	beqlr-
-	rlwinm	rTMP, rALT, 8, 24, 31
-	stb	rTMP, 7(rDEST)
-	blr
-#else
-	rlwinm.	rTMP, rALT, 8, 24, 31
-	stb	rTMP, 4(rDEST)
-	beqlr-
-	rlwinm.	rTMP, rALT, 16, 24, 31
-	stb	rTMP, 5(rDEST)
-	beqlr-
-	rlwinm.	rTMP, rALT, 24, 24, 31
-	stb	rTMP, 6(rDEST)
-	beqlr-
-	stb	rALT, 7(rDEST)
-	blr
-#endif
-
-/* Oh well.  In this case, we just do a byte-by-byte copy.  */
-	.align 4
-	nop
-L(unaligned):
-	lbz	rWORD, 0(rSRC)
-	addi	rDEST, rRTN, -1
-	cmpwi	rWORD, 0
-	beq-	L(u2)
-
-L(u0):	lbzu	rALT, 1(rSRC)
-	stbu	rWORD, 1(rDEST)
-	cmpwi	rALT, 0
-	beq-	L(u1)
-	nop		/* Let 601 load start of loop.  */
-	lbzu	rWORD, 1(rSRC)
-	stbu	rALT, 1(rDEST)
-	cmpwi	rWORD, 0
-	bne+	L(u0)
-L(u2):	stb	rWORD, 1(rDEST)
-	blr
-L(u1):	stb	rALT, 1(rDEST)
-	blr
-
-END (strcpy)
-libc_hidden_builtin_def (strcpy)
diff --git a/sysdeps/powerpc/powerpc32/strlen.S b/sysdeps/powerpc/powerpc32/strlen.S
deleted file mode 100644
index 23a6f8a..0000000
--- a/sysdeps/powerpc/powerpc32/strlen.S
+++ /dev/null
@@ -1,190 +0,0 @@
-/* Optimized strlen implementation for PowerPC.
-   Copyright (C) 1997-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* The algorithm here uses the following techniques:
-
-   1) Given a word 'x', we can test to see if it contains any 0 bytes
-      by subtracting 0x01010101, and seeing if any of the high bits of each
-      byte changed from 0 to 1. This works because the least significant
-      0 byte must have had no incoming carry (otherwise it's not the least
-      significant), so it is 0x00 - 0x01 == 0xff. For all other
-      byte values, either they have the high bit set initially, or when
-      1 is subtracted you get a value in the range 0x00-0x7f, none of which
-      have their high bit set. The expression here is
-      (x + 0xfefefeff) & ~(x | 0x7f7f7f7f), which gives 0x00000000 when
-      there were no 0x00 bytes in the word.  You get 0x80 in bytes that
-      match, but possibly false 0x80 matches in the next more significant
-      byte to a true match due to carries.  For little-endian this is
-      of no consequence since the least significant match is the one
-      we're interested in, but big-endian needs method 2 to find which
-      byte matches.
-
-   2) Given a word 'x', we can test to see _which_ byte was zero by
-      calculating ~(((x & 0x7f7f7f7f) + 0x7f7f7f7f) | x | 0x7f7f7f7f).
-      This produces 0x80 in each byte that was zero, and 0x00 in all
-      the other bytes. The '| 0x7f7f7f7f' clears the low 7 bits in each
-      byte, and the '| x' part ensures that bytes with the high bit set
-      produce 0x00. The addition will carry into the high bit of each byte
-      iff that byte had one of its low 7 bits set. We can then just see
-      which was the most significant bit set and divide by 8 to find how
-      many to add to the index.
-      This is from the book 'The PowerPC Compiler Writer's Guide',
-      by Steve Hoxey, Faraydon Karim, Bill Hay and Hank Warren.
-
-   We deal with strings not aligned to a word boundary by taking the
-   first word and ensuring that bytes not part of the string
-   are treated as nonzero. To allow for memory latency, we unroll the
-   loop a few times, being careful to ensure that we do not read ahead
-   across cache line boundaries.
-
-   Questions to answer:
-   1) How long are strings passed to strlen? If they're often really long,
-   we should probably use cache management instructions and/or unroll the
-   loop more. If they're often quite short, it might be better to use
-   fact (2) in the inner loop than have to recalculate it.
-   2) How popular are bytes with the high bit set? If they are very rare,
-   on some processors it might be useful to use the simpler expression
-   ~((x - 0x01010101) | 0x7f7f7f7f) (that is, on processors with only one
-   ALU), but this fails when any character has its high bit set.  */
-
-/* Some notes on register usage: Under the SVR4 ABI, we can use registers
-   0 and 3 through 12 (so long as we don't call any procedures) without
-   saving them. We can also use registers 14 through 31 if we save them.
-   We can't use r1 (it's the stack pointer), r2 nor r13 because the user
-   program may expect them to hold their usual value if we get sent
-   a signal. Integer parameters are passed in r3 through r10.
-   We can use condition registers cr0, cr1, cr5, cr6, and cr7 without saving
-   them, the others we must save.  */
-
-/* int [r3] strlen (char *s [r3])  */
-
-ENTRY (strlen)
-
-#define rTMP4	r0
-#define rRTN	r3	/* incoming STR arg, outgoing result */
-#define rSTR	r4	/* current string position */
-#define rPADN	r5	/* number of padding bits we prepend to the
-			   string to make it start at a word boundary */
-#define rFEFE	r6	/* constant 0xfefefeff (-0x01010101) */
-#define r7F7F	r7	/* constant 0x7f7f7f7f */
-#define rWORD1	r8	/* current string word */
-#define rWORD2	r9	/* next string word */
-#define rMASK	r9	/* mask for first string word */
-#define rTMP1	r10
-#define rTMP2	r11
-#define rTMP3	r12
-
-
-	clrrwi	rSTR, rRTN, 2
-	lis	r7F7F, 0x7f7f
-	rlwinm	rPADN, rRTN, 3, 27, 28
-	lwz	rWORD1, 0(rSTR)
-	li	rMASK, -1
-	addi	r7F7F, r7F7F, 0x7f7f
-/* We use method (2) on the first two words, because rFEFE isn't
-   required which reduces setup overhead.  Also gives a faster return
-   for small strings on big-endian due to needing to recalculate with
-   method (2) anyway.  */
-#ifdef __LITTLE_ENDIAN__
-	slw	rMASK, rMASK, rPADN
-#else
-	srw	rMASK, rMASK, rPADN
-#endif
-	and	rTMP1, r7F7F, rWORD1
-	or	rTMP2, r7F7F, rWORD1
-	add	rTMP1, rTMP1, r7F7F
-	nor	rTMP3, rTMP2, rTMP1
-	and.	rTMP3, rTMP3, rMASK
-	mtcrf	0x01, rRTN
-	bne	L(done0)
-	lis	rFEFE, -0x101
-	addi	rFEFE, rFEFE, -0x101
-/* Are we now aligned to a doubleword boundary?  */
-	bt	29, L(loop)
-
-/* Handle second word of pair.  */
-/* Perhaps use method (1) here for little-endian, saving one instruction?  */
-	lwzu	rWORD1, 4(rSTR)
-	and	rTMP1, r7F7F, rWORD1
-	or	rTMP2, r7F7F, rWORD1
-	add	rTMP1, rTMP1, r7F7F
-	nor.	rTMP3, rTMP2, rTMP1
-	bne	L(done0)
-
-/* The loop.  */
-
-L(loop):
-	lwz	rWORD1, 4(rSTR)
-	lwzu	rWORD2, 8(rSTR)
-	add	rTMP1, rFEFE, rWORD1
-	nor	rTMP2, r7F7F, rWORD1
-	and.	rTMP1, rTMP1, rTMP2
-	add	rTMP3, rFEFE, rWORD2
-	nor	rTMP4, r7F7F, rWORD2
-	bne	L(done1)
-	and.	rTMP3, rTMP3, rTMP4
-	beq	L(loop)
-
-#ifndef __LITTLE_ENDIAN__
-	and	rTMP1, r7F7F, rWORD2
-	add	rTMP1, rTMP1, r7F7F
-	andc	rTMP3, rTMP4, rTMP1
-	b	L(done0)
-
-L(done1):
-	and	rTMP1, r7F7F, rWORD1
-	subi	rSTR, rSTR, 4
-	add	rTMP1, rTMP1, r7F7F
-	andc	rTMP3, rTMP2, rTMP1
-
-/* When we get to here, rSTR points to the first word in the string that
-   contains a zero byte, and rTMP3 has 0x80 for bytes that are zero,
-   and 0x00 otherwise.  */
-L(done0):
-	cntlzw	rTMP3, rTMP3
-	subf	rTMP1, rRTN, rSTR
-	srwi	rTMP3, rTMP3, 3
-	add	rRTN, rTMP1, rTMP3
-	blr
-#else
-
-L(done0):
-	addi	rTMP1, rTMP3, -1	/* Form a mask from trailing zeros.  */
-	andc	rTMP1, rTMP1, rTMP3
-	cntlzw	rTMP1, rTMP1		/* Count bits not in the mask.  */
-	subf	rTMP3, rRTN, rSTR
-	subfic	rTMP1, rTMP1, 32-7
-	srwi	rTMP1, rTMP1, 3
-	add	rRTN, rTMP1, rTMP3
-	blr
-
-L(done1):
-	addi	rTMP3, rTMP1, -1
-	andc	rTMP3, rTMP3, rTMP1
-	cntlzw	rTMP3, rTMP3
-	subf	rTMP1, rRTN, rSTR
-	subfic	rTMP3, rTMP3, 32-7-32
-	srawi	rTMP3, rTMP3, 3
-	add	rRTN, rTMP1, rTMP3
-	blr
-#endif
-
-END (strlen)
-libc_hidden_builtin_def (strlen)
diff --git a/sysdeps/powerpc/powerpc32/strncmp.S b/sysdeps/powerpc/powerpc32/strncmp.S
deleted file mode 100644
index 2bbd4a4..0000000
--- a/sysdeps/powerpc/powerpc32/strncmp.S
+++ /dev/null
@@ -1,181 +0,0 @@
-/* Optimized strcmp implementation for PowerPC32.
-   Copyright (C) 2003-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* See strlen.s for comments on how the end-of-string testing works.  */
-
-/* int [r3] strncmp (const char *s1 [r3], const char *s2 [r4], size_t size [r5])  */
-
-EALIGN (strncmp, 4, 0)
-
-#define rTMP2	r0
-#define rRTN	r3
-#define rSTR1	r3	/* first string arg */
-#define rSTR2	r4	/* second string arg */
-#define rN	r5	/* max string length */
-#define rWORD1	r6	/* current word in s1 */
-#define rWORD2	r7	/* current word in s2 */
-#define rFEFE	r8	/* constant 0xfefefeff (-0x01010101) */
-#define r7F7F	r9	/* constant 0x7f7f7f7f */
-#define rNEG	r10	/* ~(word in s1 | 0x7f7f7f7f) */
-#define rBITDIF	r11	/* bits that differ in s1 & s2 words */
-#define rTMP	r12
-
-	dcbt	0,rSTR1
-	or	rTMP, rSTR2, rSTR1
-	lis	r7F7F, 0x7f7f
-	dcbt	0,rSTR2
-	clrlwi.	rTMP, rTMP, 30
-	cmplwi	cr1, rN, 0
-	lis	rFEFE, -0x101
-	bne	L(unaligned)
-/* We are word aligned so set up for two loops.  first a word
-   loop, then fall into the byte loop if any residual.  */
-	srwi.	rTMP, rN, 2
-	clrlwi	rN, rN, 30
-	addi	rFEFE, rFEFE, -0x101
-	addi	r7F7F, r7F7F, 0x7f7f
-	cmplwi	cr1, rN, 0
-	beq	L(unaligned)
-
-	mtctr	rTMP	/* Power4 wants mtctr 1st in dispatch group.  */
-	lwz	rWORD1, 0(rSTR1)
-	lwz	rWORD2, 0(rSTR2)
-	b	L(g1)
-
-L(g0):
-	lwzu	rWORD1, 4(rSTR1)
-	bne-	cr1, L(different)
-	lwzu	rWORD2, 4(rSTR2)
-L(g1):	add	rTMP, rFEFE, rWORD1
-	nor	rNEG, r7F7F, rWORD1
-	bdz	L(tail)
-	and.	rTMP, rTMP, rNEG
-	cmpw	cr1, rWORD1, rWORD2
-	beq+	L(g0)
-
-/* OK. We've hit the end of the string. We need to be careful that
-   we don't compare two strings as different because of gunk beyond
-   the end of the strings...  */
-
-#ifdef __LITTLE_ENDIAN__
-L(endstring):
-	slwi	rTMP, rTMP, 1
-	addi    rTMP2, rTMP, -1
-	andc    rTMP2, rTMP2, rTMP
-	and	rWORD2, rWORD2, rTMP2		/* Mask off gunk.  */
-	and	rWORD1, rWORD1, rTMP2
-	rlwinm	rTMP2, rWORD2, 8, 0xffffffff	/* Byte reverse word.  */
-	rlwinm	rTMP, rWORD1, 8, 0xffffffff
-	rlwimi	rTMP2, rWORD2, 24, 0, 7
-	rlwimi	rTMP, rWORD1, 24, 0, 7
-	rlwimi	rTMP2, rWORD2, 24, 16, 23
-	rlwimi	rTMP, rWORD1, 24, 16, 23
-	xor.	rBITDIF, rTMP, rTMP2
-	sub	rRTN, rTMP, rTMP2
-	bgelr+
-	ori	rRTN, rTMP2, 1
-	blr
-
-L(different):
-	lwz	rWORD1, -4(rSTR1)
-	rlwinm	rTMP2, rWORD2, 8, 0xffffffff	/* Byte reverse word.  */
-	rlwinm	rTMP, rWORD1, 8, 0xffffffff
-	rlwimi	rTMP2, rWORD2, 24, 0, 7
-	rlwimi	rTMP, rWORD1, 24, 0, 7
-	rlwimi	rTMP2, rWORD2, 24, 16, 23
-	rlwimi	rTMP, rWORD1, 24, 16, 23
-	xor.	rBITDIF, rTMP, rTMP2
-	sub	rRTN, rTMP, rTMP2
-	bgelr+
-	ori	rRTN, rTMP2, 1
-	blr
-
-#else
-L(endstring):
-	and	rTMP, r7F7F, rWORD1
-	beq	cr1, L(equal)
-	add	rTMP, rTMP, r7F7F
-	xor.	rBITDIF, rWORD1, rWORD2
-	andc	rNEG, rNEG, rTMP
-	blt-	L(highbit)
-	cntlzw	rBITDIF, rBITDIF
-	cntlzw	rNEG, rNEG
-	addi	rNEG, rNEG, 7
-	cmpw	cr1, rNEG, rBITDIF
-	sub	rRTN, rWORD1, rWORD2
-	bgelr+	cr1
-L(equal):
-	li	rRTN, 0
-	blr
-
-L(different):
-	lwz	rWORD1, -4(rSTR1)
-	xor.	rBITDIF, rWORD1, rWORD2
-	sub	rRTN, rWORD1, rWORD2
-	bgelr+
-L(highbit):
-	ori	rRTN, rWORD2, 1
-	blr
-#endif
-
-/* Oh well.  In this case, we just do a byte-by-byte comparison.  */
-	.align 4
-L(tail):
-	and.	rTMP, rTMP, rNEG
-	cmpw	cr1, rWORD1, rWORD2
-	bne-	L(endstring)
-	addi	rSTR1, rSTR1, 4
-	bne-	cr1, L(different)
-	addi	rSTR2, rSTR2, 4
-	cmplwi	cr1, rN, 0
-L(unaligned):
-	mtctr   rN	/* Power4 wants mtctr 1st in dispatch group */
-	bgt	cr1, L(uz)
-L(ux):
-	li	rRTN, 0
-	blr
-	.align 4
-L(uz):
-	lbz	rWORD1, 0(rSTR1)
-	lbz	rWORD2, 0(rSTR2)
-	nop
-	b	L(u1)
-L(u0):
-	lbzu	rWORD2, 1(rSTR2)
-L(u1):
-	bdz	L(u3)
-	cmpwi	cr1, rWORD1, 0
-	cmpw	rWORD1, rWORD2
-	beq-	cr1, L(u3)
-	lbzu	rWORD1, 1(rSTR1)
-	bne-	L(u2)
-	lbzu	rWORD2, 1(rSTR2)
-	bdz	L(u3)
-	cmpwi	cr1, rWORD1, 0
-	cmpw	rWORD1, rWORD2
-	bne-	L(u3)
-	lbzu	rWORD1, 1(rSTR1)
-	bne+	cr1, L(u0)
-
-L(u2):	lbzu	rWORD1, -1(rSTR1)
-L(u3):	sub	rRTN, rWORD1, rWORD2
-	blr
-END (strncmp)
-libc_hidden_builtin_def (strncmp)
diff --git a/sysdeps/powerpc/powerpc64/a2/memcpy.S b/sysdeps/powerpc/powerpc64/a2/memcpy.S
deleted file mode 100644
index 488ab6d..0000000
--- a/sysdeps/powerpc/powerpc64/a2/memcpy.S
+++ /dev/null
@@ -1,528 +0,0 @@
-/* Optimized memcpy implementation for PowerPC A2.
-   Copyright (C) 2010-2018 Free Software Foundation, Inc.
-   Contributed by Michael Brutman <brutman@us.ibm.com>.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-#ifndef MEMCPY
-# define MEMCPY memcpy
-#endif
-
-#define PREFETCH_AHEAD 4        /* no cache lines SRC prefetching ahead  */
-#define ZERO_AHEAD 2            /* no cache lines DST zeroing ahead  */
-
-	.section        ".toc","aw"
-.LC0:
-	.tc __cache_line_size[TC],__cache_line_size
-	.section        ".text"
-	.align 2
-
-
-	.machine  a2
-ENTRY (MEMCPY, 5)
-	CALL_MCOUNT 3
-
-	dcbt    0,r4            /* Prefetch ONE SRC cacheline  */
-	cmpldi  cr1,r5,16       /* is size < 16 ?  */
-	mr      r6,r3           /* Copy dest reg to r6; */
-	blt+    cr1,L(shortcopy)
-
-
-	/* Big copy (16 bytes or more)
-
-	   Figure out how far to the nearest quadword boundary, or if we are
-	   on one already.  Also get the cache line size.
-
-	   r3 - return value (always)
-	   r4 - current source addr
-	   r5 - copy length
-	   r6 - current dest addr
-	*/
-
-	neg     r8,r3           /* LS 4 bits = # bytes to 8-byte dest bdry  */
-	ld      r9,.LC0@toc(r2) /* Get cache line size (part 1) */
-	clrldi  r8,r8,64-4      /* align to 16byte boundary  */
-	sub     r7,r4,r3        /* compute offset to src from dest */
-	lwz     r9,0(r9)        /* Get cache line size (part 2) */
-	cmpldi  cr0,r8,0        /* Were we aligned on a 16 byte bdy? */
-	addi    r10,r9,-1       /* Cache line mask */
-	beq+    L(dst_aligned)
-
-
-
-	/* Destination is not aligned on quadword boundary.  Get us to one.
-
-	   r3 - return value (always)
-	   r4 - current source addr
-	   r5 - copy length
-	   r6 - current dest addr
-	   r7 - offset to src from dest
-	   r8 - number of bytes to quadword boundary
-	*/
-
-	mtcrf   0x01,r8         /* put #bytes to boundary into cr7  */
-	subf    r5,r8,r5        /* adjust remaining len */
-
-	bf      cr7*4+3,1f
-	lbzx    r0,r7,r6        /* copy 1 byte addr */
-	stb     r0,0(r6)
-	addi    r6,r6,1
-1:
-	bf      cr7*4+2,2f
-	lhzx    r0,r7,r6        /* copy 2 byte addr */
-	sth     r0,0(r6)
-	addi    r6,r6,2
-2:
-	bf      cr7*4+1,4f
-	lwzx    r0,r7,r6        /* copy 4 byte addr */
-	stw     r0,0(r6)
-	addi    r6,r6,4
-4:
-	bf      cr7*4+0,8f
-	ldx     r0,r7,r6        /* copy 8 byte addr */
-	std     r0,0(r6)
-	addi    r6,r6,8
-8:
-	add     r4,r7,r6        /* update src addr */
-
-
-
-	/* Dest is quadword aligned now.
-
-	   Lots of decisions to make.  If we are copying less than a cache
-	   line we won't be here long.  If we are not on a cache line
-	   boundary we need to get there.  And then we need to figure out
-	   how many cache lines ahead to pre-touch.
-
-	   r3 - return value (always)
-	   r4 - current source addr
-	   r5 - copy length
-	   r6 - current dest addr
-	*/
-
-
-	.align 4
-L(dst_aligned):
-	cmpdi	cr0,r9,0	/* Cache line size set? */
-	bne+	cr0,L(cachelineset)
-
-/* __cache_line_size not set: generic byte copy without much optimization */
-	clrldi.	r0,r5,63	/* If length is odd copy one byte */
-	beq	L(cachelinenotset_align)
-	lbz	r7,0(r4)	/* Read one byte from source */
-	addi	r5,r5,-1	/* Update length */
-	addi	r4,r4,1		/* Update source pointer address */
-	stb	r7,0(r6)	/* Store one byte at dest */
-	addi	r6,r6,1		/* Update dest pointer address */
-L(cachelinenotset_align):
-	cmpdi	cr7,r5,0	/* If length is 0 return */
-	beqlr	cr7
-	ori	r2,r2,0		/* Force a new dispatch group */
-L(cachelinenotset_loop):
-	addic.	r5,r5,-2	/* Update length */
-	lbz	r7,0(r4)	/* Load 2 bytes from source */
-	lbz	r8,1(r4)
-	addi	r4,r4,2		/* Update source pointer address */
-	stb	r7,0(r6)	/* Store 2 bytes on dest */
-	stb	r8,1(r6)
-	addi	r6,r6,2		/* Update dest pointer address */
-	bne	L(cachelinenotset_loop)
-	blr
-
-
-L(cachelineset):
-	cmpd	cr5,r5,r10       /* Less than a cacheline to go? */
-
-	neg     r7,r6           /* How far to next cacheline bdy? */
-
-	addi    r6,r6,-8        /* prepare for stdu  */
-	cmpdi   cr0,r9,128
-	addi    r4,r4,-8        /* prepare for ldu  */
-
-
-	ble+    cr5,L(lessthancacheline)
-
-	beq-    cr0,L(big_lines) /* 128 byte line code */
-
-
-
-	/* More than a cacheline left to go, and using 64 byte cachelines */
-
-	clrldi  r7,r7,64-6      /* How far to next cacheline bdy? */
-
-	cmpldi  cr6,r7,0        /* Are we on a cacheline bdy already? */
-
-	/* Reduce total len by what it takes to get to the next cache line */
-	subf    r5,r7,r5
-	srdi    r7,r7,4         /* How many qws to get to the line bdy? */
-
-	/* How many full cache lines to copy after getting to a line bdy? */
-	srdi    r10,r5,6
-
-	cmpldi  r10,0           /* If no full cache lines to copy ... */
-	li      r11,0           /* number cachelines to copy with prefetch  */
-	beq     L(nocacheprefetch)
-
-
-	/* We are here because we have at least one full cache line to copy,
-	   and therefore some pre-touching to do. */
-
-	cmpldi  r10,PREFETCH_AHEAD
-	li      r12,64+8        /* prefetch distance  */
-	ble     L(lessthanmaxprefetch)
-
-	/* We can only do so much pre-fetching.  R11 will have the count of
-	   lines left to prefetch after the initial batch of prefetches
-	   are executed. */
-
-	subi    r11,r10,PREFETCH_AHEAD
-	li      r10,PREFETCH_AHEAD
-
-L(lessthanmaxprefetch):
-	mtctr   r10
-
-	/* At this point r10/ctr hold the number of lines to prefetch in this
-	   initial batch, and r11 holds any remainder. */
-
-L(prefetchSRC):
-	dcbt    r12,r4
-	addi    r12,r12,64
-	bdnz    L(prefetchSRC)
-
-
-	/* Prefetching is done, or was not needed.
-
-	   cr6 - are we on a cacheline boundary already?
-	   r7  - number of quadwords to the next cacheline boundary
-	*/
-
-L(nocacheprefetch):
-	mtctr   r7
-
-	cmpldi  cr1,r5,64   /* Less than a cache line to copy? */
-
-	/* How many bytes are left after we copy whatever full
-	   cache lines we can get? */
-	clrldi  r5,r5,64-6
-
-	beq     cr6,L(cachelinealigned)
-
-
-	/* Copy quadwords up to the next cacheline boundary */
-
-L(aligntocacheline):
-	ld      r9,0x08(r4)
-	ld      r7,0x10(r4)
-	addi    r4,r4,0x10
-	std     r9,0x08(r6)
-	stdu    r7,0x10(r6)
-	bdnz    L(aligntocacheline)
-
-
-	.align 4
-L(cachelinealigned):            /* copy while cache lines  */
-
-	blt-    cr1,L(lessthancacheline) /* size <64  */
-
-L(outerloop):
-	cmpdi   r11,0
-	mtctr   r11
-	beq-    L(endloop)
-
-	li      r11,64*ZERO_AHEAD +8    /* DCBZ dist  */
-
-	.align  4
-	/* Copy whole cachelines, optimized by prefetching SRC cacheline  */
-L(loop):                        /* Copy aligned body  */
-	dcbt    r12,r4          /* PREFETCH SOURCE some cache lines ahead  */
-	ld      r9, 0x08(r4)
-	dcbz    r11,r6
-	ld      r7, 0x10(r4)
-	ld      r8, 0x18(r4)
-	ld      r0, 0x20(r4)
-	std     r9, 0x08(r6)
-	std     r7, 0x10(r6)
-	std     r8, 0x18(r6)
-	std     r0, 0x20(r6)
-	ld      r9, 0x28(r4)
-	ld      r7, 0x30(r4)
-	ld      r8, 0x38(r4)
-	ld      r0, 0x40(r4)
-	addi    r4, r4,0x40
-	std     r9, 0x28(r6)
-	std     r7, 0x30(r6)
-	std     r8, 0x38(r6)
-	stdu    r0, 0x40(r6)
-
-	bdnz    L(loop)
-
-
-L(endloop):
-	cmpdi   r10,0
-	beq-    L(endloop2)
-	mtctr   r10
-
-L(loop2):                       /* Copy aligned body  */
-	ld      r9, 0x08(r4)
-	ld      r7, 0x10(r4)
-	ld      r8, 0x18(r4)
-	ld      r0, 0x20(r4)
-	std     r9, 0x08(r6)
-	std     r7, 0x10(r6)
-	std     r8, 0x18(r6)
-	std     r0, 0x20(r6)
-	ld      r9, 0x28(r4)
-	ld      r7, 0x30(r4)
-	ld      r8, 0x38(r4)
-	ld      r0, 0x40(r4)
-	addi    r4, r4,0x40
-	std     r9, 0x28(r6)
-	std     r7, 0x30(r6)
-	std     r8, 0x38(r6)
-	stdu    r0, 0x40(r6)
-
-	bdnz    L(loop2)
-L(endloop2):
-
-
-	.align 4
-L(lessthancacheline):           /* Was there less than cache to do ?  */
-	cmpldi  cr0,r5,16
-	srdi    r7,r5,4         /* divide size by 16  */
-	blt-    L(do_lt16)
-	mtctr   r7
-
-L(copy_remaining):
-	ld      r8,0x08(r4)
-	ld      r7,0x10(r4)
-	addi    r4,r4,0x10
-	std     r8,0x08(r6)
-	stdu    r7,0x10(r6)
-	bdnz    L(copy_remaining)
-
-L(do_lt16):                     /* less than 16 ?  */
-	cmpldi  cr0,r5,0        /* copy remaining bytes (0-15)  */
-	beqlr+                  /* no rest to copy  */
-	addi    r4,r4,8
-	addi    r6,r6,8
-
-L(shortcopy):                   /* SIMPLE COPY to handle size =< 15 bytes  */
-	mtcrf   0x01,r5
-	sub     r7,r4,r6
-	bf-     cr7*4+0,8f
-	ldx     r0,r7,r6        /* copy 8 byte  */
-	std     r0,0(r6)
-	addi    r6,r6,8
-8:
-	bf      cr7*4+1,4f
-	lwzx    r0,r7,r6        /* copy 4 byte  */
-	stw     r0,0(r6)
-	addi    r6,r6,4
-4:
-	bf      cr7*4+2,2f
-	lhzx    r0,r7,r6        /* copy 2 byte  */
-	sth     r0,0(r6)
-	addi    r6,r6,2
-2:
-	bf      cr7*4+3,1f
-	lbzx    r0,r7,r6        /* copy 1 byte  */
-	stb     r0,0(r6)
-1:
-	blr
-
-
-
-
-
-	/* Similar to above, but for use with 128 byte lines. */
-
-
-L(big_lines):
-
-	clrldi  r7,r7,64-7      /* How far to next cacheline bdy? */
-
-	cmpldi  cr6,r7,0        /* Are we on a cacheline bdy already? */
-
-	/* Reduce total len by what it takes to get to the next cache line */
-	subf    r5,r7,r5
-	srdi    r7,r7,4         /* How many qws to get to the line bdy? */
-
-	/* How many full cache lines to copy after getting to a line bdy? */
-	srdi    r10,r5,7
-
-	cmpldi  r10,0           /* If no full cache lines to copy ... */
-	li      r11,0           /* number cachelines to copy with prefetch  */
-	beq     L(nocacheprefetch_128)
-
-
-	/* We are here because we have at least one full cache line to copy,
-	   and therefore some pre-touching to do. */
-
-	cmpldi  r10,PREFETCH_AHEAD
-	li      r12,128+8       /* prefetch distance  */
-	ble     L(lessthanmaxprefetch_128)
-
-	/* We can only do so much pre-fetching.  R11 will have the count of
-	   lines left to prefetch after the initial batch of prefetches
-	   are executed. */
-
-	subi    r11,r10,PREFETCH_AHEAD
-	li      r10,PREFETCH_AHEAD
-
-L(lessthanmaxprefetch_128):
-	mtctr   r10
-
-	/* At this point r10/ctr hold the number of lines to prefetch in this
-	   initial batch, and r11 holds any remainder. */
-
-L(prefetchSRC_128):
-	dcbt    r12,r4
-	addi    r12,r12,128
-	bdnz    L(prefetchSRC_128)
-
-
-	/* Prefetching is done, or was not needed.
-
-	   cr6 - are we on a cacheline boundary already?
-	   r7  - number of quadwords to the next cacheline boundary
-	*/
-
-L(nocacheprefetch_128):
-	mtctr   r7
-
-	cmpldi  cr1,r5,128  /* Less than a cache line to copy? */
-
-	/* How many bytes are left after we copy whatever full
-	   cache lines we can get? */
-	clrldi  r5,r5,64-7
-
-	beq     cr6,L(cachelinealigned_128)
-
-
-	/* Copy quadwords up to the next cacheline boundary */
-
-L(aligntocacheline_128):
-	ld      r9,0x08(r4)
-	ld      r7,0x10(r4)
-	addi    r4,r4,0x10
-	std     r9,0x08(r6)
-	stdu    r7,0x10(r6)
-	bdnz    L(aligntocacheline_128)
-
-
-L(cachelinealigned_128):        /* copy while cache lines  */
-
-	blt-    cr1,L(lessthancacheline) /* size <128  */
-
-L(outerloop_128):
-	cmpdi   r11,0
-	mtctr   r11
-	beq-    L(endloop_128)
-
-	li      r11,128*ZERO_AHEAD +8    /* DCBZ dist  */
-
-	.align  4
-	/* Copy whole cachelines, optimized by prefetching SRC cacheline  */
-L(loop_128):                    /* Copy aligned body  */
-	dcbt    r12,r4          /* PREFETCH SOURCE some cache lines ahead  */
-	ld      r9, 0x08(r4)
-	dcbz    r11,r6
-	ld      r7, 0x10(r4)
-	ld      r8, 0x18(r4)
-	ld      r0, 0x20(r4)
-	std     r9, 0x08(r6)
-	std     r7, 0x10(r6)
-	std     r8, 0x18(r6)
-	std     r0, 0x20(r6)
-	ld      r9, 0x28(r4)
-	ld      r7, 0x30(r4)
-	ld      r8, 0x38(r4)
-	ld      r0, 0x40(r4)
-	std     r9, 0x28(r6)
-	std     r7, 0x30(r6)
-	std     r8, 0x38(r6)
-	std     r0, 0x40(r6)
-	ld      r9, 0x48(r4)
-	ld      r7, 0x50(r4)
-	ld      r8, 0x58(r4)
-	ld      r0, 0x60(r4)
-	std     r9, 0x48(r6)
-	std     r7, 0x50(r6)
-	std     r8, 0x58(r6)
-	std     r0, 0x60(r6)
-	ld      r9, 0x68(r4)
-	ld      r7, 0x70(r4)
-	ld      r8, 0x78(r4)
-	ld      r0, 0x80(r4)
-	addi    r4, r4,0x80
-	std     r9, 0x68(r6)
-	std     r7, 0x70(r6)
-	std     r8, 0x78(r6)
-	stdu    r0, 0x80(r6)
-
-	bdnz    L(loop_128)
-
-
-L(endloop_128):
-	cmpdi   r10,0
-	beq-    L(endloop2_128)
-	mtctr   r10
-
-L(loop2_128):                       /* Copy aligned body  */
-	ld      r9, 0x08(r4)
-	ld      r7, 0x10(r4)
-	ld      r8, 0x18(r4)
-	ld      r0, 0x20(r4)
-	std     r9, 0x08(r6)
-	std     r7, 0x10(r6)
-	std     r8, 0x18(r6)
-	std     r0, 0x20(r6)
-	ld      r9, 0x28(r4)
-	ld      r7, 0x30(r4)
-	ld      r8, 0x38(r4)
-	ld      r0, 0x40(r4)
-	std     r9, 0x28(r6)
-	std     r7, 0x30(r6)
-	std     r8, 0x38(r6)
-	std     r0, 0x40(r6)
-	ld      r9, 0x48(r4)
-	ld      r7, 0x50(r4)
-	ld      r8, 0x58(r4)
-	ld      r0, 0x60(r4)
-	std     r9, 0x48(r6)
-	std     r7, 0x50(r6)
-	std     r8, 0x58(r6)
-	std     r0, 0x60(r6)
-	ld      r9, 0x68(r4)
-	ld      r7, 0x70(r4)
-	ld      r8, 0x78(r4)
-	ld      r0, 0x80(r4)
-	addi    r4, r4,0x80
-	std     r9, 0x68(r6)
-	std     r7, 0x70(r6)
-	std     r8, 0x78(r6)
-	stdu    r0, 0x80(r6)
-
-	bdnz    L(loop2_128)
-L(endloop2_128):
-
-	b       L(lessthancacheline)
-
-
-END_GEN_TB (MEMCPY,TB_TOCLESS)
-libc_hidden_builtin_def (memcpy)
diff --git a/sysdeps/powerpc/powerpc64/cell/memcpy.S b/sysdeps/powerpc/powerpc64/cell/memcpy.S
deleted file mode 100644
index 3e07003..0000000
--- a/sysdeps/powerpc/powerpc64/cell/memcpy.S
+++ /dev/null
@@ -1,246 +0,0 @@
-/* Optimized memcpy implementation for CELL BE PowerPC.
-   Copyright (C) 2010-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-#ifndef MEMCPY
-# define MEMCPY memcpy
-#endif
-
-#define PREFETCH_AHEAD 6	/* no cache lines SRC prefetching ahead  */
-#define ZERO_AHEAD 4		/* no cache lines DST zeroing ahead  */
-
-/* memcpy routine optimized for CELL-BE-PPC	v2.0
- *
- * The CELL PPC core has 1 integer unit and 1 load/store unit
- * CELL:
- * 1st level data cache = 32K
- * 2nd level data cache = 512K
- * 3rd level data cache = 0K
- * With 3.2 GHz clockrate the latency to 2nd level cache is >36 clocks,
- * latency to memory is >400 clocks
- * To improve copy performance we need to prefetch source data
- * far ahead to hide this latency
- * For best performance instruction forms ending in "." like "andi."
- * should be avoided as the are implemented in microcode on CELL.
- * The below code is loop unrolled for the CELL cache line of 128 bytes
- */
-
-.align  7
-
-ENTRY_TOCLESS (MEMCPY, 5)
-	CALL_MCOUNT 3
-
-	dcbt	0,r4		/* Prefetch ONE SRC cacheline  */
-	cmpldi	cr1,r5,16	/* is size < 16 ?  */
-	mr	r6,r3
-	blt+	cr1,.Lshortcopy
-
-.Lbigcopy:
-	neg	r8,r3		/* LS 3 bits = # bytes to 8-byte dest bdry  */
-	clrldi  r8,r8,64-4	/* align to 16byte boundary  */
-	sub     r7,r4,r3
-	cmpldi	cr0,r8,0
-	beq+	.Ldst_aligned
-
-.Ldst_unaligned:
-	mtcrf	0x01,r8		/* put #bytes to boundary into cr7  */
-	subf	r5,r8,r5
-
-	bf	cr7*4+3,1f
-	lbzx	r0,r7,r6	/* copy 1 byte  */
-	stb	r0,0(r6)
-	addi	r6,r6,1
-1:	bf	cr7*4+2,2f
-	lhzx	r0,r7,r6	/* copy 2 byte  */
-	sth	r0,0(r6)
-	addi	r6,r6,2
-2:	bf	cr7*4+1,4f
-	lwzx	r0,r7,r6	/* copy 4 byte  */
-	stw	r0,0(r6)
-	addi	r6,r6,4
-4:	bf	cr7*4+0,8f
-	ldx	r0,r7,r6	/* copy 8 byte  */
-	std	r0,0(r6)
-	addi	r6,r6,8
-8:
-	add	r4,r7,r6
-
-.Ldst_aligned:
-
-	cmpdi	cr5,r5,128-1
-
-	neg	r7,r6
-	addi	r6,r6,-8	/* prepare for stdu  */
-	addi	r4,r4,-8	/* prepare for ldu  */
-
-	clrldi  r7,r7,64-7	/* align to cacheline boundary  */
-	ble+	cr5,.Llessthancacheline
-
-	cmpldi	cr6,r7,0
-	subf	r5,r7,r5
-	srdi	r7,r7,4		/* divide size by 16  */
-	srdi	r10,r5,7	/* number of cache lines to copy  */
-
-	cmpldi	r10,0
-	li	r11,0		/* number cachelines to copy with prefetch  */
-	beq	.Lnocacheprefetch
-
-	cmpldi	r10,PREFETCH_AHEAD
-	li	r12,128+8	/* prefetch distance  */
-	ble	.Llessthanmaxprefetch
-
-	subi	r11,r10,PREFETCH_AHEAD
-	li	r10,PREFETCH_AHEAD
-
-.Llessthanmaxprefetch:
-	mtctr	r10
-
-.LprefetchSRC:
-	dcbt    r12,r4
-	addi    r12,r12,128
-	bdnz    .LprefetchSRC
-
-.Lnocacheprefetch:
-	mtctr	r7
-	cmpldi	cr1,r5,128
-	clrldi  r5,r5,64-7
-	beq	cr6,.Lcachelinealigned
-
-.Laligntocacheline:
-	ld	r9,0x08(r4)
-	ldu	r7,0x10(r4)
-	std	r9,0x08(r6)
-	stdu	r7,0x10(r6)
-	bdnz	.Laligntocacheline
-
-
-.Lcachelinealigned:		/* copy while cache lines  */
-
-	blt-	cr1,.Llessthancacheline	/* size <128  */
-
-.Louterloop:
-	cmpdi   r11,0
-	mtctr	r11
-	beq-	.Lendloop
-
-	li	r11,128*ZERO_AHEAD +8	/* DCBZ dist  */
-
-.align	4
-	/* Copy whole cachelines, optimized by prefetching SRC cacheline  */
-.Lloop:				/* Copy aligned body  */
-	dcbt	r12,r4		/* PREFETCH SOURCE some cache lines ahead  */
-	ld	r9, 0x08(r4)
-	dcbz	r11,r6
-	ld	r7, 0x10(r4)	/* 4 register stride copy is optimal  */
-	ld	r8, 0x18(r4)	/* to hide 1st level cache latency.  */
-	ld	r0, 0x20(r4)
-	std	r9, 0x08(r6)
-	std	r7, 0x10(r6)
-	std	r8, 0x18(r6)
-	std	r0, 0x20(r6)
-	ld	r9, 0x28(r4)
-	ld	r7, 0x30(r4)
-	ld	r8, 0x38(r4)
-	ld	r0, 0x40(r4)
-	std	r9, 0x28(r6)
-	std	r7, 0x30(r6)
-	std	r8, 0x38(r6)
-	std	r0, 0x40(r6)
-	ld	r9, 0x48(r4)
-	ld	r7, 0x50(r4)
-	ld	r8, 0x58(r4)
-	ld	r0, 0x60(r4)
-	std	r9, 0x48(r6)
-	std	r7, 0x50(r6)
-	std	r8, 0x58(r6)
-	std	r0, 0x60(r6)
-	ld	r9, 0x68(r4)
-	ld	r7, 0x70(r4)
-	ld	r8, 0x78(r4)
-	ldu	r0, 0x80(r4)
-	std	r9, 0x68(r6)
-	std	r7, 0x70(r6)
-	std	r8, 0x78(r6)
-	stdu	r0, 0x80(r6)
-
-	bdnz	.Lloop
-
-.Lendloop:
-	cmpdi	r10,0
-	sldi	r10,r10,2	/* adjust from 128 to 32 byte stride  */
-	beq-	.Lendloop2
-	mtctr	r10
-
-.Lloop2:			/* Copy aligned body  */
-	ld	r9, 0x08(r4)
-	ld	r7, 0x10(r4)
-	ld	r8, 0x18(r4)
-	ldu	r0, 0x20(r4)
-	std	r9, 0x08(r6)
-	std	r7, 0x10(r6)
-	std	r8, 0x18(r6)
-	stdu	r0, 0x20(r6)
-
-	bdnz	.Lloop2
-.Lendloop2:
-
-.Llessthancacheline:		/* less than cache to do ?  */
-	cmpldi	cr0,r5,16
-	srdi	r7,r5,4		/* divide size by 16  */
-	blt-	.Ldo_lt16
-	mtctr	r7
-
-.Lcopy_remaining:
-	ld	r8,0x08(r4)
-	ldu	r7,0x10(r4)
-	std	r8,0x08(r6)
-	stdu	r7,0x10(r6)
-	bdnz	.Lcopy_remaining
-
-.Ldo_lt16:			/* less than 16 ?  */
-	cmpldi	cr0,r5,0	/* copy remaining bytes (0-15)  */
-	beqlr+			/* no rest to copy  */
-	addi	r4,r4,8
-	addi	r6,r6,8
-
-.Lshortcopy:			/* SIMPLE COPY to handle size =< 15 bytes  */
-	mtcrf	0x01,r5
-	sub	r7,r4,r6
-	bf-	cr7*4+0,8f
-	ldx	r0,r7,r6	/* copy 8 byte  */
-	std	r0,0(r6)
-	addi	r6,r6,8
-8:
-	bf	cr7*4+1,4f
-	lwzx	r0,r7,r6	/* copy 4 byte  */
-	stw	r0,0(r6)
-	addi	r6,r6,4
-4:
-	bf	cr7*4+2,2f
-	lhzx	r0,r7,r6	/* copy 2 byte  */
-	sth	r0,0(r6)
-	addi	r6,r6,2
-2:
-	bf	cr7*4+3,1f
-	lbzx	r0,r7,r6	/* copy 1 byte  */
-	stb	r0,0(r6)
-1:	blr
-
-END_GEN_TB (MEMCPY,TB_TOCLESS)
-libc_hidden_builtin_def (memcpy)
diff --git a/sysdeps/powerpc/powerpc64/memcpy.S b/sysdeps/powerpc/powerpc64/memcpy.S
deleted file mode 100644
index ebde694..0000000
--- a/sysdeps/powerpc/powerpc64/memcpy.S
+++ /dev/null
@@ -1,397 +0,0 @@
-/* Optimized memcpy implementation for PowerPC64.
-   Copyright (C) 2003-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* void * [r3] memcpy (void *dst [r3], void *src [r4], size_t len [r5]);
-   Returns 'dst'.
-
-   Memcpy handles short copies (< 32-bytes) using a binary move blocks
-   (no loops) of lwz/stw.  The tail (remaining 1-3) bytes is handled
-   with the appropriate combination of byte and halfword load/stores.
-   There is minimal effort to optimize the alignment of short moves.
-   The 64-bit implementations of POWER3 and POWER4 do a reasonable job
-   of handling unaligned load/stores that do not cross 32-byte boundaries.
-
-   Longer moves (>= 32-bytes) justify the effort to get at least the
-   destination doubleword (8-byte) aligned.  Further optimization is
-   possible when both source and destination are doubleword aligned.
-   Each case has a optimized unrolled loop.   */
-
-#ifndef MEMCPY
-# define MEMCPY memcpy
-#endif
-
-ENTRY_TOCLESS (MEMCPY, 5)
-	CALL_MCOUNT 3
-
-    cmpldi cr1,5,31
-    neg   0,3
-    std   3,-16(1)
-    std   31,-8(1)
-    cfi_offset(31,-8)
-    andi. 11,3,7	/* check alignment of dst.  */
-    clrldi 0,0,61	/* Number of bytes until the 1st doubleword of dst.  */
-    clrldi 10,4,61	/* check alignment of src.  */
-    cmpldi cr6,5,8
-    ble-  cr1,.L2	/* If move < 32 bytes use short move code.  */
-    cmpld cr6,10,11
-    mr    12,4
-    srdi  9,5,3		/* Number of full double words remaining.  */
-    mtcrf 0x01,0
-    mr    31,5
-    beq   .L0
-
-    subf  31,0,5
-  /* Move 0-7 bytes as needed to get the destination doubleword aligned.  */
-1:  bf    31,2f
-    lbz   6,0(12)
-    addi  12,12,1
-    stb   6,0(3)
-    addi  3,3,1
-2:  bf    30,4f
-    lhz   6,0(12)
-    addi  12,12,2
-    sth   6,0(3)
-    addi  3,3,2
-4:  bf    29,0f
-    lwz   6,0(12)
-    addi  12,12,4
-    stw   6,0(3)
-    addi  3,3,4
-0:
-    clrldi 10,12,61	/* check alignment of src again.  */
-    srdi  9,31,3	/* Number of full double words remaining.  */
-
-  /* Copy doublewords from source to destination, assuming the
-     destination is aligned on a doubleword boundary.
-
-     At this point we know there are at least 25 bytes left (32-7) to copy.
-     The next step is to determine if the source is also doubleword aligned.
-     If not branch to the unaligned move code at .L6. which uses
-     a load, shift, store strategy.
-
-     Otherwise source and destination are doubleword aligned, and we can
-     the optimized doubleword copy loop.  */
-.L0:
-    clrldi	11,31,61
-    mtcrf 0x01,9
-    bne-  cr6,.L6   /* If source is not DW aligned.  */
-
-  /* Move doublewords where destination and source are DW aligned.
-     Use a unrolled loop to copy 4 doubleword (32-bytes) per iteration.
-     If the copy is not an exact multiple of 32 bytes, 1-3
-     doublewords are copied as needed to set up the main loop.  After
-     the main loop exits there may be a tail of 1-7 bytes. These byte are
-     copied a word/halfword/byte at a time as needed to preserve alignment.  */
-
-    srdi  8,31,5
-    cmpldi	cr1,9,4
-    cmpldi	cr6,11,0
-    mr    11,12
-
-    bf    30,1f
-    ld    6,0(12)
-    ld    7,8(12)
-    addi  11,12,16
-    mtctr 8
-    std   6,0(3)
-    std   7,8(3)
-    addi  10,3,16
-    bf    31,4f
-    ld    0,16(12)
-    std   0,16(3)
-    blt   cr1,3f
-    addi  11,12,24
-    addi  10,3,24
-    b     4f
-    .align  4
-1:
-    mr    10,3
-    mtctr 8
-    bf    31,4f
-    ld    6,0(12)
-    addi  11,12,8
-    std   6,0(3)
-    addi  10,3,8
-
-    .align  4
-4:
-    ld    6,0(11)
-    ld    7,8(11)
-    ld    8,16(11)
-    ld    0,24(11)
-    addi  11,11,32
-2:
-    std   6,0(10)
-    std   7,8(10)
-    std   8,16(10)
-    std   0,24(10)
-    addi  10,10,32
-    bdnz  4b
-3:
-
-    rldicr 0,31,0,60
-    mtcrf 0x01,31
-    beq   cr6,0f
-.L9:
-    add   3,3,0
-    add   12,12,0
-
-/*  At this point we have a tail of 0-7 bytes and we know that the
-    destination is double word aligned.  */
-4:  bf    29,2f
-    lwz   6,0(12)
-    addi  12,12,4
-    stw   6,0(3)
-    addi  3,3,4
-2:  bf    30,1f
-    lhz   6,0(12)
-    addi  12,12,2
-    sth   6,0(3)
-    addi  3,3,2
-1:  bf    31,0f
-    lbz   6,0(12)
-    stb   6,0(3)
-0:
-  /* Return original dst pointer.  */
-    ld 31,-8(1)
-    ld 3,-16(1)
-    blr
-
-/* Copy up to 31 bytes.  This divided into two cases 0-8 bytes and 9-31
-   bytes.  Each case is handled without loops, using binary (1,2,4,8)
-   tests.
-
-   In the short (0-8 byte) case no attempt is made to force alignment
-   of either source or destination.  The hardware will handle the
-   unaligned load/stores with small delays for crossing 32- 64-byte, and
-   4096-byte boundaries. Since these short moves are unlikely to be
-   unaligned or cross these boundaries, the overhead to force
-   alignment is not justified.
-
-   The longer (9-31 byte) move is more likely to cross 32- or 64-byte
-   boundaries.  Since only loads are sensitive to the 32-/64-byte
-   boundaries it is more important to align the source then the
-   destination.  If the source is not already word aligned, we first
-   move 1-3 bytes as needed.  Since we are only word aligned we don't
-   use double word load/stores to insure that all loads are aligned.
-   While the destination and stores may still be unaligned, this
-   is only an issue for page (4096 byte boundary) crossing, which
-   should be rare for these short moves.  The hardware handles this
-   case automatically with a small delay.  */
-
-    .align  4
-.L2:
-    mtcrf 0x01,5
-    neg   8,4
-    clrrdi	11,4,2
-    andi. 0,8,3
-    ble   cr6,.LE8	/* Handle moves of 0-8 bytes.  */
-/* At least 9 bytes left.  Get the source word aligned.  */
-    cmpldi	cr1,5,16
-    mr    10,5
-    mr    12,4
-    cmpldi	cr6,0,2
-    beq   .L3	/* If the source is already word aligned skip this.  */
-/* Copy 1-3 bytes to get source address word aligned.  */
-    lwz   6,0(11)
-    subf  10,0,5
-    add   12,4,0
-    blt   cr6,5f
-    srdi  7,6,16
-    bgt	  cr6,3f
-#ifdef __LITTLE_ENDIAN__
-    sth   7,0(3)
-#else
-    sth   6,0(3)
-#endif
-    b     7f
-    .align  4
-3:
-#ifdef __LITTLE_ENDIAN__
-    rotlwi 6,6,24
-    stb   6,0(3)
-    sth   7,1(3)
-#else
-    stb   7,0(3)
-    sth   6,1(3)
-#endif
-    b     7f
-    .align  4
-5:
-#ifdef __LITTLE_ENDIAN__
-    rotlwi 6,6,8
-#endif
-    stb   6,0(3)
-7:
-    cmpldi	cr1,10,16
-    add   3,3,0
-    mtcrf 0x01,10
-    .align  4
-.L3:
-/* At least 6 bytes left and the source is word aligned.  */
-    blt   cr1,8f
-16: /* Move 16 bytes.  */
-    lwz   6,0(12)
-    lwz   7,4(12)
-    stw   6,0(3)
-    lwz   6,8(12)
-    stw   7,4(3)
-    lwz   7,12(12)
-    addi  12,12,16
-    stw   6,8(3)
-    stw   7,12(3)
-    addi  3,3,16
-8:  /* Move 8 bytes.  */
-    bf    28,4f
-    lwz   6,0(12)
-    lwz   7,4(12)
-    addi  12,12,8
-    stw   6,0(3)
-    stw   7,4(3)
-    addi  3,3,8
-4:  /* Move 4 bytes.  */
-    bf    29,2f
-    lwz   6,0(12)
-    addi  12,12,4
-    stw   6,0(3)
-    addi  3,3,4
-2:  /* Move 2-3 bytes.  */
-    bf    30,1f
-    lhz   6,0(12)
-    sth   6,0(3)
-    bf    31,0f
-    lbz   7,2(12)
-    stb   7,2(3)
-    ld 3,-16(1)
-    blr
-1:  /* Move 1 byte.  */
-    bf    31,0f
-    lbz   6,0(12)
-    stb   6,0(3)
-0:
-  /* Return original dst pointer.  */
-    ld    3,-16(1)
-    blr
-
-/* Special case to copy 0-8 bytes.  */
-    .align  4
-.LE8:
-    mr    12,4
-    bne   cr6,4f
-/* Would have liked to use use ld/std here but the 630 processors are
-   slow for load/store doubles that are not at least word aligned.
-   Unaligned Load/Store word execute with only a 1 cycle penalty.  */
-    lwz   6,0(4)
-    lwz   7,4(4)
-    stw   6,0(3)
-    stw   7,4(3)
-  /* Return original dst pointer.  */
-    ld    3,-16(1)
-    blr
-    .align  4
-4:  bf    29,2b
-    lwz   6,0(4)
-    stw   6,0(3)
-6:
-    bf    30,5f
-    lhz   7,4(4)
-    sth   7,4(3)
-    bf    31,0f
-    lbz   8,6(4)
-    stb   8,6(3)
-    ld 3,-16(1)
-    blr
-    .align  4
-5:
-    bf    31,0f
-    lbz   6,4(4)
-    stb   6,4(3)
-    .align  4
-0:
-  /* Return original dst pointer.  */
-    ld    3,-16(1)
-    blr
-
-    .align  4
-.L6:
-
-  /* Copy doublewords where the destination is aligned but the source is
-     not.  Use aligned doubleword loads from the source, shifted to realign
-     the data, to allow aligned destination stores.  */
-    subf  5,10,12
-    andi. 0,9,1
-    cmpldi cr6,11,0
-    sldi  10,10,3
-    mr    11,9
-    mr    4,3
-    ld    6,0(5)
-    ld    7,8(5)
-    subfic  9,10,64
-    beq   2f
-#ifdef __LITTLE_ENDIAN__
-    srd   0,6,10
-#else
-    sld   0,6,10
-#endif
-    cmpldi  11,1
-    mr    6,7
-    addi  4,4,-8
-    addi  11,11,-1
-    b     1f
-2:  addi  5,5,8
-    .align  4
-#ifdef __LITTLE_ENDIAN__
-0:  srd   0,6,10
-    sld   8,7,9
-#else
-0:  sld   0,6,10
-    srd   8,7,9
-#endif
-    cmpldi  11,2
-    ld    6,8(5)
-    or    0,0,8
-    addi  11,11,-2
-    std   0,0(4)
-#ifdef __LITTLE_ENDIAN__
-    srd   0,7,10
-1:  sld   8,6,9
-#else
-    sld   0,7,10
-1:  srd   8,6,9
-#endif
-    or    0,0,8
-    beq   8f
-    ld    7,16(5)
-    std   0,8(4)
-    addi  5,5,16
-    addi  4,4,16
-    b     0b
-    .align 4
-8:
-    std   0,8(4)
-    rldicr 0,31,0,60
-    mtcrf 0x01,31
-    bne   cr6,.L9	/* If the tail is 0 bytes we are done!  */
-  /* Return original dst pointer.  */
-    ld 31,-8(1)
-    ld 3,-16(1)
-    blr
-END_GEN_TB (MEMCPY,TB_TOCLESS)
-libc_hidden_builtin_def (memcpy)
diff --git a/sysdeps/powerpc/powerpc64/memset.S b/sysdeps/powerpc/powerpc64/memset.S
deleted file mode 100644
index a36df7c..0000000
--- a/sysdeps/powerpc/powerpc64/memset.S
+++ /dev/null
@@ -1,265 +0,0 @@
-/* Optimized memset implementation for PowerPC64.
-   Copyright (C) 1997-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-	.section	".toc","aw"
-.LC0:
-	.tc __cache_line_size[TC],__cache_line_size
-	.section	".text"
-	.align 2
-
-/* void * [r3] memset (void *s [r3], int c [r4], size_t n [r5]));
-   Returns 's'.
-
-   The memset is done in three sizes: byte (8 bits), word (32 bits),
-   cache line (256 bits). There is a special case for setting cache lines
-   to 0, to take advantage of the dcbz instruction.  */
-
-#ifndef MEMSET
-# define MEMSET memset
-#endif
-
-ENTRY (MEMSET, 5)
-	CALL_MCOUNT 3
-
-#define rTMP	r0
-#define rRTN	r3	/* Initial value of 1st argument.  */
-#define rMEMP0	r3	/* Original value of 1st arg.  */
-#define rCHR	r4	/* Char to set in each byte.  */
-#define rLEN	r5	/* Length of region to set.  */
-#define rMEMP	r6	/* Address at which we are storing.  */
-#define rALIGN	r7	/* Number of bytes we are setting now (when aligning). */
-#define rMEMP2	r8
-
-#define rNEG64	r8	/* Constant -64 for clearing with dcbz.  */
-#define rCLS	r8	/* Cache line size obtained from static.  */
-#define rCLM	r9	/* Cache line size mask to check for cache alignment.  */
-L(_memset):
-/* Take care of case for size <= 4.  */
-	cmpldi	cr1, rLEN, 8
-	andi.	rALIGN, rMEMP0, 7
-	mr	rMEMP, rMEMP0
-	ble-	cr1, L(small)
-
-/* Align to doubleword boundary.  */
-	cmpldi	cr5, rLEN, 31
-	insrdi	rCHR, rCHR, 8, 48	/* Replicate byte to halfword.  */
-	beq+	L(aligned2)
-	mtcrf	0x01, rMEMP0
-	subfic	rALIGN, rALIGN, 8
-	cror	28,30,31		/* Detect odd word aligned.  */
-	add	rMEMP, rMEMP, rALIGN
-	sub	rLEN, rLEN, rALIGN
-	insrdi	rCHR, rCHR, 16, 32	/* Replicate halfword to word.  */
-	bt	29, L(g4)
-/* Process the even word of doubleword.  */
-	bf+	31, L(g2)
-	stb	rCHR, 0(rMEMP0)
-	bt	30, L(g4x)
-L(g2):
-	sth	rCHR, -6(rMEMP)
-L(g4x):
-	stw	rCHR, -4(rMEMP)
-	b	L(aligned)
-/* Process the odd word of doubleword.  */
-L(g4):
-	bf	28, L(g4x) /* If false, word aligned on odd word.  */
-	bf+	31, L(g0)
-	stb	rCHR, 0(rMEMP0)
-	bt	30, L(aligned)
-L(g0):
-	sth	rCHR, -2(rMEMP)
-
-/* Handle the case of size < 31.  */
-L(aligned2):
-	insrdi	rCHR, rCHR, 16, 32	/* Replicate halfword to word.  */
-L(aligned):
-	mtcrf	0x01, rLEN
-	ble	cr5, L(medium)
-/* Align to 32-byte boundary.  */
-	andi.	rALIGN, rMEMP, 0x18
-	subfic	rALIGN, rALIGN, 0x20
-	insrdi	rCHR, rCHR, 32, 0	/* Replicate word to double word. */
-	beq	L(caligned)
-	mtcrf	0x01, rALIGN
-	add	rMEMP, rMEMP, rALIGN
-	sub	rLEN, rLEN, rALIGN
-	cmplwi	cr1, rALIGN, 0x10
-	mr	rMEMP2, rMEMP
-	bf	28, L(a1)
-	stdu	rCHR, -8(rMEMP2)
-L(a1):	blt	cr1, L(a2)
-	std	rCHR, -8(rMEMP2)
-	stdu	rCHR, -16(rMEMP2)
-L(a2):
-
-/* Now aligned to a 32 byte boundary.  */
-L(caligned):
-	cmpldi	cr1, rCHR, 0
-	clrrdi.	rALIGN, rLEN, 5
-	mtcrf	0x01, rLEN
-	beq	cr1, L(zloopstart) /* Special case for clearing memory using dcbz.  */
-L(nondcbz):
-	srdi	rTMP, rALIGN, 5
-	mtctr	rTMP
-	beq	L(medium)	/* We may not actually get to do a full line.  */
-	clrldi.	rLEN, rLEN, 59
-	add	rMEMP, rMEMP, rALIGN
-	li	rNEG64, -0x40
-	bdz	L(cloopdone)
-
-L(c3):	dcbtst	rNEG64, rMEMP
-	std	rCHR, -8(rMEMP)
-	std	rCHR, -16(rMEMP)
-	std	rCHR, -24(rMEMP)
-	stdu	rCHR, -32(rMEMP)
-	bdnz	L(c3)
-L(cloopdone):
-	std	rCHR, -8(rMEMP)
-	std	rCHR, -16(rMEMP)
-	cmpldi	cr1, rLEN, 16
-	std	rCHR, -24(rMEMP)
-	stdu	rCHR, -32(rMEMP)
-	beqlr
-	add	rMEMP, rMEMP, rALIGN
-	b	L(medium_tail2)
-
-	.align 5
-/* Clear lines of memory in 128-byte chunks.  */
-L(zloopstart):
-/* If the remaining length is less the 32 bytes, don't bother getting
-	 the cache line size.  */
-	beq	L(medium)
-	ld	rCLS,.LC0@toc(r2)
-	lwz	rCLS,0(rCLS)
-/* If the cache line size was not set just goto to L(nondcbz) which is
-	 safe for any cache line size.  */
-	cmpldi	cr1,rCLS,0
-	beq		cr1,L(nondcbz)
-
-
-/* Now we know the cache line size, and it is not 32-bytes, but
-	 we may not yet be aligned to the cache line. May have a partial
-	 line to fill, so touch it 1st.  */
-	dcbt	0,rMEMP
-	addi	rCLM,rCLS,-1
-L(getCacheAligned):
-	cmpldi	cr1,rLEN,32
-	and.	rTMP,rCLM,rMEMP
-	blt		cr1,L(handletail32)
-	beq		L(cacheAligned)
-	addi	rMEMP,rMEMP,32
-	addi	rLEN,rLEN,-32
-	std		rCHR,-32(rMEMP)
-	std		rCHR,-24(rMEMP)
-	std		rCHR,-16(rMEMP)
-	std		rCHR,-8(rMEMP)
-	b		L(getCacheAligned)
-
-/* Now we are aligned to the cache line and can use dcbz.  */
-L(cacheAligned):
-	cmpld	cr1,rLEN,rCLS
-	blt		cr1,L(handletail32)
-	dcbz	0,rMEMP
-	subf	rLEN,rCLS,rLEN
-	add		rMEMP,rMEMP,rCLS
-	b		L(cacheAligned)
-
-/* We are here because the cache line size was set and was not 32-bytes
-   and the remainder (rLEN) is less than the actual cache line size.
-   So set up the preconditions for L(nondcbz) and go there.  */
-L(handletail32):
-	clrrwi.	rALIGN, rLEN, 5
-	b		L(nondcbz)
-
-	.align 5
-L(small):
-/* Memset of 8 bytes or less.  */
-	cmpldi	cr6, rLEN, 4
-	cmpldi	cr5, rLEN, 1
-	ble	cr6,L(le4)
-	subi	rLEN, rLEN, 4
-	stb	rCHR,0(rMEMP)
-	stb	rCHR,1(rMEMP)
-	stb	rCHR,2(rMEMP)
-	stb	rCHR,3(rMEMP)
-	addi	rMEMP,rMEMP, 4
-	cmpldi	cr5, rLEN, 1
-L(le4):
-	cmpldi	cr1, rLEN, 3
-	bltlr	cr5
-	stb	rCHR, 0(rMEMP)
-	beqlr	cr5
-	stb	rCHR, 1(rMEMP)
-	bltlr	cr1
-	stb	rCHR, 2(rMEMP)
-	beqlr	cr1
-	stb	rCHR, 3(rMEMP)
-	blr
-
-/* Memset of 0-31 bytes.  */
-	.align 5
-L(medium):
-	insrdi	rCHR, rCHR, 32, 0	/* Replicate word to double word.  */
-	cmpldi	cr1, rLEN, 16
-L(medium_tail2):
-	add	rMEMP, rMEMP, rLEN
-L(medium_tail):
-	bt-	31, L(medium_31t)
-	bt-	30, L(medium_30t)
-L(medium_30f):
-	bt-	29, L(medium_29t)
-L(medium_29f):
-	bge-	cr1, L(medium_27t)
-	bflr-	28
-	std	rCHR, -8(rMEMP)
-	blr
-
-L(medium_31t):
-	stbu	rCHR, -1(rMEMP)
-	bf-	30, L(medium_30f)
-L(medium_30t):
-	sthu	rCHR, -2(rMEMP)
-	bf-	29, L(medium_29f)
-L(medium_29t):
-	stwu	rCHR, -4(rMEMP)
-	blt-	cr1, L(medium_27f)
-L(medium_27t):
-	std	rCHR, -8(rMEMP)
-	stdu	rCHR, -16(rMEMP)
-L(medium_27f):
-	bflr-	28
-L(medium_28t):
-	std	rCHR, -8(rMEMP)
-	blr
-END_GEN_TB (MEMSET,TB_TOCLESS)
-libc_hidden_builtin_def (memset)
-
-#ifndef NO_BZERO_IMPL
-/* Copied from bzero.S to prevent the linker from inserting a stub
-   between bzero and memset.  */
-ENTRY (__bzero)
-	CALL_MCOUNT 3
-	mr	r5,r4
-	li	r4,0
-	b	L(_memset)
-END_GEN_TB (__bzero,TB_TOCLESS)
-
-weak_alias (__bzero, bzero)
-#endif
diff --git a/sysdeps/powerpc/powerpc64/multiarch/ifunc-impl-list.c b/sysdeps/powerpc/powerpc64/multiarch/ifunc-impl-list.c
index 38a21e4..50b1285 100644
--- a/sysdeps/powerpc/powerpc64/multiarch/ifunc-impl-list.c
+++ b/sysdeps/powerpc/powerpc64/multiarch/ifunc-impl-list.c
@@ -48,350 +48,5 @@ __libc_ifunc_impl_list (const char *name, struct libc_ifunc_impl *array,
   else if (hwcap & PPC_FEATURE_POWER5)
     hwcap |= PPC_FEATURE_POWER4;
 
-#ifdef SHARED
-  /* Support sysdeps/powerpc/powerpc64/multiarch/memcpy.c.  */
-  IFUNC_IMPL (i, name, memcpy,
-	      IFUNC_IMPL_ADD (array, i, memcpy, hwcap2 & PPC_FEATURE2_ARCH_2_07,
-			      __memcpy_power8_cached)
-	      IFUNC_IMPL_ADD (array, i, memcpy, hwcap & PPC_FEATURE_HAS_VSX,
-			      __memcpy_power7)
-	      IFUNC_IMPL_ADD (array, i, memcpy, hwcap & PPC_FEATURE_ARCH_2_06,
-			      __memcpy_a2)
-	      IFUNC_IMPL_ADD (array, i, memcpy, hwcap & PPC_FEATURE_ARCH_2_05,
-			      __memcpy_power6)
-	      IFUNC_IMPL_ADD (array, i, memcpy, hwcap & PPC_FEATURE_CELL_BE,
-			      __memcpy_cell)
-	      IFUNC_IMPL_ADD (array, i, memcpy, hwcap & PPC_FEATURE_POWER4,
-			      __memcpy_power4)
-	      IFUNC_IMPL_ADD (array, i, memcpy, 1, __memcpy_ppc))
-
-  /* Support sysdeps/powerpc/powerpc64/multiarch/memmove.c.  */
-  IFUNC_IMPL (i, name, memmove,
-	      IFUNC_IMPL_ADD (array, i, memmove, hwcap & PPC_FEATURE_HAS_VSX,
-			      __memmove_power7)
-	      IFUNC_IMPL_ADD (array, i, memmove, 1, __memmove_ppc))
-
-  /* Support sysdeps/powerpc/powerpc64/multiarch/memset.c.  */
-  IFUNC_IMPL (i, name, memset,
-	      IFUNC_IMPL_ADD (array, i, memset, hwcap2 & PPC_FEATURE2_ARCH_2_07,
-			      __memset_power8)
-	      IFUNC_IMPL_ADD (array, i, memset, hwcap & PPC_FEATURE_HAS_VSX,
-			      __memset_power7)
-	      IFUNC_IMPL_ADD (array, i, memset, hwcap & PPC_FEATURE_ARCH_2_05,
-			      __memset_power6)
-	      IFUNC_IMPL_ADD (array, i, memset, hwcap & PPC_FEATURE_POWER4,
-			      __memset_power4)
-	      IFUNC_IMPL_ADD (array, i, memset, 1, __memset_ppc))
-
-  /* Support sysdeps/powerpc/powerpc64/multiarch/strcpy.c.  */
-  IFUNC_IMPL (i, name, strcpy,
-	      IFUNC_IMPL_ADD (array, i, strcpy, hwcap2 & PPC_FEATURE2_ARCH_2_07,
-			      __strcpy_power8)
-	      IFUNC_IMPL_ADD (array, i, strcpy, hwcap & PPC_FEATURE_HAS_VSX,
-			      __strcpy_power7)
-	      IFUNC_IMPL_ADD (array, i, strcpy, 1,
-			      __strcpy_ppc))
-
-  /* Support sysdeps/powerpc/powerpc64/multiarch/stpcpy.c.  */
-  IFUNC_IMPL (i, name, stpcpy,
-	      IFUNC_IMPL_ADD (array, i, stpcpy, hwcap2 & PPC_FEATURE2_ARCH_2_07,
-			      __stpcpy_power8)
-	      IFUNC_IMPL_ADD (array, i, stpcpy, hwcap & PPC_FEATURE_HAS_VSX,
-			      __stpcpy_power7)
-	      IFUNC_IMPL_ADD (array, i, stpcpy, 1,
-			      __stpcpy_ppc))
-
-  /* Support sysdeps/powerpc/powerpc64/multiarch/strlen.c.  */
-  IFUNC_IMPL (i, name, strlen,
-	      IFUNC_IMPL_ADD (array, i, strlen, hwcap2 & PPC_FEATURE2_ARCH_2_07,
-			      __strlen_power8)
-	      IFUNC_IMPL_ADD (array, i, strlen, hwcap & PPC_FEATURE_HAS_VSX,
-			      __strlen_power7)
-	      IFUNC_IMPL_ADD (array, i, strlen, 1,
-			      __strlen_ppc))
-
-  /* Support sysdeps/powerpc/powerpc64/multiarch/strncmp.c.  */
-  IFUNC_IMPL (i, name, strncmp,
-	      IFUNC_IMPL_ADD (array, i, strncmp, hwcap2 & PPC_FEATURE2_ARCH_3_00,
-			      __strncmp_power9)
-	      IFUNC_IMPL_ADD (array, i, strncmp, hwcap2 & PPC_FEATURE2_ARCH_2_07,
-			      __strncmp_power8)
-	      IFUNC_IMPL_ADD (array, i, strncmp, hwcap & PPC_FEATURE_HAS_VSX,
-			      __strncmp_power7)
-	      IFUNC_IMPL_ADD (array, i, strncmp, hwcap & PPC_FEATURE_POWER4,
-			      __strncmp_power4)
-	      IFUNC_IMPL_ADD (array, i, strncmp, 1,
-			      __strncmp_ppc))
-
-  /* Support sysdeps/powerpc/powerpc64/multiarch/strchr.c.  */
-  IFUNC_IMPL (i, name, strchr,
-	      IFUNC_IMPL_ADD (array, i, strchr,
-			      hwcap2 & PPC_FEATURE2_ARCH_2_07,
-			      __strchr_power8)
-	      IFUNC_IMPL_ADD (array, i, strchr,
-			      hwcap & PPC_FEATURE_HAS_VSX,
-			      __strchr_power7)
-	      IFUNC_IMPL_ADD (array, i, strchr, 1,
-			      __strchr_ppc))
-
-  /* Support sysdeps/powerpc/powerpc64/multiarch/strchrnul.c.  */
-  IFUNC_IMPL (i, name, strchrnul,
-	      IFUNC_IMPL_ADD (array, i, strchrnul,
-			      hwcap2 & PPC_FEATURE2_ARCH_2_07,
-			      __strchrnul_power8)
-	      IFUNC_IMPL_ADD (array, i, strchrnul,
-			      hwcap & PPC_FEATURE_HAS_VSX,
-			      __strchrnul_power7)
-	      IFUNC_IMPL_ADD (array, i, strchrnul, 1,
-			      __strchrnul_ppc))
-#endif
-
-  /* Support sysdeps/powerpc/powerpc64/multiarch/memcmp.c.  */
-  IFUNC_IMPL (i, name, memcmp,
-	      IFUNC_IMPL_ADD (array, i, memcmp, hwcap2 & PPC_FEATURE2_ARCH_2_07,
-			      __memcmp_power8)
-	      IFUNC_IMPL_ADD (array, i, memcmp, hwcap & PPC_FEATURE_HAS_VSX,
-			      __memcmp_power7)
-	      IFUNC_IMPL_ADD (array, i, memcmp, hwcap & PPC_FEATURE_POWER4,
-			      __memcmp_power4)
-	      IFUNC_IMPL_ADD (array, i, memcmp, 1, __memcmp_ppc))
-
-  /* Support sysdeps/powerpc/powerpc64/multiarch/bzero.c.  */
-  IFUNC_IMPL (i, name, bzero,
-	      IFUNC_IMPL_ADD (array, i, bzero, hwcap2 & PPC_FEATURE2_ARCH_2_07,
-			      __bzero_power8)
-	      IFUNC_IMPL_ADD (array, i, bzero, hwcap & PPC_FEATURE_HAS_VSX,
-			      __bzero_power7)
-	      IFUNC_IMPL_ADD (array, i, bzero, hwcap & PPC_FEATURE_ARCH_2_05,
-			      __bzero_power6)
-	      IFUNC_IMPL_ADD (array, i, bzero, hwcap & PPC_FEATURE_POWER4,
-			      __bzero_power4)
-	      IFUNC_IMPL_ADD (array, i, bzero, 1, __bzero_ppc))
-
-  /* Support sysdeps/powerpc/powerpc64/multiarch/bcopy.c.  */
-  IFUNC_IMPL (i, name, bcopy,
-	      IFUNC_IMPL_ADD (array, i, bcopy, hwcap & PPC_FEATURE_HAS_VSX,
-			      __bcopy_power7)
-	      IFUNC_IMPL_ADD (array, i, bcopy, 1, __bcopy_ppc))
-
-  /* Support sysdeps/powerpc/powerpc64/multiarch/mempcpy.c.  */
-  IFUNC_IMPL (i, name, mempcpy,
-	      IFUNC_IMPL_ADD (array, i, mempcpy,
-			      hwcap & PPC_FEATURE_HAS_VSX,
-			      __mempcpy_power7)
-	      IFUNC_IMPL_ADD (array, i, mempcpy, 1,
-			      __mempcpy_ppc))
-
-  /* Support sysdeps/powerpc/powerpc64/multiarch/memchr.c.  */
-  IFUNC_IMPL (i, name, memchr,
-	      IFUNC_IMPL_ADD (array, i, memchr,
-			      hwcap2 & PPC_FEATURE2_ARCH_2_07,
-			      __memchr_power8)
-	      IFUNC_IMPL_ADD (array, i, memchr,
-			      hwcap & PPC_FEATURE_HAS_VSX,
-			      __memchr_power7)
-	      IFUNC_IMPL_ADD (array, i, memchr, 1,
-			      __memchr_ppc))
-
-  /* Support sysdeps/powerpc/powerpc64/multiarch/memrchr.c.  */
-  IFUNC_IMPL (i, name, memrchr,
-	      IFUNC_IMPL_ADD (array, i, memrchr,
-			      hwcap2 & PPC_FEATURE2_ARCH_2_07,
-			      __memrchr_power8)
-	      IFUNC_IMPL_ADD (array, i, memrchr,
-			      hwcap & PPC_FEATURE_HAS_VSX,
-			      __memrchr_power7)
-	      IFUNC_IMPL_ADD (array, i, memrchr, 1,
-			      __memrchr_ppc))
-
-  /* Support sysdeps/powerpc/powerpc64/multiarch/rawmemchr.c.  */
-  IFUNC_IMPL (i, name, rawmemchr,
-	      IFUNC_IMPL_ADD (array, i, rawmemchr,
-			      hwcap & PPC_FEATURE_HAS_VSX,
-			      __rawmemchr_power7)
-	      IFUNC_IMPL_ADD (array, i, rawmemchr, 1,
-			      __rawmemchr_ppc))
-
-  /* Support sysdeps/powerpc/powerpc64/multiarch/strnlen.c.  */
-  IFUNC_IMPL (i, name, strnlen,
-	      IFUNC_IMPL_ADD (array, i, strnlen,
-			      hwcap2 & PPC_FEATURE2_ARCH_2_07,
-			      __strnlen_power8)
-	      IFUNC_IMPL_ADD (array, i, strnlen, hwcap & PPC_FEATURE_HAS_VSX,
-			      __strnlen_power7)
-	      IFUNC_IMPL_ADD (array, i, strnlen, 1,
-			      __strnlen_ppc))
-
-  /* Support sysdeps/powerpc/powerpc64/multiarch/strcasecmp.c.  */
-  IFUNC_IMPL (i, name, strcasecmp,
-	      IFUNC_IMPL_ADD (array, i, strcasecmp,
-			      hwcap2 & PPC_FEATURE2_ARCH_2_07,
-			      __strcasecmp_power8)
-	      IFUNC_IMPL_ADD (array, i, strcasecmp,
-			      hwcap & PPC_FEATURE_HAS_VSX,
-			      __strcasecmp_power7)
-	      IFUNC_IMPL_ADD (array, i, strcasecmp, 1, __strcasecmp_ppc))
-
-  /* Support sysdeps/powerpc/powerpc64/multiarch/strcasecmp_l.c.  */
-  IFUNC_IMPL (i, name, strcasecmp_l,
-	      IFUNC_IMPL_ADD (array, i, strcasecmp_l,
-			      hwcap & PPC_FEATURE_HAS_VSX,
-			      __strcasecmp_l_power7)
-	      IFUNC_IMPL_ADD (array, i, strcasecmp_l, 1,
-			      __strcasecmp_l_ppc))
-
-  /* Support sysdeps/powerpc/powerpc64/multiarch/strncase.c.  */
-  IFUNC_IMPL (i, name, strncasecmp,
-	      IFUNC_IMPL_ADD (array, i, strncasecmp,
-			      hwcap2 & PPC_FEATURE2_ARCH_2_07,
-			      __strncasecmp_power8)
-	      IFUNC_IMPL_ADD (array, i, strncasecmp,
-			      hwcap & PPC_FEATURE_HAS_VSX,
-			      __strncasecmp_power7)
-	      IFUNC_IMPL_ADD (array, i, strncasecmp, 1, __strncasecmp_ppc))
-
-  /* Support sysdeps/powerpc/powerpc64/multiarch/strncase_l.c.  */
-  IFUNC_IMPL (i, name, strncasecmp_l,
-	      IFUNC_IMPL_ADD (array, i, strncasecmp_l,
-			      hwcap & PPC_FEATURE_HAS_VSX,
-			      __strncasecmp_l_power7)
-	      IFUNC_IMPL_ADD (array, i, strncasecmp_l, 1,
-			      __strncasecmp_l_ppc))
-
-  /* Support sysdeps/powerpc/powerpc64/multiarch/wcschr.c.  */
-  IFUNC_IMPL (i, name, wcschr,
-	      IFUNC_IMPL_ADD (array, i, wcschr,
-			      hwcap & PPC_FEATURE_HAS_VSX,
-			      __wcschr_power7)
-	      IFUNC_IMPL_ADD (array, i, wcschr,
-			      hwcap & PPC_FEATURE_ARCH_2_05,
-			      __wcschr_power6)
-	      IFUNC_IMPL_ADD (array, i, wcschr, 1,
-			      __wcschr_ppc))
-
-  /* Support sysdeps/powerpc/powerpc64/multiarch/wcschr.c.  */
-  IFUNC_IMPL (i, name, wcsrchr,
-	      IFUNC_IMPL_ADD (array, i, wcsrchr,
-			      hwcap & PPC_FEATURE_HAS_VSX,
-			      __wcsrchr_power7)
-	      IFUNC_IMPL_ADD (array, i, wcsrchr,
-			      hwcap & PPC_FEATURE_ARCH_2_05,
-			      __wcsrchr_power6)
-	      IFUNC_IMPL_ADD (array, i, wcsrchr, 1,
-			      __wcsrchr_ppc))
-
-  /* Support sysdeps/powerpc/powerpc64/multiarch/wcscpy.c.  */
-  IFUNC_IMPL (i, name, wcscpy,
-	      IFUNC_IMPL_ADD (array, i, wcscpy,
-			      hwcap & PPC_FEATURE_HAS_VSX,
-			      __wcscpy_power7)
-	      IFUNC_IMPL_ADD (array, i, wcscpy,
-			      hwcap & PPC_FEATURE_ARCH_2_05,
-			      __wcscpy_power6)
-	      IFUNC_IMPL_ADD (array, i, wcscpy, 1,
-			      __wcscpy_ppc))
-
-  /* Support sysdeps/powerpc/powerpc64/multiarch/strrchr.c.  */
-  IFUNC_IMPL (i, name, strrchr,
-	      IFUNC_IMPL_ADD (array, i, strrchr,
-			      hwcap2 & PPC_FEATURE2_ARCH_2_07,
-			      __strrchr_power8)
-	      IFUNC_IMPL_ADD (array, i, strrchr,
-			      hwcap & PPC_FEATURE_HAS_VSX,
-			      __strrchr_power7)
-	      IFUNC_IMPL_ADD (array, i, strrchr, 1,
-			      __strrchr_ppc))
-
-  /* Support sysdeps/powerpc/powerpc64/multiarch/strncat.c.  */
-  IFUNC_IMPL (i, name, strncat,
-	      IFUNC_IMPL_ADD (array, i, strncat,
-			      hwcap2 & PPC_FEATURE2_ARCH_2_07,
-			      __strncat_power8)
-	      IFUNC_IMPL_ADD (array, i, strncat,
-			      hwcap & PPC_FEATURE_HAS_VSX,
-			      __strncat_power7)
-	      IFUNC_IMPL_ADD (array, i, strncat, 1,
-			      __strncat_ppc))
-
-  /* Support sysdeps/powerpc/powerpc64/multiarch/strncpy.c.  */
-  IFUNC_IMPL (i, name, strncpy,
-	      IFUNC_IMPL_ADD (array, i, strncpy,
-			      hwcap2 & PPC_FEATURE2_ARCH_2_07,
-			      __strncpy_power8)
-	      IFUNC_IMPL_ADD (array, i, strncpy,
-			      hwcap & PPC_FEATURE_HAS_VSX,
-			      __strncpy_power7)
-	      IFUNC_IMPL_ADD (array, i, strncpy, 1,
-			     __strncpy_ppc))
-
-  /* Support sysdeps/powerpc/powerpc64/multiarch/stpncpy.c.  */
-  IFUNC_IMPL (i, name, stpncpy,
-	      IFUNC_IMPL_ADD (array, i, stpncpy,
-			      hwcap2 & PPC_FEATURE2_ARCH_2_07,
-			      __stpncpy_power8)
-	      IFUNC_IMPL_ADD (array, i, stpncpy,
-			      hwcap & PPC_FEATURE_HAS_VSX,
-			      __stpncpy_power7)
-	      IFUNC_IMPL_ADD (array, i, stpncpy, 1,
-			     __stpncpy_ppc))
-
-  /* Support sysdeps/powerpc/powerpc64/multiarch/strcmp.c.  */
-  IFUNC_IMPL (i, name, strcmp,
-	      IFUNC_IMPL_ADD (array, i, strcmp,
-			      hwcap2 & PPC_FEATURE2_ARCH_3_00,
-			      __strcmp_power9)
-	      IFUNC_IMPL_ADD (array, i, strcmp,
-			      hwcap2 & PPC_FEATURE2_ARCH_2_07,
-			      __strcmp_power8)
-	      IFUNC_IMPL_ADD (array, i, strcmp,
-			      hwcap & PPC_FEATURE_HAS_VSX,
-			      __strcmp_power7)
-	      IFUNC_IMPL_ADD (array, i, strcmp, 1,
-			     __strcmp_ppc))
-
-  /* Support sysdeps/powerpc/powerpc64/multiarch/strcat.c.  */
-  IFUNC_IMPL (i, name, strcat,
-	      IFUNC_IMPL_ADD (array, i, strcat,
-			      hwcap2 & PPC_FEATURE2_ARCH_2_07,
-			      __strcat_power8)
-	      IFUNC_IMPL_ADD (array, i, strcat,
-			      hwcap & PPC_FEATURE_HAS_VSX,
-			      __strcat_power7)
-	      IFUNC_IMPL_ADD (array, i, strcat, 1,
-			     __strcat_ppc))
-
-  /* Support sysdeps/powerpc/powerpc64/multiarch/strspn.c.  */
-  IFUNC_IMPL (i, name, strspn,
-             IFUNC_IMPL_ADD (array, i, strspn,
-                             hwcap2 & PPC_FEATURE2_ARCH_2_07,
-                             __strspn_power8)
-             IFUNC_IMPL_ADD (array, i, strspn, 1,
-                             __strspn_ppc))
-
-  /* Support sysdeps/powerpc/powerpc64/multiarch/strcspn.c.  */
-  IFUNC_IMPL (i, name, strcspn,
-             IFUNC_IMPL_ADD (array, i, strcspn,
-                             hwcap2 & PPC_FEATURE2_ARCH_2_07,
-                             __strcspn_power8)
-             IFUNC_IMPL_ADD (array, i, strcspn, 1,
-                             __strcspn_ppc))
-
-  /* Support sysdeps/powerpc/powerpc64/multiarch/strstr.c.  */
-  IFUNC_IMPL (i, name, strstr,
-             IFUNC_IMPL_ADD (array, i, strstr,
-                             hwcap & PPC_FEATURE_HAS_VSX,
-                             __strstr_power7)
-             IFUNC_IMPL_ADD (array, i, strstr, 1,
-                             __strstr_ppc))
-
-
-  /* Support sysdeps/powerpc/powerpc64/multiarch/strcasestr.c.  */
-  IFUNC_IMPL (i, name, strcasestr,
-	      IFUNC_IMPL_ADD (array, i, strcasestr,
-			      hwcap2 & PPC_FEATURE2_ARCH_2_07,
-			      __strcasestr_power8)
-             IFUNC_IMPL_ADD (array, i, strcasestr, 1,
-                             __strcasestr_ppc))
-
   return i;
 }
diff --git a/sysdeps/powerpc/powerpc64/multiarch/memchr-power7.S b/sysdeps/powerpc/powerpc64/multiarch/memchr-power7.S
deleted file mode 100644
index 33b565f..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/memchr-power7.S
+++ /dev/null
@@ -1,26 +0,0 @@
-/* Optimized memchr implementation for PowerPC64/POWER7.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define MEMCHR __memchr_power7
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-#undef weak_alias
-#define weak_alias(name,alias)
-
-#include <sysdeps/powerpc/powerpc64/power7/memchr.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/memchr-power8.S b/sysdeps/powerpc/powerpc64/multiarch/memchr-power8.S
deleted file mode 100644
index cb1f0fa..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/memchr-power8.S
+++ /dev/null
@@ -1,26 +0,0 @@
-/* Optimized memchr implementation for PowerPC64/POWER8.
-   Copyright (C) 2017-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define MEMCHR __memchr_power8
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-#undef weak_alias
-#define weak_alias(name,alias)
-
-#include <sysdeps/powerpc/powerpc64/power8/memchr.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/memchr-ppc64.c b/sysdeps/powerpc/powerpc64/multiarch/memchr-ppc64.c
deleted file mode 100644
index 48cbe60..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/memchr-ppc64.c
+++ /dev/null
@@ -1,31 +0,0 @@
-/* PowerPC64 default implementation of memchr.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <string.h>
-
-#define MEMCHR  __memchr_ppc
-
-#undef weak_alias
-#define weak_alias(a, b)
-
-# undef libc_hidden_builtin_def
-# define libc_hidden_builtin_def(name)
-
-extern __typeof (memchr) __memchr_ppc attribute_hidden;
-
-#include <string/memchr.c>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/memchr.c b/sysdeps/powerpc/powerpc64/multiarch/memchr.c
deleted file mode 100644
index cd71db9..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/memchr.c
+++ /dev/null
@@ -1,41 +0,0 @@
-/* Multiple versions of memchr.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if IS_IN (libc)
-# include <string.h>
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-extern __typeof (__memchr) __memchr_ppc attribute_hidden;
-extern __typeof (__memchr) __memchr_power7 attribute_hidden;
-extern __typeof (__memchr) __memchr_power8 attribute_hidden;
-
-/* Avoid DWARF definition DIE on ifunc symbol so that GDB can handle
-   ifunc symbol properly.  */
-libc_ifunc (__memchr,
-	    (hwcap2 & PPC_FEATURE2_ARCH_2_07)
-	    ? __memchr_power8 :
-	    (hwcap & PPC_FEATURE_HAS_VSX)
-            ? __memchr_power7
-            : __memchr_ppc);
-
-weak_alias (__memchr, memchr)
-libc_hidden_builtin_def (memchr)
-#else
-#include <string/memchr.c>
-#endif
diff --git a/sysdeps/powerpc/powerpc64/multiarch/memcmp-power4.S b/sysdeps/powerpc/powerpc64/multiarch/memcmp-power4.S
deleted file mode 100644
index 26879a2..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/memcmp-power4.S
+++ /dev/null
@@ -1,26 +0,0 @@
-/* Optimized memcmp implementation for PowerPC64/POWER4.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define MEMCMP __memcmp_power4
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-#undef weak_alias
-#define weak_alias(name,alias)
-
-#include <sysdeps/powerpc/powerpc64/power4/memcmp.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/memcmp-power7.S b/sysdeps/powerpc/powerpc64/multiarch/memcmp-power7.S
deleted file mode 100644
index 9715d11..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/memcmp-power7.S
+++ /dev/null
@@ -1,26 +0,0 @@
-/* Optimized memcmp implementation for PowerPC64/POWER7.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define MEMCMP __memcmp_power7
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-#undef weak_alias
-#define weak_alias(name,alias)
-
-#include <sysdeps/powerpc/powerpc64/power7/memcmp.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/memcmp-power8.S b/sysdeps/powerpc/powerpc64/multiarch/memcmp-power8.S
deleted file mode 100644
index c4da81c..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/memcmp-power8.S
+++ /dev/null
@@ -1,26 +0,0 @@
-/* Optimized memcmp implementation for PowerPC64/POWER8.
-   Copyright (C) 2017-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define MEMCMP __memcmp_power8
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-#undef weak_alias
-#define weak_alias(name,alias)
-
-#include <sysdeps/powerpc/powerpc64/power8/memcmp.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/memcmp-ppc64.c b/sysdeps/powerpc/powerpc64/multiarch/memcmp-ppc64.c
deleted file mode 100644
index 8180ed1..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/memcmp-ppc64.c
+++ /dev/null
@@ -1,33 +0,0 @@
-/* Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <string.h>
-
-#define MEMCMP __memcmp_ppc
-#undef weak_alias
-#define weak_alias(name, aliasname) \
-  extern __typeof (__memcmp_ppc) aliasname \
-    __attribute__ ((weak, alias ("__memcmp_ppc")));
-#if IS_IN (libc) && defined(SHARED)
-# undef libc_hidden_builtin_def
-# define libc_hidden_builtin_def(name) \
-  __hidden_ver1(__memcmp_ppc, __GI_memcmp, __memcmp_ppc);
-#endif
-
-extern __typeof (memcmp) __memcmp_ppc attribute_hidden;
-
-#include <string/memcmp.c>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/memcmp.c b/sysdeps/powerpc/powerpc64/multiarch/memcmp.c
deleted file mode 100644
index 2c7a083..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/memcmp.c
+++ /dev/null
@@ -1,44 +0,0 @@
-/* Multiple versions of memcmp. PowerPC64 version.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-/* Define multiple versions only for definition in libc.  */
-#if IS_IN (libc)
-# define memcmp __redirect_memcmp
-# include <string.h>
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-extern __typeof (memcmp) __memcmp_ppc attribute_hidden;
-extern __typeof (memcmp) __memcmp_power4 attribute_hidden;
-extern __typeof (memcmp) __memcmp_power7 attribute_hidden;
-extern __typeof (memcmp) __memcmp_power8 attribute_hidden;
-# undef memcmp
-
-/* Avoid DWARF definition DIE on ifunc symbol so that GDB can handle
-   ifunc symbol properly.  */
-libc_ifunc_redirected (__redirect_memcmp, memcmp,
-		       (hwcap2 & PPC_FEATURE2_ARCH_2_07)
-		       ? __memcmp_power8 :
-		       (hwcap & PPC_FEATURE_HAS_VSX)
-		       ? __memcmp_power7
-		       : (hwcap & PPC_FEATURE_POWER4)
-			 ? __memcmp_power4
-			 : __memcmp_ppc);
-#else
-#include <string/memcmp.c>
-#endif
diff --git a/sysdeps/powerpc/powerpc64/multiarch/memcpy-a2.S b/sysdeps/powerpc/powerpc64/multiarch/memcpy-a2.S
deleted file mode 100644
index 91eddce..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/memcpy-a2.S
+++ /dev/null
@@ -1,24 +0,0 @@
-/* Optimized memcpy implementation for PowerPC A2.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define MEMCPY __memcpy_a2
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc64/a2/memcpy.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/memcpy-cell.S b/sysdeps/powerpc/powerpc64/multiarch/memcpy-cell.S
deleted file mode 100644
index a93f514..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/memcpy-cell.S
+++ /dev/null
@@ -1,24 +0,0 @@
-/* Optimized memcpy implementation for PowerPC/CELL.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define MEMCPY __memcpy_cell
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc64/cell/memcpy.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/memcpy-power4.S b/sysdeps/powerpc/powerpc64/multiarch/memcpy-power4.S
deleted file mode 100644
index bc68445..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/memcpy-power4.S
+++ /dev/null
@@ -1,24 +0,0 @@
-/* Optimized memcpy implementation for PowerPC64/POWER4.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define MEMCPY __memcpy_power4
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc64/power4/memcpy.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/memcpy-power6.S b/sysdeps/powerpc/powerpc64/multiarch/memcpy-power6.S
deleted file mode 100644
index 9d4c992..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/memcpy-power6.S
+++ /dev/null
@@ -1,24 +0,0 @@
-/* Optimized memcpy implementation for PowerPC/POWER6.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define MEMCPY __memcpy_power6
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc64/power6/memcpy.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/memcpy-power7.S b/sysdeps/powerpc/powerpc64/multiarch/memcpy-power7.S
deleted file mode 100644
index b24452e..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/memcpy-power7.S
+++ /dev/null
@@ -1,24 +0,0 @@
-/* Optimized memcpy implementation for PowerPC/POWER7.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define MEMCPY __memcpy_power7
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc64/power7/memcpy.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/memcpy-power8-cached.S b/sysdeps/powerpc/powerpc64/multiarch/memcpy-power8-cached.S
deleted file mode 100644
index 6b69e57..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/memcpy-power8-cached.S
+++ /dev/null
@@ -1,176 +0,0 @@
-/* Optimized memcpy implementation for cached memory on PowerPC64/POWER8.
-   Copyright (C) 2017-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-
-/* __ptr_t [r3] memcpy (__ptr_t dst [r3], __ptr_t src [r4], size_t len [r5]);
-   Returns 'dst'.  */
-
-	.machine power8
-ENTRY_TOCLESS (__memcpy_power8_cached, 5)
-	CALL_MCOUNT 3
-
-	cmpldi	cr7,r5,15
-	bgt	cr7,L(ge_16)
-	andi.	r9,r5,0x1
-	mr	r9,r3
-	beq	cr0,1f
-	lbz	r10,0(r4)
-	addi	r9,r3,1
-	addi	r4,r4,1
-	stb	r10,0(r3)
-1:
-	andi.	r10,r5,0x2
-	beq	cr0,2f
-	lhz	r10,0(r4)
-	addi	r9,r9,2
-	addi	r4,r4,2
-	sth	r10,-2(r9)
-2:
-	andi.	r10,r5,0x4
-	beq	cr0,3f
-	lwz	r10,0(r4)
-	addi	r9,9,4
-	addi	r4,4,4
-	stw	r10,-4(r9)
-3:
-	andi.	r10,r5,0x8
-	beqlr	cr0
-	ld	r10,0(r4)
-	std	r10,0(r9)
-	blr
-
-	.align 4
-L(ge_16):
-	cmpldi	cr7,r5,32
-	ble	cr7,L(ge_16_le_32)
-	cmpldi	cr7,r5,64
-	ble	cr7,L(gt_32_le_64)
-
-	/* Align dst to 16 bytes.  */
-	andi.	r9,r3,0xf
-	mr	r12,r3
-	beq	cr0,L(dst_is_align_16)
-	lxvd2x	v0,0,r4
-	subfic	r12,r9,16
-	subf	r5,r12,r5
-	add	r4,r4,r12
-	add	r12,r3,r12
-	stxvd2x	v0,0,r3
-L(dst_is_align_16):
-	cmpldi	cr7,r5,127
-	ble	cr7,L(tail_copy)
-	mr	r9,r12
-	srdi	r10,r5,7
-	li	r11,16
-	li	r6,32
-	li	r7,48
-	mtctr	r10
-	clrrdi	r0,r5,7
-
-	/* Main loop, copy 128 bytes each time.  */
-	.align 4
-L(copy_128):
-	lxvd2x	v10,0,r4
-	lxvd2x	v11,r4,r11
-	addi	r8,r4,64
-	addi	r10,r9,64
-	lxvd2x	v12,r4,r6
-	lxvd2x	v0,r4,r7
-	addi	r4,r4,128
-	stxvd2x v10,0,r9
-	stxvd2x v11,r9,r11
-	stxvd2x v12,r9,r6
-	stxvd2x v0,r9,r7
-	addi	r9,r9,128
-	lxvd2x	v10,0,r8
-	lxvd2x	v11,r8,r11
-	lxvd2x	v12,r8,r6
-	lxvd2x	v0,r8,r7
-	stxvd2x v10,0,r10
-	stxvd2x v11,r10,r11
-	stxvd2x v12,r10,r6
-	stxvd2x v0,r10,r7
-	bdnz	L(copy_128)
-
-	add	r12,r12,r0
-	rldicl 	r5,r5,0,57
-L(tail_copy):
-	cmpldi	cr7,r5,63
-	ble	cr7,L(tail_le_64)
-	li	r8,16
-	li	r10,32
-	lxvd2x	v10,0,r4
-	li	r9,48
-	addi	r5,r5,-64
-	lxvd2x	v11,r4,r8
-	lxvd2x	v12,r4,r10
-	lxvd2x	v0,r4,r9
-	addi	r4,r4,64
-	stxvd2x	v10,0,r12
-	stxvd2x	v11,r12,r8
-	stxvd2x	v12,r12,r10
-	stxvd2x	v0,r12,9
-	addi	r12,r12,64
-
-L(tail_le_64):
-	cmpldi	cr7,r5,32
-	bgt	cr7,L(tail_gt_32_le_64)
-	cmpdi	cr7,r5,0
-	beqlr	cr7
-	addi	r5,r5,-32
-	li	r9,16
-	add	r8,r4,r5
-	add	r10,r12,r5
-	lxvd2x	v12,r4,r5
-	lxvd2x	v0,r8,r9
-	stxvd2x	v12,r12,r5
-	stxvd2x	v0,r10,r9
-	blr
-
-	.align 4
-L(ge_16_le_32):
-	addi	r5,r5,-16
-	lxvd2x	v0,0,r4
-	lxvd2x	v1,r4,r5
-	stxvd2x	v0,0,r3
-	stxvd2x	v1,r3,r5
-	blr
-
-	.align 4
-L(gt_32_le_64):
-	mr	r12,r3
-
-	.align 4
-L(tail_gt_32_le_64):
-	li	r9,16
-	lxvd2x	v0,0,r4
-	addi	r5,r5,-32
-	lxvd2x	v1,r4,r9
-	add	r8,r4,r5
-	lxvd2x	v2,r4,r5
-	add	r10,r12,r5
-	lxvd2x	v3,r8,r9
-	stxvd2x	v0,0,r12
-	stxvd2x	v1,r12,r9
-	stxvd2x	v2,r12,r5
-	stxvd2x	v3,r10,r9
-	blr
-
-END_GEN_TB (__memcpy_power8_cached,TB_TOCLESS)
diff --git a/sysdeps/powerpc/powerpc64/multiarch/memcpy-ppc64.S b/sysdeps/powerpc/powerpc64/multiarch/memcpy-ppc64.S
deleted file mode 100644
index 5503667..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/memcpy-ppc64.S
+++ /dev/null
@@ -1,26 +0,0 @@
-/* Default memcpy implementation for PowerPC64.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if defined SHARED && IS_IN (libc)
-# define MEMCPY __memcpy_ppc
-
-# undef libc_hidden_builtin_def
-# define libc_hidden_builtin_def(name)
-#endif
-
-#include <sysdeps/powerpc/powerpc64/memcpy.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/memcpy.c b/sysdeps/powerpc/powerpc64/multiarch/memcpy.c
deleted file mode 100644
index 44dea59..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/memcpy.c
+++ /dev/null
@@ -1,58 +0,0 @@
-/* Multiple versions of memcpy. PowerPC64 version.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-/* Define multiple versions only for the definition in lib and for
-   DSO.  In static binaries we need memcpy before the initialization
-   happened.  */
-#if defined SHARED && IS_IN (libc)
-/* Redefine memcpy so that the compiler won't complain about the type
-   mismatch with the IFUNC selector in strong_alias, below.  */
-# undef memcpy
-# define memcpy __redirect_memcpy
-# include <string.h>
-# include "init-arch.h"
-
-extern __typeof (__redirect_memcpy) __libc_memcpy;
-
-extern __typeof (__redirect_memcpy) __memcpy_ppc attribute_hidden;
-extern __typeof (__redirect_memcpy) __memcpy_power4 attribute_hidden;
-extern __typeof (__redirect_memcpy) __memcpy_cell attribute_hidden;
-extern __typeof (__redirect_memcpy) __memcpy_power6 attribute_hidden;
-extern __typeof (__redirect_memcpy) __memcpy_a2 attribute_hidden;
-extern __typeof (__redirect_memcpy) __memcpy_power7 attribute_hidden;
-extern __typeof (__redirect_memcpy) __memcpy_power8_cached attribute_hidden;
-
-libc_ifunc (__libc_memcpy,
-	    ((hwcap2 & PPC_FEATURE2_ARCH_2_07) && use_cached_memopt)
-	    ? __memcpy_power8_cached :
-	      (hwcap & PPC_FEATURE_HAS_VSX)
-	      ? __memcpy_power7 :
-		(hwcap & PPC_FEATURE_ARCH_2_06)
-		? __memcpy_a2 :
-		  (hwcap & PPC_FEATURE_ARCH_2_05)
-		  ? __memcpy_power6 :
-		    (hwcap & PPC_FEATURE_CELL_BE)
-		    ? __memcpy_cell :
-		      (hwcap & PPC_FEATURE_POWER4)
-		      ? __memcpy_power4
-            : __memcpy_ppc);
-
-#undef memcpy
-strong_alias (__libc_memcpy, memcpy);
-libc_hidden_ver (__libc_memcpy, memcpy);
-#endif
diff --git a/sysdeps/powerpc/powerpc64/multiarch/memmove-power7.S b/sysdeps/powerpc/powerpc64/multiarch/memmove-power7.S
deleted file mode 100644
index 0b251d0..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/memmove-power7.S
+++ /dev/null
@@ -1,27 +0,0 @@
-/* Optimized memmove implementation for PowerPC64/POWER7.
-   Copyright (C) 2014-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define MEMMOVE __memmove_power7
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#undef bcopy
-#define bcopy __bcopy_power7
-
-#include <sysdeps/powerpc/powerpc64/power7/memmove.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/memmove-ppc64.c b/sysdeps/powerpc/powerpc64/multiarch/memmove-ppc64.c
deleted file mode 100644
index a185190..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/memmove-ppc64.c
+++ /dev/null
@@ -1,44 +0,0 @@
-/* Copyright (C) 2014-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <string.h>
-#include <memcopy.h>
-
-extern __typeof (_wordcopy_fwd_aligned) _wordcopy_fwd_aligned_ppc;
-extern __typeof (_wordcopy_fwd_dest_aligned) _wordcopy_fwd_dest_aligned_ppc;
-extern __typeof (_wordcopy_bwd_aligned) _wordcopy_bwd_aligned_ppc;
-extern __typeof (_wordcopy_bwd_dest_aligned) _wordcopy_bwd_dest_aligned_ppc;
-
-#define _wordcopy_fwd_aligned       _wordcopy_fwd_aligned_ppc
-#define _wordcopy_fwd_dest_aligned  _wordcopy_fwd_dest_aligned_ppc
-#define _wordcopy_bwd_aligned       _wordcopy_bwd_aligned_ppc
-#define _wordcopy_bwd_dest_aligned  _wordcopy_bwd_dest_aligned_ppc
-
-extern __typeof (memmove) __memmove_ppc attribute_hidden;
-#define MEMMOVE __memmove_ppc
-
-extern __typeof (memcpy) __memcpy_ppc attribute_hidden;
-#ifdef SHARED
-# define memcpy __memcpy_ppc
-#endif
-
-#if IS_IN (libc) && defined(SHARED)
-# undef libc_hidden_builtin_def
-# define libc_hidden_builtin_def(name)
-#endif
-
-#include <string/memmove.c>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/memmove.c b/sysdeps/powerpc/powerpc64/multiarch/memmove.c
deleted file mode 100644
index 3998715..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/memmove.c
+++ /dev/null
@@ -1,45 +0,0 @@
-/* Multiple versions of memmove. PowerPC64 version.
-   Copyright (C) 2014-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-/* Define multiple versions only for the definition in lib and for
-   DSO.  In static binaries we need memmove before the initialization
-   happened.  */
-#if defined SHARED && IS_IN (libc)
-/* Redefine memmove so that the compiler won't complain about the type
-   mismatch with the IFUNC selector in strong_alias, below.  */
-# undef memmove
-# define memmove __redirect_memmove
-# include <string.h>
-# include "init-arch.h"
-
-extern __typeof (__redirect_memmove) __libc_memmove;
-
-extern __typeof (__redirect_memmove) __memmove_ppc attribute_hidden;
-extern __typeof (__redirect_memmove) __memmove_power7 attribute_hidden;
-
-libc_ifunc (__libc_memmove,
-            (hwcap & PPC_FEATURE_HAS_VSX)
-            ? __memmove_power7
-            : __memmove_ppc);
-
-#undef memmove
-strong_alias (__libc_memmove, memmove);
-libc_hidden_ver (__libc_memmove, memmove);
-#else
-# include <string/memmove.c>
-#endif
diff --git a/sysdeps/powerpc/powerpc64/multiarch/mempcpy-power7.S b/sysdeps/powerpc/powerpc64/multiarch/mempcpy-power7.S
deleted file mode 100644
index bee44f0..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/mempcpy-power7.S
+++ /dev/null
@@ -1,26 +0,0 @@
-/* Optimized mempcpy implementation for PowerPC/POWER7.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define MEMPCPY __mempcpy_power7
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-#undef weak_alias
-#define weak_alias(name, alias)
-
-#include <sysdeps/powerpc/powerpc64/power7/mempcpy.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/mempcpy-ppc64.c b/sysdeps/powerpc/powerpc64/multiarch/mempcpy-ppc64.c
deleted file mode 100644
index a03748e..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/mempcpy-ppc64.c
+++ /dev/null
@@ -1,19 +0,0 @@
-/* PowerPC64 default implementation of mempcpy.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdeps/powerpc/powerpc32/power4/multiarch/mempcpy-ppc32.c>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/mempcpy.c b/sysdeps/powerpc/powerpc64/multiarch/mempcpy.c
deleted file mode 100644
index 35e2368..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/mempcpy.c
+++ /dev/null
@@ -1,43 +0,0 @@
-/* Multiple versions of mempcpy.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if IS_IN (libc)
-# define mempcpy __redirect_mempcpy
-# define __mempcpy __redirect___mempcpy
-# define NO_MEMPCPY_STPCPY_REDIRECT
-# define __NO_STRING_INLINES
-# include <string.h>
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-extern __typeof (__mempcpy) __mempcpy_ppc attribute_hidden;
-extern __typeof (__mempcpy) __mempcpy_power7 attribute_hidden;
-# undef mempcpy
-# undef __mempcpy
-
-/* Avoid DWARF definition DIE on ifunc symbol so that GDB can handle
-   ifunc symbol properly.  */
-libc_ifunc_redirected (__redirect___mempcpy, __mempcpy,
-		       (hwcap & PPC_FEATURE_HAS_VSX)
-		       ? __mempcpy_power7
-		       : __mempcpy_ppc);
-
-weak_alias (__mempcpy, mempcpy)
-#else
-# include <string/mempcpy.c>
-#endif
diff --git a/sysdeps/powerpc/powerpc64/multiarch/memrchr-power7.S b/sysdeps/powerpc/powerpc64/multiarch/memrchr-power7.S
deleted file mode 100644
index afaae46..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/memrchr-power7.S
+++ /dev/null
@@ -1,26 +0,0 @@
-/* Optimized memrchr implementation for PowerPC64/POWER7.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define MEMRCHR __memrchr_power7
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-#undef weak_alias
-#define weak_alias(name,alias)
-
-#include <sysdeps/powerpc/powerpc64/power7/memrchr.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/memrchr-power8.S b/sysdeps/powerpc/powerpc64/multiarch/memrchr-power8.S
deleted file mode 100644
index 453e2b6..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/memrchr-power8.S
+++ /dev/null
@@ -1,26 +0,0 @@
-/* Optimized memrchr implementation for PowerPC64/POWER8.
-   Copyright (C) 2017-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define MEMRCHR __memrchr_power8
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-#undef weak_alias
-#define weak_alias(name,alias)
-
-#include <sysdeps/powerpc/powerpc64/power8/memrchr.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/memrchr-ppc64.c b/sysdeps/powerpc/powerpc64/multiarch/memrchr-ppc64.c
deleted file mode 100644
index e6d60c3..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/memrchr-ppc64.c
+++ /dev/null
@@ -1,18 +0,0 @@
-/* PowerPC64 default implementation of memrchr.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-#include <sysdeps/powerpc/powerpc32/power4/multiarch/memrchr-ppc32.c>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/memrchr.c b/sysdeps/powerpc/powerpc64/multiarch/memrchr.c
deleted file mode 100644
index 48be951..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/memrchr.c
+++ /dev/null
@@ -1,40 +0,0 @@
-/* Multiple versions of memrchr.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if IS_IN (libc)
-# include <string.h>
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-extern __typeof (__memrchr) __memrchr_ppc attribute_hidden;
-extern __typeof (__memrchr) __memrchr_power7 attribute_hidden;
-extern __typeof (__memrchr) __memrchr_power8 attribute_hidden;
-
-/* Avoid DWARF definition DIE on ifunc symbol so that GDB can handle
-   ifunc symbol properly.  */
-libc_ifunc (__memrchr,
-	    (hwcap2 & PPC_FEATURE2_ARCH_2_07)
-	    ? __memrchr_power8 :
-	      (hwcap & PPC_FEATURE_HAS_VSX)
-	      ? __memrchr_power7
-	    : __memrchr_ppc);
-
-weak_alias (__memrchr, memrchr)
-#else
-#include <string/memrchr.c>
-#endif
diff --git a/sysdeps/powerpc/powerpc64/multiarch/memset-power4.S b/sysdeps/powerpc/powerpc64/multiarch/memset-power4.S
deleted file mode 100644
index 78d6de9..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/memset-power4.S
+++ /dev/null
@@ -1,27 +0,0 @@
-/* Optimized memset implementation for PowerPC64/POWER4.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define MEMSET __memset_power4
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#undef __bzero
-#define __bzero __bzero_power4
-
-#include <sysdeps/powerpc/powerpc64/power4/memset.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/memset-power6.S b/sysdeps/powerpc/powerpc64/multiarch/memset-power6.S
deleted file mode 100644
index 79d93c7..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/memset-power6.S
+++ /dev/null
@@ -1,27 +0,0 @@
-/* Optimized memset implementation for PowerPC64/POWER6.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define MEMSET __memset_power6
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#undef __bzero
-#define __bzero __bzero_power6
-
-#include <sysdeps/powerpc/powerpc64/power6/memset.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/memset-power7.S b/sysdeps/powerpc/powerpc64/multiarch/memset-power7.S
deleted file mode 100644
index 02d1855..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/memset-power7.S
+++ /dev/null
@@ -1,26 +0,0 @@
-/* Optimized memset implementation for PowerPC64/POWER7.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define MEMSET __memset_power7
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#undef __bzero
-#define __bzero __bzero_power7
-#include <sysdeps/powerpc/powerpc64/power7/memset.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/memset-power8.S b/sysdeps/powerpc/powerpc64/multiarch/memset-power8.S
deleted file mode 100644
index 932eeef..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/memset-power8.S
+++ /dev/null
@@ -1,27 +0,0 @@
-/* Optimized memset implementation for PowerPC64/POWER8.
-   Copyright (C) 2014-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define MEMSET __memset_power8
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#undef __bzero
-#define __bzero __bzero_power8
-
-#include <sysdeps/powerpc/powerpc64/power8/memset.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/memset-ppc64.S b/sysdeps/powerpc/powerpc64/multiarch/memset-ppc64.S
deleted file mode 100644
index 61f4bc5..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/memset-ppc64.S
+++ /dev/null
@@ -1,42 +0,0 @@
-/* Default memset/bzero implementation for PowerPC64.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* Copied from bzero.S to prevent the linker from inserting a stub
-   between bzero and memset.  NOTE: this code should be positioned
-   before ENTRY/END_GEN_TB redefinition.  */
-ENTRY (__bzero_ppc)
-        CALL_MCOUNT 3
-        mr      r5,r4
-        li      r4,0
-        b       L(_memset)
-END_GEN_TB (__bzero_ppc,TB_TOCLESS)
-
-
-#if defined SHARED && IS_IN (libc)
-# define MEMSET __memset_ppc
-
-# undef libc_hidden_builtin_def
-# define libc_hidden_builtin_def(name)
-#endif
-
-/* Do not implement __bzero at powerpc64/memset.S.  */
-#define NO_BZERO_IMPL
-
-#include <sysdeps/powerpc/powerpc64/memset.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/memset.c b/sysdeps/powerpc/powerpc64/multiarch/memset.c
deleted file mode 100644
index 1a7c46f..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/memset.c
+++ /dev/null
@@ -1,53 +0,0 @@
-/* Multiple versions of memset.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-/* Define multiple versions only for definition in libc.  */
-#if defined SHARED && IS_IN (libc)
-/* Redefine memset so that the compiler won't complain about the type
-   mismatch with the IFUNC selector in strong_alias, below.  */
-# undef memset
-# define memset __redirect_memset
-# include <string.h>
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-extern __typeof (__redirect_memset) __libc_memset;
-
-extern __typeof (__redirect_memset) __memset_ppc attribute_hidden;
-extern __typeof (__redirect_memset) __memset_power4 attribute_hidden;
-extern __typeof (__redirect_memset) __memset_power6 attribute_hidden;
-extern __typeof (__redirect_memset) __memset_power7 attribute_hidden;
-extern __typeof (__redirect_memset) __memset_power8 attribute_hidden;
-
-/* Avoid DWARF definition DIE on ifunc symbol so that GDB can handle
-   ifunc symbol properly.  */
-libc_ifunc (__libc_memset,
-            (hwcap2 & PPC_FEATURE2_ARCH_2_07)
-            ? __memset_power8 :
-	      (hwcap & PPC_FEATURE_HAS_VSX)
-	      ? __memset_power7 :
-		(hwcap & PPC_FEATURE_ARCH_2_05)
-		? __memset_power6 :
-		  (hwcap & PPC_FEATURE_POWER4)
-		  ? __memset_power4
-            : __memset_ppc);
-
-#undef memset
-strong_alias (__libc_memset, memset);
-libc_hidden_ver (__libc_memset, memset);
-#endif
diff --git a/sysdeps/powerpc/powerpc64/multiarch/rawmemchr-power7.S b/sysdeps/powerpc/powerpc64/multiarch/rawmemchr-power7.S
deleted file mode 100644
index a268376..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/rawmemchr-power7.S
+++ /dev/null
@@ -1,21 +0,0 @@
-/* Optimized rawmemchr implementation for PowerPC64/POWER7.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define RAWMEMCHR __rawmemchr_power7
-
-#include <sysdeps/powerpc/powerpc64/power7/rawmemchr.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/rawmemchr-ppc64.c b/sysdeps/powerpc/powerpc64/multiarch/rawmemchr-ppc64.c
deleted file mode 100644
index e5daa92..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/rawmemchr-ppc64.c
+++ /dev/null
@@ -1,19 +0,0 @@
-/* PowerPC64 default implementation of rawmemchr.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdeps/powerpc/powerpc32/power4/multiarch/rawmemchr-ppc32.c>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/rawmemchr.c b/sysdeps/powerpc/powerpc64/multiarch/rawmemchr.c
deleted file mode 100644
index 02bac49..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/rawmemchr.c
+++ /dev/null
@@ -1,39 +0,0 @@
-/* Multiple versions of rawmemchr.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if IS_IN (libc)
-# define __rawmemchr __redirect___rawmemchr
-# include <string.h>
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-extern __typeof (__rawmemchr) __rawmemchr_ppc attribute_hidden;
-extern __typeof (__rawmemchr) __rawmemchr_power7 attribute_hidden;
-# undef __rawmemchr
-
-/* Avoid DWARF definition DIE on ifunc symbol so that GDB can handle
-   ifunc symbol properly.  */
-libc_ifunc_redirected (__redirect___rawmemchr, __rawmemchr,
-		       (hwcap & PPC_FEATURE_HAS_VSX)
-		       ? __rawmemchr_power7
-		       : __rawmemchr_ppc);
-
-weak_alias (__rawmemchr, rawmemchr)
-#else
-#include <string/rawmemchr.c>
-#endif
diff --git a/sysdeps/powerpc/powerpc64/multiarch/rtld-memset.c b/sysdeps/powerpc/powerpc64/multiarch/rtld-memset.c
deleted file mode 100644
index 611eff4..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/rtld-memset.c
+++ /dev/null
@@ -1,18 +0,0 @@
-/* Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdeps/powerpc/powerpc64/rtld-memset.c>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/rtld-strchr.S b/sysdeps/powerpc/powerpc64/multiarch/rtld-strchr.S
deleted file mode 100644
index 9ec081a..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/rtld-strchr.S
+++ /dev/null
@@ -1,18 +0,0 @@
-/* Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdeps/powerpc/powerpc64/strchr.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strcasecmp-power7.S b/sysdeps/powerpc/powerpc64/multiarch/strcasecmp-power7.S
deleted file mode 100644
index bec2f30..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strcasecmp-power7.S
+++ /dev/null
@@ -1,26 +0,0 @@
-/* Optimized strcasecmp implementation for POWER7.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define __strcasecmp __strcasecmp_power7
-#undef weak_alias
-#define weak_alias(name, alias)
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc64/power7/strcasecmp.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strcasecmp-power8.S b/sysdeps/powerpc/powerpc64/multiarch/strcasecmp-power8.S
deleted file mode 100644
index 29453ff..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strcasecmp-power8.S
+++ /dev/null
@@ -1,26 +0,0 @@
-/* Optimized strcasecmp implementation for POWER8.
-   Copyright (C) 2016-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define __strcasecmp __strcasecmp_power8
-#undef weak_alias
-#define weak_alias(name, alias)
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc64/power8/strcasecmp.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strcasecmp-ppc64.c b/sysdeps/powerpc/powerpc64/multiarch/strcasecmp-ppc64.c
deleted file mode 100644
index b477255..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strcasecmp-ppc64.c
+++ /dev/null
@@ -1,21 +0,0 @@
-/* Multiarch strcasecmp for PPC64.
-   Copyright (C) 2016-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define strcasecmp __strcasecmp_ppc
-
-#include <string/strcasecmp.c>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strcasecmp.c b/sysdeps/powerpc/powerpc64/multiarch/strcasecmp.c
deleted file mode 100644
index 1a6661e..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strcasecmp.c
+++ /dev/null
@@ -1,36 +0,0 @@
-/* Multiple versions of strcasecmp
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <string.h>
-#include <shlib-compat.h>
-#include "init-arch.h"
-
-extern __typeof (__strcasecmp) __libc_strcasecmp;
-
-extern __typeof (__strcasecmp) __strcasecmp_ppc attribute_hidden;
-extern __typeof (__strcasecmp) __strcasecmp_power7 attribute_hidden;
-extern __typeof (__strcasecmp) __strcasecmp_power8 attribute_hidden;
-
-libc_ifunc (__libc_strcasecmp,
-	     (hwcap2 & PPC_FEATURE2_ARCH_2_07)
-             ? __strcasecmp_power8:
-	     (hwcap & PPC_FEATURE_HAS_VSX)
-             ? __strcasecmp_power7
-             : __strcasecmp_ppc);
-
-weak_alias (__libc_strcasecmp, strcasecmp)
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strcasecmp_l-power7.S b/sysdeps/powerpc/powerpc64/multiarch/strcasecmp_l-power7.S
deleted file mode 100644
index 07e7169..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strcasecmp_l-power7.S
+++ /dev/null
@@ -1,31 +0,0 @@
-/* Optimized strcasecmp_l implementation for POWER7.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define __strcasecmp_l __strcasecmp_l_power7
-
-#undef weak_alias
-#define weak_alias(name, alias)
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#define USE_IN_EXTENDED_LOCALE_MODEL
-#define __STRCMP __strcasecmp_l
-#define STRCMP   strcasecmp_l
-
-#include <sysdeps/powerpc/powerpc64/power7/strcasecmp.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strcasecmp_l.c b/sysdeps/powerpc/powerpc64/multiarch/strcasecmp_l.c
deleted file mode 100644
index 3edccc4..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strcasecmp_l.c
+++ /dev/null
@@ -1,40 +0,0 @@
-/* Multiple versions of strcasecmp_l.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if IS_IN (libc)
-# include <string.h>
-# define strcasecmp_l __strcasecmp_l_ppc
-extern __typeof (__strcasecmp_l) __strcasecmp_l_ppc attribute_hidden;
-extern __typeof (__strcasecmp_l) __strcasecmp_l_power7 attribute_hidden;
-#endif
-
-#include <string/strcasecmp_l.c>
-#undef strcasecmp_l
-
-#if IS_IN (libc)
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-extern __typeof (__strcasecmp_l) __libc_strcasecmp_l;
-libc_ifunc (__libc_strcasecmp_l,
-	    (hwcap & PPC_FEATURE_HAS_VSX)
-            ? __strcasecmp_l_power7
-            : __strcasecmp_l_ppc);
-
-weak_alias (__libc_strcasecmp_l, strcasecmp_l)
-#endif
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strcasestr-power8.S b/sysdeps/powerpc/powerpc64/multiarch/strcasestr-power8.S
deleted file mode 100644
index 985f4e4..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strcasestr-power8.S
+++ /dev/null
@@ -1,33 +0,0 @@
-/* Optimized strcasestr implementation for POWER8.
-   Copyright (C) 2016-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define STRCASESTR __strcasestr_power8
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-/* The following definitions are used in strcasestr optimization.  */
-
-/* strlen is used to calculate len of r4.  */
-#define STRLEN __strlen_power8
-/* strnlen is used to check if len of r3 is more than r4.  */
-#define STRNLEN __strnlen_power8
-/* strchr is used to check if first char of r4 is present in r3.  */
-#define STRCHR __strchr_power8
-
-#include <sysdeps/powerpc/powerpc64/power8/strcasestr.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strcasestr-ppc64.c b/sysdeps/powerpc/powerpc64/multiarch/strcasestr-ppc64.c
deleted file mode 100644
index 0805b6f..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strcasestr-ppc64.c
+++ /dev/null
@@ -1,34 +0,0 @@
-/* PowerPC64 default implementation of strcasestr.
-   Copyright (C) 2016-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <string.h>
-
-#define STRCASESTR  __strcasestr_ppc
-#if IS_IN (libc) && defined(SHARED)
-# undef libc_hidden_builtin_def
-# define libc_hidden_builtin_def(name) \
-  __hidden_ver1(__strcasestr_ppc, __GI_strcasestr, __strcasestr_ppc);
-#endif
-
-
-#undef weak_alias
-#define weak_alias(a,b)
-
-extern __typeof (strcasestr) __strcasestr_ppc attribute_hidden;
-
-#include <string/strcasestr.c>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strcasestr.c b/sysdeps/powerpc/powerpc64/multiarch/strcasestr.c
deleted file mode 100644
index dc46bfd..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strcasestr.c
+++ /dev/null
@@ -1,37 +0,0 @@
-/* Multiple versions of strcasestr.
-   Copyright (C) 2016-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if IS_IN (libc)
-# include <string.h>
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-extern __typeof (__strcasestr) __strcasestr_ppc attribute_hidden;
-extern __typeof (__strcasestr) __strcasestr_power8 attribute_hidden;
-
-/* Avoid DWARF definition DIE on ifunc symbol so that GDB can handle
-   ifunc symbol properly.  */
-libc_ifunc (__strcasestr,
-		(hwcap2 & PPC_FEATURE2_ARCH_2_07)
-		? __strcasestr_power8
-		: __strcasestr_ppc);
-
-weak_alias (__strcasestr, strcasestr)
-#else
-#include <string/strcasestr.c>
-#endif
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strcat-power7.c b/sysdeps/powerpc/powerpc64/multiarch/strcat-power7.c
deleted file mode 100644
index 3196682..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strcat-power7.c
+++ /dev/null
@@ -1,30 +0,0 @@
-/* Copyright (C) 2014-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/ >.  */
-
-#include <string.h>
-
-#define STRCAT __strcat_power7
-
-#undef libc_hidden_def
-#define libc_hidden_def(name)
-
-extern typeof (strcpy) __strcpy_power7;
-extern typeof (strlen) __strlen_power7;
-
-#define strcpy __strcpy_power7
-#define strlen __strlen_power7
-#include <string/strcat.c>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strcat-power8.c b/sysdeps/powerpc/powerpc64/multiarch/strcat-power8.c
deleted file mode 100644
index 996a3b6..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strcat-power8.c
+++ /dev/null
@@ -1,30 +0,0 @@
-/* Copyright (C) 2015-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/ >.  */
-
-#include <string.h>
-
-#define STRCAT __strcat_power8
-
-#undef libc_hidden_def
-#define libc_hidden_def(name)
-
-extern typeof (strcpy) __strcpy_power8;
-extern typeof (strlen) __strlen_power8;
-
-#define strcpy __strcpy_power8
-#define strlen __strlen_power8
-#include <string/strcat.c>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strcat-ppc64.c b/sysdeps/powerpc/powerpc64/multiarch/strcat-ppc64.c
deleted file mode 100644
index fc3ef2a..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strcat-ppc64.c
+++ /dev/null
@@ -1,29 +0,0 @@
-/* Copyright (C) 2014-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/ >.  */
-
-#include <string.h>
-
-#define STRCAT __strcat_ppc
-#ifdef SHARED
-# undef libc_hidden_builtin_def
-# define libc_hidden_builtin_def(name) \
-  __hidden_ver1 (__strcat_ppc, __GI_strcat, __strcat_ppc);
-#endif
-
-extern __typeof (strcat) __strcat_ppc attribute_hidden;
-
-#include <string/strcat.c>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strcat.c b/sysdeps/powerpc/powerpc64/multiarch/strcat.c
deleted file mode 100644
index 48035ed..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strcat.c
+++ /dev/null
@@ -1,36 +0,0 @@
-/* Multiple versions of strcat. PowerPC64 version.
-   Copyright (C) 2014-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if IS_IN (libc)
-# define strcat __redirect_strcat
-# include <string.h>
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-extern __typeof (strcat) __strcat_ppc attribute_hidden;
-extern __typeof (strcat) __strcat_power7 attribute_hidden;
-extern __typeof (strcat) __strcat_power8 attribute_hidden;
-# undef strcat
-
-libc_ifunc_redirected (__redirect_strcat, strcat,
-		       (hwcap2 & PPC_FEATURE2_ARCH_2_07)
-		       ? __strcat_power8
-		       : (hwcap & PPC_FEATURE_HAS_VSX)
-			 ? __strcat_power7
-			 : __strcat_ppc);
-#endif
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strchr-power7.S b/sysdeps/powerpc/powerpc64/multiarch/strchr-power7.S
deleted file mode 100644
index f91b809..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strchr-power7.S
+++ /dev/null
@@ -1,24 +0,0 @@
-/* Optimized strchr implementation for POWER7.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define STRCHR __strchr_power7
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc64/power7/strchr.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strchr-power8.S b/sysdeps/powerpc/powerpc64/multiarch/strchr-power8.S
deleted file mode 100644
index 16a484d..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strchr-power8.S
+++ /dev/null
@@ -1,24 +0,0 @@
-/* Optimized strchr implementation for POWER8.
-   Copyright (C) 2016-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define STRCHR __strchr_power8
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc64/power8/strchr.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strchr-ppc64.S b/sysdeps/powerpc/powerpc64/multiarch/strchr-ppc64.S
deleted file mode 100644
index cdbb9c1..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strchr-ppc64.S
+++ /dev/null
@@ -1,27 +0,0 @@
-/* PowerPC64 default implementation of strchr.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#ifdef SHARED
-# define STRCHR __strchr_ppc
-
-# undef libc_hidden_builtin_def
-# define libc_hidden_builtin_def(name)				\
-    .globl __GI_strchr; __GI_strchr = __strchr_ppc
-#endif
-
-#include <sysdeps/powerpc/powerpc64/strchr.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strchr.c b/sysdeps/powerpc/powerpc64/multiarch/strchr.c
deleted file mode 100644
index 6528469..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strchr.c
+++ /dev/null
@@ -1,42 +0,0 @@
-/* Multiple versions of strchr.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-/* Define multiple versions only for definition in libc.  */
-#if defined SHARED && IS_IN (libc)
-# define strchr __redirect_strchr
-/* Omit the strchr inline definitions because it would redefine strchr.  */
-# define __NO_STRING_INLINES
-# include <string.h>
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-extern __typeof (strchr) __strchr_ppc attribute_hidden;
-extern __typeof (strchr) __strchr_power7 attribute_hidden;
-extern __typeof (strchr) __strchr_power8 attribute_hidden;
-# undef strchr
-
-/* Avoid DWARF definition DIE on ifunc symbol so that GDB can handle
-   ifunc symbol properly.  */
-libc_ifunc_redirected (__redirect_strchr, strchr,
-		       (hwcap2 & PPC_FEATURE2_ARCH_2_07)
-		       ? __strchr_power8 :
-		       (hwcap & PPC_FEATURE_HAS_VSX)
-		       ? __strchr_power7
-		       : __strchr_ppc);
-weak_alias (strchr, index)
-#endif
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strchrnul-power7.S b/sysdeps/powerpc/powerpc64/multiarch/strchrnul-power7.S
deleted file mode 100644
index fee1409..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strchrnul-power7.S
+++ /dev/null
@@ -1,24 +0,0 @@
-/* Optimized strchrnul implementation for POWER7.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define STRCHRNUL __strchrnul_power7
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc64/power7/strchrnul.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strchrnul-power8.S b/sysdeps/powerpc/powerpc64/multiarch/strchrnul-power8.S
deleted file mode 100644
index e17e918..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strchrnul-power8.S
+++ /dev/null
@@ -1,24 +0,0 @@
-/* Optimized strchrnul implementation for POWER8.
-   Copyright (C) 2016-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define STRCHRNUL __strchrnul_power8
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc64/power8/strchrnul.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strchrnul-ppc64.c b/sysdeps/powerpc/powerpc64/multiarch/strchrnul-ppc64.c
deleted file mode 100644
index 59c6bc3..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strchrnul-ppc64.c
+++ /dev/null
@@ -1,19 +0,0 @@
-/* PowerPC64 default implementation of strchrnul.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdeps/powerpc/powerpc32/power4/multiarch/strchrnul-ppc32.c>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strchrnul.c b/sysdeps/powerpc/powerpc64/multiarch/strchrnul.c
deleted file mode 100644
index ead31f7..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strchrnul.c
+++ /dev/null
@@ -1,40 +0,0 @@
-/* Multiple versions of strchrnul.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if IS_IN (libc)
-# include <string.h>
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-extern __typeof (__strchrnul) __strchrnul_ppc attribute_hidden;
-extern __typeof (__strchrnul) __strchrnul_power7 attribute_hidden;
-extern __typeof (__strchrnul) __strchrnul_power8 attribute_hidden;
-
-/* Avoid DWARF definition DIE on ifunc symbol so that GDB can handle
-   ifunc symbol properly.  */
-libc_ifunc (__strchrnul,
-	    (hwcap2 & PPC_FEATURE2_ARCH_2_07)
-	    ? __strchrnul_power8 :
-	    (hwcap & PPC_FEATURE_HAS_VSX)
-            ? __strchrnul_power7
-            : __strchrnul_ppc);
-
-weak_alias (__strchrnul, strchrnul)
-#else
-#include <string/strchrnul.c>
-#endif
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strcmp-power7.S b/sysdeps/powerpc/powerpc64/multiarch/strcmp-power7.S
deleted file mode 100644
index 814d472..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strcmp-power7.S
+++ /dev/null
@@ -1,24 +0,0 @@
-/* Optimized strcmp implementation for POWER7.
-   Copyright (C) 2014-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define STRCMP __strcmp_power7
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc64/power7/strcmp.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strcmp-power8.S b/sysdeps/powerpc/powerpc64/multiarch/strcmp-power8.S
deleted file mode 100644
index 68803ff..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strcmp-power8.S
+++ /dev/null
@@ -1,26 +0,0 @@
-/* Optimized strcmp implementation for POWER8/PPC64.
-   Copyright (C) 2015-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if IS_IN (libc)
-#define STRCMP __strcmp_power8
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc64/power8/strcmp.S>
-#endif
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strcmp-power9.S b/sysdeps/powerpc/powerpc64/multiarch/strcmp-power9.S
deleted file mode 100644
index 8b569d3..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strcmp-power9.S
+++ /dev/null
@@ -1,26 +0,0 @@
-/* Optimized strcmp implementation for POWER9/PPC64.
-   Copyright (C) 2016-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if IS_IN (libc)
-#define STRCMP __strcmp_power9
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc64/power9/strcmp.S>
-#endif
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strcmp-ppc64.S b/sysdeps/powerpc/powerpc64/multiarch/strcmp-ppc64.S
deleted file mode 100644
index 43e1c6f..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strcmp-ppc64.S
+++ /dev/null
@@ -1,27 +0,0 @@
-/* Default strcmp implementation for PowerPC64.
-   Copyright (C) 2014-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if defined SHARED && IS_IN (libc)
-# define STRCMP __strcmp_ppc
-
-# undef libc_hidden_builtin_def
-# define libc_hidden_builtin_def(name)				\
-    .globl __GI_strcmp; __GI_strcmp = __strcmp_ppc
-#endif /* SHARED && IS_IN  */
-
-#include <sysdeps/powerpc/powerpc64/strcmp.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strcmp.c b/sysdeps/powerpc/powerpc64/multiarch/strcmp.c
deleted file mode 100644
index b669053..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strcmp.c
+++ /dev/null
@@ -1,42 +0,0 @@
-/* Multiple versions of strcmp. PowerPC64 version.
-   Copyright (C) 2014-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if defined SHARED && IS_IN (libc)
-# define strcmp __redirect_strcmp
-/* Omit the strcmp inline definitions because it would redefine strcmp.  */
-# define __NO_STRING_INLINES
-# include <string.h>
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-extern __typeof (strcmp) __strcmp_ppc attribute_hidden;
-extern __typeof (strcmp) __strcmp_power7 attribute_hidden;
-extern __typeof (strcmp) __strcmp_power8 attribute_hidden;
-extern __typeof (strcmp) __strcmp_power9 attribute_hidden;
-
-# undef strcmp
-
-libc_ifunc_redirected (__redirect_strcmp, strcmp,
-			(hwcap2 & PPC_FEATURE2_ARCH_3_00)
-			? __strcmp_power9 :
-		       (hwcap2 & PPC_FEATURE2_ARCH_2_07)
-		       ? __strcmp_power8
-		       : (hwcap & PPC_FEATURE_HAS_VSX)
-			 ? __strcmp_power7
-			 : __strcmp_ppc);
-#endif
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strcpy-power7.c b/sysdeps/powerpc/powerpc64/multiarch/strcpy-power7.c
deleted file mode 100644
index 0a71951..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strcpy-power7.c
+++ /dev/null
@@ -1,32 +0,0 @@
-/* Multiarch strcpy for POWER7/PPC64.
-   Copyright (C) 2015-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <string.h>
-
-extern __typeof (memcpy) __memcpy_power7 attribute_hidden;
-extern __typeof (strlen) __strlen_power7 attribute_hidden;
-extern __typeof (strcpy) __strcpy_power7 attribute_hidden;
-
-#define STRCPY __strcpy_power7
-#define memcpy __memcpy_power7
-#define strlen __strlen_power7
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <string/strcpy.c>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strcpy-power8.S b/sysdeps/powerpc/powerpc64/multiarch/strcpy-power8.S
deleted file mode 100644
index 5b68fc9..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strcpy-power8.S
+++ /dev/null
@@ -1,24 +0,0 @@
-/* Optimized strcpy implementation for POWER8/PPC64.
-   Copyright (C) 2015-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define STRCPY __strcpy_power8
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc64/power8/strcpy.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strcpy-ppc64.c b/sysdeps/powerpc/powerpc64/multiarch/strcpy-ppc64.c
deleted file mode 100644
index 2283197..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strcpy-ppc64.c
+++ /dev/null
@@ -1,35 +0,0 @@
-/* Multiarch strcpy for PPC64.
-   Copyright (C) 2015-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <string.h>
-
-#if defined SHARED && IS_IN (libc)
-extern __typeof (memcpy) __memcpy_ppc attribute_hidden;
-extern __typeof (strlen) __strlen_ppc attribute_hidden;
-extern __typeof (strcpy) __strcpy_ppc attribute_hidden;
-
-# define STRCPY __strcpy_ppc
-# define memcpy __memcpy_ppc
-# define strlen __strlen_ppc
-
-# undef libc_hidden_builtin_def
-# define libc_hidden_builtin_def(name) \
-  __hidden_ver1 (__strcpy_ppc, __GI_strcpy, __strcpy_ppc);
-#endif
-
-#include <string/strcpy.c>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strcpy.c b/sysdeps/powerpc/powerpc64/multiarch/strcpy.c
deleted file mode 100644
index b18a92a..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strcpy.c
+++ /dev/null
@@ -1,36 +0,0 @@
-/* Multiple versions of strcpy. PowerPC64 version.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if defined SHARED && IS_IN (libc)
-# define strcpy __redirect_strcpy
-# include <string.h>
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-extern __typeof (strcpy) __strcpy_ppc attribute_hidden;
-extern __typeof (strcpy) __strcpy_power7 attribute_hidden;
-extern __typeof (strcpy) __strcpy_power8 attribute_hidden;
-#undef strcpy
-
-libc_ifunc_redirected (__redirect_strcpy, strcpy,
-		       (hwcap2 & PPC_FEATURE2_ARCH_2_07)
-		       ? __strcpy_power8
-		       : (hwcap & PPC_FEATURE_HAS_VSX)
-			 ? __strcpy_power7
-			 : __strcpy_ppc);
-#endif
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strcspn-power8.S b/sysdeps/powerpc/powerpc64/multiarch/strcspn-power8.S
deleted file mode 100644
index 23bf1c1..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strcspn-power8.S
+++ /dev/null
@@ -1,23 +0,0 @@
-/* Optimized strcspn implementation for POWER8.
-   Copyright (C) 2016-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define STRSPN __strcspn_power8
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc64/power8/strcspn.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strcspn-ppc64.c b/sysdeps/powerpc/powerpc64/multiarch/strcspn-ppc64.c
deleted file mode 100644
index 03eac0d..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strcspn-ppc64.c
+++ /dev/null
@@ -1,26 +0,0 @@
-/* Default strcspn implementation for PowerPC64.
-   Copyright (C) 2016-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define STRCSPN __strcspn_ppc
-
-#ifdef SHARED
-#  undef libc_hidden_def
-#  define libc_hidden_def(name)
-#endif
-
-#include <string/strcspn.c>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strcspn.c b/sysdeps/powerpc/powerpc64/multiarch/strcspn.c
deleted file mode 100644
index 308aab5..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strcspn.c
+++ /dev/null
@@ -1,35 +0,0 @@
-/* Multiple versions of strcspn. PowerPC64 version.
-   Copyright (C) 2016-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <string.h>
-#include <shlib-compat.h>
-#include "init-arch.h"
-
-#undef strcspn
-extern __typeof (strcspn) __libc_strcspn;
-
-extern __typeof (strcspn) __strcspn_ppc attribute_hidden;
-extern __typeof (strcspn) __strcspn_power8 attribute_hidden;
-
-libc_ifunc (__libc_strcspn,
-	    (hwcap2 & PPC_FEATURE2_ARCH_2_07)
-	    ? __strcspn_power8
-	    : __strcspn_ppc);
-
-weak_alias (__libc_strcspn, strcspn)
-libc_hidden_builtin_def (strcspn)
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strlen-power7.S b/sysdeps/powerpc/powerpc64/multiarch/strlen-power7.S
deleted file mode 100644
index 5f4591f..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strlen-power7.S
+++ /dev/null
@@ -1,24 +0,0 @@
-/* Optimized strlen implementation for POWER7.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define STRLEN __strlen_power7
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc64/power7/strlen.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strlen-power8.S b/sysdeps/powerpc/powerpc64/multiarch/strlen-power8.S
deleted file mode 100644
index fb8ffbf..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strlen-power8.S
+++ /dev/null
@@ -1,24 +0,0 @@
-/* Optimized strlen implementation for POWER8.
-   Copyright (C) 2016-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define STRLEN __strlen_power8
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc64/power8/strlen.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strlen-ppc64.S b/sysdeps/powerpc/powerpc64/multiarch/strlen-ppc64.S
deleted file mode 100644
index 3e9e481..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strlen-ppc64.S
+++ /dev/null
@@ -1,26 +0,0 @@
-/* Default strlen implementation for PowerPC64.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if defined SHARED && IS_IN (libc)
-# define STRLEN __strlen_ppc
-
-# undef libc_hidden_builtin_def
-# define libc_hidden_builtin_def(name)
-#endif
-
-#include <sysdeps/powerpc/powerpc64/strlen.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strlen.c b/sysdeps/powerpc/powerpc64/multiarch/strlen.c
deleted file mode 100644
index 74810da..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strlen.c
+++ /dev/null
@@ -1,44 +0,0 @@
-/* Multiple versions of strlen. PowerPC64 version.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if defined SHARED && IS_IN (libc)
-/* Redefine strlen so that the compiler won't complain about the type
-   mismatch with the IFUNC selector in strong_alias, below.  */
-# undef strlen
-# define strlen __redirect_strlen
-# include <string.h>
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-extern __typeof (__redirect_strlen) __libc_strlen;
-
-extern __typeof (__redirect_strlen) __strlen_ppc attribute_hidden;
-extern __typeof (__redirect_strlen) __strlen_power7 attribute_hidden;
-extern __typeof (__redirect_strlen) __strlen_power8 attribute_hidden;
-
-libc_ifunc (__libc_strlen,
-	    (hwcap2 & PPC_FEATURE2_ARCH_2_07)
-	    ? __strlen_power8 :
-	      (hwcap & PPC_FEATURE_HAS_VSX)
-	      ? __strlen_power7
-	      : __strlen_ppc);
-
-#undef strlen
-strong_alias (__libc_strlen, strlen)
-libc_hidden_ver (__libc_strlen, strlen)
-#endif
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strncase-power7.c b/sysdeps/powerpc/powerpc64/multiarch/strncase-power7.c
deleted file mode 100644
index 27ca40c..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strncase-power7.c
+++ /dev/null
@@ -1,24 +0,0 @@
-/* Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <string.h>
-
-#define __strncasecmp __strncasecmp_power7
-
-extern __typeof (strncasecmp) __strncasecmp_power7 attribute_hidden;
-
-#include <string/strncase.c>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strncase-power8.S b/sysdeps/powerpc/powerpc64/multiarch/strncase-power8.S
deleted file mode 100644
index c0a0901..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strncase-power8.S
+++ /dev/null
@@ -1,26 +0,0 @@
-/* Optimized strncasecmp implementation for POWER8.
-   Copyright (C) 2016-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define __strncasecmp __strncasecmp_power8
-#undef weak_alias
-#define weak_alias(name, alias)
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc64/power8/strncase.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strncase-ppc64.c b/sysdeps/powerpc/powerpc64/multiarch/strncase-ppc64.c
deleted file mode 100644
index 31ed951..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strncase-ppc64.c
+++ /dev/null
@@ -1,21 +0,0 @@
-/* Multiarch strncasecmp for PPC64.
-   Copyright (C) 2016-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define strncasecmp __strncasecmp_ppc
-
-#include <string/strncase.c>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strncase.c b/sysdeps/powerpc/powerpc64/multiarch/strncase.c
deleted file mode 100644
index 8cf7154..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strncase.c
+++ /dev/null
@@ -1,36 +0,0 @@
-/* Multiple versions of strncasecmp
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <string.h>
-#include <shlib-compat.h>
-#include "init-arch.h"
-
-extern __typeof (__strncasecmp) __libc_strncasecmp;
-
-extern __typeof (__strncasecmp) __strncasecmp_ppc attribute_hidden;
-extern __typeof (__strncasecmp) __strncasecmp_power7 attribute_hidden;
-extern __typeof (__strncasecmp) __strncasecmp_power8 attribute_hidden;
-
-libc_ifunc (__libc_strncasecmp,
-	     (hwcap2 & PPC_FEATURE2_ARCH_2_07)
-             ? __strncasecmp_power8:
-	     (hwcap & PPC_FEATURE_HAS_VSX)
-             ? __strncasecmp_power7
-             : __strncasecmp_ppc);
-
-weak_alias (__libc_strncasecmp, strncasecmp)
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strncase_l-power7.c b/sysdeps/powerpc/powerpc64/multiarch/strncase_l-power7.c
deleted file mode 100644
index ae2c4a3..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strncase_l-power7.c
+++ /dev/null
@@ -1,27 +0,0 @@
-/* Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <string.h>
-
-#define __strncasecmp_l __strncasecmp_l_power7
-
-#undef libc_hidden_def
-#define libc_hidden_def(name)
-
-extern __typeof (strncasecmp_l) __strncasecmp_l_power7 attribute_hidden;
-
-#include <string/strncase_l.c>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strncase_l.c b/sysdeps/powerpc/powerpc64/multiarch/strncase_l.c
deleted file mode 100644
index d3c4bf1..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strncase_l.c
+++ /dev/null
@@ -1,42 +0,0 @@
-/* Multiple versions of strncasecmp_l
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if IS_IN (libc)
-# include <string.h>
-# define strncasecmp_l __strncasecmp_l_ppc
-extern __typeof (__strncasecmp_l) __strncasecmp_l_ppc attribute_hidden;
-extern __typeof (__strncasecmp_l) __strncasecmp_l_power7 attribute_hidden;
-#endif
-
-#include <string/strncase_l.c>
-#undef strncasecmp_l
-
-#if IS_IN (libc)
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-/* Avoid DWARF definition DIE on ifunc symbol so that GDB can handle
-   ifunc symbol properly.  */
-extern __typeof (__strncasecmp_l) __libc_strncasecmp_l;
-libc_ifunc (__libc_strncasecmp_l,
-	     (hwcap & PPC_FEATURE_HAS_VSX)
-             ? __strncasecmp_l_power7
-             : __strncasecmp_l_ppc);
-
-weak_alias (__libc_strncasecmp_l, strncasecmp_l)
-#endif
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strncat-power7.c b/sysdeps/powerpc/powerpc64/multiarch/strncat-power7.c
deleted file mode 100644
index a393c2e..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strncat-power7.c
+++ /dev/null
@@ -1,31 +0,0 @@
-/* Copyright (C) 2015-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/ >.  */
-
-#include <string.h>
-
-#define STRNCAT __strncat_power7
-
-extern __typeof (strncat) __strncat_power7 attribute_hidden;
-extern __typeof (strlen) __strlen_power7 attribute_hidden;
-extern __typeof (strnlen) __strnlen_power7 attribute_hidden;
-extern __typeof (memcpy) __memcpy_power7 attribute_hidden;
-
-#define strlen    __strlen_power7
-#define __strnlen __strnlen_power7
-#define memcpy    __memcpy_power7
-
-#include <string/strncat.c>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strncat-power8.c b/sysdeps/powerpc/powerpc64/multiarch/strncat-power8.c
deleted file mode 100644
index 7842a50..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strncat-power8.c
+++ /dev/null
@@ -1,31 +0,0 @@
-/* Copyright (C) 2017-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/ >.  */
-
-#include <string.h>
-
-#define STRNCAT __strncat_power8
-
-extern __typeof (strncat) __strncat_power8 attribute_hidden;
-extern __typeof (strlen) __strlen_power8 attribute_hidden;
-extern __typeof (strnlen) __strnlen_power8 attribute_hidden;
-extern __typeof (memcpy) __memcpy_power7 attribute_hidden;
-
-#define strlen    __strlen_power8
-#define __strnlen __strnlen_power8
-#define memcpy    __memcpy_power7
-
-#include <string/strncat.c>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strncat-ppc64.c b/sysdeps/powerpc/powerpc64/multiarch/strncat-ppc64.c
deleted file mode 100644
index dd0f166..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strncat-ppc64.c
+++ /dev/null
@@ -1,29 +0,0 @@
-/* Copyright (C) 2014-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/ >.  */
-
-#include <string.h>
-
-#define STRNCAT __strncat_ppc
-#ifdef SHARED
-# undef libc_hidden_builtin_def
-# define libc_hidden_builtin_def(name) \
-  __hidden_ver1 (__strncat_ppc, __GI_strncat, __strncat_ppc);
-#endif
-
-extern __typeof (strncat) __strncat_ppc attribute_hidden;
-
-#include <string/strncat.c>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strncat.c b/sysdeps/powerpc/powerpc64/multiarch/strncat.c
deleted file mode 100644
index a2e5038..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strncat.c
+++ /dev/null
@@ -1,34 +0,0 @@
-/* Multiple versions of strncat. PowerPC64 version.
-   Copyright (C) 2014-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if IS_IN (libc)
-# include <string.h>
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-extern __typeof (strncat) __strncat_ppc attribute_hidden;
-extern __typeof (strncat) __strncat_power7 attribute_hidden;
-extern __typeof (strncat) __strncat_power8 attribute_hidden;
-
-libc_ifunc (strncat,
-	    (hwcap2 & PPC_FEATURE2_ARCH_2_07)
-	    ? __strncat_power8
-	    : (hwcap & PPC_FEATURE_HAS_VSX)
-            ? __strncat_power7
-            : __strncat_ppc);
-#endif
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strncmp-power4.S b/sysdeps/powerpc/powerpc64/multiarch/strncmp-power4.S
deleted file mode 100644
index 860f2ec..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strncmp-power4.S
+++ /dev/null
@@ -1,23 +0,0 @@
-/* Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define STRNCMP __strncmp_power4
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc64/power4/strncmp.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strncmp-power7.S b/sysdeps/powerpc/powerpc64/multiarch/strncmp-power7.S
deleted file mode 100644
index 8d4108e..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strncmp-power7.S
+++ /dev/null
@@ -1,23 +0,0 @@
-/* Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define STRNCMP __strncmp_power7
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc64/power7/strncmp.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strncmp-power8.S b/sysdeps/powerpc/powerpc64/multiarch/strncmp-power8.S
deleted file mode 100644
index e8a5fb8..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strncmp-power8.S
+++ /dev/null
@@ -1,25 +0,0 @@
-/* Copyright (C) 2015-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if IS_IN (libc)
-#define STRNCMP __strncmp_power8
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc64/power8/strncmp.S>
-#endif
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strncmp-power9.S b/sysdeps/powerpc/powerpc64/multiarch/strncmp-power9.S
deleted file mode 100644
index 3356f72..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strncmp-power9.S
+++ /dev/null
@@ -1,25 +0,0 @@
-/* Copyright (C) 2016-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if IS_IN (libc)
-#define STRNCMP __strncmp_power9
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc64/power9/strncmp.S>
-#endif
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strncmp-ppc64.S b/sysdeps/powerpc/powerpc64/multiarch/strncmp-ppc64.S
deleted file mode 100644
index 1b5704a..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strncmp-ppc64.S
+++ /dev/null
@@ -1,26 +0,0 @@
-/* Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if defined SHARED && IS_IN (libc)
-# define STRNCMP __strncmp_ppc
-
-# undef libc_hidden_builtin_def
-# define libc_hidden_builtin_def(name)				\
-    .globl __GI_strncmp; __GI_strncmp = __strncmp_ppc
-#endif
-
-#include <sysdeps/powerpc/powerpc64/strncmp.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strncmp.c b/sysdeps/powerpc/powerpc64/multiarch/strncmp.c
deleted file mode 100644
index c4a40d1..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strncmp.c
+++ /dev/null
@@ -1,47 +0,0 @@
-/* Multiple versions of strncmp.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-/* Define multiple versions only for definition in libc.  */
-#if defined SHARED && IS_IN (libc)
-# define strncmp __redirect_strncmp
-/* Omit the strncmp inline definitions because it would redefine strncmp.  */
-# define __NO_STRING_INLINES
-# include <string.h>
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-extern __typeof (strncmp) __strncmp_ppc attribute_hidden;
-extern __typeof (strncmp) __strncmp_power4 attribute_hidden;
-extern __typeof (strncmp) __strncmp_power7 attribute_hidden;
-extern __typeof (strncmp) __strncmp_power8 attribute_hidden;
-extern __typeof (strncmp) __strncmp_power9 attribute_hidden;
-# undef strncmp
-
-/* Avoid DWARF definition DIE on ifunc symbol so that GDB can handle
-   ifunc symbol properly.  */
-libc_ifunc_redirected (__redirect_strncmp, strncmp,
-			(hwcap2 & PPC_FEATURE2_ARCH_3_00)
-			? __strncmp_power9 :
-		       (hwcap2 & PPC_FEATURE2_ARCH_2_07)
-		       ? __strncmp_power8
-		       : (hwcap & PPC_FEATURE_HAS_VSX)
-			 ? __strncmp_power7
-			 : (hwcap & PPC_FEATURE_POWER4)
-			   ? __strncmp_power4
-			   : __strncmp_ppc);
-#endif
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strncpy-power7.S b/sysdeps/powerpc/powerpc64/multiarch/strncpy-power7.S
deleted file mode 100644
index a044c11..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strncpy-power7.S
+++ /dev/null
@@ -1,29 +0,0 @@
-/* Optimized strncpy implementation for POWER7.
-   Copyright (C) 2014-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define STRNCPY __strncpy_power7
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#define MEMSET __memset_power7
-#ifdef SHARED
-#define MEMSET_is_local
-#endif
-
-#include <sysdeps/powerpc/powerpc64/power7/strncpy.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strncpy-power8.S b/sysdeps/powerpc/powerpc64/multiarch/strncpy-power8.S
deleted file mode 100644
index 10b8453..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strncpy-power8.S
+++ /dev/null
@@ -1,30 +0,0 @@
-/* Optimized strncpy implementation for POWER8.
-   Copyright (C) 2015-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define STRNCPY __strncpy_power8
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-/* memset is used to pad the end of the string.  */
-#define MEMSET __memset_power8
-#ifdef SHARED
-#define MEMSET_is_local
-#endif
-
-#include <sysdeps/powerpc/powerpc64/power8/strncpy.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strncpy-ppc64.c b/sysdeps/powerpc/powerpc64/multiarch/strncpy-ppc64.c
deleted file mode 100644
index 7efbe10..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strncpy-ppc64.c
+++ /dev/null
@@ -1,33 +0,0 @@
-/* Copyright (C) 2014-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <string.h>
-
-#define STRNCPY __strncpy_ppc
-#undef weak_alias
-#define weak_alias(name, aliasname) \
-  extern __typeof (__strncpy_ppc) aliasname \
-    __attribute__ ((weak, alias ("__strncpy_ppc")));
-#if IS_IN (libc) && defined(SHARED)
-# undef libc_hidden_builtin_def
-# define libc_hidden_builtin_def(name) \
-  __hidden_ver1(__strncpy_ppc, __GI_strncpy, __strncpy_ppc);
-#endif
-
-extern __typeof (strncpy) __strncpy_ppc attribute_hidden;
-
-#include <string/strncpy.c>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strncpy.c b/sysdeps/powerpc/powerpc64/multiarch/strncpy.c
deleted file mode 100644
index 41e5ea8..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strncpy.c
+++ /dev/null
@@ -1,42 +0,0 @@
-/* Multiple versions of strncpy.
-   Copyright (C) 2014-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/ >.  */
-
-/* Define multiple versions only for definition in libc. */
-#if IS_IN (libc)
-# define strncpy __redirect_strncpy
-/* Omit the strncpy inline definitions because it would redefine strncpy.  */
-# define __NO_STRING_INLINES
-# include <string.h>
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-extern __typeof (strncpy) __strncpy_ppc attribute_hidden;
-extern __typeof (strncpy) __strncpy_power7 attribute_hidden;
-extern __typeof (strncpy) __strncpy_power8 attribute_hidden;
-# undef strncpy
-
-/* Avoid DWARF definition DIE on ifunc symbol so that GDB can handle
- ifunc symbol properly. */
-libc_ifunc_redirected (__redirect_strncpy, strncpy,
-		       (hwcap2 & PPC_FEATURE2_ARCH_2_07)
-		       ? __strncpy_power8
-		       : (hwcap & PPC_FEATURE_HAS_VSX)
-			 ? __strncpy_power7
-			 : __strncpy_ppc);
-
-#endif
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strnlen-power7.S b/sysdeps/powerpc/powerpc64/multiarch/strnlen-power7.S
deleted file mode 100644
index 565937b..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strnlen-power7.S
+++ /dev/null
@@ -1,26 +0,0 @@
-/* Optimized strnlen version for POWER7.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define STRNLEN __strnlen_power7
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-#undef weak_alias
-#define weak_alias(name, alias)
-
-#include <sysdeps/powerpc/powerpc64/power7/strnlen.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strnlen-power8.S b/sysdeps/powerpc/powerpc64/multiarch/strnlen-power8.S
deleted file mode 100644
index ed5b67e..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strnlen-power8.S
+++ /dev/null
@@ -1,26 +0,0 @@
-/* Optimized strnlen version for POWER8.
-   Copyright (C) 2017-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define __strnlen __strnlen_power8
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-#undef weak_alias
-#define weak_alias(name, alias)
-
-#include <sysdeps/powerpc/powerpc64/power8/strnlen.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strnlen-ppc64.c b/sysdeps/powerpc/powerpc64/multiarch/strnlen-ppc64.c
deleted file mode 100644
index ce710e2..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strnlen-ppc64.c
+++ /dev/null
@@ -1,18 +0,0 @@
-/* Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdeps/powerpc/powerpc32/power4/multiarch/strnlen-ppc32.c>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strnlen.c b/sysdeps/powerpc/powerpc64/multiarch/strnlen.c
deleted file mode 100644
index 298bfa0..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strnlen.c
+++ /dev/null
@@ -1,41 +0,0 @@
-/* Multiple versions of strnlen.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if IS_IN (libc)
-# define strnlen __redirect_strnlen
-# define __strnlen __redirect___strnlen
-# include <string.h>
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-extern __typeof (__strnlen) __strnlen_ppc attribute_hidden;
-extern __typeof (__strnlen) __strnlen_power7 attribute_hidden;
-extern __typeof (__strnlen) __strnlen_power8 attribute_hidden;
-# undef strnlen
-# undef __strnlen
-libc_ifunc_redirected (__redirect___strnlen, __strnlen,
-		       (hwcap2 & PPC_FEATURE2_ARCH_2_07)
-		       ? __strnlen_power8 :
-			 (hwcap & PPC_FEATURE_HAS_VSX)
-			 ? __strnlen_power7
-			 : __strnlen_ppc);
-weak_alias (__strnlen, strnlen)
-
-#else
-#include <string/strnlen.c>
-#endif
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strrchr-power7.S b/sysdeps/powerpc/powerpc64/multiarch/strrchr-power7.S
deleted file mode 100644
index 9498030..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strrchr-power7.S
+++ /dev/null
@@ -1,24 +0,0 @@
-/* Optimized strrchr implementation for POWER7.
-   Copyright (C) 2014-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define STRRCHR __strrchr_power7
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc64/power7/strrchr.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strrchr-power8.S b/sysdeps/powerpc/powerpc64/multiarch/strrchr-power8.S
deleted file mode 100644
index 342d02a..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strrchr-power8.S
+++ /dev/null
@@ -1,24 +0,0 @@
-/* Optimized strrchr implementation for POWER8.
-   Copyright (C) 2017-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define STRRCHR __strrchr_power8
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc64/power8/strrchr.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strrchr-ppc64.c b/sysdeps/powerpc/powerpc64/multiarch/strrchr-ppc64.c
deleted file mode 100644
index bcf049a..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strrchr-ppc64.c
+++ /dev/null
@@ -1,33 +0,0 @@
-/* Copyright (C) 2014-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <string.h>
-
-#define STRRCHR __strrchr_ppc
-
-#undef weak_alias
-#define weak_alias(name, aliasname)
-
-#if IS_IN (libc) && defined(SHARED)
-# undef libc_hidden_builtin_def
-# define libc_hidden_builtin_def(name) \
-  __hidden_ver1(__strrchr_ppc, __GI_strrchr, __strrchr_ppc);
-#endif
-
-extern __typeof (strrchr) __strrchr_ppc attribute_hidden;
-
-#include <string/strrchr.c>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strrchr.c b/sysdeps/powerpc/powerpc64/multiarch/strrchr.c
deleted file mode 100644
index d46f7c0..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strrchr.c
+++ /dev/null
@@ -1,40 +0,0 @@
-/* Multiple versions of strrchr. PowerPC64 version.
-   Copyright (C) 2014-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-/* Define multiple versions only for definition in libc.  */
-#if IS_IN (libc)
-# define strrchr __redirect_strrchr
-# include <string.h>
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-extern __typeof (strrchr) __strrchr_ppc attribute_hidden;
-extern __typeof (strrchr) __strrchr_power7 attribute_hidden;
-extern __typeof (strrchr) __strrchr_power8 attribute_hidden;
-#undef strrchr
-
-/* Avoid DWARF definition DIE on ifunc symbol so that GDB can handle
-   ifunc symbol properly.  */
-libc_ifunc_redirected (__redirect_strrchr, strrchr,
-		       (hwcap2 & PPC_FEATURE2_ARCH_2_07)
-		       ? __strrchr_power8 :
-		       (hwcap & PPC_FEATURE_HAS_VSX)
-		       ? __strrchr_power7
-		       : __strrchr_ppc);
-weak_alias (strrchr, rindex)
-#endif
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strspn-power8.S b/sysdeps/powerpc/powerpc64/multiarch/strspn-power8.S
deleted file mode 100644
index bc9f493..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strspn-power8.S
+++ /dev/null
@@ -1,23 +0,0 @@
-/* Optimized strspn implementation for POWER8.
-   Copyright (C) 2016-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define STRSPN __strspn_power8
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#include <sysdeps/powerpc/powerpc64/power8/strspn.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strspn-ppc64.c b/sysdeps/powerpc/powerpc64/multiarch/strspn-ppc64.c
deleted file mode 100644
index 05a240b..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strspn-ppc64.c
+++ /dev/null
@@ -1,25 +0,0 @@
-/* Default strspn implementation for PowerPC64.
-   Copyright (C) 2016-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define STRSPN __strspn_ppc
-#ifdef SHARED
-#undef libc_hidden_def
-#define libc_hidden_def(name)
-#endif
-
-#include <string/strspn.c>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strspn.c b/sysdeps/powerpc/powerpc64/multiarch/strspn.c
deleted file mode 100644
index 6125161..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strspn.c
+++ /dev/null
@@ -1,35 +0,0 @@
-/* Multiple versions of strspn. PowerPC64 version.
-   Copyright (C) 2016-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-# include <string.h>
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-#undef strspn
-extern __typeof (strspn) __libc_strspn;
-
-extern __typeof (strspn) __strspn_ppc attribute_hidden;
-extern __typeof (strspn) __strspn_power8 attribute_hidden;
-
-libc_ifunc (__libc_strspn,
-	    (hwcap2 & PPC_FEATURE2_ARCH_2_07)
-	    ? __strspn_power8
-	    : __strspn_ppc);
-
-weak_alias (__libc_strspn, strspn)
-libc_hidden_builtin_def (strspn)
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strstr-power7.S b/sysdeps/powerpc/powerpc64/multiarch/strstr-power7.S
deleted file mode 100644
index a24ab58..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strstr-power7.S
+++ /dev/null
@@ -1,33 +0,0 @@
-/* Optimized strstr implementation for POWER7.
-   Copyright (C) 2015-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define STRSTR __strstr_power7
-
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(name)
-
-#define STRLEN __strlen_power7
-#define STRNLEN __strnlen_power7
-#define STRCHR __strchr_power7
-#ifdef SHARED
-#define STRLEN_is_local
-#define STRNLEN_is_local
-#define STRCHR_is_local
-#endif
-
-#include <sysdeps/powerpc/powerpc64/power7/strstr.S>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strstr-ppc64.c b/sysdeps/powerpc/powerpc64/multiarch/strstr-ppc64.c
deleted file mode 100644
index 971bb18..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strstr-ppc64.c
+++ /dev/null
@@ -1,29 +0,0 @@
-/* Copyright (C) 2015-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <string.h>
-
-#define STRSTR __strstr_ppc
-#if IS_IN (libc) && defined(SHARED)
-# undef libc_hidden_builtin_def
-# define libc_hidden_builtin_def(name) \
-  __hidden_ver1(__strstr_ppc, __GI_strstr, __strstr_ppc);
-#endif
-
-extern __typeof (strstr) __strstr_ppc attribute_hidden;
-
-#include <string/strstr.c>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/strstr.c b/sysdeps/powerpc/powerpc64/multiarch/strstr.c
deleted file mode 100644
index 264b5d8..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/strstr.c
+++ /dev/null
@@ -1,36 +0,0 @@
-/* Multiple versions of strstr. PowerPC64 version.
-   Copyright (C) 2015-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-/* Define multiple versions only for definition in libc.  */
-#if IS_IN (libc)
-# define strstr __redirect_strstr
-# include <string.h>
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-extern __typeof (strstr) __strstr_ppc attribute_hidden;
-extern __typeof (strstr) __strstr_power7 attribute_hidden;
-# undef strstr
-
-/* Avoid DWARF definition DIE on ifunc symbol so that GDB can handle
-   ifunc symbol properly.  */
-libc_ifunc_redirected (__redirect_strstr, strstr,
-		       (hwcap & PPC_FEATURE_HAS_VSX)
-		       ? __strstr_power7
-		       : __strstr_ppc);
-#endif
diff --git a/sysdeps/powerpc/powerpc64/multiarch/wcschr-power6.c b/sysdeps/powerpc/powerpc64/multiarch/wcschr-power6.c
deleted file mode 100644
index 52f562b..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/wcschr-power6.c
+++ /dev/null
@@ -1,19 +0,0 @@
-/* wcschr.c - Wide Character Search for powerpc64/power6.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; see the file COPYING.LIB.  If
-   not, see <http://www.gnu.org/licenses/>.  */
-
-#include <sysdeps/powerpc/powerpc32/power4/multiarch/wcschr-power6.c>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/wcschr-power7.c b/sysdeps/powerpc/powerpc64/multiarch/wcschr-power7.c
deleted file mode 100644
index 0acad04..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/wcschr-power7.c
+++ /dev/null
@@ -1,19 +0,0 @@
-/* wcschr.c - Wide Character Search for powerpc64/power7.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; see the file COPYING.LIB.  If
-   not, see <http://www.gnu.org/licenses/>.  */
-
-#include <sysdeps/powerpc/powerpc32/power4/multiarch/wcschr-power7.c>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/wcschr-ppc64.c b/sysdeps/powerpc/powerpc64/multiarch/wcschr-ppc64.c
deleted file mode 100644
index f728652..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/wcschr-ppc64.c
+++ /dev/null
@@ -1,18 +0,0 @@
-/* Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdeps/powerpc/powerpc32/power4/multiarch/wcschr-ppc32.c>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/wcschr.c b/sysdeps/powerpc/powerpc64/multiarch/wcschr.c
deleted file mode 100644
index 9976a63..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/wcschr.c
+++ /dev/null
@@ -1,43 +0,0 @@
-/* Multiple versions of wcschr
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if IS_IN (libc)
-# define wcschr __redirect_wcschr
-# define __wcschr __redirect___wcschr
-# include <wchar.h>
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-extern __typeof (wcschr) __wcschr_ppc attribute_hidden;
-extern __typeof (wcschr) __wcschr_power6 attribute_hidden;
-extern __typeof (wcschr) __wcschr_power7 attribute_hidden;
-# undef wcschr
-# undef __wcschr
-
-libc_ifunc_redirected (__redirect___wcschr, __wcschr,
-		       (hwcap & PPC_FEATURE_HAS_VSX)
-		       ? __wcschr_power7
-		       : (hwcap & PPC_FEATURE_ARCH_2_05)
-			 ? __wcschr_power6
-			 : __wcschr_ppc);
-weak_alias (__wcschr, wcschr)
-#else
-#undef libc_hidden_def
-#define libc_hidden_def(a)
-#include <wcsmbs/wcschr.c>
-#endif
diff --git a/sysdeps/powerpc/powerpc64/multiarch/wcscpy-power6.c b/sysdeps/powerpc/powerpc64/multiarch/wcscpy-power6.c
deleted file mode 100644
index ef0f7cc..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/wcscpy-power6.c
+++ /dev/null
@@ -1,19 +0,0 @@
-/* wcscpy.c - Wide Character Search for powerpc64/power6.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; see the file COPYING.LIB.  If
-   not, see <http://www.gnu.org/licenses/>.  */
-
-#include <sysdeps/powerpc/powerpc32/power4/multiarch/wcscpy-power6.c>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/wcscpy-power7.c b/sysdeps/powerpc/powerpc64/multiarch/wcscpy-power7.c
deleted file mode 100644
index 2712f58..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/wcscpy-power7.c
+++ /dev/null
@@ -1,19 +0,0 @@
-/* wcscpy.c - Wide Character Search for powerpc64/power7.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; see the file COPYING.LIB.  If
-   not, see <http://www.gnu.org/licenses/>.  */
-
-#include <sysdeps/powerpc/powerpc32/power4/multiarch/wcscpy-power7.c>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/wcscpy-ppc64.c b/sysdeps/powerpc/powerpc64/multiarch/wcscpy-ppc64.c
deleted file mode 100644
index 4bcf792..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/wcscpy-ppc64.c
+++ /dev/null
@@ -1,18 +0,0 @@
-/* Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdeps/powerpc/powerpc32/power4/multiarch/wcscpy-ppc32.c>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/wcscpy.c b/sysdeps/powerpc/powerpc64/multiarch/wcscpy.c
deleted file mode 100644
index 76fc356..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/wcscpy.c
+++ /dev/null
@@ -1,36 +0,0 @@
-/* Multiple versions of wcscpy.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if IS_IN (libc)
-# include <wchar.h>
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-extern __typeof (wcscpy) __wcscpy_ppc attribute_hidden;
-extern __typeof (wcscpy) __wcscpy_power6 attribute_hidden;
-extern __typeof (wcscpy) __wcscpy_power7 attribute_hidden;
-
-libc_ifunc (wcscpy,
-	     (hwcap & PPC_FEATURE_HAS_VSX)
-             ? __wcscpy_power7 :
-	       (hwcap & PPC_FEATURE_ARCH_2_05)
-	       ? __wcscpy_power6
-             : __wcscpy_ppc);
-#else
-#include <wcsmbs/wcscpy.c>
-#endif
diff --git a/sysdeps/powerpc/powerpc64/multiarch/wcsrchr-power6.c b/sysdeps/powerpc/powerpc64/multiarch/wcsrchr-power6.c
deleted file mode 100644
index 05414b0..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/wcsrchr-power6.c
+++ /dev/null
@@ -1,19 +0,0 @@
-/* wcsrchr.c - Wide Character Search for powerpc64/power6.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; see the file COPYING.LIB.  If
-   not, see <http://www.gnu.org/licenses/>.  */
-
-#include <sysdeps/powerpc/powerpc32/power4/multiarch/wcsrchr-power6.c>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/wcsrchr-power7.c b/sysdeps/powerpc/powerpc64/multiarch/wcsrchr-power7.c
deleted file mode 100644
index 35a5638..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/wcsrchr-power7.c
+++ /dev/null
@@ -1,19 +0,0 @@
-/* wcsrchr.c - Wide Character Search for powerpc64/power7.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; see the file COPYING.LIB.  If
-   not, see <http://www.gnu.org/licenses/>.  */
-
-#include <sysdeps/powerpc/powerpc32/power4/multiarch/wcsrchr-power7.c>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/wcsrchr-ppc64.c b/sysdeps/powerpc/powerpc64/multiarch/wcsrchr-ppc64.c
deleted file mode 100644
index 7085750..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/wcsrchr-ppc64.c
+++ /dev/null
@@ -1,18 +0,0 @@
-/* Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdeps/powerpc/powerpc32/power4/multiarch/wcsrchr-ppc32.c>
diff --git a/sysdeps/powerpc/powerpc64/multiarch/wcsrchr.c b/sysdeps/powerpc/powerpc64/multiarch/wcsrchr.c
deleted file mode 100644
index 06e4b61..0000000
--- a/sysdeps/powerpc/powerpc64/multiarch/wcsrchr.c
+++ /dev/null
@@ -1,36 +0,0 @@
-/* Multiple versions of wcsrchr.
-   Copyright (C) 2013-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#if IS_IN (libc)
-# include <wchar.h>
-# include <shlib-compat.h>
-# include "init-arch.h"
-
-extern __typeof (wcsrchr) __wcsrchr_ppc attribute_hidden;
-extern __typeof (wcsrchr) __wcsrchr_power6 attribute_hidden;
-extern __typeof (wcsrchr) __wcsrchr_power7 attribute_hidden;
-
-libc_ifunc (wcsrchr,
-	     (hwcap & PPC_FEATURE_HAS_VSX)
-             ? __wcsrchr_power7 :
-	       (hwcap & PPC_FEATURE_ARCH_2_05)
-	       ? __wcsrchr_power6
-             : __wcsrchr_ppc);
-#else
-#include <wcsmbs/wcsrchr.c>
-#endif
diff --git a/sysdeps/powerpc/powerpc64/power4/memcmp.S b/sysdeps/powerpc/powerpc64/power4/memcmp.S
deleted file mode 100644
index e5319f1..0000000
--- a/sysdeps/powerpc/powerpc64/power4/memcmp.S
+++ /dev/null
@@ -1,1369 +0,0 @@
-/* Optimized memcmp implementation for PowerPC64.
-   Copyright (C) 2003-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* int [r3] memcmp (const char *s1 [r3],
-		    const char *s2 [r4],
-		    size_t size [r5])  */
-
-#ifndef MEMCMP
-# define MEMCMP memcmp
-#endif
-
-	.machine power4
-ENTRY_TOCLESS (MEMCMP, 4)
-	CALL_MCOUNT 3
-
-#define rRTN	r3
-#define rSTR1	r3	/* first string arg */
-#define rSTR2	r4	/* second string arg */
-#define rN	r5	/* max string length */
-#define rWORD1	r6	/* current word in s1 */
-#define rWORD2	r7	/* current word in s2 */
-#define rWORD3	r8	/* next word in s1 */
-#define rWORD4	r9	/* next word in s2 */
-#define rWORD5	r10	/* next word in s1 */
-#define rWORD6	r11	/* next word in s2 */
-#define rWORD7	r30	/* next word in s1 */
-#define rWORD8	r31	/* next word in s2 */
-
-	xor	r0, rSTR2, rSTR1
-	cmpldi	cr6, rN, 0
-	cmpldi	cr1, rN, 12
-	clrldi.	r0, r0, 61
-	clrldi	r12, rSTR1, 61
-	cmpldi	cr5, r12, 0
-	beq-	cr6, L(zeroLength)
-	dcbt	0, rSTR1
-	dcbt	0, rSTR2
-/* If less than 8 bytes or not aligned, use the unaligned
-   byte loop.  */
-	blt	cr1, L(bytealigned)
-	std	rWORD8, -8(r1)
-	std	rWORD7, -16(r1)
-	cfi_offset(rWORD8, -8)
-	cfi_offset(rWORD7, -16)
-	bne	L(unaligned)
-/* At this point we know both strings have the same alignment and the
-   compare length is at least 8 bytes.  r12 contains the low order
-   3 bits of rSTR1 and cr5 contains the result of the logical compare
-   of r12 to 0.  If r12 == 0 then we are already double word
-   aligned and can perform the DW aligned loop.
-
-   Otherwise we know the two strings have the same alignment (but not
-   yet DW).  So we force the string addresses to the next lower DW
-   boundary and special case this first DW using shift left to
-   eliminate bits preceding the first byte.  Since we want to join the
-   normal (DW aligned) compare loop, starting at the second double word,
-   we need to adjust the length (rN) and special case the loop
-   versioning for the first DW. This ensures that the loop count is
-   correct and the first DW (shifted) is in the expected register pair.  */
-	.align	4
-L(samealignment):
-	clrrdi	rSTR1, rSTR1, 3
-	clrrdi	rSTR2, rSTR2, 3
-	beq	cr5, L(DWaligned)
-	add	rN, rN, r12
-	sldi	rWORD6, r12, 3
-	srdi	r0, rN, 5	/* Divide by 32 */
-	andi.	r12, rN, 24	/* Get the DW remainder */
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD1, 0, rSTR1
-	ldbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD1, 0(rSTR1)
-	ld	rWORD2, 0(rSTR2)
-#endif
-	cmpldi	cr1, r12, 16
-	cmpldi	cr7, rN, 32
-	clrldi	rN, rN, 61
-	beq	L(dPs4)
-	mtctr	r0	/* Power4 wants mtctr 1st in dispatch group */
-	bgt	cr1, L(dPs3)
-	beq	cr1, L(dPs2)
-
-/* Remainder is 8 */
-	.align	3
-L(dsP1):
-	sld	rWORD5, rWORD1, rWORD6
-	sld	rWORD6, rWORD2, rWORD6
-	cmpld	cr5, rWORD5, rWORD6
-	blt	cr7, L(dP1x)
-/* Do something useful in this cycle since we have to branch anyway.  */
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD1, 0, rSTR1
-	ldbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD1, 8(rSTR1)
-	ld	rWORD2, 8(rSTR2)
-#endif
-	cmpld	cr7, rWORD1, rWORD2
-	b	L(dP1e)
-/* Remainder is 16 */
-	.align	4
-L(dPs2):
-	sld	rWORD5, rWORD1, rWORD6
-	sld	rWORD6, rWORD2, rWORD6
-	cmpld	cr6, rWORD5, rWORD6
-	blt	cr7, L(dP2x)
-/* Do something useful in this cycle since we have to branch anyway.  */
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD7, 0, rSTR1
-	ldbrx	rWORD8, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD7, 8(rSTR1)
-	ld	rWORD8, 8(rSTR2)
-#endif
-	cmpld	cr5, rWORD7, rWORD8
-	b	L(dP2e)
-/* Remainder is 24 */
-	.align	4
-L(dPs3):
-	sld	rWORD3, rWORD1, rWORD6
-	sld	rWORD4, rWORD2, rWORD6
-	cmpld	cr1, rWORD3, rWORD4
-	b	L(dP3e)
-/* Count is a multiple of 32, remainder is 0 */
-	.align	4
-L(dPs4):
-	mtctr	r0	/* Power4 wants mtctr 1st in dispatch group */
-	sld	rWORD1, rWORD1, rWORD6
-	sld	rWORD2, rWORD2, rWORD6
-	cmpld	cr7, rWORD1, rWORD2
-	b	L(dP4e)
-
-/* At this point we know both strings are double word aligned and the
-   compare length is at least 8 bytes.  */
-	.align	4
-L(DWaligned):
-	andi.	r12, rN, 24	/* Get the DW remainder */
-	srdi	r0, rN, 5	/* Divide by 32 */
-	cmpldi	cr1, r12, 16
-	cmpldi	cr7, rN, 32
-	clrldi	rN, rN, 61
-	beq	L(dP4)
-	bgt	cr1, L(dP3)
-	beq	cr1, L(dP2)
-
-/* Remainder is 8 */
-	.align	4
-L(dP1):
-	mtctr	r0	/* Power4 wants mtctr 1st in dispatch group */
-/* Normally we'd use rWORD7/rWORD8 here, but since we might exit early
-   (8-15 byte compare), we want to use only volatile registers.  This
-   means we can avoid restoring non-volatile registers since we did not
-   change any on the early exit path.  The key here is the non-early
-   exit path only cares about the condition code (cr5), not about which
-   register pair was used.  */
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD5, 0, rSTR1
-	ldbrx	rWORD6, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD5, 0(rSTR1)
-	ld	rWORD6, 0(rSTR2)
-#endif
-	cmpld	cr5, rWORD5, rWORD6
-	blt	cr7, L(dP1x)
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD1, 0, rSTR1
-	ldbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD1, 8(rSTR1)
-	ld	rWORD2, 8(rSTR2)
-#endif
-	cmpld	cr7, rWORD1, rWORD2
-L(dP1e):
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD3, 0, rSTR1
-	ldbrx	rWORD4, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD3, 16(rSTR1)
-	ld	rWORD4, 16(rSTR2)
-#endif
-	cmpld	cr1, rWORD3, rWORD4
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD5, 0, rSTR1
-	ldbrx	rWORD6, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD5, 24(rSTR1)
-	ld	rWORD6, 24(rSTR2)
-#endif
-	cmpld	cr6, rWORD5, rWORD6
-	bne	cr5, L(dLcr5x)
-	bne	cr7, L(dLcr7x)
-
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD7, 0, rSTR1
-	ldbrx	rWORD8, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ldu	rWORD7, 32(rSTR1)
-	ldu	rWORD8, 32(rSTR2)
-#endif
-	bne	cr1, L(dLcr1)
-	cmpld	cr5, rWORD7, rWORD8
-	bdnz	L(dLoop)
-	bne	cr6, L(dLcr6)
-	ld	rWORD8, -8(r1)
-	ld	rWORD7, -16(r1)
-	.align	3
-L(dP1x):
-	sldi.	r12, rN, 3
-	bne	cr5, L(dLcr5x)
-	subfic	rN, r12, 64	/* Shift count is 64 - (rN * 8).  */
-	bne	L(d00)
-	li	rRTN, 0
-	blr
-
-/* Remainder is 16 */
-	.align	4
-L(dP2):
-	mtctr	r0	/* Power4 wants mtctr 1st in dispatch group */
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD5, 0, rSTR1
-	ldbrx	rWORD6, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD5, 0(rSTR1)
-	ld	rWORD6, 0(rSTR2)
-#endif
-	cmpld	cr6, rWORD5, rWORD6
-	blt	cr7, L(dP2x)
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD7, 0, rSTR1
-	ldbrx	rWORD8, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD7, 8(rSTR1)
-	ld	rWORD8, 8(rSTR2)
-#endif
-	cmpld	cr5, rWORD7, rWORD8
-L(dP2e):
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD1, 0, rSTR1
-	ldbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD1, 16(rSTR1)
-	ld	rWORD2, 16(rSTR2)
-#endif
-	cmpld	cr7, rWORD1, rWORD2
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD3, 0, rSTR1
-	ldbrx	rWORD4, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD3, 24(rSTR1)
-	ld	rWORD4, 24(rSTR2)
-#endif
-	cmpld	cr1, rWORD3, rWORD4
-#ifndef __LITTLE_ENDIAN__
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#endif
-	bne	cr6, L(dLcr6)
-	bne	cr5, L(dLcr5)
-	b	L(dLoop2)
-/* Again we are on a early exit path (16-23 byte compare), we want to
-   only use volatile registers and avoid restoring non-volatile
-   registers.  */
-	.align	4
-L(dP2x):
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD3, 0, rSTR1
-	ldbrx	rWORD4, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD3, 8(rSTR1)
-	ld	rWORD4, 8(rSTR2)
-#endif
-	cmpld	cr1, rWORD3, rWORD4
-	sldi.	r12, rN, 3
-	bne	cr6, L(dLcr6x)
-#ifndef __LITTLE_ENDIAN__
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#endif
-	bne	cr1, L(dLcr1x)
-	subfic	rN, r12, 64	/* Shift count is 64 - (rN * 8).  */
-	bne	L(d00)
-	li	rRTN, 0
-	blr
-
-/* Remainder is 24 */
-	.align	4
-L(dP3):
-	mtctr	r0	/* Power4 wants mtctr 1st in dispatch group */
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD3, 0, rSTR1
-	ldbrx	rWORD4, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD3, 0(rSTR1)
-	ld	rWORD4, 0(rSTR2)
-#endif
-	cmpld	cr1, rWORD3, rWORD4
-L(dP3e):
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD5, 0, rSTR1
-	ldbrx	rWORD6, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD5, 8(rSTR1)
-	ld	rWORD6, 8(rSTR2)
-#endif
-	cmpld	cr6, rWORD5, rWORD6
-	blt	cr7, L(dP3x)
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD7, 0, rSTR1
-	ldbrx	rWORD8, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD7, 16(rSTR1)
-	ld	rWORD8, 16(rSTR2)
-#endif
-	cmpld	cr5, rWORD7, rWORD8
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD1, 0, rSTR1
-	ldbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD1, 24(rSTR1)
-	ld	rWORD2, 24(rSTR2)
-#endif
-	cmpld	cr7, rWORD1, rWORD2
-#ifndef __LITTLE_ENDIAN__
-	addi	rSTR1, rSTR1, 16
-	addi	rSTR2, rSTR2, 16
-#endif
-	bne	cr1, L(dLcr1)
-	bne	cr6, L(dLcr6)
-	b	L(dLoop1)
-/* Again we are on a early exit path (24-31 byte compare), we want to
-   only use volatile registers and avoid restoring non-volatile
-   registers.  */
-	.align	4
-L(dP3x):
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD1, 0, rSTR1
-	ldbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD1, 16(rSTR1)
-	ld	rWORD2, 16(rSTR2)
-#endif
-	cmpld	cr7, rWORD1, rWORD2
-	sldi.	r12, rN, 3
-	bne	cr1, L(dLcr1x)
-#ifndef __LITTLE_ENDIAN__
-	addi	rSTR1, rSTR1, 16
-	addi	rSTR2, rSTR2, 16
-#endif
-	bne	cr6, L(dLcr6x)
-	subfic	rN, r12, 64	/* Shift count is 64 - (rN * 8).  */
-	bne	cr7, L(dLcr7x)
-	bne	L(d00)
-	li	rRTN, 0
-	blr
-
-/* Count is a multiple of 32, remainder is 0 */
-	.align	4
-L(dP4):
-	mtctr	r0	/* Power4 wants mtctr 1st in dispatch group */
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD1, 0, rSTR1
-	ldbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD1, 0(rSTR1)
-	ld	rWORD2, 0(rSTR2)
-#endif
-	cmpld	cr7, rWORD1, rWORD2
-L(dP4e):
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD3, 0, rSTR1
-	ldbrx	rWORD4, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD3, 8(rSTR1)
-	ld	rWORD4, 8(rSTR2)
-#endif
-	cmpld	cr1, rWORD3, rWORD4
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD5, 0, rSTR1
-	ldbrx	rWORD6, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD5, 16(rSTR1)
-	ld	rWORD6, 16(rSTR2)
-#endif
-	cmpld	cr6, rWORD5, rWORD6
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD7, 0, rSTR1
-	ldbrx	rWORD8, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ldu	rWORD7, 24(rSTR1)
-	ldu	rWORD8, 24(rSTR2)
-#endif
-	cmpld	cr5, rWORD7, rWORD8
-	bne	cr7, L(dLcr7)
-	bne	cr1, L(dLcr1)
-	bdz-	L(d24)		/* Adjust CTR as we start with +4 */
-/* This is the primary loop */
-	.align	4
-L(dLoop):
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD1, 0, rSTR1
-	ldbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD1, 8(rSTR1)
-	ld	rWORD2, 8(rSTR2)
-#endif
-	cmpld	cr1, rWORD3, rWORD4
-	bne	cr6, L(dLcr6)
-L(dLoop1):
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD3, 0, rSTR1
-	ldbrx	rWORD4, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD3, 16(rSTR1)
-	ld	rWORD4, 16(rSTR2)
-#endif
-	cmpld	cr6, rWORD5, rWORD6
-	bne	cr5, L(dLcr5)
-L(dLoop2):
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD5, 0, rSTR1
-	ldbrx	rWORD6, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD5, 24(rSTR1)
-	ld	rWORD6, 24(rSTR2)
-#endif
-	cmpld	cr5, rWORD7, rWORD8
-	bne	cr7, L(dLcr7)
-L(dLoop3):
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD7, 0, rSTR1
-	ldbrx	rWORD8, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ldu	rWORD7, 32(rSTR1)
-	ldu	rWORD8, 32(rSTR2)
-#endif
-	bne-	cr1, L(dLcr1)
-	cmpld	cr7, rWORD1, rWORD2
-	bdnz+	L(dLoop)
-
-L(dL4):
-	cmpld	cr1, rWORD3, rWORD4
-	bne	cr6, L(dLcr6)
-	cmpld	cr6, rWORD5, rWORD6
-	bne	cr5, L(dLcr5)
-	cmpld	cr5, rWORD7, rWORD8
-L(d44):
-	bne	cr7, L(dLcr7)
-L(d34):
-	bne	cr1, L(dLcr1)
-L(d24):
-	bne	cr6, L(dLcr6)
-L(d14):
-	sldi.	r12, rN, 3
-	bne	cr5, L(dLcr5)
-L(d04):
-	ld	rWORD8, -8(r1)
-	ld	rWORD7, -16(r1)
-	subfic	rN, r12, 64	/* Shift count is 64 - (rN * 8).  */
-	beq	L(zeroLength)
-/* At this point we have a remainder of 1 to 7 bytes to compare.  Since
-   we are aligned it is safe to load the whole double word, and use
-   shift right double to eliminate bits beyond the compare length.  */
-L(d00):
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD1, 0, rSTR1
-	ldbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD1, 8(rSTR1)
-	ld	rWORD2, 8(rSTR2)
-#endif
-	srd	rWORD1, rWORD1, rN
-	srd	rWORD2, rWORD2, rN
-	cmpld	cr7, rWORD1, rWORD2
-	bne	cr7, L(dLcr7x)
-	li	rRTN, 0
-	blr
-
-	.align	4
-L(dLcr7):
-	ld	rWORD8, -8(r1)
-	ld	rWORD7, -16(r1)
-L(dLcr7x):
-	li	rRTN, 1
-	bgtlr	cr7
-	li	rRTN, -1
-	blr
-	.align	4
-L(dLcr1):
-	ld	rWORD8, -8(r1)
-	ld	rWORD7, -16(r1)
-L(dLcr1x):
-	li	rRTN, 1
-	bgtlr	cr1
-	li	rRTN, -1
-	blr
-	.align	4
-L(dLcr6):
-	ld	rWORD8, -8(r1)
-	ld	rWORD7, -16(r1)
-L(dLcr6x):
-	li	rRTN, 1
-	bgtlr	cr6
-	li	rRTN, -1
-	blr
-	.align	4
-L(dLcr5):
-	ld	rWORD8, -8(r1)
-	ld	rWORD7, -16(r1)
-L(dLcr5x):
-	li	rRTN, 1
-	bgtlr	cr5
-	li	rRTN, -1
-	blr
-
-	.align	4
-L(bytealigned):
-	mtctr	rN	/* Power4 wants mtctr 1st in dispatch group */
-#if 0
-/* Huh?  We've already branched on cr6!  */
-	beq-	cr6, L(zeroLength)
-#endif
-
-/* We need to prime this loop.  This loop is swing modulo scheduled
-   to avoid pipe delays.  The dependent instruction latencies (load to
-   compare to conditional branch) is 2 to 3 cycles.  In this loop each
-   dispatch group ends in a branch and takes 1 cycle.  Effectively
-   the first iteration of the loop only serves to load operands and
-   branches based on compares are delayed until the next loop.
-
-   So we must precondition some registers and condition codes so that
-   we don't exit the loop early on the first iteration.  */
-
-	lbz	rWORD1, 0(rSTR1)
-	lbz	rWORD2, 0(rSTR2)
-	bdz-	L(b11)
-	cmpld	cr7, rWORD1, rWORD2
-	lbz	rWORD3, 1(rSTR1)
-	lbz	rWORD4, 1(rSTR2)
-	bdz-	L(b12)
-	cmpld	cr1, rWORD3, rWORD4
-	lbzu	rWORD5, 2(rSTR1)
-	lbzu	rWORD6, 2(rSTR2)
-	bdz-	L(b13)
-	.align	4
-L(bLoop):
-	lbzu	rWORD1, 1(rSTR1)
-	lbzu	rWORD2, 1(rSTR2)
-	bne-	cr7, L(bLcr7)
-
-	cmpld	cr6, rWORD5, rWORD6
-	bdz-	L(b3i)
-
-	lbzu	rWORD3, 1(rSTR1)
-	lbzu	rWORD4, 1(rSTR2)
-	bne-	cr1, L(bLcr1)
-
-	cmpld	cr7, rWORD1, rWORD2
-	bdz-	L(b2i)
-
-	lbzu	rWORD5, 1(rSTR1)
-	lbzu	rWORD6, 1(rSTR2)
-	bne-	cr6, L(bLcr6)
-
-	cmpld	cr1, rWORD3, rWORD4
-	bdnz+	L(bLoop)
-
-/* We speculatively loading bytes before we have tested the previous
-   bytes.  But we must avoid overrunning the length (in the ctr) to
-   prevent these speculative loads from causing a segfault.  In this
-   case the loop will exit early (before the all pending bytes are
-   tested.  In this case we must complete the pending operations
-   before returning.  */
-L(b1i):
-	bne-	cr7, L(bLcr7)
-	bne-	cr1, L(bLcr1)
-	b	L(bx56)
-	.align	4
-L(b2i):
-	bne-	cr6, L(bLcr6)
-	bne-	cr7, L(bLcr7)
-	b	L(bx34)
-	.align	4
-L(b3i):
-	bne-	cr1, L(bLcr1)
-	bne-	cr6, L(bLcr6)
-	b	L(bx12)
-	.align	4
-L(bLcr7):
-	li	rRTN, 1
-	bgtlr	cr7
-	li	rRTN, -1
-	blr
-L(bLcr1):
-	li	rRTN, 1
-	bgtlr	cr1
-	li	rRTN, -1
-	blr
-L(bLcr6):
-	li	rRTN, 1
-	bgtlr	cr6
-	li	rRTN, -1
-	blr
-
-L(b13):
-	bne-	cr7, L(bx12)
-	bne-	cr1, L(bx34)
-L(bx56):
-	sub	rRTN, rWORD5, rWORD6
-	blr
-	nop
-L(b12):
-	bne-	cr7, L(bx12)
-L(bx34):
-	sub	rRTN, rWORD3, rWORD4
-	blr
-L(b11):
-L(bx12):
-	sub	rRTN, rWORD1, rWORD2
-	blr
-	.align	4
-L(zeroLength):
-	li	rRTN, 0
-	blr
-
-	.align	4
-/* At this point we know the strings have different alignment and the
-   compare length is at least 8 bytes.  r12 contains the low order
-   3 bits of rSTR1 and cr5 contains the result of the logical compare
-   of r12 to 0.  If r12 == 0 then rStr1 is double word
-   aligned and can perform the DWunaligned loop.
-
-   Otherwise we know that rSTR1 is not already DW aligned yet.
-   So we can force the string addresses to the next lower DW
-   boundary and special case this first DW using shift left to
-   eliminate bits preceding the first byte.  Since we want to join the
-   normal (DWaligned) compare loop, starting at the second double word,
-   we need to adjust the length (rN) and special case the loop
-   versioning for the first DW. This ensures that the loop count is
-   correct and the first DW (shifted) is in the expected resister pair.  */
-#define rSHL		r29	/* Unaligned shift left count.  */
-#define rSHR		r28	/* Unaligned shift right count.  */
-#define rWORD8_SHIFT	r27	/* Left rotation temp for rWORD2.  */
-#define rWORD2_SHIFT	r26	/* Left rotation temp for rWORD4.  */
-#define rWORD4_SHIFT	r25	/* Left rotation temp for rWORD6.  */
-#define rWORD6_SHIFT	r24	/* Left rotation temp for rWORD8.  */
-L(unaligned):
-	std	rSHL, -24(r1)
-	cfi_offset(rSHL, -24)
-	clrldi	rSHL, rSTR2, 61
-	beq-	cr6, L(duzeroLength)
-	std	rSHR, -32(r1)
-	cfi_offset(rSHR, -32)
-	beq	cr5, L(DWunaligned)
-	std	rWORD8_SHIFT, -40(r1)
-	cfi_offset(rWORD8_SHIFT, -40)
-/* Adjust the logical start of rSTR2 to compensate for the extra bits
-   in the 1st rSTR1 DW.  */
-	sub	rWORD8_SHIFT, rSTR2, r12
-/* But do not attempt to address the DW before that DW that contains
-   the actual start of rSTR2.  */
-	clrrdi	rSTR2, rSTR2, 3
-	std	rWORD2_SHIFT, -48(r1)
-/* Compute the left/right shift counts for the unaligned rSTR2,
-   compensating for the logical (DW aligned) start of rSTR1.  */
-	clrldi	rSHL, rWORD8_SHIFT, 61
-	clrrdi	rSTR1, rSTR1, 3
-	std	rWORD4_SHIFT, -56(r1)
-	sldi	rSHL, rSHL, 3
-	cmpld	cr5, rWORD8_SHIFT, rSTR2
-	add	rN, rN, r12
-	sldi	rWORD6, r12, 3
-	std	rWORD6_SHIFT, -64(r1)
-	cfi_offset(rWORD2_SHIFT, -48)
-	cfi_offset(rWORD4_SHIFT, -56)
-	cfi_offset(rWORD6_SHIFT, -64)
-	subfic	rSHR, rSHL, 64
-	srdi	r0, rN, 5	/* Divide by 32 */
-	andi.	r12, rN, 24	/* Get the DW remainder */
-/* We normally need to load 2 DWs to start the unaligned rSTR2, but in
-   this special case those bits may be discarded anyway.  Also we
-   must avoid loading a DW where none of the bits are part of rSTR2 as
-   this may cross a page boundary and cause a page fault.  */
-	li	rWORD8, 0
-	blt	cr5, L(dus0)
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD8, 0, rSTR2
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD8, 0(rSTR2)
-	addi	rSTR2, rSTR2, 8
-#endif
-	sld	rWORD8, rWORD8, rSHL
-
-L(dus0):
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD1, 0, rSTR1
-	ldbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD1, 0(rSTR1)
-	ld	rWORD2, 0(rSTR2)
-#endif
-	cmpldi	cr1, r12, 16
-	cmpldi	cr7, rN, 32
-	srd	r12, rWORD2, rSHR
-	clrldi	rN, rN, 61
-	beq	L(duPs4)
-	mtctr	r0	/* Power4 wants mtctr 1st in dispatch group */
-	or	rWORD8, r12, rWORD8
-	bgt	cr1, L(duPs3)
-	beq	cr1, L(duPs2)
-
-/* Remainder is 8 */
-	.align	4
-L(dusP1):
-	sld	rWORD8_SHIFT, rWORD2, rSHL
-	sld	rWORD7, rWORD1, rWORD6
-	sld	rWORD8, rWORD8, rWORD6
-	bge	cr7, L(duP1e)
-/* At this point we exit early with the first double word compare
-   complete and remainder of 0 to 7 bytes.  See L(du14) for details on
-   how we handle the remaining bytes.  */
-	cmpld	cr5, rWORD7, rWORD8
-	sldi.	rN, rN, 3
-	bne	cr5, L(duLcr5)
-	cmpld	cr7, rN, rSHR
-	beq	L(duZeroReturn)
-	li	r0, 0
-	ble	cr7, L(dutrim)
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD2, 0, rSTR2
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD2, 8(rSTR2)
-#endif
-	srd	r0, rWORD2, rSHR
-	b	L(dutrim)
-/* Remainder is 16 */
-	.align	4
-L(duPs2):
-	sld	rWORD6_SHIFT, rWORD2, rSHL
-	sld	rWORD5, rWORD1, rWORD6
-	sld	rWORD6, rWORD8, rWORD6
-	b	L(duP2e)
-/* Remainder is 24 */
-	.align	4
-L(duPs3):
-	sld	rWORD4_SHIFT, rWORD2, rSHL
-	sld	rWORD3, rWORD1, rWORD6
-	sld	rWORD4, rWORD8, rWORD6
-	b	L(duP3e)
-/* Count is a multiple of 32, remainder is 0 */
-	.align	4
-L(duPs4):
-	mtctr	r0	/* Power4 wants mtctr 1st in dispatch group */
-	or	rWORD8, r12, rWORD8
-	sld	rWORD2_SHIFT, rWORD2, rSHL
-	sld	rWORD1, rWORD1, rWORD6
-	sld	rWORD2, rWORD8, rWORD6
-	b	L(duP4e)
-
-/* At this point we know rSTR1 is double word aligned and the
-   compare length is at least 8 bytes.  */
-	.align	4
-L(DWunaligned):
-	std	rWORD8_SHIFT, -40(r1)
-	clrrdi	rSTR2, rSTR2, 3
-	std	rWORD2_SHIFT, -48(r1)
-	srdi	r0, rN, 5	/* Divide by 32 */
-	std	rWORD4_SHIFT, -56(r1)
-	andi.	r12, rN, 24	/* Get the DW remainder */
-	std	rWORD6_SHIFT, -64(r1)
-	cfi_offset(rWORD8_SHIFT, -40)
-	cfi_offset(rWORD2_SHIFT, -48)
-	cfi_offset(rWORD4_SHIFT, -56)
-	cfi_offset(rWORD6_SHIFT, -64)
-	sldi	rSHL, rSHL, 3
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD6, 0, rSTR2
-	addi	rSTR2, rSTR2, 8
-	ldbrx	rWORD8, 0, rSTR2
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD6, 0(rSTR2)
-	ldu	rWORD8, 8(rSTR2)
-#endif
-	cmpldi	cr1, r12, 16
-	cmpldi	cr7, rN, 32
-	clrldi	rN, rN, 61
-	subfic	rSHR, rSHL, 64
-	sld	rWORD6_SHIFT, rWORD6, rSHL
-	beq	L(duP4)
-	mtctr	r0	/* Power4 wants mtctr 1st in dispatch group */
-	bgt	cr1, L(duP3)
-	beq	cr1, L(duP2)
-
-/* Remainder is 8 */
-	.align	4
-L(duP1):
-	srd	r12, rWORD8, rSHR
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD7, 0, rSTR1
-	addi	rSTR1, rSTR1, 8
-#else
-	ld	rWORD7, 0(rSTR1)
-#endif
-	sld	rWORD8_SHIFT, rWORD8, rSHL
-	or	rWORD8, r12, rWORD6_SHIFT
-	blt	cr7, L(duP1x)
-L(duP1e):
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD1, 0, rSTR1
-	ldbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD1, 8(rSTR1)
-	ld	rWORD2, 8(rSTR2)
-#endif
-	cmpld	cr5, rWORD7, rWORD8
-	srd	r0, rWORD2, rSHR
-	sld	rWORD2_SHIFT, rWORD2, rSHL
-	or	rWORD2, r0, rWORD8_SHIFT
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD3, 0, rSTR1
-	ldbrx	rWORD4, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD3, 16(rSTR1)
-	ld	rWORD4, 16(rSTR2)
-#endif
-	cmpld	cr7, rWORD1, rWORD2
-	srd	r12, rWORD4, rSHR
-	sld	rWORD4_SHIFT, rWORD4, rSHL
-	bne	cr5, L(duLcr5)
-	or	rWORD4, r12, rWORD2_SHIFT
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD5, 0, rSTR1
-	ldbrx	rWORD6, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD5, 24(rSTR1)
-	ld	rWORD6, 24(rSTR2)
-#endif
-	cmpld	cr1, rWORD3, rWORD4
-	srd	r0, rWORD6, rSHR
-	sld	rWORD6_SHIFT, rWORD6, rSHL
-	bne	cr7, L(duLcr7)
-	or	rWORD6, r0, rWORD4_SHIFT
-	cmpld	cr6, rWORD5, rWORD6
-	b	L(duLoop3)
-	.align	4
-/* At this point we exit early with the first double word compare
-   complete and remainder of 0 to 7 bytes.  See L(du14) for details on
-   how we handle the remaining bytes.  */
-L(duP1x):
-	cmpld	cr5, rWORD7, rWORD8
-	sldi.	rN, rN, 3
-	bne	cr5, L(duLcr5)
-	cmpld	cr7, rN, rSHR
-	beq	L(duZeroReturn)
-	li	r0, 0
-	ble	cr7, L(dutrim)
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD2, 0, rSTR2
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD2, 8(rSTR2)
-#endif
-	srd	r0, rWORD2, rSHR
-	b	L(dutrim)
-/* Remainder is 16 */
-	.align	4
-L(duP2):
-	srd	r0, rWORD8, rSHR
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD5, 0, rSTR1
-	addi	rSTR1, rSTR1, 8
-#else
-	ld	rWORD5, 0(rSTR1)
-#endif
-	or	rWORD6, r0, rWORD6_SHIFT
-	sld	rWORD6_SHIFT, rWORD8, rSHL
-L(duP2e):
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD7, 0, rSTR1
-	ldbrx	rWORD8, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD7, 8(rSTR1)
-	ld	rWORD8, 8(rSTR2)
-#endif
-	cmpld	cr6, rWORD5, rWORD6
-	srd	r12, rWORD8, rSHR
-	sld	rWORD8_SHIFT, rWORD8, rSHL
-	or	rWORD8, r12, rWORD6_SHIFT
-	blt	cr7, L(duP2x)
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD1, 0, rSTR1
-	ldbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD1, 16(rSTR1)
-	ld	rWORD2, 16(rSTR2)
-#endif
-	cmpld	cr5, rWORD7, rWORD8
-	bne	cr6, L(duLcr6)
-	srd	r0, rWORD2, rSHR
-	sld	rWORD2_SHIFT, rWORD2, rSHL
-	or	rWORD2, r0, rWORD8_SHIFT
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD3, 0, rSTR1
-	ldbrx	rWORD4, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD3, 24(rSTR1)
-	ld	rWORD4, 24(rSTR2)
-#endif
-	cmpld	cr7, rWORD1, rWORD2
-	bne	cr5, L(duLcr5)
-	srd	r12, rWORD4, rSHR
-	sld	rWORD4_SHIFT, rWORD4, rSHL
-	or	rWORD4, r12, rWORD2_SHIFT
-#ifndef __LITTLE_ENDIAN__
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#endif
-	cmpld	cr1, rWORD3, rWORD4
-	b	L(duLoop2)
-	.align	4
-L(duP2x):
-	cmpld	cr5, rWORD7, rWORD8
-#ifndef __LITTLE_ENDIAN__
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#endif
-	bne	cr6, L(duLcr6)
-	sldi.	rN, rN, 3
-	bne	cr5, L(duLcr5)
-	cmpld	cr7, rN, rSHR
-	beq	L(duZeroReturn)
-	li	r0, 0
-	ble	cr7, L(dutrim)
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD2, 0, rSTR2
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD2, 8(rSTR2)
-#endif
-	srd	r0, rWORD2, rSHR
-	b	L(dutrim)
-
-/* Remainder is 24 */
-	.align	4
-L(duP3):
-	srd	r12, rWORD8, rSHR
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD3, 0, rSTR1
-	addi	rSTR1, rSTR1, 8
-#else
-	ld	rWORD3, 0(rSTR1)
-#endif
-	sld	rWORD4_SHIFT, rWORD8, rSHL
-	or	rWORD4, r12, rWORD6_SHIFT
-L(duP3e):
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD5, 0, rSTR1
-	ldbrx	rWORD6, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD5, 8(rSTR1)
-	ld	rWORD6, 8(rSTR2)
-#endif
-	cmpld	cr1, rWORD3, rWORD4
-	srd	r0, rWORD6, rSHR
-	sld	rWORD6_SHIFT, rWORD6, rSHL
-	or	rWORD6, r0, rWORD4_SHIFT
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD7, 0, rSTR1
-	ldbrx	rWORD8, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD7, 16(rSTR1)
-	ld	rWORD8, 16(rSTR2)
-#endif
-	cmpld	cr6, rWORD5, rWORD6
-	bne	cr1, L(duLcr1)
-	srd	r12, rWORD8, rSHR
-	sld	rWORD8_SHIFT, rWORD8, rSHL
-	or	rWORD8, r12, rWORD6_SHIFT
-	blt	cr7, L(duP3x)
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD1, 0, rSTR1
-	ldbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD1, 24(rSTR1)
-	ld	rWORD2, 24(rSTR2)
-#endif
-	cmpld	cr5, rWORD7, rWORD8
-	bne	cr6, L(duLcr6)
-	srd	r0, rWORD2, rSHR
-	sld	rWORD2_SHIFT, rWORD2, rSHL
-	or	rWORD2, r0, rWORD8_SHIFT
-#ifndef __LITTLE_ENDIAN__
-	addi	rSTR1, rSTR1, 16
-	addi	rSTR2, rSTR2, 16
-#endif
-	cmpld	cr7, rWORD1, rWORD2
-	b	L(duLoop1)
-	.align	4
-L(duP3x):
-#ifndef __LITTLE_ENDIAN__
-	addi	rSTR1, rSTR1, 16
-	addi	rSTR2, rSTR2, 16
-#endif
-#if 0
-/* Huh?  We've already branched on cr1!  */
-	bne	cr1, L(duLcr1)
-#endif
-	cmpld	cr5, rWORD7, rWORD8
-	bne	cr6, L(duLcr6)
-	sldi.	rN, rN, 3
-	bne	cr5, L(duLcr5)
-	cmpld	cr7, rN, rSHR
-	beq	L(duZeroReturn)
-	li	r0, 0
-	ble	cr7, L(dutrim)
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD2, 0, rSTR2
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD2, 8(rSTR2)
-#endif
-	srd	r0, rWORD2, rSHR
-	b	L(dutrim)
-
-/* Count is a multiple of 32, remainder is 0 */
-	.align	4
-L(duP4):
-	mtctr	r0	/* Power4 wants mtctr 1st in dispatch group */
-	srd	r0, rWORD8, rSHR
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD1, 0, rSTR1
-	addi	rSTR1, rSTR1, 8
-#else
-	ld	rWORD1, 0(rSTR1)
-#endif
-	sld	rWORD2_SHIFT, rWORD8, rSHL
-	or	rWORD2, r0, rWORD6_SHIFT
-L(duP4e):
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD3, 0, rSTR1
-	ldbrx	rWORD4, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD3, 8(rSTR1)
-	ld	rWORD4, 8(rSTR2)
-#endif
-	cmpld	cr7, rWORD1, rWORD2
-	srd	r12, rWORD4, rSHR
-	sld	rWORD4_SHIFT, rWORD4, rSHL
-	or	rWORD4, r12, rWORD2_SHIFT
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD5, 0, rSTR1
-	ldbrx	rWORD6, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD5, 16(rSTR1)
-	ld	rWORD6, 16(rSTR2)
-#endif
-	cmpld	cr1, rWORD3, rWORD4
-	bne	cr7, L(duLcr7)
-	srd	r0, rWORD6, rSHR
-	sld	rWORD6_SHIFT, rWORD6, rSHL
-	or	rWORD6, r0, rWORD4_SHIFT
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD7, 0, rSTR1
-	ldbrx	rWORD8, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ldu	rWORD7, 24(rSTR1)
-	ldu	rWORD8, 24(rSTR2)
-#endif
-	cmpld	cr6, rWORD5, rWORD6
-	bne	cr1, L(duLcr1)
-	srd	r12, rWORD8, rSHR
-	sld	rWORD8_SHIFT, rWORD8, rSHL
-	or	rWORD8, r12, rWORD6_SHIFT
-	cmpld	cr5, rWORD7, rWORD8
-	bdz-	L(du24)		/* Adjust CTR as we start with +4 */
-/* This is the primary loop */
-	.align	4
-L(duLoop):
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD1, 0, rSTR1
-	ldbrx	rWORD2, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD1, 8(rSTR1)
-	ld	rWORD2, 8(rSTR2)
-#endif
-	cmpld	cr1, rWORD3, rWORD4
-	bne	cr6, L(duLcr6)
-	srd	r0, rWORD2, rSHR
-	sld	rWORD2_SHIFT, rWORD2, rSHL
-	or	rWORD2, r0, rWORD8_SHIFT
-L(duLoop1):
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD3, 0, rSTR1
-	ldbrx	rWORD4, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD3, 16(rSTR1)
-	ld	rWORD4, 16(rSTR2)
-#endif
-	cmpld	cr6, rWORD5, rWORD6
-	bne	cr5, L(duLcr5)
-	srd	r12, rWORD4, rSHR
-	sld	rWORD4_SHIFT, rWORD4, rSHL
-	or	rWORD4, r12, rWORD2_SHIFT
-L(duLoop2):
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD5, 0, rSTR1
-	ldbrx	rWORD6, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD5, 24(rSTR1)
-	ld	rWORD6, 24(rSTR2)
-#endif
-	cmpld	cr5, rWORD7, rWORD8
-	bne	cr7, L(duLcr7)
-	srd	r0, rWORD6, rSHR
-	sld	rWORD6_SHIFT, rWORD6, rSHL
-	or	rWORD6, r0, rWORD4_SHIFT
-L(duLoop3):
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD7, 0, rSTR1
-	ldbrx	rWORD8, 0, rSTR2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-#else
-	ldu	rWORD7, 32(rSTR1)
-	ldu	rWORD8, 32(rSTR2)
-#endif
-	cmpld	cr7, rWORD1, rWORD2
-	bne-	cr1, L(duLcr1)
-	srd	r12, rWORD8, rSHR
-	sld	rWORD8_SHIFT, rWORD8, rSHL
-	or	rWORD8, r12, rWORD6_SHIFT
-	bdnz+	L(duLoop)
-
-L(duL4):
-#if 0
-/* Huh?  We've already branched on cr1!  */
-	bne	cr1, L(duLcr1)
-#endif
-	cmpld	cr1, rWORD3, rWORD4
-	bne	cr6, L(duLcr6)
-	cmpld	cr6, rWORD5, rWORD6
-	bne	cr5, L(duLcr5)
-	cmpld	cr5, rWORD7, rWORD8
-L(du44):
-	bne	cr7, L(duLcr7)
-L(du34):
-	bne	cr1, L(duLcr1)
-L(du24):
-	bne	cr6, L(duLcr6)
-L(du14):
-	sldi.	rN, rN, 3
-	bne	cr5, L(duLcr5)
-/* At this point we have a remainder of 1 to 7 bytes to compare.  We use
-   shift right double to eliminate bits beyond the compare length.
-
-   However it may not be safe to load rWORD2 which may be beyond the
-   string length. So we compare the bit length of the remainder to
-   the right shift count (rSHR). If the bit count is less than or equal
-   we do not need to load rWORD2 (all significant bits are already in
-   rWORD8_SHIFT).  */
-	cmpld	cr7, rN, rSHR
-	beq	L(duZeroReturn)
-	li	r0, 0
-	ble	cr7, L(dutrim)
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD2, 0, rSTR2
-	addi	rSTR2, rSTR2, 8
-#else
-	ld	rWORD2, 8(rSTR2)
-#endif
-	srd	r0, rWORD2, rSHR
-	.align	4
-L(dutrim):
-#ifdef __LITTLE_ENDIAN__
-	ldbrx	rWORD1, 0, rSTR1
-#else
-	ld	rWORD1, 8(rSTR1)
-#endif
-	ld	rWORD8, -8(r1)
-	subfic	rN, rN, 64	/* Shift count is 64 - (rN * 8).  */
-	or	rWORD2, r0, rWORD8_SHIFT
-	ld	rWORD7, -16(r1)
-	ld	rSHL, -24(r1)
-	srd	rWORD1, rWORD1, rN
-	srd	rWORD2, rWORD2, rN
-	ld	rSHR, -32(r1)
-	ld	rWORD8_SHIFT, -40(r1)
-	li	rRTN, 0
-	cmpld	cr7, rWORD1, rWORD2
-	ld	rWORD2_SHIFT, -48(r1)
-	ld	rWORD4_SHIFT, -56(r1)
-	beq	cr7, L(dureturn24)
-	li	rRTN, 1
-	ld	rWORD6_SHIFT, -64(r1)
-	bgtlr	cr7
-	li	rRTN, -1
-	blr
-	.align	4
-L(duLcr7):
-	ld	rWORD8, -8(r1)
-	ld	rWORD7, -16(r1)
-	li	rRTN, 1
-	bgt	cr7, L(dureturn29)
-	ld	rSHL, -24(r1)
-	ld	rSHR, -32(r1)
-	li	rRTN, -1
-	b	L(dureturn27)
-	.align	4
-L(duLcr1):
-	ld	rWORD8, -8(r1)
-	ld	rWORD7, -16(r1)
-	li	rRTN, 1
-	bgt	cr1, L(dureturn29)
-	ld	rSHL, -24(r1)
-	ld	rSHR, -32(r1)
-	li	rRTN, -1
-	b	L(dureturn27)
-	.align	4
-L(duLcr6):
-	ld	rWORD8, -8(r1)
-	ld	rWORD7, -16(r1)
-	li	rRTN, 1
-	bgt	cr6, L(dureturn29)
-	ld	rSHL, -24(r1)
-	ld	rSHR, -32(r1)
-	li	rRTN, -1
-	b	L(dureturn27)
-	.align	4
-L(duLcr5):
-	ld	rWORD8, -8(r1)
-	ld	rWORD7, -16(r1)
-	li	rRTN, 1
-	bgt	cr5, L(dureturn29)
-	ld	rSHL, -24(r1)
-	ld	rSHR, -32(r1)
-	li	rRTN, -1
-	b	L(dureturn27)
-	.align	3
-L(duZeroReturn):
-	li	rRTN, 0
-	.align	4
-L(dureturn):
-	ld	rWORD8, -8(r1)
-	ld	rWORD7, -16(r1)
-L(dureturn29):
-	ld	rSHL, -24(r1)
-	ld	rSHR, -32(r1)
-L(dureturn27):
-	ld	rWORD8_SHIFT, -40(r1)
-L(dureturn26):
-	ld	rWORD2_SHIFT, -48(r1)
-L(dureturn25):
-	ld	rWORD4_SHIFT, -56(r1)
-L(dureturn24):
-	ld	rWORD6_SHIFT, -64(r1)
-	blr
-L(duzeroLength):
-	li	rRTN, 0
-	blr
-
-END (MEMCMP)
-libc_hidden_builtin_def (memcmp)
-weak_alias (memcmp, bcmp)
diff --git a/sysdeps/powerpc/powerpc64/power4/memcopy.h b/sysdeps/powerpc/powerpc64/power4/memcopy.h
deleted file mode 100644
index 9a4ff79..0000000
--- a/sysdeps/powerpc/powerpc64/power4/memcopy.h
+++ /dev/null
@@ -1 +0,0 @@
-#include "../../powerpc32/power4/memcopy.h"
diff --git a/sysdeps/powerpc/powerpc64/power4/memcpy.S b/sysdeps/powerpc/powerpc64/power4/memcpy.S
deleted file mode 100644
index ce07494..0000000
--- a/sysdeps/powerpc/powerpc64/power4/memcpy.S
+++ /dev/null
@@ -1,477 +0,0 @@
-/* Optimized memcpy implementation for PowerPC64.
-   Copyright (C) 2003-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* void * [r3] memcpy (void *dst [r3], void *src [r4], size_t len [r5]);
-   Returns 'dst'.
-
-   Memcpy handles short copies (< 32-bytes) using a binary move blocks
-   (no loops) of lwz/stw.  The tail (remaining 1-3) bytes is handled
-   with the appropriate combination of byte and halfword load/stores.
-   There is minimal effort to optimize the alignment of short moves.
-   The 64-bit implementations of POWER3 and POWER4 do a reasonable job
-   of handling unaligned load/stores that do not cross 32-byte boundaries.
-
-   Longer moves (>= 32-bytes) justify the effort to get at least the
-   destination doubleword (8-byte) aligned.  Further optimization is
-   possible when both source and destination are doubleword aligned.
-   Each case has a optimized unrolled loop.   */
-
-#ifndef MEMCPY
-# define MEMCPY memcpy
-#endif
-	.machine power4
-ENTRY_TOCLESS (MEMCPY, 5)
-	CALL_MCOUNT 3
-
-    cmpldi cr1,5,31
-    neg   0,3
-    std   3,-16(1)
-    std   31,-8(1)
-    cfi_offset(31,-8)
-    andi. 11,3,7	/* check alignment of dst.  */
-    clrldi 0,0,61	/* Number of bytes until the 1st doubleword of dst.  */
-    clrldi 10,4,61	/* check alignment of src.  */
-    cmpldi cr6,5,8
-    ble-  cr1,.L2	/* If move < 32 bytes use short move code.  */
-    cmpld cr6,10,11
-    mr    12,4
-    srdi  9,5,3		/* Number of full double words remaining.  */
-    mtcrf 0x01,0
-    mr    31,5
-    beq   .L0
-
-    subf  31,0,5
-  /* Move 0-7 bytes as needed to get the destination doubleword aligned.  */
-1:  bf    31,2f
-    lbz   6,0(12)
-    addi  12,12,1
-    stb   6,0(3)
-    addi  3,3,1
-2:  bf    30,4f
-    lhz   6,0(12)
-    addi  12,12,2
-    sth   6,0(3)
-    addi  3,3,2
-4:  bf    29,0f
-    lwz   6,0(12)
-    addi  12,12,4
-    stw   6,0(3)
-    addi  3,3,4
-0:
-    clrldi 10,12,61	/* check alignment of src again.  */
-    srdi  9,31,3	/* Number of full double words remaining.  */
-
-  /* Copy doublewords from source to destination, assuming the
-     destination is aligned on a doubleword boundary.
-
-     At this point we know there are at least 25 bytes left (32-7) to copy.
-     The next step is to determine if the source is also doubleword aligned.
-     If not branch to the unaligned move code at .L6. which uses
-     a load, shift, store strategy.
-
-     Otherwise source and destination are doubleword aligned, and we can
-     the optimized doubleword copy loop.  */
-.L0:
-    clrldi  11,31,61
-    mtcrf   0x01,9
-    cmpldi  cr1,11,0
-    bne-    cr6,.L6   /* If source is not DW aligned.  */
-
-  /* Move doublewords where destination and source are DW aligned.
-     Use a unrolled loop to copy 4 doubleword (32-bytes) per iteration.
-     If the copy is not an exact multiple of 32 bytes, 1-3
-     doublewords are copied as needed to set up the main loop.  After
-     the main loop exits there may be a tail of 1-7 bytes. These byte are
-     copied a word/halfword/byte at a time as needed to preserve alignment.  */
-
-    srdi  8,31,5
-    cmpldi	cr1,9,4
-    cmpldi	cr6,11,0
-    mr    11,12
-
-    bf    30,1f
-    ld    6,0(12)
-    ld    7,8(12)
-    addi  11,12,16
-    mtctr 8
-    std   6,0(3)
-    std   7,8(3)
-    addi  10,3,16
-    bf    31,4f
-    ld    0,16(12)
-    std   0,16(3)
-    blt   cr1,3f
-    addi  11,12,24
-    addi  10,3,24
-    b     4f
-    .align  4
-1:
-    mr    10,3
-    mtctr 8
-    bf    31,4f
-    ld    6,0(12)
-    addi  11,12,8
-    std   6,0(3)
-    addi  10,3,8
-
-    .align  4
-4:
-    ld    6,0(11)
-    ld    7,8(11)
-    ld    8,16(11)
-    ld    0,24(11)
-    addi  11,11,32
-2:
-    std   6,0(10)
-    std   7,8(10)
-    std   8,16(10)
-    std   0,24(10)
-    addi  10,10,32
-    bdnz  4b
-3:
-
-    rldicr 0,31,0,60
-    mtcrf 0x01,31
-    beq   cr6,0f
-.L9:
-    add   3,3,0
-    add   12,12,0
-
-/*  At this point we have a tail of 0-7 bytes and we know that the
-    destination is double word aligned.  */
-4:  bf    29,2f
-    lwz   6,0(12)
-    addi  12,12,4
-    stw   6,0(3)
-    addi  3,3,4
-2:  bf    30,1f
-    lhz   6,0(12)
-    addi  12,12,2
-    sth   6,0(3)
-    addi  3,3,2
-1:  bf    31,0f
-    lbz   6,0(12)
-    stb   6,0(3)
-0:
-  /* Return original dst pointer.  */
-    ld 31,-8(1)
-    ld 3,-16(1)
-    blr
-
-/* Copy up to 31 bytes.  This divided into two cases 0-8 bytes and 9-31
-   bytes.  Each case is handled without loops, using binary (1,2,4,8)
-   tests.
-
-   In the short (0-8 byte) case no attempt is made to force alignment
-   of either source or destination.  The hardware will handle the
-   unaligned load/stores with small delays for crossing 32- 64-byte, and
-   4096-byte boundaries. Since these short moves are unlikely to be
-   unaligned or cross these boundaries, the overhead to force
-   alignment is not justified.
-
-   The longer (9-31 byte) move is more likely to cross 32- or 64-byte
-   boundaries.  Since only loads are sensitive to the 32-/64-byte
-   boundaries it is more important to align the source then the
-   destination.  If the source is not already word aligned, we first
-   move 1-3 bytes as needed.  Since we are only word aligned we don't
-   use double word load/stores to insure that all loads are aligned.
-   While the destination and stores may still be unaligned, this
-   is only an issue for page (4096 byte boundary) crossing, which
-   should be rare for these short moves.  The hardware handles this
-   case automatically with a small delay.  */
-
-    .align  4
-.L2:
-    mtcrf 0x01,5
-    neg   8,4
-    clrrdi	11,4,2
-    andi. 0,8,3
-    ble   cr6,.LE8	/* Handle moves of 0-8 bytes.  */
-/* At least 9 bytes left.  Get the source word aligned.  */
-    cmpldi	cr1,5,16
-    mr    10,5
-    mr    12,4
-    cmpldi	cr6,0,2
-    beq   .L3	/* If the source is already word aligned skip this.  */
-/* Copy 1-3 bytes to get source address word aligned.  */
-    lwz   6,0(11)
-    subf  10,0,5
-    add   12,4,0
-    blt   cr6,5f
-    srdi  7,6,16
-    bgt	  cr6,3f
-#ifdef __LITTLE_ENDIAN__
-    sth   7,0(3)
-#else
-    sth   6,0(3)
-#endif
-    b     7f
-    .align  4
-3:
-#ifdef __LITTLE_ENDIAN__
-    rotlwi 6,6,24
-    stb   6,0(3)
-    sth   7,1(3)
-#else
-    stb   7,0(3)
-    sth   6,1(3)
-#endif
-    b     7f
-    .align  4
-5:
-#ifdef __LITTLE_ENDIAN__
-    rotlwi 6,6,8
-#endif
-    stb   6,0(3)
-7:
-    cmpldi	cr1,10,16
-    add   3,3,0
-    mtcrf 0x01,10
-    .align  4
-.L3:
-/* At least 6 bytes left and the source is word aligned.  */
-    blt   cr1,8f
-16: /* Move 16 bytes.  */
-    lwz   6,0(12)
-    lwz   7,4(12)
-    stw   6,0(3)
-    lwz   6,8(12)
-    stw   7,4(3)
-    lwz   7,12(12)
-    addi  12,12,16
-    stw   6,8(3)
-    stw   7,12(3)
-    addi  3,3,16
-8:  /* Move 8 bytes.  */
-    bf    28,4f
-    lwz   6,0(12)
-    lwz   7,4(12)
-    addi  12,12,8
-    stw   6,0(3)
-    stw   7,4(3)
-    addi  3,3,8
-4:  /* Move 4 bytes.  */
-    bf    29,2f
-    lwz   6,0(12)
-    addi  12,12,4
-    stw   6,0(3)
-    addi  3,3,4
-2:  /* Move 2-3 bytes.  */
-    bf    30,1f
-    lhz   6,0(12)
-    sth   6,0(3)
-    bf    31,0f
-    lbz   7,2(12)
-    stb   7,2(3)
-    ld 3,-16(1)
-    blr
-1:  /* Move 1 byte.  */
-    bf    31,0f
-    lbz   6,0(12)
-    stb   6,0(3)
-0:
-  /* Return original dst pointer.  */
-    ld    3,-16(1)
-    blr
-
-/* Special case to copy 0-8 bytes.  */
-    .align  4
-.LE8:
-    mr    12,4
-    bne   cr6,4f
-/* Would have liked to use use ld/std here but the 630 processors are
-   slow for load/store doubles that are not at least word aligned.
-   Unaligned Load/Store word execute with only a 1 cycle penalty.  */
-    lwz   6,0(4)
-    lwz   7,4(4)
-    stw   6,0(3)
-    stw   7,4(3)
-  /* Return original dst pointer.  */
-    ld    3,-16(1)
-    blr
-    .align  4
-4:  bf    29,2b
-    lwz   6,0(4)
-    stw   6,0(3)
-6:
-    bf    30,5f
-    lhz   7,4(4)
-    sth   7,4(3)
-    bf    31,0f
-    lbz   8,6(4)
-    stb   8,6(3)
-    ld 3,-16(1)
-    blr
-    .align  4
-5:
-    bf    31,0f
-    lbz   6,4(4)
-    stb   6,4(3)
-    .align  4
-0:
-  /* Return original dst pointer.  */
-    ld    3,-16(1)
-    blr
-
-    .align  4
-.L6:
-
-  /* Copy doublewords where the destination is aligned but the source is
-     not.  Use aligned doubleword loads from the source, shifted to realign
-     the data, to allow aligned destination stores.  */
-    addi    11,9,-1  /* loop DW count is one less than total */
-    subf    5,10,12
-    sldi    10,10,3
-    mr      4,3
-    srdi    8,11,2   /* calculate the 32 byte loop count */
-    ld      6,0(5)
-    mtcrf   0x01,11
-    cmpldi  cr6,9,4
-    mtctr   8
-    ld      7,8(5)
-    subfic  9,10,64
-    bf      30,1f
-
-    /* there are at least two DWs to copy */
-#ifdef __LITTLE_ENDIAN__
-    srd     0,6,10
-    sld     8,7,9
-#else
-    sld     0,6,10
-    srd     8,7,9
-#endif
-    or      0,0,8
-    ld      6,16(5)
-    std     0,0(4)
-#ifdef __LITTLE_ENDIAN__
-    srd     0,7,10
-    sld     8,6,9
-#else
-    sld     0,7,10
-    srd     8,6,9
-#endif
-    or      0,0,8
-    ld      7,24(5)
-    std     0,8(4)
-    addi    4,4,16
-    addi    5,5,32
-    blt     cr6,8f  /* if total DWs = 3, then bypass loop */
-    bf      31,4f
-    /* there is a third DW to copy */
-#ifdef __LITTLE_ENDIAN__
-    srd     0,6,10
-    sld     8,7,9
-#else
-    sld     0,6,10
-    srd     8,7,9
-#endif
-    or      0,0,8
-    std     0,0(4)
-    mr      6,7
-    ld      7,0(5)
-    addi    5,5,8
-    addi    4,4,8
-    beq     cr6,8f  /* if total DWs = 4, then bypass loop */
-    b       4f
-    .align 4
-1:
-#ifdef __LITTLE_ENDIAN__
-    srd     0,6,10
-    sld     8,7,9
-#else
-    sld     0,6,10
-    srd     8,7,9
-#endif
-    addi    5,5,16
-    or      0,0,8
-    bf      31,4f
-    mr      6,7
-    ld      7,0(5)
-    addi    5,5,8
-    std     0,0(4)
-    addi    4,4,8
-    .align 4
-/* copy 32 bytes at a time */
-4:
-#ifdef __LITTLE_ENDIAN__
-    srd   0,6,10
-    sld   8,7,9
-#else
-    sld   0,6,10
-    srd   8,7,9
-#endif
-    or    0,0,8
-    ld    6,0(5)
-    std   0,0(4)
-#ifdef __LITTLE_ENDIAN__
-    srd   0,7,10
-    sld   8,6,9
-#else
-    sld   0,7,10
-    srd   8,6,9
-#endif
-    or    0,0,8
-    ld    7,8(5)
-    std   0,8(4)
-#ifdef __LITTLE_ENDIAN__
-    srd   0,6,10
-    sld   8,7,9
-#else
-    sld   0,6,10
-    srd   8,7,9
-#endif
-    or    0,0,8
-    ld    6,16(5)
-    std   0,16(4)
-#ifdef __LITTLE_ENDIAN__
-    srd   0,7,10
-    sld   8,6,9
-#else
-    sld   0,7,10
-    srd   8,6,9
-#endif
-    or    0,0,8
-    ld    7,24(5)
-    std   0,24(4)
-    addi  5,5,32
-    addi  4,4,32
-    bdnz+ 4b
-    .align 4
-8:
-    /* calculate and store the final DW */
-#ifdef __LITTLE_ENDIAN__
-    srd   0,6,10
-    sld   8,7,9
-#else
-    sld   0,6,10
-    srd   8,7,9
-#endif
-    or    0,0,8
-    std   0,0(4)
-3:
-    rldicr 0,31,0,60
-    mtcrf 0x01,31
-    bne   cr1,.L9	/* If the tail is 0 bytes we are done!  */
-  /* Return original dst pointer.  */
-    ld 31,-8(1)
-    ld 3,-16(1)
-    blr
-END_GEN_TB (MEMCPY,TB_TOCLESS)
-libc_hidden_builtin_def (memcpy)
diff --git a/sysdeps/powerpc/powerpc64/power4/memset.S b/sysdeps/powerpc/powerpc64/power4/memset.S
deleted file mode 100644
index a8f0dfa..0000000
--- a/sysdeps/powerpc/powerpc64/power4/memset.S
+++ /dev/null
@@ -1,251 +0,0 @@
-/* Optimized memset implementation for PowerPC64.
-   Copyright (C) 1997-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* void * [r3] memset (void *s [r3], int c [r4], size_t n [r5]));
-   Returns 's'.
-
-   The memset is done in three sizes: byte (8 bits), word (32 bits),
-   cache line (256 bits). There is a special case for setting cache lines
-   to 0, to take advantage of the dcbz instruction.  */
-
-#ifndef MEMSET
-# define MEMSET memset
-#endif
-	.machine power4
-ENTRY_TOCLESS (MEMSET, 5)
-	CALL_MCOUNT 3
-
-#define rTMP	r0
-#define rRTN	r3	/* Initial value of 1st argument.  */
-#define rMEMP0	r3	/* Original value of 1st arg.  */
-#define rCHR	r4	/* Char to set in each byte.  */
-#define rLEN	r5	/* Length of region to set.  */
-#define rMEMP	r6	/* Address at which we are storing.  */
-#define rALIGN	r7	/* Number of bytes we are setting now (when aligning). */
-#define rMEMP2	r8
-
-#define rNEG64	r8	/* Constant -64 for clearing with dcbz.  */
-#define rCLS	r8	/* Cache line size obtained from static.  */
-#define rCLM	r9	/* Cache line size mask to check for cache alignment.  */
-L(_memset):
-/* Take care of case for size <= 4.  */
-	cmpldi	cr1, rLEN, 8
-	andi.	rALIGN, rMEMP0, 7
-	mr	rMEMP, rMEMP0
-	ble-	cr1, L(small)
-
-/* Align to doubleword boundary.  */
-	cmpldi	cr5, rLEN, 31
-	insrdi	rCHR, rCHR, 8, 48	/* Replicate byte to halfword.  */
-	beq+	L(aligned2)
-	mtcrf	0x01, rMEMP0
-	subfic	rALIGN, rALIGN, 8
-	cror	28,30,31		/* Detect odd word aligned.  */
-	add	rMEMP, rMEMP, rALIGN
-	sub	rLEN, rLEN, rALIGN
-	insrdi	rCHR, rCHR, 16, 32	/* Replicate halfword to word.  */
-	bt	29, L(g4)
-/* Process the even word of doubleword.  */
-	bf+	31, L(g2)
-	stb	rCHR, 0(rMEMP0)
-	bt	30, L(g4x)
-L(g2):
-	sth	rCHR, -6(rMEMP)
-L(g4x):
-	stw	rCHR, -4(rMEMP)
-	b	L(aligned)
-/* Process the odd word of doubleword.  */
-L(g4):
-	bf	28, L(g4x) /* If false, word aligned on odd word.  */
-	bf+	31, L(g0)
-	stb	rCHR, 0(rMEMP0)
-	bt	30, L(aligned)
-L(g0):
-	sth	rCHR, -2(rMEMP)
-
-/* Handle the case of size < 31.  */
-L(aligned2):
-	insrdi	rCHR, rCHR, 16, 32	/* Replicate halfword to word.  */
-L(aligned):
-	mtcrf	0x01, rLEN
-	ble	cr5, L(medium)
-/* Align to 32-byte boundary.  */
-	andi.	rALIGN, rMEMP, 0x18
-	subfic	rALIGN, rALIGN, 0x20
-	insrdi	rCHR, rCHR, 32, 0	/* Replicate word to double word. */
-	beq	L(caligned)
-	mtcrf	0x01, rALIGN
-	add	rMEMP, rMEMP, rALIGN
-	sub	rLEN, rLEN, rALIGN
-	cmplwi	cr1, rALIGN, 0x10
-	mr	rMEMP2, rMEMP
-	bf	28, L(a1)
-	stdu	rCHR, -8(rMEMP2)
-L(a1):	blt	cr1, L(a2)
-	std	rCHR, -8(rMEMP2)
-	stdu	rCHR, -16(rMEMP2)
-L(a2):
-
-/* Now aligned to a 32 byte boundary.  */
-L(caligned):
-	cmpldi	cr1, rCHR, 0
-	clrrdi.	rALIGN, rLEN, 5
-	mtcrf	0x01, rLEN
-	beq	cr1, L(zloopstart) /* Special case for clearing memory using dcbz.  */
-L(nondcbz):
-	srdi	rTMP, rALIGN, 5
-	mtctr	rTMP
-	beq	L(medium)	/* We may not actually get to do a full line.  */
-	clrldi.	rLEN, rLEN, 59
-	add	rMEMP, rMEMP, rALIGN
-	li	rNEG64, -0x40
-	bdz	L(cloopdone)
-
-L(c3):	dcbtst	rNEG64, rMEMP
-	std	rCHR, -8(rMEMP)
-	std	rCHR, -16(rMEMP)
-	std	rCHR, -24(rMEMP)
-	stdu	rCHR, -32(rMEMP)
-	bdnz	L(c3)
-L(cloopdone):
-	std	rCHR, -8(rMEMP)
-	std	rCHR, -16(rMEMP)
-	cmpldi	cr1, rLEN, 16
-	std	rCHR, -24(rMEMP)
-	stdu	rCHR, -32(rMEMP)
-	beqlr
-	add	rMEMP, rMEMP, rALIGN
-	b	L(medium_tail2)
-
-	.align 5
-/* Clear lines of memory in 128-byte chunks.  */
-L(zloopstart):
-/* If the remaining length is less the 32 bytes, don't bother getting
-	 the cache line size.  */
-	beq	L(medium)
-	li      rCLS,128  /* cache line size is 128 */
-
-/* Now we know the cache line size, and it is not 32-bytes, but
-	 we may not yet be aligned to the cache line. May have a partial
-	 line to fill, so touch it 1st.  */
-	dcbt	0,rMEMP
-L(getCacheAligned):
-	cmpldi	cr1,rLEN,32
-	andi.	rTMP,rMEMP,127
-	blt	cr1,L(handletail32)
-	beq	L(cacheAligned)
-	addi	rMEMP,rMEMP,32
-	addi	rLEN,rLEN,-32
-	std	rCHR,-32(rMEMP)
-	std	rCHR,-24(rMEMP)
-	std	rCHR,-16(rMEMP)
-	std	rCHR,-8(rMEMP)
-	b	L(getCacheAligned)
-
-/* Now we are aligned to the cache line and can use dcbz.  */
-L(cacheAligned):
-	cmpld	cr1,rLEN,rCLS
-	blt	cr1,L(handletail32)
-	dcbz	0,rMEMP
-	subf	rLEN,rCLS,rLEN
-	add	rMEMP,rMEMP,rCLS
-	b	L(cacheAligned)
-
-/* We are here because the cache line size was set and was not 32-bytes
-   and the remainder (rLEN) is less than the actual cache line size.
-   So set up the preconditions for L(nondcbz) and go there.  */
-L(handletail32):
-	clrrwi.	rALIGN, rLEN, 5
-	b		L(nondcbz)
-
-	.align 5
-L(small):
-/* Memset of 8 bytes or less.  */
-	cmpldi	cr6, rLEN, 4
-	cmpldi	cr5, rLEN, 1
-	ble	cr6,L(le4)
-	subi	rLEN, rLEN, 4
-	stb	rCHR,0(rMEMP)
-	stb	rCHR,1(rMEMP)
-	stb	rCHR,2(rMEMP)
-	stb	rCHR,3(rMEMP)
-	addi	rMEMP,rMEMP, 4
-	cmpldi	cr5, rLEN, 1
-L(le4):
-	cmpldi	cr1, rLEN, 3
-	bltlr	cr5
-	stb	rCHR, 0(rMEMP)
-	beqlr	cr5
-	stb	rCHR, 1(rMEMP)
-	bltlr	cr1
-	stb	rCHR, 2(rMEMP)
-	beqlr	cr1
-	stb	rCHR, 3(rMEMP)
-	blr
-
-/* Memset of 0-31 bytes.  */
-	.align 5
-L(medium):
-	insrdi	rCHR, rCHR, 32, 0	/* Replicate word to double word.  */
-	cmpldi	cr1, rLEN, 16
-L(medium_tail2):
-	add	rMEMP, rMEMP, rLEN
-L(medium_tail):
-	bt-	31, L(medium_31t)
-	bt-	30, L(medium_30t)
-L(medium_30f):
-	bt-	29, L(medium_29t)
-L(medium_29f):
-	bge-	cr1, L(medium_27t)
-	bflr-	28
-	std	rCHR, -8(rMEMP)
-	blr
-
-L(medium_31t):
-	stbu	rCHR, -1(rMEMP)
-	bf-	30, L(medium_30f)
-L(medium_30t):
-	sthu	rCHR, -2(rMEMP)
-	bf-	29, L(medium_29f)
-L(medium_29t):
-	stwu	rCHR, -4(rMEMP)
-	blt-	cr1, L(medium_27f)
-L(medium_27t):
-	std	rCHR, -8(rMEMP)
-	stdu	rCHR, -16(rMEMP)
-L(medium_27f):
-	bflr-	28
-L(medium_28t):
-	std	rCHR, -8(rMEMP)
-	blr
-END_GEN_TB (MEMSET,TB_TOCLESS)
-libc_hidden_builtin_def (memset)
-
-/* Copied from bzero.S to prevent the linker from inserting a stub
-   between bzero and memset.  */
-ENTRY_TOCLESS (__bzero)
-	CALL_MCOUNT 3
-	mr	r5,r4
-	li	r4,0
-	b	L(_memset)
-END (__bzero)
-#ifndef __bzero
-weak_alias (__bzero, bzero)
-#endif
diff --git a/sysdeps/powerpc/powerpc64/power4/strncmp.S b/sysdeps/powerpc/powerpc64/power4/strncmp.S
deleted file mode 100644
index 73629e4..0000000
--- a/sysdeps/powerpc/powerpc64/power4/strncmp.S
+++ /dev/null
@@ -1,225 +0,0 @@
-/* Optimized strcmp implementation for PowerPC64.
-   Copyright (C) 2003-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-#ifndef STRNCMP
-# define STRNCMP strncmp
-#endif
-
-/* See strlen.s for comments on how the end-of-string testing works.  */
-
-/* int [r3] strncmp (const char *s1 [r3], const char *s2 [r4], size_t size [r5])  */
-
-ENTRY_TOCLESS (STRNCMP, 4)
-	CALL_MCOUNT 3
-
-#define rTMP2	r0
-#define rRTN	r3
-#define rSTR1	r3	/* first string arg */
-#define rSTR2	r4	/* second string arg */
-#define rN	r5	/* max string length */
-#define rWORD1	r6	/* current word in s1 */
-#define rWORD2	r7	/* current word in s2 */
-#define rWORD3  r10
-#define rWORD4  r11
-#define rFEFE	r8	/* constant 0xfefefefefefefeff (-0x0101010101010101) */
-#define r7F7F	r9	/* constant 0x7f7f7f7f7f7f7f7f */
-#define rNEG	r10	/* ~(word in s1 | 0x7f7f7f7f7f7f7f7f) */
-#define rBITDIF	r11	/* bits that differ in s1 & s2 words */
-#define rTMP	r12
-
-	dcbt	0,rSTR1
-	or	rTMP, rSTR2, rSTR1
-	lis	r7F7F, 0x7f7f
-	dcbt	0,rSTR2
-	clrldi.	rTMP, rTMP, 61
-	cmpldi	cr1, rN, 0
-	lis	rFEFE, -0x101
-	bne	L(unaligned)
-/* We are doubleword aligned so set up for two loops.  first a double word
-   loop, then fall into the byte loop if any residual.  */
-	srdi.	rTMP, rN, 3
-	clrldi	rN, rN, 61
-	addi	rFEFE, rFEFE, -0x101
-	addi	r7F7F, r7F7F, 0x7f7f
-	cmpldi	cr1, rN, 0
-	beq	L(unaligned)
-
-	mtctr	rTMP	/* Power4 wants mtctr 1st in dispatch group.  */
-	ld	rWORD1, 0(rSTR1)
-	ld	rWORD2, 0(rSTR2)
-	sldi	rTMP, rFEFE, 32
-	insrdi	r7F7F, r7F7F, 32, 0
-	add	rFEFE, rFEFE, rTMP
-	b	L(g1)
-
-L(g0):
-	ldu	rWORD1, 8(rSTR1)
-	bne-	cr1, L(different)
-	ldu	rWORD2, 8(rSTR2)
-L(g1):	add	rTMP, rFEFE, rWORD1
-	nor	rNEG, r7F7F, rWORD1
-	bdz	L(tail)
-	and.	rTMP, rTMP, rNEG
-	cmpd	cr1, rWORD1, rWORD2
-	beq+	L(g0)
-
-/* OK. We've hit the end of the string. We need to be careful that
-   we don't compare two strings as different because of gunk beyond
-   the end of the strings...  */
-
-#ifdef __LITTLE_ENDIAN__
-L(endstring):
-	addi    rTMP2, rTMP, -1
-	beq	cr1, L(equal)
-	andc    rTMP2, rTMP2, rTMP
-	rldimi	rTMP2, rTMP2, 1, 0
-	and	rWORD2, rWORD2, rTMP2	/* Mask off gunk.  */
-	and	rWORD1, rWORD1, rTMP2
-	cmpd	cr1, rWORD1, rWORD2
-	beq	cr1, L(equal)
-	xor	rBITDIF, rWORD1, rWORD2	/* rBITDIF has bits that differ.  */
-	neg	rNEG, rBITDIF
-	and	rNEG, rNEG, rBITDIF	/* rNEG has LS bit that differs.  */
-	cntlzd	rNEG, rNEG		/* bitcount of the bit.  */
-	andi.	rNEG, rNEG, 56		/* bitcount to LS byte that differs. */
-	sld	rWORD1, rWORD1, rNEG	/* shift left to clear MS bytes.  */
-	sld	rWORD2, rWORD2, rNEG
-	xor.	rBITDIF, rWORD1, rWORD2
-	sub	rRTN, rWORD1, rWORD2
-	blt-	L(highbit)
-	sradi	rRTN, rRTN, 63		/* must return an int.  */
-	ori	rRTN, rRTN, 1
-	blr
-L(equal):
-	li	rRTN, 0
-	blr
-
-L(different):
-	ld	rWORD1, -8(rSTR1)
-	xor	rBITDIF, rWORD1, rWORD2	/* rBITDIF has bits that differ.  */
-	neg	rNEG, rBITDIF
-	and	rNEG, rNEG, rBITDIF	/* rNEG has LS bit that differs.  */
-	cntlzd	rNEG, rNEG		/* bitcount of the bit.  */
-	andi.	rNEG, rNEG, 56		/* bitcount to LS byte that differs. */
-	sld	rWORD1, rWORD1, rNEG	/* shift left to clear MS bytes.  */
-	sld	rWORD2, rWORD2, rNEG
-	xor.	rBITDIF, rWORD1, rWORD2
-	sub	rRTN, rWORD1, rWORD2
-	blt-	L(highbit)
-	sradi	rRTN, rRTN, 63
-	ori	rRTN, rRTN, 1
-	blr
-L(highbit):
-	sradi	rRTN, rWORD2, 63
-	ori	rRTN, rRTN, 1
-	blr
-
-#else
-L(endstring):
-	and	rTMP, r7F7F, rWORD1
-	beq	cr1, L(equal)
-	add	rTMP, rTMP, r7F7F
-	xor.	rBITDIF, rWORD1, rWORD2
-	andc	rNEG, rNEG, rTMP
-	blt-	L(highbit)
-	cntlzd	rBITDIF, rBITDIF
-	cntlzd	rNEG, rNEG
-	addi	rNEG, rNEG, 7
-	cmpd	cr1, rNEG, rBITDIF
-	sub	rRTN, rWORD1, rWORD2
-	blt-	cr1, L(equal)
-	sradi	rRTN, rRTN, 63		/* must return an int.  */
-	ori	rRTN, rRTN, 1
-	blr
-L(equal):
-	li	rRTN, 0
-	blr
-
-L(different):
-	ld	rWORD1, -8(rSTR1)
-	xor.	rBITDIF, rWORD1, rWORD2
-	sub	rRTN, rWORD1, rWORD2
-	blt-	L(highbit)
-	sradi	rRTN, rRTN, 63
-	ori	rRTN, rRTN, 1
-	blr
-L(highbit):
-	sradi	rRTN, rWORD2, 63
-	ori	rRTN, rRTN, 1
-	blr
-#endif
-
-/* Oh well.  In this case, we just do a byte-by-byte comparison.  */
-	.align 4
-L(tail):
-	and.	rTMP, rTMP, rNEG
-	cmpd	cr1, rWORD1, rWORD2
-	bne-	L(endstring)
-	addi	rSTR1, rSTR1, 8
-	bne-	cr1, L(different)
-	addi	rSTR2, rSTR2, 8
-	cmpldi	cr1, rN, 0
-L(unaligned):
-	mtctr   rN	/* Power4 wants mtctr 1st in dispatch group */
-	ble	cr1, L(ux)
-L(uz):
-	lbz	rWORD1, 0(rSTR1)
-	lbz	rWORD2, 0(rSTR2)
-	.align 4
-L(u1):
-	cmpdi	cr1, rWORD1, 0
-	bdz	L(u4)
-	cmpd	rWORD1, rWORD2
-	beq-	cr1, L(u4)
-	bne-	L(u4)
-	lbzu    rWORD3, 1(rSTR1)
-	lbzu	rWORD4, 1(rSTR2)
-	cmpdi	cr1, rWORD3, 0
-	bdz	L(u3)
-	cmpd	rWORD3, rWORD4
-	beq-    cr1, L(u3)
-	bne-    L(u3)
-	lbzu	rWORD1, 1(rSTR1)
-	lbzu	rWORD2, 1(rSTR2)
-	cmpdi	cr1, rWORD1, 0
-	bdz	L(u4)
-	cmpd	rWORD1, rWORD2
-	beq-	cr1, L(u4)
-	bne-	L(u4)
-	lbzu	rWORD3, 1(rSTR1)
-	lbzu	rWORD4, 1(rSTR2)
-	cmpdi	cr1, rWORD3, 0
-	bdz	L(u3)
-	cmpd	rWORD3, rWORD4
-	beq-    cr1, L(u3)
-	bne-    L(u3)
-	lbzu	rWORD1, 1(rSTR1)
-	lbzu	rWORD2, 1(rSTR2)
-	b       L(u1)
-
-L(u3):  sub     rRTN, rWORD3, rWORD4
-	blr
-L(u4):	sub	rRTN, rWORD1, rWORD2
-	blr
-L(ux):
-	li	rRTN, 0
-	blr
-END (STRNCMP)
-libc_hidden_builtin_def (strncmp)
diff --git a/sysdeps/powerpc/powerpc64/power6/memcpy.S b/sysdeps/powerpc/powerpc64/power6/memcpy.S
deleted file mode 100644
index 9356867..0000000
--- a/sysdeps/powerpc/powerpc64/power6/memcpy.S
+++ /dev/null
@@ -1,1499 +0,0 @@
-/* Optimized memcpy implementation for PowerPC64.
-   Copyright (C) 2003-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* void * [r3] memcpy (void *dst [r3], void *src [r4], size_t len [r5]);
-   Returns 'dst'.
-
-   Memcpy handles short copies (< 32-bytes) using a binary move blocks
-   (no loops) of lwz/stw.  The tail (remaining 1-3) bytes is handled
-   with the appropriate combination of byte and halfword load/stores.
-   There is minimal effort to optimize the alignment of short moves.
-   The 64-bit implementations of POWER3 and POWER4 do a reasonable job
-   of handling unaligned load/stores that do not cross 32-byte boundaries.
-
-   Longer moves (>= 32-bytes) justify the effort to get at least the
-   destination doubleword (8-byte) aligned.  Further optimization is
-   possible when both source and destination are doubleword aligned.
-   Each case has a optimized unrolled loop.
-
-   For POWER6 unaligned loads will take a 20+ cycle hiccup for any
-   L1 cache miss that crosses a 32- or 128-byte boundary.  Store
-   is more forgiving and does not take a hiccup until page or
-   segment boundaries.  So we require doubleword alignment for
-   the source but may take a risk and only require word alignment
-   for the destination.  */
-
-#ifndef MEMCPY
-# define MEMCPY memcpy
-#endif
-	.machine	"power6"
-ENTRY_TOCLESS (MEMCPY, 7)
-	CALL_MCOUNT 3
-
-    cmpldi cr1,5,31
-    neg   0,3
-    std   3,-16(1)
-    std   31,-8(1)
-    andi. 11,3,7	/* check alignment of dst.  */
-    clrldi 0,0,61	/* Number of bytes until the 1st doubleword of dst.  */
-    clrldi 10,4,61	/* check alignment of src.  */
-    cmpldi cr6,5,8
-    ble-  cr1,.L2	/* If move < 32 bytes use short move code.  */
-    mtcrf 0x01,0
-    cmpld cr6,10,11
-    srdi  9,5,3		/* Number of full double words remaining.  */
-    beq   .L0
-
-    subf  5,0,5
-  /* Move 0-7 bytes as needed to get the destination doubleword aligned.
-     Duplicate some code to maximize fall-through and minimize agen delays.  */
-1:  bf    31,2f
-    lbz   6,0(4)
-    stb   6,0(3)
-    bf    30,5f
-    lhz   6,1(4)
-    sth   6,1(3)
-    bf    29,0f
-    lwz   6,3(4)
-    stw   6,3(3)
-    b     0f
-5:
-    bf    29,0f
-    lwz   6,1(4)
-    stw   6,1(3)
-    b     0f
-
-2:  bf    30,4f
-    lhz   6,0(4)
-    sth   6,0(3)
-    bf    29,0f
-    lwz   6,2(4)
-    stw   6,2(3)
-    b     0f
-
-4:  bf    29,0f
-    lwz   6,0(4)
-    stw   6,0(3)
-0:
-/* Add the number of bytes until the 1st doubleword of dst to src and dst.  */
-    add   4,4,0
-    add   3,3,0
-
-    clrldi 10,4,61	/* check alignment of src again.  */
-    srdi  9,5,3	/* Number of full double words remaining.  */
-
-  /* Copy doublewords from source to destination, assuming the
-     destination is aligned on a doubleword boundary.
-
-     At this point we know there are at least 25 bytes left (32-7) to copy.
-     The next step is to determine if the source is also doubleword aligned.
-     If not branch to the unaligned move code at .L6. which uses
-     a load, shift, store strategy.
-
-     Otherwise source and destination are doubleword aligned, and we can
-     the optimized doubleword copy loop.  */
-    .align  4
-.L0:
-    clrldi  11,5,61
-    andi.   0,5,0x78
-    srdi    12,5,7	/* Number of 128-byte blocks to move.  */
-    cmpldi  cr1,11,0	/* If the tail is 0 bytes  */
-    bne-    cr6,.L6     /* If source is not DW aligned.  */
-
-  /* Move doublewords where destination and source are DW aligned.
-     Use a unrolled loop to copy 16 doublewords (128-bytes) per iteration.
-     If the copy is not an exact multiple of 128 bytes, 1-15
-     doublewords are copied as needed to set up the main loop.  After
-     the main loop exits there may be a tail of 1-7 bytes. These byte
-     are copied a word/halfword/byte at a time as needed to preserve
-     alignment.
-
-     For POWER6 the L1 is store-through and the L2 is store-in.  The
-     L2 is clocked at half CPU clock so we can store 16 bytes every
-     other cycle.  POWER6 also has a load/store bypass so we can do
-     load, load, store, store every 2 cycles.
-
-     The following code is sensitive to cache line alignment.  Do not
-     make any change with out first making sure they don't result in
-     splitting ld/std pairs across a cache line.  */
-
-    mtcrf 0x02,5
-    mtcrf 0x01,5
-    cmpldi  cr5,12,1
-    beq   L(das_loop)
-
-    bf    25,4f
-    .align  3
-    ld    6,0(4)
-    ld    7,8(4)
-    mr    11,4
-    mr    10,3
-    std   6,0(3)
-    std   7,8(3)
-    ld    6,16(4)
-    ld    7,24(4)
-    std   6,16(3)
-    std   7,24(3)
-    ld    6,0+32(4)
-    ld    7,8+32(4)
-    addi  4,4,64
-    addi  3,3,64
-    std   6,0+32(10)
-    std   7,8+32(10)
-    ld    6,16+32(11)
-    ld    7,24+32(11)
-    std   6,16+32(10)
-    std   7,24+32(10)
-4:
-    mr    10,3
-    bf    26,2f
-    ld    6,0(4)
-    ld    7,8(4)
-    mr    11,4
-    nop
-    std   6,0(3)
-    std   7,8(3)
-    ld    6,16(4)
-    ld    7,24(4)
-    addi  4,4,32
-    std   6,16(3)
-    std   7,24(3)
-    addi  3,3,32
-6:
-    nop
-    bf    27,5f
-    ld    6,0+32(11)
-    ld    7,8+32(11)
-    addi  4,4,16
-    addi  3,3,16
-    std   6,0+32(10)
-    std   7,8+32(10)
-    bf    28,L(das_loop_s)
-    ld    0,16+32(11)
-    addi  4,4,8
-    addi  3,3,8
-    std   0,16+32(10)
-    blt   cr5,L(das_tail)
-    b     L(das_loop)
-    .align  3
-5:
-    nop
-    bf    28,L(das_loop_s)
-    ld    6,32(11)
-    addi  4,4,8
-    addi  3,3,8
-    std   6,32(10)
-    blt   cr5,L(das_tail)
-    b     L(das_loop)
-    .align  3
-2:
-    mr    11,4
-    bf    27,1f
-    ld    6,0(4)
-    ld    7,8(4)
-    addi  4,4,16
-    addi  3,3,16
-    std   6,0(10)
-    std   7,8(10)
-    bf    28,L(das_loop_s)
-    ld    0,16(11)
-    addi  4,11,24
-    addi  3,10,24
-    std   0,16(10)
-    blt   cr5,L(das_tail)
-    b     L(das_loop)
-    .align  3
-1:
-    nop
-    bf    28,L(das_loop_s)
-    ld    6,0(4)
-    addi  4,4,8
-    addi  3,3,8
-    std   6,0(10)
-L(das_loop_s):
-    nop
-    blt   cr5,L(das_tail)
-    .align  4
-L(das_loop):
-    ld    6,0(4)
-    ld    7,8(4)
-    mr    10,3
-    mr    11,4
-    std   6,0(3)
-    std   7,8(3)
-    addi  12,12,-1
-    nop
-    ld    8,16(4)
-    ld    0,24(4)
-    std   8,16(3)
-    std   0,24(3)
-
-    ld    6,0+32(4)
-    ld    7,8+32(4)
-    std   6,0+32(3)
-    std   7,8+32(3)
-    ld    8,16+32(4)
-    ld    0,24+32(4)
-    std   8,16+32(3)
-    std   0,24+32(3)
-
-    ld    6,0+64(11)
-    ld    7,8+64(11)
-    std   6,0+64(10)
-    std   7,8+64(10)
-    ld    8,16+64(11)
-    ld    0,24+64(11)
-    std   8,16+64(10)
-    std   0,24+64(10)
-
-    ld    6,0+96(11)
-    ld    7,8+96(11)
-    addi  4,4,128
-    addi  3,3,128
-    std   6,0+96(10)
-    std   7,8+96(10)
-    ld    8,16+96(11)
-    ld    0,24+96(11)
-    std   8,16+96(10)
-    std   0,24+96(10)
-    ble   cr5,L(das_loop_e)
-
-    mtctr   12
-    .align  4
-L(das_loop2):
-    ld    6,0(4)
-    ld    7,8(4)
-    mr    10,3
-    mr    11,4
-    std   6,0(3)
-    std   7,8(3)
-    ld    8,16(4)
-    ld    0,24(4)
-    std   8,16(3)
-    std   0,24(3)
-
-    ld    6,0+32(4)
-    ld    7,8+32(4)
-    std   6,0+32(3)
-    std   7,8+32(3)
-    ld    8,16+32(4)
-    ld    0,24+32(4)
-    std   8,16+32(3)
-    std   0,24+32(3)
-
-    ld    6,0+64(11)
-    ld    7,8+64(11)
-    std   6,0+64(10)
-    std   7,8+64(10)
-    ld    8,16+64(11)
-    ld    0,24+64(11)
-    std   8,16+64(10)
-    std   0,24+64(10)
-
-    ld    6,0+96(11)
-    ld    7,8+96(11)
-    addi  4,4,128
-    addi  3,3,128
-    std   6,0+96(10)
-    std   7,8+96(10)
-    ld    8,16+96(11)
-    ld    0,24+96(11)
-    std   8,16+96(10)
-    std   0,24+96(10)
-    bdnz  L(das_loop2)
-L(das_loop_e):
-/* Check of a 1-7 byte tail, return if none.  */
-    bne   cr1,L(das_tail2)
-/* Return original dst pointer.  */
-    ld 3,-16(1)
-    blr
-    .align  4
-L(das_tail):
-    beq   cr1,0f
-
-L(das_tail2):
-/*  At this point we have a tail of 0-7 bytes and we know that the
-    destination is double word aligned.  */
-4:  bf    29,2f
-    lwz   6,0(4)
-    stw   6,0(3)
-    bf    30,5f
-    lhz   6,4(4)
-    sth   6,4(3)
-    bf    31,0f
-    lbz   6,6(4)
-    stb   6,6(3)
-    b     0f
-5:  bf    31,0f
-    lbz   6,4(4)
-    stb   6,4(3)
-    b     0f
-
-2:  bf    30,1f
-    lhz   6,0(4)
-    sth   6,0(3)
-    bf    31,0f
-    lbz   6,2(4)
-    stb   6,2(3)
-    b     0f
-
-1:  bf    31,0f
-    lbz   6,0(4)
-    stb   6,0(3)
-0:
-  /* Return original dst pointer.  */
-    ld 3,-16(1)
-    blr
-
-/* Copy up to 31 bytes.  This divided into two cases 0-8 bytes and 9-31
-   bytes.  Each case is handled without loops, using binary (1,2,4,8)
-   tests.
-
-   In the short (0-8 byte) case no attempt is made to force alignment
-   of either source or destination.  The hardware will handle the
-   unaligned load/stores with small delays for crossing 32- 128-byte,
-   and 4096-byte boundaries. Since these short moves are unlikely to be
-   unaligned or cross these boundaries, the overhead to force
-   alignment is not justified.
-
-   The longer (9-31 byte) move is more likely to cross 32- or 128-byte
-   boundaries.  Since only loads are sensitive to the 32-/128-byte
-   boundaries it is more important to align the source then the
-   destination.  If the source is not already word aligned, we first
-   move 1-3 bytes as needed.  Since we are only word aligned we don't
-   use double word load/stores to insure that all loads are aligned.
-   While the destination and stores may still be unaligned, this
-   is only an issue for page (4096 byte boundary) crossing, which
-   should be rare for these short moves.  The hardware handles this
-   case automatically with a small (~20 cycle) delay.  */
-    .align  4
-.L2:
-    mtcrf 0x01,5
-    neg   8,4
-    clrrdi	11,4,2
-    andi. 0,8,3
-    ble   cr6,.LE8	/* Handle moves of 0-8 bytes.  */
-/* At least 9 bytes left.  Get the source word aligned.  */
-    cmpldi	cr1,5,16
-    mr    10,5
-    mr    12,4
-    cmpldi	cr6,0,2
-    beq   L(dus_tail)	/* If the source is already word aligned skip this.  */
-/* Copy 1-3 bytes to get source address word aligned.  */
-    lwz   6,0(11)
-    subf  10,0,5
-    add   12,4,0
-    blt   cr6,5f
-    srdi  7,6,16
-    bgt	  cr6,3f
-#ifdef __LITTLE_ENDIAN__
-    sth   7,0(3)
-#else
-    sth   6,0(3)
-#endif
-    b     7f
-    .align  4
-3:
-#ifdef __LITTLE_ENDIAN__
-    rotlwi 6,6,24
-    stb   6,0(3)
-    sth   7,1(3)
-#else
-    stb   7,0(3)
-    sth   6,1(3)
-#endif
-    b     7f
-    .align  4
-5:
-#ifdef __LITTLE_ENDIAN__
-    rotlwi 6,6,8
-#endif
-    stb   6,0(3)
-7:
-    cmpldi	cr1,10,16
-    add   3,3,0
-    mtcrf 0x01,10
-    .align  4
-L(dus_tail):
-/* At least 6 bytes left and the source is word aligned.  This allows
-   some speculative loads up front.  */
-/* We need to special case the fall-through because the biggest delays
-   are due to address computation not being ready in time for the
-   AGEN.  */
-    lwz   6,0(12)
-    lwz   7,4(12)
-    blt   cr1,L(dus_tail8)
-    cmpldi	cr0,10,24
-L(dus_tail16): /* Move 16 bytes.  */
-    stw   6,0(3)
-    stw   7,4(3)
-    lwz   6,8(12)
-    lwz   7,12(12)
-    stw   6,8(3)
-    stw   7,12(3)
-/* Move 8 bytes more.  */
-    bf    28,L(dus_tail16p8)
-    cmpldi	cr1,10,28
-    lwz   6,16(12)
-    lwz   7,20(12)
-    stw   6,16(3)
-    stw   7,20(3)
-/* Move 4 bytes more.  */
-    bf    29,L(dus_tail16p4)
-    lwz   6,24(12)
-    stw   6,24(3)
-    addi  12,12,28
-    addi  3,3,28
-    bgt   cr1,L(dus_tail2)
- /* exactly 28 bytes.  Return original dst pointer and exit.  */
-    ld    3,-16(1)
-    blr
-    .align  4
-L(dus_tail16p8):  /* less than 8 bytes left.  */
-    beq   cr1,L(dus_tailX) /* exactly 16 bytes, early exit.  */
-    cmpldi	cr1,10,20
-    bf    29,L(dus_tail16p2)
-/* Move 4 bytes more.  */
-    lwz   6,16(12)
-    stw   6,16(3)
-    addi  12,12,20
-    addi  3,3,20
-    bgt   cr1,L(dus_tail2)
- /* exactly 20 bytes.  Return original dst pointer and exit.  */
-    ld    3,-16(1)
-    blr
-    .align  4
-L(dus_tail16p4):  /* less than 4 bytes left.  */
-    addi  12,12,24
-    addi  3,3,24
-    bgt   cr0,L(dus_tail2)
- /* exactly 24 bytes.  Return original dst pointer and exit.  */
-    ld    3,-16(1)
-    blr
-    .align  4
-L(dus_tail16p2):  /* 16 bytes moved, less than 4 bytes left.  */
-    addi  12,12,16
-    addi  3,3,16
-    b     L(dus_tail2)
-
-    .align  4
-L(dus_tail8):  /* Move 8 bytes.  */
-/*  r6, r7 already loaded speculatively.  */
-    cmpldi	cr1,10,8
-    cmpldi	cr0,10,12
-    bf    28,L(dus_tail4)
-    .align  2
-    stw   6,0(3)
-    stw   7,4(3)
-/* Move 4 bytes more.  */
-    bf    29,L(dus_tail8p4)
-    lwz   6,8(12)
-    stw   6,8(3)
-    addi  12,12,12
-    addi  3,3,12
-    bgt   cr0,L(dus_tail2)
- /* exactly 12 bytes.  Return original dst pointer and exit.  */
-    ld    3,-16(1)
-    blr
-    .align  4
-L(dus_tail8p4):  /* less than 4 bytes left.  */
-    addi  12,12,8
-    addi  3,3,8
-    bgt   cr1,L(dus_tail2)
- /* exactly 8 bytes.  Return original dst pointer and exit.  */
-    ld    3,-16(1)
-    blr
-
-    .align  4
-L(dus_tail4):  /* Move 4 bytes.  */
-/*  r6 already loaded speculatively.  If we are here we know there is
-    more than 4 bytes left.  So there is no need to test.  */
-    addi  12,12,4
-    stw   6,0(3)
-    addi  3,3,4
-L(dus_tail2):  /* Move 2-3 bytes.  */
-    bf    30,L(dus_tail1)
-    lhz   6,0(12)
-    sth   6,0(3)
-    bf    31,L(dus_tailX)
-    lbz   7,2(12)
-    stb   7,2(3)
-    ld 3,-16(1)
-    blr
-L(dus_tail1):  /* Move 1 byte.  */
-    bf    31,L(dus_tailX)
-    lbz   6,0(12)
-    stb   6,0(3)
-L(dus_tailX):
-  /* Return original dst pointer.  */
-    ld    3,-16(1)
-    blr
-
-/* Special case to copy 0-8 bytes.  */
-    .align  4
-.LE8:
-    mr    12,4
-    bne   cr6,L(dus_4)
-/* Exactly 8 bytes.  We may cross a 32-/128-byte boundary and take a ~20
-   cycle delay.  This case should be rare and any attempt to avoid this
-   would take most of 20 cycles any way.  */
-    ld   6,0(4)
-    std   6,0(3)
-  /* Return original dst pointer.  */
-    ld    3,-16(1)
-    blr
-    .align  4
-L(dus_4):
-    bf    29,L(dus_tail2)
-    lwz   6,0(4)
-    stw   6,0(3)
-    bf    30,L(dus_5)
-    lhz   7,4(4)
-    sth   7,4(3)
-    bf    31,L(dus_0)
-    lbz   8,6(4)
-    stb   8,6(3)
-    ld 3,-16(1)
-    blr
-    .align  4
-L(dus_5):
-    bf    31,L(dus_0)
-    lbz   6,4(4)
-    stb   6,4(3)
-L(dus_0):
-  /* Return original dst pointer.  */
-    ld    3,-16(1)
-    blr
-
-    .align  4
-.L6:
-    cfi_offset(31,-8)
-    mr    12,4
-    mr    31,5
-  /* Copy doublewords where the destination is aligned but the source is
-     not.  Use aligned doubleword loads from the source, shifted to realign
-     the data, to allow aligned destination stores.  */
-    addi    11,9,-1  /* loop DW count is one less than total */
-    subf    5,10,12  /* Move source addr to previous full double word.  */
-    cmpldi  cr5, 10, 2
-    cmpldi  cr0, 10, 4
-    mr      4,3
-    srdi    8,11,2   /* calculate the 32 byte loop count */
-    ld      6,0(5)   /* pre load 1st full doubleword.  */
-    mtcrf   0x01,11
-    cmpldi  cr6,9,4
-    mtctr   8
-    ld      7,8(5)   /* pre load 2nd full doubleword.  */
-    bge     cr0, L(du4_do)
-    blt     cr5, L(du1_do)
-    beq     cr5, L(du2_do)
-    b       L(du3_do)
-
-    .align 4
-L(du1_do):
-    bf      30,L(du1_1dw)
-
-    /* there are at least two DWs to copy */
-    /* FIXME: can combine last shift and "or" into "rldimi" */
-#ifdef __LITTLE_ENDIAN__
-    srdi     0,6, 8
-    sldi     8,7, 64-8
-#else
-    sldi     0,6, 8
-    srdi     8,7, 64-8
-#endif
-    or      0,0,8
-    ld      6,16(5)
-    std     0,0(4)
-#ifdef __LITTLE_ENDIAN__
-    srdi     0,7, 8
-    sldi     8,6, 64-8
-#else
-    sldi     0,7, 8
-    srdi     8,6, 64-8
-#endif
-    or      0,0,8
-    ld      7,24(5)
-    std     0,8(4)
-    addi    4,4,16
-    addi    5,5,32
-    blt     cr6,L(du1_fini)  /* if total DWs = 3, then bypass loop */
-    bf      31,L(du1_loop)
-    /* there is a third DW to copy */
-#ifdef __LITTLE_ENDIAN__
-    srdi     0,6, 8
-    sldi     8,7, 64-8
-#else
-    sldi     0,6, 8
-    srdi     8,7, 64-8
-#endif
-    or      0,0,8
-    std     0,0(4)
-    mr      6,7
-    ld      7,0(5)
-    addi    5,5,8
-    addi    4,4,8
-    beq     cr6,L(du1_fini)  /* if total DWs = 4, then bypass loop */
-    b       L(du1_loop)
-    .align 4
-L(du1_1dw):
-#ifdef __LITTLE_ENDIAN__
-    srdi     0,6, 8
-    sldi     8,7, 64-8
-#else
-    sldi     0,6, 8
-    srdi     8,7, 64-8
-#endif
-    addi    5,5,16
-    or      0,0,8
-    bf      31,L(du1_loop)
-    mr      6,7
-    ld      7,0(5)
-    addi    5,5,8
-    std     0,0(4)
-    addi    4,4,8
-    .align 4
-/* copy 32 bytes at a time */
-L(du1_loop):
-#ifdef __LITTLE_ENDIAN__
-    srdi   0,6, 8
-    sldi   8,7, 64-8
-#else
-    sldi   0,6, 8
-    srdi   8,7, 64-8
-#endif
-    or    0,0,8
-    ld    6,0(5)
-    std   0,0(4)
-#ifdef __LITTLE_ENDIAN__
-    srdi   0,7, 8
-    sldi   8,6, 64-8
-#else
-    sldi   0,7, 8
-    srdi   8,6, 64-8
-#endif
-    or    0,0,8
-    ld    7,8(5)
-    std   0,8(4)
-#ifdef __LITTLE_ENDIAN__
-    srdi   0,6, 8
-    sldi   8,7, 64-8
-#else
-    sldi   0,6, 8
-    srdi   8,7, 64-8
-#endif
-    or    0,0,8
-    ld    6,16(5)
-    std   0,16(4)
-#ifdef __LITTLE_ENDIAN__
-    srdi   0,7, 8
-    sldi   8,6, 64-8
-#else
-    sldi   0,7, 8
-    srdi   8,6, 64-8
-#endif
-    or    0,0,8
-    ld    7,24(5)
-    std   0,24(4)
-    addi  5,5,32
-    addi  4,4,32
-    bdnz+ L(du1_loop)
-    .align 4
-L(du1_fini):
-    /* calculate and store the final DW */
-#ifdef __LITTLE_ENDIAN__
-    srdi   0,6, 8
-    sldi   8,7, 64-8
-#else
-    sldi   0,6, 8
-    srdi   8,7, 64-8
-#endif
-    or    0,0,8
-    std   0,0(4)
-    b     L(du_done)
-
-    .align 4
-L(du2_do):
-    bf      30,L(du2_1dw)
-
-    /* there are at least two DWs to copy */
-#ifdef __LITTLE_ENDIAN__
-    srdi     0,6, 16
-    sldi     8,7, 64-16
-#else
-    sldi     0,6, 16
-    srdi     8,7, 64-16
-#endif
-    or      0,0,8
-    ld      6,16(5)
-    std     0,0(4)
-#ifdef __LITTLE_ENDIAN__
-    srdi     0,7, 16
-    sldi     8,6, 64-16
-#else
-    sldi     0,7, 16
-    srdi     8,6, 64-16
-#endif
-    or      0,0,8
-    ld      7,24(5)
-    std     0,8(4)
-    addi    4,4,16
-    addi    5,5,32
-    blt     cr6,L(du2_fini)  /* if total DWs = 3, then bypass loop */
-    bf      31,L(du2_loop)
-    /* there is a third DW to copy */
-#ifdef __LITTLE_ENDIAN__
-    srdi     0,6, 16
-    sldi     8,7, 64-16
-#else
-    sldi     0,6, 16
-    srdi     8,7, 64-16
-#endif
-    or      0,0,8
-    std     0,0(4)
-    mr      6,7
-    ld      7,0(5)
-    addi    5,5,8
-    addi    4,4,8
-    beq     cr6,L(du2_fini)  /* if total DWs = 4, then bypass loop */
-    b       L(du2_loop)
-    .align 4
-L(du2_1dw):
-#ifdef __LITTLE_ENDIAN__
-    srdi     0,6, 16
-    sldi     8,7, 64-16
-#else
-    sldi     0,6, 16
-    srdi     8,7, 64-16
-#endif
-    addi    5,5,16
-    or      0,0,8
-    bf      31,L(du2_loop)
-    mr      6,7
-    ld      7,0(5)
-    addi    5,5,8
-    std     0,0(4)
-    addi    4,4,8
-    .align 4
-/* copy 32 bytes at a time */
-L(du2_loop):
-#ifdef __LITTLE_ENDIAN__
-    srdi   0,6, 16
-    sldi   8,7, 64-16
-#else
-    sldi   0,6, 16
-    srdi   8,7, 64-16
-#endif
-    or    0,0,8
-    ld    6,0(5)
-    std   0,0(4)
-#ifdef __LITTLE_ENDIAN__
-    srdi   0,7, 16
-    sldi   8,6, 64-16
-#else
-    sldi   0,7, 16
-    srdi   8,6, 64-16
-#endif
-    or    0,0,8
-    ld    7,8(5)
-    std   0,8(4)
-#ifdef __LITTLE_ENDIAN__
-    srdi   0,6, 16
-    sldi   8,7, 64-16
-#else
-    sldi   0,6, 16
-    srdi   8,7, 64-16
-#endif
-    or    0,0,8
-    ld    6,16(5)
-    std   0,16(4)
-#ifdef __LITTLE_ENDIAN__
-    srdi   0,7, 16
-    sldi   8,6, 64-16
-#else
-    sldi   0,7, 16
-    srdi   8,6, 64-16
-#endif
-    or    0,0,8
-    ld    7,24(5)
-    std   0,24(4)
-    addi  5,5,32
-    addi  4,4,32
-    bdnz+ L(du2_loop)
-    .align 4
-L(du2_fini):
-    /* calculate and store the final DW */
-#ifdef __LITTLE_ENDIAN__
-    srdi   0,6, 16
-    sldi   8,7, 64-16
-#else
-    sldi   0,6, 16
-    srdi   8,7, 64-16
-#endif
-    or    0,0,8
-    std   0,0(4)
-    b     L(du_done)
-
-    .align 4
-L(du3_do):
-    bf      30,L(du3_1dw)
-
-    /* there are at least two DWs to copy */
-#ifdef __LITTLE_ENDIAN__
-    srdi     0,6, 24
-    sldi     8,7, 64-24
-#else
-    sldi     0,6, 24
-    srdi     8,7, 64-24
-#endif
-    or      0,0,8
-    ld      6,16(5)
-    std     0,0(4)
-#ifdef __LITTLE_ENDIAN__
-    srdi     0,7, 24
-    sldi     8,6, 64-24
-#else
-    sldi     0,7, 24
-    srdi     8,6, 64-24
-#endif
-    or      0,0,8
-    ld      7,24(5)
-    std     0,8(4)
-    addi    4,4,16
-    addi    5,5,32
-    blt     cr6,L(du3_fini)  /* if total DWs = 3, then bypass loop */
-    bf      31,L(du3_loop)
-    /* there is a third DW to copy */
-#ifdef __LITTLE_ENDIAN__
-    srdi     0,6, 24
-    sldi     8,7, 64-24
-#else
-    sldi     0,6, 24
-    srdi     8,7, 64-24
-#endif
-    or      0,0,8
-    std     0,0(4)
-    mr      6,7
-    ld      7,0(5)
-    addi    5,5,8
-    addi    4,4,8
-    beq     cr6,L(du3_fini)  /* if total DWs = 4, then bypass loop */
-    b       L(du3_loop)
-    .align 4
-L(du3_1dw):
-#ifdef __LITTLE_ENDIAN__
-    srdi     0,6, 24
-    sldi     8,7, 64-24
-#else
-    sldi     0,6, 24
-    srdi     8,7, 64-24
-#endif
-    addi    5,5,16
-    or      0,0,8
-    bf      31,L(du3_loop)
-    mr      6,7
-    ld      7,0(5)
-    addi    5,5,8
-    std     0,0(4)
-    addi    4,4,8
-    .align 4
-/* copy 32 bytes at a time */
-L(du3_loop):
-#ifdef __LITTLE_ENDIAN__
-    srdi   0,6, 24
-    sldi   8,7, 64-24
-#else
-    sldi   0,6, 24
-    srdi   8,7, 64-24
-#endif
-    or    0,0,8
-    ld    6,0(5)
-    std   0,0(4)
-#ifdef __LITTLE_ENDIAN__
-    srdi   0,7, 24
-    sldi   8,6, 64-24
-#else
-    sldi   0,7, 24
-    srdi   8,6, 64-24
-#endif
-    or    0,0,8
-    ld    7,8(5)
-    std   0,8(4)
-#ifdef __LITTLE_ENDIAN__
-    srdi   0,6, 24
-    sldi   8,7, 64-24
-#else
-    sldi   0,6, 24
-    srdi   8,7, 64-24
-#endif
-    or    0,0,8
-    ld    6,16(5)
-    std   0,16(4)
-#ifdef __LITTLE_ENDIAN__
-    srdi   0,7, 24
-    sldi   8,6, 64-24
-#else
-    sldi   0,7, 24
-    srdi   8,6, 64-24
-#endif
-    or    0,0,8
-    ld    7,24(5)
-    std   0,24(4)
-    addi  5,5,32
-    addi  4,4,32
-    bdnz+ L(du3_loop)
-    .align 4
-L(du3_fini):
-    /* calculate and store the final DW */
-#ifdef __LITTLE_ENDIAN__
-    srdi   0,6, 24
-    sldi   8,7, 64-24
-#else
-    sldi   0,6, 24
-    srdi   8,7, 64-24
-#endif
-    or    0,0,8
-    std   0,0(4)
-    b     L(du_done)
-
-    .align 4
-L(du4_do):
-    cmpldi  cr5, 10, 6
-    beq     cr0, L(du4_dox)
-    blt     cr5, L(du5_do)
-    beq     cr5, L(du6_do)
-    b       L(du7_do)
-L(du4_dox):
-    bf      30,L(du4_1dw)
-
-    /* there are at least two DWs to copy */
-#ifdef __LITTLE_ENDIAN__
-    srdi     0,6, 32
-    sldi     8,7, 64-32
-#else
-    sldi     0,6, 32
-    srdi     8,7, 64-32
-#endif
-    or      0,0,8
-    ld      6,16(5)
-    std     0,0(4)
-#ifdef __LITTLE_ENDIAN__
-    srdi     0,7, 32
-    sldi     8,6, 64-32
-#else
-    sldi     0,7, 32
-    srdi     8,6, 64-32
-#endif
-    or      0,0,8
-    ld      7,24(5)
-    std     0,8(4)
-    addi    4,4,16
-    addi    5,5,32
-    blt     cr6,L(du4_fini)  /* if total DWs = 3, then bypass loop */
-    bf      31,L(du4_loop)
-    /* there is a third DW to copy */
-#ifdef __LITTLE_ENDIAN__
-    srdi     0,6, 32
-    sldi     8,7, 64-32
-#else
-    sldi     0,6, 32
-    srdi     8,7, 64-32
-#endif
-    or      0,0,8
-    std     0,0(4)
-    mr      6,7
-    ld      7,0(5)
-    addi    5,5,8
-    addi    4,4,8
-    beq     cr6,L(du4_fini)  /* if total DWs = 4, then bypass loop */
-    b       L(du4_loop)
-    .align 4
-L(du4_1dw):
-#ifdef __LITTLE_ENDIAN__
-    srdi     0,6, 32
-    sldi     8,7, 64-32
-#else
-    sldi     0,6, 32
-    srdi     8,7, 64-32
-#endif
-    addi    5,5,16
-    or      0,0,8
-    bf      31,L(du4_loop)
-    mr      6,7
-    ld      7,0(5)
-    addi    5,5,8
-    std     0,0(4)
-    addi    4,4,8
-    .align 4
-/* copy 32 bytes at a time */
-L(du4_loop):
-#ifdef __LITTLE_ENDIAN__
-    srdi   0,6, 32
-    sldi   8,7, 64-32
-#else
-    sldi   0,6, 32
-    srdi   8,7, 64-32
-#endif
-    or    0,0,8
-    ld    6,0(5)
-    std   0,0(4)
-#ifdef __LITTLE_ENDIAN__
-    srdi   0,7, 32
-    sldi   8,6, 64-32
-#else
-    sldi   0,7, 32
-    srdi   8,6, 64-32
-#endif
-    or    0,0,8
-    ld    7,8(5)
-    std   0,8(4)
-#ifdef __LITTLE_ENDIAN__
-    srdi   0,6, 32
-    sldi   8,7, 64-32
-#else
-    sldi   0,6, 32
-    srdi   8,7, 64-32
-#endif
-    or    0,0,8
-    ld    6,16(5)
-    std   0,16(4)
-#ifdef __LITTLE_ENDIAN__
-    srdi   0,7, 32
-    sldi   8,6, 64-32
-#else
-    sldi   0,7, 32
-    srdi   8,6, 64-32
-#endif
-    or    0,0,8
-    ld    7,24(5)
-    std   0,24(4)
-    addi  5,5,32
-    addi  4,4,32
-    bdnz+ L(du4_loop)
-    .align 4
-L(du4_fini):
-    /* calculate and store the final DW */
-#ifdef __LITTLE_ENDIAN__
-    srdi   0,6, 32
-    sldi   8,7, 64-32
-#else
-    sldi   0,6, 32
-    srdi   8,7, 64-32
-#endif
-    or    0,0,8
-    std   0,0(4)
-    b     L(du_done)
-
-    .align 4
-L(du5_do):
-    bf      30,L(du5_1dw)
-
-    /* there are at least two DWs to copy */
-#ifdef __LITTLE_ENDIAN__
-    srdi     0,6, 40
-    sldi     8,7, 64-40
-#else
-    sldi     0,6, 40
-    srdi     8,7, 64-40
-#endif
-    or      0,0,8
-    ld      6,16(5)
-    std     0,0(4)
-#ifdef __LITTLE_ENDIAN__
-    srdi     0,7, 40
-    sldi     8,6, 64-40
-#else
-    sldi     0,7, 40
-    srdi     8,6, 64-40
-#endif
-    or      0,0,8
-    ld      7,24(5)
-    std     0,8(4)
-    addi    4,4,16
-    addi    5,5,32
-    blt     cr6,L(du5_fini)  /* if total DWs = 3, then bypass loop */
-    bf      31,L(du5_loop)
-    /* there is a third DW to copy */
-#ifdef __LITTLE_ENDIAN__
-    srdi     0,6, 40
-    sldi     8,7, 64-40
-#else
-    sldi     0,6, 40
-    srdi     8,7, 64-40
-#endif
-    or      0,0,8
-    std     0,0(4)
-    mr      6,7
-    ld      7,0(5)
-    addi    5,5,8
-    addi    4,4,8
-    beq     cr6,L(du5_fini)  /* if total DWs = 4, then bypass loop */
-    b       L(du5_loop)
-    .align 4
-L(du5_1dw):
-#ifdef __LITTLE_ENDIAN__
-    srdi     0,6, 40
-    sldi     8,7, 64-40
-#else
-    sldi     0,6, 40
-    srdi     8,7, 64-40
-#endif
-    addi    5,5,16
-    or      0,0,8
-    bf      31,L(du5_loop)
-    mr      6,7
-    ld      7,0(5)
-    addi    5,5,8
-    std     0,0(4)
-    addi    4,4,8
-    .align 4
-/* copy 32 bytes at a time */
-L(du5_loop):
-#ifdef __LITTLE_ENDIAN__
-    srdi   0,6, 40
-    sldi   8,7, 64-40
-#else
-    sldi   0,6, 40
-    srdi   8,7, 64-40
-#endif
-    or    0,0,8
-    ld    6,0(5)
-    std   0,0(4)
-#ifdef __LITTLE_ENDIAN__
-    srdi   0,7, 40
-    sldi   8,6, 64-40
-#else
-    sldi   0,7, 40
-    srdi   8,6, 64-40
-#endif
-    or    0,0,8
-    ld    7,8(5)
-    std   0,8(4)
-#ifdef __LITTLE_ENDIAN__
-    srdi   0,6, 40
-    sldi   8,7, 64-40
-#else
-    sldi   0,6, 40
-    srdi   8,7, 64-40
-#endif
-    or    0,0,8
-    ld    6,16(5)
-    std   0,16(4)
-#ifdef __LITTLE_ENDIAN__
-    srdi   0,7, 40
-    sldi   8,6, 64-40
-#else
-    sldi   0,7, 40
-    srdi   8,6, 64-40
-#endif
-    or    0,0,8
-    ld    7,24(5)
-    std   0,24(4)
-    addi  5,5,32
-    addi  4,4,32
-    bdnz+ L(du5_loop)
-    .align 4
-L(du5_fini):
-    /* calculate and store the final DW */
-#ifdef __LITTLE_ENDIAN__
-    srdi   0,6, 40
-    sldi   8,7, 64-40
-#else
-    sldi   0,6, 40
-    srdi   8,7, 64-40
-#endif
-    or    0,0,8
-    std   0,0(4)
-    b     L(du_done)
-
-    .align 4
-L(du6_do):
-    bf      30,L(du6_1dw)
-
-    /* there are at least two DWs to copy */
-#ifdef __LITTLE_ENDIAN__
-    srdi     0,6, 48
-    sldi     8,7, 64-48
-#else
-    sldi     0,6, 48
-    srdi     8,7, 64-48
-#endif
-    or      0,0,8
-    ld      6,16(5)
-    std     0,0(4)
-#ifdef __LITTLE_ENDIAN__
-    srdi     0,7, 48
-    sldi     8,6, 64-48
-#else
-    sldi     0,7, 48
-    srdi     8,6, 64-48
-#endif
-    or      0,0,8
-    ld      7,24(5)
-    std     0,8(4)
-    addi    4,4,16
-    addi    5,5,32
-    blt     cr6,L(du6_fini)  /* if total DWs = 3, then bypass loop */
-    bf      31,L(du6_loop)
-    /* there is a third DW to copy */
-#ifdef __LITTLE_ENDIAN__
-    srdi     0,6, 48
-    sldi     8,7, 64-48
-#else
-    sldi     0,6, 48
-    srdi     8,7, 64-48
-#endif
-    or      0,0,8
-    std     0,0(4)
-    mr      6,7
-    ld      7,0(5)
-    addi    5,5,8
-    addi    4,4,8
-    beq     cr6,L(du6_fini)  /* if total DWs = 4, then bypass loop */
-    b       L(du6_loop)
-    .align 4
-L(du6_1dw):
-#ifdef __LITTLE_ENDIAN__
-    srdi     0,6, 48
-    sldi     8,7, 64-48
-#else
-    sldi     0,6, 48
-    srdi     8,7, 64-48
-#endif
-    addi    5,5,16
-    or      0,0,8
-    bf      31,L(du6_loop)
-    mr      6,7
-    ld      7,0(5)
-    addi    5,5,8
-    std     0,0(4)
-    addi    4,4,8
-    .align 4
-/* copy 32 bytes at a time */
-L(du6_loop):
-#ifdef __LITTLE_ENDIAN__
-    srdi   0,6, 48
-    sldi   8,7, 64-48
-#else
-    sldi   0,6, 48
-    srdi   8,7, 64-48
-#endif
-    or    0,0,8
-    ld    6,0(5)
-    std   0,0(4)
-#ifdef __LITTLE_ENDIAN__
-    srdi   0,7, 48
-    sldi   8,6, 64-48
-#else
-    sldi   0,7, 48
-    srdi   8,6, 64-48
-#endif
-    or    0,0,8
-    ld    7,8(5)
-    std   0,8(4)
-#ifdef __LITTLE_ENDIAN__
-    srdi   0,6, 48
-    sldi   8,7, 64-48
-#else
-    sldi   0,6, 48
-    srdi   8,7, 64-48
-#endif
-    or    0,0,8
-    ld    6,16(5)
-    std   0,16(4)
-#ifdef __LITTLE_ENDIAN__
-    srdi   0,7, 48
-    sldi   8,6, 64-48
-#else
-    sldi   0,7, 48
-    srdi   8,6, 64-48
-#endif
-    or    0,0,8
-    ld    7,24(5)
-    std   0,24(4)
-    addi  5,5,32
-    addi  4,4,32
-    bdnz+ L(du6_loop)
-    .align 4
-L(du6_fini):
-    /* calculate and store the final DW */
-#ifdef __LITTLE_ENDIAN__
-    srdi   0,6, 48
-    sldi   8,7, 64-48
-#else
-    sldi   0,6, 48
-    srdi   8,7, 64-48
-#endif
-    or    0,0,8
-    std   0,0(4)
-    b     L(du_done)
-
-    .align 4
-L(du7_do):
-    bf      30,L(du7_1dw)
-
-    /* there are at least two DWs to copy */
-#ifdef __LITTLE_ENDIAN__
-    srdi     0,6, 56
-    sldi     8,7, 64-56
-#else
-    sldi     0,6, 56
-    srdi     8,7, 64-56
-#endif
-    or      0,0,8
-    ld      6,16(5)
-    std     0,0(4)
-#ifdef __LITTLE_ENDIAN__
-    srdi     0,7, 56
-    sldi     8,6, 64-56
-#else
-    sldi     0,7, 56
-    srdi     8,6, 64-56
-#endif
-    or      0,0,8
-    ld      7,24(5)
-    std     0,8(4)
-    addi    4,4,16
-    addi    5,5,32
-    blt     cr6,L(du7_fini)  /* if total DWs = 3, then bypass loop */
-    bf      31,L(du7_loop)
-    /* there is a third DW to copy */
-#ifdef __LITTLE_ENDIAN__
-    srdi     0,6, 56
-    sldi     8,7, 64-56
-#else
-    sldi     0,6, 56
-    srdi     8,7, 64-56
-#endif
-    or      0,0,8
-    std     0,0(4)
-    mr      6,7
-    ld      7,0(5)
-    addi    5,5,8
-    addi    4,4,8
-    beq     cr6,L(du7_fini)  /* if total DWs = 4, then bypass loop */
-    b       L(du7_loop)
-    .align 4
-L(du7_1dw):
-#ifdef __LITTLE_ENDIAN__
-    srdi     0,6, 56
-    sldi     8,7, 64-56
-#else
-    sldi     0,6, 56
-    srdi     8,7, 64-56
-#endif
-    addi    5,5,16
-    or      0,0,8
-    bf      31,L(du7_loop)
-    mr      6,7
-    ld      7,0(5)
-    addi    5,5,8
-    std     0,0(4)
-    addi    4,4,8
-    .align 4
-/* copy 32 bytes at a time */
-L(du7_loop):
-#ifdef __LITTLE_ENDIAN__
-    srdi   0,6, 56
-    sldi   8,7, 64-56
-#else
-    sldi   0,6, 56
-    srdi   8,7, 64-56
-#endif
-    or    0,0,8
-    ld    6,0(5)
-    std   0,0(4)
-#ifdef __LITTLE_ENDIAN__
-    srdi   0,7, 56
-    sldi   8,6, 64-56
-#else
-    sldi   0,7, 56
-    srdi   8,6, 64-56
-#endif
-    or    0,0,8
-    ld    7,8(5)
-    std   0,8(4)
-#ifdef __LITTLE_ENDIAN__
-    srdi   0,6, 56
-    sldi   8,7, 64-56
-#else
-    sldi   0,6, 56
-    srdi   8,7, 64-56
-#endif
-    or    0,0,8
-    ld    6,16(5)
-    std   0,16(4)
-#ifdef __LITTLE_ENDIAN__
-    srdi   0,7, 56
-    sldi   8,6, 64-56
-#else
-    sldi   0,7, 56
-    srdi   8,6, 64-56
-#endif
-    or    0,0,8
-    ld    7,24(5)
-    std   0,24(4)
-    addi  5,5,32
-    addi  4,4,32
-    bdnz+ L(du7_loop)
-    .align 4
-L(du7_fini):
-    /* calculate and store the final DW */
-#ifdef __LITTLE_ENDIAN__
-    srdi   0,6, 56
-    sldi   8,7, 64-56
-#else
-    sldi   0,6, 56
-    srdi   8,7, 64-56
-#endif
-    or    0,0,8
-    std   0,0(4)
-    b     L(du_done)
-
-    .align 4
-L(du_done):
-    rldicr 0,31,0,60
-    mtcrf 0x01,31
-    beq   cr1,0f	/* If the tail is 0 bytes we are done!  */
-
-    add   3,3,0
-    add   12,12,0
-/*  At this point we have a tail of 0-7 bytes and we know that the
-    destination is double word aligned.  */
-4:  bf    29,2f
-    lwz   6,0(12)
-    addi  12,12,4
-    stw   6,0(3)
-    addi  3,3,4
-2:  bf    30,1f
-    lhz   6,0(12)
-    addi  12,12,2
-    sth   6,0(3)
-    addi  3,3,2
-1:  bf    31,0f
-    lbz   6,0(12)
-    stb   6,0(3)
-0:
-  /* Return original dst pointer.  */
-    ld 31,-8(1)
-    ld 3,-16(1)
-    blr
-END_GEN_TB (MEMCPY,TB_TOCLESS)
-libc_hidden_builtin_def (memcpy)
diff --git a/sysdeps/powerpc/powerpc64/power6/memset.S b/sysdeps/powerpc/powerpc64/power6/memset.S
deleted file mode 100644
index 3901e33..0000000
--- a/sysdeps/powerpc/powerpc64/power6/memset.S
+++ /dev/null
@@ -1,395 +0,0 @@
-/* Optimized 64-bit memset implementation for POWER6.
-   Copyright (C) 1997-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* void * [r3] memset (void *s [r3], int c [r4], size_t n [r5]));
-   Returns 's'.
-
-   The memset is done in three sizes: byte (8 bits), word (32 bits),
-   cache line (256 bits). There is a special case for setting cache lines
-   to 0, to take advantage of the dcbz instruction.  */
-
-#ifndef MEMSET
-# define MEMSET memset
-#endif
-	.machine power6
-ENTRY_TOCLESS (MEMSET, 7)
-	CALL_MCOUNT 3
-
-#define rTMP	r0
-#define rRTN	r3	/* Initial value of 1st argument.  */
-#define rMEMP0	r3	/* Original value of 1st arg.  */
-#define rCHR	r4	/* Char to set in each byte.  */
-#define rLEN	r5	/* Length of region to set.  */
-#define rMEMP	r6	/* Address at which we are storing.  */
-#define rALIGN	r7	/* Number of bytes we are setting now (when aligning). */
-#define rMEMP2	r8
-#define rMEMP3	r9	/* Alt mem pointer.  */
-L(_memset):
-/* Take care of case for size <= 4.  */
-	cmpldi	cr1, rLEN, 8
-	andi.	rALIGN, rMEMP0, 7
-	mr	rMEMP, rMEMP0
-	ble	cr1, L(small)
-
-/* Align to doubleword boundary.  */
-	cmpldi	cr5, rLEN, 31
-	insrdi	rCHR, rCHR, 8, 48	/* Replicate byte to halfword.  */
-	beq+	L(aligned2)
-	mtcrf	0x01, rMEMP0
-	subfic	rALIGN, rALIGN, 8
-	cror	28,30,31		/* Detect odd word aligned.  */
-	add	rMEMP, rMEMP, rALIGN
-	sub	rLEN, rLEN, rALIGN
-	insrdi	rCHR, rCHR, 16, 32	/* Replicate halfword to word.  */
-	bt	29, L(g4)
-/* Process the even word of doubleword.  */
-	bf+	31, L(g2)
-	stb	rCHR, 0(rMEMP0)
-	bt	30, L(g4x)
-L(g2):
-	sth	rCHR, -6(rMEMP)
-L(g4x):
-	stw	rCHR, -4(rMEMP)
-	b	L(aligned)
-/* Process the odd word of doubleword.  */
-L(g4):
-	bf	28, L(g4x) /* If false, word aligned on odd word.  */
-	bf+	31, L(g0)
-	stb	rCHR, 0(rMEMP0)
-	bt	30, L(aligned)
-L(g0):
-	sth	rCHR, -2(rMEMP)
-
-/* Handle the case of size < 31.  */
-L(aligned2):
-	insrdi	rCHR, rCHR, 16, 32	/* Replicate halfword to word.  */
-L(aligned):
-	mtcrf	0x01, rLEN
-	ble	cr5, L(medium)
-/* Align to 32-byte boundary.  */
-	andi.	rALIGN, rMEMP, 0x18
-	subfic	rALIGN, rALIGN, 0x20
-	insrdi	rCHR, rCHR, 32, 0	/* Replicate word to double word. */
-	beq	L(caligned)
-	mtcrf	0x01, rALIGN
-	add	rMEMP, rMEMP, rALIGN
-	sub	rLEN, rLEN, rALIGN
-	cmplwi	cr1, rALIGN, 0x10
-	mr	rMEMP2, rMEMP
-	bf	28, L(a1)
-	stdu	rCHR, -8(rMEMP2)
-L(a1):	blt	cr1, L(a2)
-	std	rCHR, -8(rMEMP2)
-	stdu	rCHR, -16(rMEMP2)
-L(a2):
-
-/* Now aligned to a 32 byte boundary.  */
-        .align 4
-L(caligned):
-	cmpldi	cr1, rCHR, 0
-	clrrdi.	rALIGN, rLEN, 5
-	mtcrf	0x01, rLEN
-	beq	cr1, L(zloopstart) /* Special case for clearing memory using dcbz.  */
-	beq	L(medium)	/* We may not actually get to do a full line.  */
-	.align 4
-/* Storing a non-zero "c" value. We are aligned at a sector (32-byte)
-   boundary may not be at cache line (128-byte) boundary.  */
-L(nzloopstart):
-/* memset in 32-byte chunks until we get to a cache line boundary.
-   If rLEN is less than the distance to the next cache-line boundary use
-   cacheAligned1 code to finish the tail.  */
-	cmpldi	cr1,rLEN,128
-
-	andi.	rTMP,rMEMP,127
-	blt	cr1,L(cacheAligned1)
-	addi	rMEMP3,rMEMP,32
-	beq	L(nzCacheAligned)
-	addi	rLEN,rLEN,-32
-	std	rCHR,0(rMEMP)
-	std	rCHR,8(rMEMP)
-	std	rCHR,16(rMEMP)
-	addi	rMEMP,rMEMP,32
-	andi.	rTMP,rMEMP3,127
-	std	rCHR,-8(rMEMP3)
-
-	beq	L(nzCacheAligned)
-	addi	rLEN,rLEN,-32
-	std	rCHR,0(rMEMP3)
-	addi	rMEMP,rMEMP,32
-	std	rCHR,8(rMEMP3)
-	andi.	rTMP,rMEMP,127
-	std	rCHR,16(rMEMP3)
-	std	rCHR,24(rMEMP3)
-
-	beq	L(nzCacheAligned)
-	addi	rLEN,rLEN,-32
-	std	rCHR,32(rMEMP3)
-	addi	rMEMP,rMEMP,32
-	cmpldi	cr1,rLEN,128
-	std	rCHR,40(rMEMP3)
-	cmpldi	cr6,rLEN,256
-	li	rMEMP2,128
-	std	rCHR,48(rMEMP3)
-	std	rCHR,56(rMEMP3)
-	blt	cr1,L(cacheAligned1)
-	b	L(nzCacheAligned128)
-
-/* Now we are aligned to the cache line and can use dcbtst.  */
-        .align 4
-L(nzCacheAligned):
-	cmpldi	cr1,rLEN,128
-	blt	cr1,L(cacheAligned1)
-	b	L(nzCacheAligned128)
-        .align 5
-L(nzCacheAligned128):
-	cmpldi	cr1,rLEN,256
-	addi	rMEMP3,rMEMP,64
-	std	rCHR,0(rMEMP)
-	std	rCHR,8(rMEMP)
-	std	rCHR,16(rMEMP)
-	std	rCHR,24(rMEMP)
-	std	rCHR,32(rMEMP)
-	std	rCHR,40(rMEMP)
-	std	rCHR,48(rMEMP)
-	std	rCHR,56(rMEMP)
-	addi	rMEMP,rMEMP3,64
-	addi	rLEN,rLEN,-128
-	std	rCHR,0(rMEMP3)
-	std	rCHR,8(rMEMP3)
-	std	rCHR,16(rMEMP3)
-	std	rCHR,24(rMEMP3)
-	std	rCHR,32(rMEMP3)
-	std	rCHR,40(rMEMP3)
-	std	rCHR,48(rMEMP3)
-	std	rCHR,56(rMEMP3)
-	bge	cr1,L(nzCacheAligned128)
-	dcbtst	0,rMEMP
-	b	L(cacheAligned1)
-	.align 5
-/* Storing a zero "c" value. We are aligned at a sector (32-byte)
-   boundary but may not be at cache line (128-byte) boundary.  If the
-   remaining length spans a full cache line we can use the Data cache
-   block zero instruction. */
-L(zloopstart):
-/* memset in 32-byte chunks until we get to a cache line boundary.
-   If rLEN is less than the distance to the next cache-line boundary use
-   cacheAligned1 code to finish the tail.  */
-	cmpldi	cr1,rLEN,128
-	beq	L(medium)
-L(getCacheAligned):
-	andi.	rTMP,rMEMP,127
-	nop
-	blt	cr1,L(cacheAligned1)
-	addi	rMEMP3,rMEMP,32
-	beq	L(cacheAligned)
-	addi	rLEN,rLEN,-32
-	std	rCHR,0(rMEMP)
-	std	rCHR,8(rMEMP)
-	std	rCHR,16(rMEMP)
-	addi	rMEMP,rMEMP,32
-	andi.	rTMP,rMEMP3,127
-	std	rCHR,-8(rMEMP3)
-L(getCacheAligned2):
-	beq	L(cacheAligned)
-	addi	rLEN,rLEN,-32
-	std	rCHR,0(rMEMP3)
-	std	rCHR,8(rMEMP3)
-	addi	rMEMP,rMEMP,32
-	andi.	rTMP,rMEMP,127
-	std	rCHR,16(rMEMP3)
-	std	rCHR,24(rMEMP3)
-L(getCacheAligned3):
-	beq	L(cacheAligned)
-	addi	rLEN,rLEN,-32
-	std	rCHR,32(rMEMP3)
-	addi	rMEMP,rMEMP,32
-	cmpldi	cr1,rLEN,128
-	std	rCHR,40(rMEMP3)
-	cmpldi	cr6,rLEN,256
-	li	rMEMP2,128
-	std	rCHR,48(rMEMP3)
-	std	rCHR,56(rMEMP3)
-	blt	cr1,L(cacheAligned1)
-	blt	cr6,L(cacheAligned128)
-	b	L(cacheAlignedx)
-
-/* Now we are aligned to the cache line and can use dcbz.  */
-        .align 5
-L(cacheAligned):
-	cmpldi	cr1,rLEN,128
-	cmpldi	cr6,rLEN,256
-	blt	cr1,L(cacheAligned1)
-	li	rMEMP2,128
-L(cacheAlignedx):
-	cmpldi	cr5,rLEN,640
-	blt	cr6,L(cacheAligned128)
-	bgt	cr5,L(cacheAligned512)
-	cmpldi	cr6,rLEN,512
-	dcbz	0,rMEMP
-	cmpldi	cr1,rLEN,384
-	dcbz	rMEMP2,rMEMP
-	addi	rMEMP,rMEMP,256
-	addi	rLEN,rLEN,-256
-	blt	cr1,L(cacheAligned1)
-	blt	cr6,L(cacheAligned128)
-	b	L(cacheAligned256)
-	.align 5
-/* A simple loop for the longer (>640 bytes) lengths.  This form limits
-   the branch miss-predicted to exactly 1 at loop exit.*/
-L(cacheAligned512):
-	cmpldi	cr1,rLEN,128
-	blt	cr1,L(cacheAligned1)
-	dcbz	0,rMEMP
-	addi	rLEN,rLEN,-128
-	addi	rMEMP,rMEMP,128
-	b	L(cacheAligned512)
-        .align 5
-L(cacheAligned256):
-
-	cmpldi	cr6,rLEN,512
-
-	dcbz	0,rMEMP
-	cmpldi	cr1,rLEN,384
-	dcbz	rMEMP2,rMEMP
-	addi	rMEMP,rMEMP,256
-	addi	rLEN,rLEN,-256
-
-	bge	cr6,L(cacheAligned256)
-
-	blt	cr1,L(cacheAligned1)
-        .align 4
-L(cacheAligned128):
-	dcbz	0,rMEMP
-	addi	rMEMP,rMEMP,128
-	addi	rLEN,rLEN,-128
-        nop
-L(cacheAligned1):
-	cmpldi	cr1,rLEN,32
-	blt	cr1,L(handletail32)
-	addi	rMEMP3,rMEMP,32
-	addi	rLEN,rLEN,-32
-	std	rCHR,0(rMEMP)
-	std	rCHR,8(rMEMP)
-	std	rCHR,16(rMEMP)
-	addi	rMEMP,rMEMP,32
-	cmpldi	cr1,rLEN,32
-	std	rCHR,-8(rMEMP3)
-L(cacheAligned2):
-	blt	cr1,L(handletail32)
-	addi	rLEN,rLEN,-32
-	std	rCHR,0(rMEMP3)
-	std	rCHR,8(rMEMP3)
-	addi	rMEMP,rMEMP,32
-	cmpldi	cr1,rLEN,32
-	std	rCHR,16(rMEMP3)
-	std	rCHR,24(rMEMP3)
-	nop
-L(cacheAligned3):
-	blt	cr1,L(handletail32)
-	addi	rMEMP,rMEMP,32
-	addi	rLEN,rLEN,-32
-	std	rCHR,32(rMEMP3)
-	std	rCHR,40(rMEMP3)
-	std	rCHR,48(rMEMP3)
-	std	rCHR,56(rMEMP3)
-
-/* We are here because the length or remainder (rLEN) is less than the
-   cache line/sector size and does not justify aggressive loop unrolling.
-   So set up the preconditions for L(medium) and go there.  */
-        .align 3
-L(handletail32):
-	cmpldi	cr1,rLEN,0
-	beqlr   cr1
-	b	L(medium)
-
-	.align 5
-L(small):
-/* Memset of 8 bytes or less.  */
-	cmpldi	cr6, rLEN, 4
-	cmpldi	cr5, rLEN, 1
-	ble	cr6,L(le4)
-	subi	rLEN, rLEN, 4
-	stb	rCHR,0(rMEMP)
-	stb	rCHR,1(rMEMP)
-	stb	rCHR,2(rMEMP)
-	stb	rCHR,3(rMEMP)
-	addi	rMEMP,rMEMP, 4
-	cmpldi	cr5, rLEN, 1
-L(le4):
-	cmpldi	cr1, rLEN, 3
-	bltlr	cr5
-	stb	rCHR, 0(rMEMP)
-	beqlr	cr5
-	stb	rCHR, 1(rMEMP)
-	bltlr	cr1
-	stb	rCHR, 2(rMEMP)
-	beqlr	cr1
-	stb	rCHR, 3(rMEMP)
-	blr
-
-/* Memset of 0-31 bytes.  */
-	.align 5
-L(medium):
-	insrdi	rCHR, rCHR, 32, 0	/* Replicate word to double word.  */
-	cmpldi	cr1, rLEN, 16
-L(medium_tail2):
-	add	rMEMP, rMEMP, rLEN
-L(medium_tail):
-	bt-	31, L(medium_31t)
-	bt-	30, L(medium_30t)
-L(medium_30f):
-	bt	29, L(medium_29t)
-L(medium_29f):
-	bge	cr1, L(medium_27t)
-	bflr	28
-	std	rCHR, -8(rMEMP)
-	blr
-
-L(medium_31t):
-	stbu	rCHR, -1(rMEMP)
-	bf-	30, L(medium_30f)
-L(medium_30t):
-	sthu	rCHR, -2(rMEMP)
-	bf-	29, L(medium_29f)
-L(medium_29t):
-	stwu	rCHR, -4(rMEMP)
-	blt	cr1, L(medium_27f)
-L(medium_27t):
-	std	rCHR, -8(rMEMP)
-	stdu	rCHR, -16(rMEMP)
-L(medium_27f):
-	bflr	28
-L(medium_28t):
-	std	rCHR, -8(rMEMP)
-	blr
-END_GEN_TB (MEMSET,TB_TOCLESS)
-libc_hidden_builtin_def (memset)
-
-/* Copied from bzero.S to prevent the linker from inserting a stub
-   between bzero and memset.  */
-ENTRY_TOCLESS (__bzero)
-	CALL_MCOUNT 3
-	mr	r5,r4
-	li	r4,0
-	b	L(_memset)
-END (__bzero)
-#ifndef __bzero
-weak_alias (__bzero, bzero)
-#endif
diff --git a/sysdeps/powerpc/powerpc64/power6/wcschr.c b/sysdeps/powerpc/powerpc64/power6/wcschr.c
deleted file mode 100644
index ae04a13..0000000
--- a/sysdeps/powerpc/powerpc64/power6/wcschr.c
+++ /dev/null
@@ -1 +0,0 @@
-#include <sysdeps/powerpc/power6/wcschr.c>
diff --git a/sysdeps/powerpc/powerpc64/power6/wcscpy.c b/sysdeps/powerpc/powerpc64/power6/wcscpy.c
deleted file mode 100644
index 722c8f9..0000000
--- a/sysdeps/powerpc/powerpc64/power6/wcscpy.c
+++ /dev/null
@@ -1 +0,0 @@
-#include <sysdeps/powerpc/power6/wcscpy.c>
diff --git a/sysdeps/powerpc/powerpc64/power6/wcsrchr.c b/sysdeps/powerpc/powerpc64/power6/wcsrchr.c
deleted file mode 100644
index b86472d..0000000
--- a/sysdeps/powerpc/powerpc64/power6/wcsrchr.c
+++ /dev/null
@@ -1 +0,0 @@
-#include <sysdeps/powerpc/power6/wcsrchr.c>
diff --git a/sysdeps/powerpc/powerpc64/power7/memchr.S b/sysdeps/powerpc/powerpc64/power7/memchr.S
deleted file mode 100644
index 9ab5ab2..0000000
--- a/sysdeps/powerpc/powerpc64/power7/memchr.S
+++ /dev/null
@@ -1,199 +0,0 @@
-/* Optimized memchr implementation for PowerPC64/POWER7 using cmpb insn.
-   Copyright (C) 2010-2018 Free Software Foundation, Inc.
-   Contributed by Luis Machado <luisgpm@br.ibm.com>.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* int [r3] memchr (char *s [r3], int byte [r4], int size [r5])  */
-
-#ifndef MEMCHR
-# define MEMCHR __memchr
-#endif
-	.machine  power7
-ENTRY_TOCLESS (MEMCHR)
-	CALL_MCOUNT 3
-	dcbt	0,r3
-	clrrdi  r8,r3,3
-	insrdi	r4,r4,8,48
-
-	/* Calculate the last acceptable address and check for possible
-	   addition overflow by using satured math:
-	   r7 = r3 + r5
-	   r7 |= -(r7 < x)  */
-	add     r7,r3,r5
-	subfc   r6,r3,r7
-	subfe   r9,r9,r9
-	extsw   r6,r9
-	or      r7,r7,r6
-
-	insrdi	r4,r4,16,32
-	cmpldi	r5,32
-	li	r9, -1
-	rlwinm	r6,r3,3,26,28 /* Calculate padding.  */
-	insrdi  r4,r4,32,0
-	addi	r7,r7,-1
-#ifdef __LITTLE_ENDIAN__
-	sld	r9,r9,r6
-#else
-	srd	r9,r9,r6
-#endif
-	ble	L(small_range)
-
-	ld	r12,0(r8)     /* Load doubleword from memory.  */
-	cmpb	r3,r12,r4     /* Check for BYTEs in DWORD1.  */
-	and	r3,r3,r9
-	clrldi	r5,r7,61      /* Byte count - 1 in last dword.  */
-	clrrdi	r7,r7,3       /* Address of last doubleword.  */
-	cmpldi	cr7,r3,0      /* Does r3 indicate we got a hit?  */
-	bne	cr7,L(done)
-
-	mtcrf   0x01,r8
-	/* Are we now aligned to a quadword boundary?  If so, skip to
-	   the main loop.  Otherwise, go through the alignment code.  */
-	bt	28,L(loop_setup)
-
-	/* Handle DWORD2 of pair.  */
-	ldu	r12,8(r8)
-	cmpb	r3,r12,r4
-	cmpldi	cr7,r3,0
-	bne	cr7,L(done)
-
-L(loop_setup):
-	/* The last dword we want to read in the loop below is the one
-	   containing the last byte of the string, ie. the dword at
-	   (s + size - 1) & ~7, or r7.  The first dword read is at
-	   r8 + 8, we read 2 * cnt dwords, so the last dword read will
-	   be at r8 + 8 + 16 * cnt - 8.  Solving for cnt gives
-	   cnt = (r7 - r8) / 16  */
-	sub	r6,r7,r8
-	srdi	r6,r6,4	      /* Number of loop iterations.  */
-	mtctr	r6            /* Setup the counter.  */
-
-	/* Main loop to look for BYTE in the string.  Since
-	   it's a small loop (8 instructions), align it to 32-bytes.  */
-	.align	5
-L(loop):
-	/* Load two doublewords, compare and merge in a
-	   single register for speed.  This is an attempt
-	   to speed up the byte-checking process for bigger strings.  */
-	ld	r12,8(r8)
-	ldu	r11,16(r8)
-	cmpb	r3,r12,r4
-	cmpb	r9,r11,r4
-	or	r6,r9,r3      /* Merge everything in one doubleword.  */
-	cmpldi	cr7,r6,0
-	bne	cr7,L(found)
-	bdnz	L(loop)
-
-	/* We may have one more dword to read.  */
-	cmpld	r8,r7
-	beqlr
-
-	ldu	r12,8(r8)
-	cmpb	r3,r12,r4
-	cmpldi	cr6,r3,0
-	bne	cr6,L(done)
-	blr
-
-	.align	4
-L(found):
-	/* OK, one (or both) of the doublewords contains BYTE.  Check
-	   the first doubleword and decrement the address in case the first
-	   doubleword really contains BYTE.  */
-	cmpldi	cr6,r3,0
-	addi	r8,r8,-8
-	bne	cr6,L(done)
-
-	/* BYTE must be in the second doubleword.  Adjust the address
-	   again and move the result of cmpb to r3 so we can calculate the
-	   pointer.  */
-
-	mr	r3,r9
-	addi	r8,r8,8
-
-	/* r3 has the output of the cmpb instruction, that is, it contains
-	   0xff in the same position as BYTE in the original
-	   doubleword from the string.  Use that to calculate the pointer.
-	   We need to make sure BYTE is *before* the end of the range.  */
-L(done):
-#ifdef __LITTLE_ENDIAN__
-	addi    r0,r3,-1
-	andc    r0,r0,r3
-	popcntd	r0,r0	      /* Count trailing zeros.  */
-#else
-	cntlzd	r0,r3	      /* Count leading zeros before the match.  */
-#endif
-	cmpld	r8,r7         /* Are we on the last dword?  */
-	srdi	r0,r0,3	      /* Convert leading/trailing zeros to bytes.  */
-	add	r3,r8,r0
-	cmpld	cr7,r0,r5     /* If on the last dword, check byte offset.  */
-	bnelr
-	blelr	cr7
-	li	r3,0
-	blr
-
-	.align	4
-L(null):
-	li	r3,0
-	blr
-
-/* Deals with size <= 32.  */
-	.align	4
-L(small_range):
-	cmpldi	r5,0
-	beq	L(null)
-	ld	r12,0(r8)     /* Load word from memory.  */
-	cmpb	r3,r12,r4     /* Check for BYTE in DWORD1.  */
-	and	r3,r3,r9
-	cmpldi	cr7,r3,0
-	clrldi	r5,r7,61      /* Byte count - 1 in last dword.  */
-	clrrdi	r7,r7,3       /* Address of last doubleword.  */
-	cmpld	r8,r7         /* Are we done already?  */
-	bne	cr7,L(done)
-	beqlr
-
-	ldu	r12,8(r8)
-	cmpb	r3,r12,r4
-	cmpldi	cr6,r3,0
-	cmpld	r8,r7
-	bne	cr6,L(done)   /* Found something.  */
-	beqlr		      /* Hit end of string (length).  */
-
-	ldu	r12,8(r8)
-	cmpb	r3,r12,r4
-	cmpldi	cr6,r3,0
-	cmpld	r8,r7
-	bne	cr6,L(done)
-	beqlr
-
-	ldu	r12,8(r8)
-	cmpb	r3,r12,r4
-	cmpldi	cr6,r3,0
-	cmpld	r8,r7
-	bne	cr6,L(done)
-	beqlr
-
-	ldu	r12,8(r8)
-	cmpb	r3,r12,r4
-	cmpldi	cr6,r3,0
-	bne	cr6,L(done)
-	blr
-
-END (MEMCHR)
-weak_alias (__memchr, memchr)
-libc_hidden_builtin_def (memchr)
diff --git a/sysdeps/powerpc/powerpc64/power7/memcmp.S b/sysdeps/powerpc/powerpc64/power7/memcmp.S
deleted file mode 100644
index 91acdfb..0000000
--- a/sysdeps/powerpc/powerpc64/power7/memcmp.S
+++ /dev/null
@@ -1,1061 +0,0 @@
-/* Optimized memcmp implementation for POWER7/PowerPC64.
-   Copyright (C) 2010-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* int [r3] memcmp (const char *s1 [r3],
-		    const char *s2 [r4],
-		    size_t size [r5])  */
-#ifndef MEMCMP
-# define MEMCMP memcmp
-#endif
-	.machine power7
-ENTRY_TOCLESS (MEMCMP, 4)
-	CALL_MCOUNT 3
-
-#define rRTN		r3
-#define rSTR1		r3	/* first string arg */
-#define rSTR2		r4	/* second string arg */
-#define rN		r5	/* max string length */
-#define rWORD1		r6	/* current word in s1 */
-#define rWORD2		r7	/* current word in s2 */
-#define rWORD3		r8	/* next word in s1 */
-#define rWORD4		r9	/* next word in s2 */
-#define rWORD5		r10	/* next word in s1 */
-#define rWORD6		r11	/* next word in s2 */
-
-#define rOFF8		r20	/* 8 bytes offset.  */
-#define rOFF16  	r21	/* 16 bytes offset.  */
-#define rOFF24		r22	/* 24 bytes offset.  */
-#define rOFF32		r23	/* 24 bytes offset.  */
-#define rWORD6_SHIFT	r24	/* Left rotation temp for rWORD8.  */
-#define rWORD4_SHIFT	r25	/* Left rotation temp for rWORD6.  */
-#define rWORD2_SHIFT	r26	/* Left rotation temp for rWORD4.  */
-#define rWORD8_SHIFT	r27	/* Left rotation temp for rWORD2.  */
-#define rSHR		r28	/* Unaligned shift right count.  */
-#define rSHL		r29	/* Unaligned shift left count.  */
-#define rWORD7		r30	/* next word in s1 */
-#define rWORD8		r31	/* next word in s2 */
-
-#define rWORD8SAVE	(-8)
-#define rWORD7SAVE	(-16)
-#define rOFF8SAVE	(-24)
-#define rOFF16SAVE	(-32)
-#define rOFF24SAVE	(-40)
-#define rOFF32SAVE	(-48)
-#define rSHRSAVE	(-56)
-#define rSHLSAVE	(-64)
-#define rWORD8SHIFTSAVE	(-72)
-#define rWORD2SHIFTSAVE	(-80)
-#define rWORD4SHIFTSAVE	(-88)
-#define rWORD6SHIFTSAVE	(-96)
-
-#ifdef __LITTLE_ENDIAN__
-# define LD	ldbrx
-#else
-# define LD	ldx
-#endif
-
-	xor	r0, rSTR2, rSTR1
-	cmpldi	cr6, rN, 0
-	cmpldi	cr1, rN, 12
-	clrldi.	r0, r0, 61
-	clrldi	r12, rSTR1, 61
-	cmpldi	cr5, r12, 0
-	beq-	cr6, L(zeroLength)
-	dcbt	0, rSTR1
-	dcbt	0, rSTR2
-/* If less than 8 bytes or not aligned, use the unaligned
-   byte loop.  */
-	blt	cr1, L(bytealigned)
-	std	rWORD8, rWORD8SAVE(r1)
-	std	rWORD7, rWORD7SAVE(r1)
-	std	rOFF8, rOFF8SAVE(r1)
-	std	rOFF16, rOFF16SAVE(r1)
-	std	rOFF24, rOFF24SAVE(r1)
-	std	rOFF32, rOFF32SAVE(r1)
-	cfi_offset(rWORD8, rWORD8SAVE)
-	cfi_offset(rWORD7, rWORD7SAVE)
-	cfi_offset(rOFF8, rOFF8SAVE)
-	cfi_offset(rOFF16, rOFF16SAVE)
-	cfi_offset(rOFF24, rOFF24SAVE)
-	cfi_offset(rOFF32, rOFF32SAVE)
-
-	li	rOFF8,8
-	li	rOFF16,16
-	li	rOFF24,24
-	li	rOFF32,32
-
-	bne	L(unaligned)
-/* At this point we know both strings have the same alignment and the
-   compare length is at least 8 bytes.  r12 contains the low order
-   3 bits of rSTR1 and cr5 contains the result of the logical compare
-   of r12 to 0.  If r12 == 0 then we are already double word
-   aligned and can perform the DW aligned loop.
-
-   Otherwise we know the two strings have the same alignment (but not
-   yet DW).  So we force the string addresses to the next lower DW
-   boundary and special case this first DW using shift left to
-   eliminate bits preceding the first byte.  Since we want to join the
-   normal (DW aligned) compare loop, starting at the second double word,
-   we need to adjust the length (rN) and special case the loop
-   versioning for the first DW. This ensures that the loop count is
-   correct and the first DW (shifted) is in the expected register pair.  */
-	.align	4
-L(samealignment):
-	clrrdi	rSTR1, rSTR1, 3
-	clrrdi	rSTR2, rSTR2, 3
-	beq	cr5, L(DWaligned)
-	add	rN, rN, r12
-	sldi	rWORD6, r12, 3
-	srdi	r0, rN, 5	/* Divide by 32 */
-	andi.	r12, rN, 24	/* Get the DW remainder */
-	LD	rWORD1, 0, rSTR1
-	LD	rWORD2, 0, rSTR2
-	cmpldi	cr1, r12, 16
-	cmpldi	cr7, rN, 32
-	clrldi	rN, rN, 61
-	beq	L(dPs4)
-	mtctr	r0
-	bgt	cr1, L(dPs3)
-	beq	cr1, L(dPs2)
-
-/* Remainder is 8 */
-	.align	3
-L(dsP1):
-	sld	rWORD5, rWORD1, rWORD6
-	sld	rWORD6, rWORD2, rWORD6
-	cmpld	cr5, rWORD5, rWORD6
-	blt	cr7, L(dP1x)
-/* Do something useful in this cycle since we have to branch anyway.  */
-	LD	rWORD1, rOFF8, rSTR1
-	LD	rWORD2, rOFF8, rSTR2
-	cmpld	cr7, rWORD1, rWORD2
-	b	L(dP1e)
-/* Remainder is 16 */
-	.align	4
-L(dPs2):
-	sld	rWORD5, rWORD1, rWORD6
-	sld	rWORD6, rWORD2, rWORD6
-	cmpld	cr6, rWORD5, rWORD6
-	blt	cr7, L(dP2x)
-/* Do something useful in this cycle since we have to branch anyway.  */
-	LD	rWORD7, rOFF8, rSTR1
-	LD	rWORD8, rOFF8, rSTR2
-	cmpld	cr5, rWORD7, rWORD8
-	b	L(dP2e)
-/* Remainder is 24 */
-	.align	4
-L(dPs3):
-	sld	rWORD3, rWORD1, rWORD6
-	sld	rWORD4, rWORD2, rWORD6
-	cmpld	cr1, rWORD3, rWORD4
-	b	L(dP3e)
-/* Count is a multiple of 32, remainder is 0 */
-	.align	4
-L(dPs4):
-	mtctr	r0
-	sld	rWORD1, rWORD1, rWORD6
-	sld	rWORD2, rWORD2, rWORD6
-	cmpld	cr7, rWORD1, rWORD2
-	b	L(dP4e)
-
-/* At this point we know both strings are double word aligned and the
-   compare length is at least 8 bytes.  */
-	.align	4
-L(DWaligned):
-	andi.	r12, rN, 24	/* Get the DW remainder */
-	srdi	r0, rN, 5	/* Divide by 32 */
-	cmpldi	cr1, r12, 16
-	cmpldi	cr7, rN, 32
-	clrldi	rN, rN, 61
-	beq	L(dP4)
-	bgt	cr1, L(dP3)
-	beq	cr1, L(dP2)
-
-/* Remainder is 8 */
-	.align	4
-L(dP1):
-	mtctr	r0
-/* Normally we'd use rWORD7/rWORD8 here, but since we might exit early
-   (8-15 byte compare), we want to use only volatile registers.  This
-   means we can avoid restoring non-volatile registers since we did not
-   change any on the early exit path.  The key here is the non-early
-   exit path only cares about the condition code (cr5), not about which
-   register pair was used.  */
-	LD	rWORD5, 0, rSTR1
-	LD	rWORD6, 0, rSTR2
-	cmpld	cr5, rWORD5, rWORD6
-	blt	cr7, L(dP1x)
-	LD	rWORD1, rOFF8, rSTR1
-	LD	rWORD2, rOFF8, rSTR2
-	cmpld	cr7, rWORD1, rWORD2
-L(dP1e):
-	LD	rWORD3, rOFF16, rSTR1
-	LD	rWORD4, rOFF16, rSTR2
-	cmpld	cr1, rWORD3, rWORD4
-	LD	rWORD5, rOFF24, rSTR1
-	LD	rWORD6, rOFF24, rSTR2
-	cmpld	cr6, rWORD5, rWORD6
-	bne	cr5, L(dLcr5x)
-	bne	cr7, L(dLcr7x)
-
-	LD	rWORD7, rOFF32, rSTR1
-	LD	rWORD8, rOFF32, rSTR2
-	addi	rSTR1, rSTR1, 32
-	addi	rSTR2, rSTR2, 32
-	bne	cr1, L(dLcr1)
-	cmpld	cr5, rWORD7, rWORD8
-	bdnz	L(dLoop)
-	bne	cr6, L(dLcr6)
-	ld	rWORD8, rWORD8SAVE(r1)
-	ld	rWORD7, rWORD7SAVE(r1)
-	.align	3
-L(dP1x):
-	sldi.	r12, rN, 3
-	bne	cr5, L(dLcr5x)
-	subfic	rN, r12, 64	/* Shift count is 64 - (rN * 8).  */
-	bne	L(d00)
-	ld	rOFF8,  rOFF8SAVE(r1)
-	ld	rOFF16, rOFF16SAVE(r1)
-	ld	rOFF24, rOFF24SAVE(r1)
-	ld	rOFF32, rOFF32SAVE(r1)
-	li	rRTN, 0
-	blr
-
-/* Remainder is 16 */
-	.align	4
-L(dP2):
-	mtctr	r0
-	LD	rWORD5, 0, rSTR1
-	LD	rWORD6, 0, rSTR2
-	cmpld	cr6, rWORD5, rWORD6
-	blt	cr7, L(dP2x)
-	LD	rWORD7, rOFF8, rSTR1
-	LD	rWORD8, rOFF8, rSTR2
-	cmpld	cr5, rWORD7, rWORD8
-L(dP2e):
-	LD	rWORD1, rOFF16, rSTR1
-	LD	rWORD2, rOFF16, rSTR2
-	cmpld	cr7, rWORD1, rWORD2
-	LD	rWORD3, rOFF24, rSTR1
-	LD	rWORD4, rOFF24, rSTR2
-	cmpld	cr1, rWORD3, rWORD4
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-	bne	cr6, L(dLcr6)
-	bne	cr5, L(dLcr5)
-	b	L(dLoop2)
-	.align	4
-L(dP2x):
-	LD	rWORD3, rOFF8, rSTR1
-	LD	rWORD4, rOFF8, rSTR2
-	cmpld	cr1, rWORD3, rWORD4
-	sldi.	r12, rN, 3
-	bne	cr6, L(dLcr6x)
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-	bne	cr1, L(dLcr1x)
-	subfic	rN, r12, 64	/* Shift count is 64 - (rN * 8).  */
-	bne	L(d00)
-	ld	rOFF8,  rOFF8SAVE(r1)
-	ld	rOFF16, rOFF16SAVE(r1)
-	ld	rOFF24, rOFF24SAVE(r1)
-	ld	rOFF32, rOFF32SAVE(r1)
-	li	rRTN, 0
-	blr
-
-/* Remainder is 24 */
-	.align	4
-L(dP3):
-	mtctr	r0
-	LD	rWORD3, 0, rSTR1
-	LD	rWORD4, 0, rSTR2
-	cmpld	cr1, rWORD3, rWORD4
-L(dP3e):
-	LD	rWORD5, rOFF8, rSTR1
-	LD	rWORD6, rOFF8, rSTR2
-	cmpld	cr6, rWORD5, rWORD6
-	blt	cr7, L(dP3x)
-	LD	rWORD7, rOFF16, rSTR1
-	LD	rWORD8, rOFF16, rSTR2
-	cmpld	cr5, rWORD7, rWORD8
-	LD	rWORD1, rOFF24, rSTR1
-	LD	rWORD2, rOFF24, rSTR2
-	cmpld	cr7, rWORD1, rWORD2
-	addi	rSTR1, rSTR1, 16
-	addi	rSTR2, rSTR2, 16
-	bne	cr1, L(dLcr1)
-	bne	cr6, L(dLcr6)
-	b	L(dLoop1)
-/* Again we are on a early exit path (24-31 byte compare), we want to
-   only use volatile registers and avoid restoring non-volatile
-   registers.  */
-	.align	4
-L(dP3x):
-	LD	rWORD1, rOFF16, rSTR1
-	LD	rWORD2, rOFF16, rSTR2
-	cmpld	cr7, rWORD1, rWORD2
-	sldi.	r12, rN, 3
-	bne	cr1, L(dLcr1x)
-	addi	rSTR1, rSTR1, 16
-	addi	rSTR2, rSTR2, 16
-	bne	cr6, L(dLcr6x)
-	subfic	rN, r12, 64	/* Shift count is 64 - (rN * 8).  */
-	bne	cr7, L(dLcr7x)
-	bne	L(d00)
-	ld	rOFF8,  rOFF8SAVE(r1)
-	ld	rOFF16, rOFF16SAVE(r1)
-	ld	rOFF24, rOFF24SAVE(r1)
-	ld	rOFF32, rOFF32SAVE(r1)
-	li	rRTN, 0
-	blr
-
-/* Count is a multiple of 32, remainder is 0 */
-	.align	4
-L(dP4):
-	mtctr	r0
-	LD	rWORD1, 0, rSTR1
-	LD	rWORD2, 0, rSTR2
-	cmpld	cr7, rWORD1, rWORD2
-L(dP4e):
-	LD	rWORD3, rOFF8, rSTR1
-	LD	rWORD4, rOFF8, rSTR2
-	cmpld	cr1, rWORD3, rWORD4
-	LD	rWORD5, rOFF16, rSTR1
-	LD	rWORD6, rOFF16, rSTR2
-	cmpld	cr6, rWORD5, rWORD6
-	LD	rWORD7, rOFF24, rSTR1
-	LD	rWORD8, rOFF24, rSTR2
-	addi	rSTR1, rSTR1, 24
-	addi	rSTR2, rSTR2, 24
-	cmpld	cr5, rWORD7, rWORD8
-	bne	cr7, L(dLcr7)
-	bne	cr1, L(dLcr1)
-	bdz-	L(d24)		/* Adjust CTR as we start with +4 */
-/* This is the primary loop */
-	.align	4
-L(dLoop):
-	LD	rWORD1, rOFF8, rSTR1
-	LD	rWORD2, rOFF8, rSTR2
-	cmpld	cr1, rWORD3, rWORD4
-	bne	cr6, L(dLcr6)
-L(dLoop1):
-	LD	rWORD3, rOFF16, rSTR1
-	LD	rWORD4, rOFF16, rSTR2
-	cmpld	cr6, rWORD5, rWORD6
-	bne	cr5, L(dLcr5)
-L(dLoop2):
-	LD	rWORD5, rOFF24, rSTR1
-	LD	rWORD6, rOFF24, rSTR2
-	cmpld	cr5, rWORD7, rWORD8
-	bne	cr7, L(dLcr7)
-L(dLoop3):
-	LD	rWORD7, rOFF32, rSTR1
-	LD	rWORD8, rOFF32, rSTR2
-	addi	rSTR1, rSTR1, 32
-	addi	rSTR2, rSTR2, 32
-	bne	cr1, L(dLcr1)
-	cmpld	cr7, rWORD1, rWORD2
-	bdnz	L(dLoop)
-
-L(dL4):
-	cmpld	cr1, rWORD3, rWORD4
-	bne	cr6, L(dLcr6)
-	cmpld	cr6, rWORD5, rWORD6
-	bne	cr5, L(dLcr5)
-	cmpld	cr5, rWORD7, rWORD8
-L(d44):
-	bne	cr7, L(dLcr7)
-L(d34):
-	bne	cr1, L(dLcr1)
-L(d24):
-	bne	cr6, L(dLcr6)
-L(d14):
-	sldi.	r12, rN, 3
-	bne	cr5, L(dLcr5)
-L(d04):
-	ld	rWORD8, rWORD8SAVE(r1)
-	ld	rWORD7, rWORD7SAVE(r1)
-	subfic	rN, r12, 64	/* Shift count is 64 - (rN * 8).  */
-	beq	L(duzeroLength)
-/* At this point we have a remainder of 1 to 7 bytes to compare.  Since
-   we are aligned it is safe to load the whole double word, and use
-   shift right double to eliminate bits beyond the compare length.  */
-L(d00):
-	LD	rWORD1, rOFF8, rSTR1
-	LD	rWORD2, rOFF8, rSTR2
-	srd	rWORD1, rWORD1, rN
-	srd	rWORD2, rWORD2, rN
-	cmpld	cr7, rWORD1, rWORD2
-	bne	cr7, L(dLcr7x)
-	ld	rOFF8,  rOFF8SAVE(r1)
-	ld	rOFF16, rOFF16SAVE(r1)
-	ld	rOFF24, rOFF24SAVE(r1)
-	ld	rOFF32, rOFF32SAVE(r1)
-	li	rRTN, 0
-	blr
-
-	.align	4
-L(dLcr7):
-	ld	rWORD8, rWORD8SAVE(r1)
-	ld	rWORD7, rWORD7SAVE(r1)
-L(dLcr7x):
-	ld	rOFF8,  rOFF8SAVE(r1)
-	ld	rOFF16, rOFF16SAVE(r1)
-	ld	rOFF24, rOFF24SAVE(r1)
-	ld	rOFF32, rOFF32SAVE(r1)
-	li	rRTN, 1
-	bgtlr	cr7
-	li	rRTN, -1
-	blr
-	.align	4
-L(dLcr1):
-	ld	rWORD8, rWORD8SAVE(r1)
-	ld	rWORD7, rWORD7SAVE(r1)
-L(dLcr1x):
-	ld	rOFF8,  rOFF8SAVE(r1)
-	ld	rOFF16, rOFF16SAVE(r1)
-	ld	rOFF24, rOFF24SAVE(r1)
-	ld	rOFF32, rOFF32SAVE(r1)
-	li	rRTN, 1
-	bgtlr	cr1
-	li	rRTN, -1
-	blr
-	.align	4
-L(dLcr6):
-	ld	rWORD8, rWORD8SAVE(r1)
-	ld	rWORD7, rWORD7SAVE(r1)
-L(dLcr6x):
-	ld	rOFF8,  rOFF8SAVE(r1)
-	ld	rOFF16, rOFF16SAVE(r1)
-	ld	rOFF24, rOFF24SAVE(r1)
-	ld	rOFF32, rOFF32SAVE(r1)
-	li	rRTN, 1
-	bgtlr	cr6
-	li	rRTN, -1
-	blr
-	.align	4
-L(dLcr5):
-	ld	rWORD8, rWORD8SAVE(r1)
-	ld	rWORD7, rWORD7SAVE(r1)
-L(dLcr5x):
-	ld	rOFF8,  rOFF8SAVE(r1)
-	ld	rOFF16, rOFF16SAVE(r1)
-	ld	rOFF24, rOFF24SAVE(r1)
-	ld	rOFF32, rOFF32SAVE(r1)
-	li	rRTN, 1
-	bgtlr	cr5
-	li	rRTN, -1
-	blr
-
-	.align	4
-L(bytealigned):
-	mtctr	rN
-
-/* We need to prime this loop.  This loop is swing modulo scheduled
-   to avoid pipe delays.  The dependent instruction latencies (load to
-   compare to conditional branch) is 2 to 3 cycles.  In this loop each
-   dispatch group ends in a branch and takes 1 cycle.  Effectively
-   the first iteration of the loop only serves to load operands and
-   branches based on compares are delayed until the next loop.
-
-   So we must precondition some registers and condition codes so that
-   we don't exit the loop early on the first iteration.  */
-
-	lbz	rWORD1, 0(rSTR1)
-	lbz	rWORD2, 0(rSTR2)
-	bdz	L(b11)
-	cmpld	cr7, rWORD1, rWORD2
-	lbz	rWORD3, 1(rSTR1)
-	lbz	rWORD4, 1(rSTR2)
-	bdz	L(b12)
-	cmpld	cr1, rWORD3, rWORD4
-	lbzu	rWORD5, 2(rSTR1)
-	lbzu	rWORD6, 2(rSTR2)
-	bdz	L(b13)
-	.align	4
-L(bLoop):
-	lbzu	rWORD1, 1(rSTR1)
-	lbzu	rWORD2, 1(rSTR2)
-	bne	cr7, L(bLcr7)
-
-	cmpld	cr6, rWORD5, rWORD6
-	bdz	L(b3i)
-
-	lbzu	rWORD3, 1(rSTR1)
-	lbzu	rWORD4, 1(rSTR2)
-	bne	cr1, L(bLcr1)
-
-	cmpld	cr7, rWORD1, rWORD2
-	bdz	L(b2i)
-
-	lbzu	rWORD5, 1(rSTR1)
-	lbzu	rWORD6, 1(rSTR2)
-	bne	cr6, L(bLcr6)
-
-	cmpld	cr1, rWORD3, rWORD4
-	bdnz	L(bLoop)
-
-/* We speculatively loading bytes before we have tested the previous
-   bytes.  But we must avoid overrunning the length (in the ctr) to
-   prevent these speculative loads from causing a segfault.  In this
-   case the loop will exit early (before the all pending bytes are
-   tested.  In this case we must complete the pending operations
-   before returning.  */
-L(b1i):
-	bne	cr7, L(bLcr7)
-	bne	cr1, L(bLcr1)
-	b	L(bx56)
-	.align	4
-L(b2i):
-	bne	cr6, L(bLcr6)
-	bne	cr7, L(bLcr7)
-	b	L(bx34)
-	.align	4
-L(b3i):
-	bne	cr1, L(bLcr1)
-	bne	cr6, L(bLcr6)
-	b	L(bx12)
-	.align	4
-L(bLcr7):
-	li	rRTN, 1
-	bgtlr	cr7
-	li	rRTN, -1
-	blr
-L(bLcr1):
-	li	rRTN, 1
-	bgtlr	cr1
-	li	rRTN, -1
-	blr
-L(bLcr6):
-	li	rRTN, 1
-	bgtlr	cr6
-	li	rRTN, -1
-	blr
-
-L(b13):
-	bne	cr7, L(bx12)
-	bne	cr1, L(bx34)
-L(bx56):
-	sub	rRTN, rWORD5, rWORD6
-	blr
-	nop
-L(b12):
-	bne	cr7, L(bx12)
-L(bx34):
-	sub	rRTN, rWORD3, rWORD4
-	blr
-L(b11):
-L(bx12):
-	sub	rRTN, rWORD1, rWORD2
-	blr
-
-	.align	4
-L(zeroLength):
-	li	rRTN, 0
-	blr
-
-	.align	4
-/* At this point we know the strings have different alignment and the
-   compare length is at least 8 bytes.  r12 contains the low order
-   3 bits of rSTR1 and cr5 contains the result of the logical compare
-   of r12 to 0.  If r12 == 0 then rStr1 is double word
-   aligned and can perform the DWunaligned loop.
-
-   Otherwise we know that rSTR1 is not already DW aligned yet.
-   So we can force the string addresses to the next lower DW
-   boundary and special case this first DW using shift left to
-   eliminate bits preceding the first byte.  Since we want to join the
-   normal (DWaligned) compare loop, starting at the second double word,
-   we need to adjust the length (rN) and special case the loop
-   versioning for the first DW. This ensures that the loop count is
-   correct and the first DW (shifted) is in the expected resister pair.  */
-L(unaligned):
-	std	rSHL, rSHLSAVE(r1)
-	cfi_offset(rSHL, rSHLSAVE)
-	clrldi	rSHL, rSTR2, 61
-	beq	cr6, L(duzeroLength)
-	std	rSHR, rSHRSAVE(r1)
-	cfi_offset(rSHR, rSHRSAVE)
-	beq	cr5, L(DWunaligned)
-	std	rWORD8_SHIFT, rWORD8SHIFTSAVE(r1)
-	cfi_offset(rWORD8_SHIFT, rWORD8SHIFTSAVE)
-/* Adjust the logical start of rSTR2 to compensate for the extra bits
-   in the 1st rSTR1 DW.  */
-	sub	rWORD8_SHIFT, rSTR2, r12
-/* But do not attempt to address the DW before that DW that contains
-   the actual start of rSTR2.  */
-	clrrdi	rSTR2, rSTR2, 3
-	std	rWORD2_SHIFT, rWORD2SHIFTSAVE(r1)
-/* Compute the left/right shift counts for the unaligned rSTR2,
-   compensating for the logical (DW aligned) start of rSTR1.  */
-	clrldi	rSHL, rWORD8_SHIFT, 61
-	clrrdi	rSTR1, rSTR1, 3
-	std	rWORD4_SHIFT, rWORD4SHIFTSAVE(r1)
-	sldi	rSHL, rSHL, 3
-	cmpld	cr5, rWORD8_SHIFT, rSTR2
-	add	rN, rN, r12
-	sldi	rWORD6, r12, 3
-	std	rWORD6_SHIFT, rWORD6SHIFTSAVE(r1)
-	cfi_offset(rWORD2_SHIFT, rWORD2SHIFTSAVE)
-	cfi_offset(rWORD4_SHIFT, rWORD4SHIFTSAVE)
-	cfi_offset(rWORD6_SHIFT, rWORD6SHIFTSAVE)
-	subfic	rSHR, rSHL, 64
-	srdi	r0, rN, 5	/* Divide by 32 */
-	andi.	r12, rN, 24	/* Get the DW remainder */
-/* We normally need to load 2 DWs to start the unaligned rSTR2, but in
-   this special case those bits may be discarded anyway.  Also we
-   must avoid loading a DW where none of the bits are part of rSTR2 as
-   this may cross a page boundary and cause a page fault.  */
-	li	rWORD8, 0
-	blt	cr5, L(dus0)
-	LD	rWORD8, 0, rSTR2
-	addi	rSTR2, rSTR2, 8
-	sld	rWORD8, rWORD8, rSHL
-
-L(dus0):
-	LD	rWORD1, 0, rSTR1
-	LD	rWORD2, 0, rSTR2
-	cmpldi	cr1, r12, 16
-	cmpldi	cr7, rN, 32
-	srd	r12, rWORD2, rSHR
-	clrldi	rN, rN, 61
-	beq	L(duPs4)
-	mtctr	r0
-	or	rWORD8, r12, rWORD8
-	bgt	cr1, L(duPs3)
-	beq	cr1, L(duPs2)
-
-/* Remainder is 8 */
-	.align	4
-L(dusP1):
-	sld	rWORD8_SHIFT, rWORD2, rSHL
-	sld	rWORD7, rWORD1, rWORD6
-	sld	rWORD8, rWORD8, rWORD6
-	bge	cr7, L(duP1e)
-/* At this point we exit early with the first double word compare
-   complete and remainder of 0 to 7 bytes.  See L(du14) for details on
-   how we handle the remaining bytes.  */
-	cmpld	cr5, rWORD7, rWORD8
-	sldi.	rN, rN, 3
-	bne	cr5, L(duLcr5)
-	cmpld	cr7, rN, rSHR
-	beq	L(duZeroReturn)
-	li	r0, 0
-	ble	cr7, L(dutrim)
-	LD	rWORD2, rOFF8, rSTR2
-	srd	r0, rWORD2, rSHR
-	b	L(dutrim)
-/* Remainder is 16 */
-	.align	4
-L(duPs2):
-	sld	rWORD6_SHIFT, rWORD2, rSHL
-	sld	rWORD5, rWORD1, rWORD6
-	sld	rWORD6, rWORD8, rWORD6
-	b	L(duP2e)
-/* Remainder is 24 */
-	.align	4
-L(duPs3):
-	sld	rWORD4_SHIFT, rWORD2, rSHL
-	sld	rWORD3, rWORD1, rWORD6
-	sld	rWORD4, rWORD8, rWORD6
-	b	L(duP3e)
-/* Count is a multiple of 32, remainder is 0 */
-	.align	4
-L(duPs4):
-	mtctr	r0
-	or	rWORD8, r12, rWORD8
-	sld	rWORD2_SHIFT, rWORD2, rSHL
-	sld	rWORD1, rWORD1, rWORD6
-	sld	rWORD2, rWORD8, rWORD6
-	b	L(duP4e)
-
-/* At this point we know rSTR1 is double word aligned and the
-   compare length is at least 8 bytes.  */
-	.align	4
-L(DWunaligned):
-	std	rWORD8_SHIFT, rWORD8SHIFTSAVE(r1)
-	clrrdi	rSTR2, rSTR2, 3
-	std	rWORD2_SHIFT, rWORD2SHIFTSAVE(r1)
-	srdi	r0, rN, 5	/* Divide by 32 */
-	std	rWORD4_SHIFT, rWORD4SHIFTSAVE(r1)
-	andi.	r12, rN, 24	/* Get the DW remainder */
-	std	rWORD6_SHIFT, rWORD6SHIFTSAVE(r1)
-	cfi_offset(rWORD8_SHIFT, rWORD8SHIFTSAVE)
-	cfi_offset(rWORD2_SHIFT, rWORD2SHIFTSAVE)
-	cfi_offset(rWORD4_SHIFT, rWORD4SHIFTSAVE)
-	cfi_offset(rWORD6_SHIFT, rWORD6SHIFTSAVE)
-	sldi	rSHL, rSHL, 3
-	LD	rWORD6, 0, rSTR2
-	LD	rWORD8, rOFF8, rSTR2
-	addi	rSTR2, rSTR2, 8
-	cmpldi	cr1, r12, 16
-	cmpldi	cr7, rN, 32
-	clrldi	rN, rN, 61
-	subfic	rSHR, rSHL, 64
-	sld	rWORD6_SHIFT, rWORD6, rSHL
-	beq	L(duP4)
-	mtctr	r0
-	bgt	cr1, L(duP3)
-	beq	cr1, L(duP2)
-
-/* Remainder is 8 */
-	.align	4
-L(duP1):
-	srd	r12, rWORD8, rSHR
-	LD	rWORD7, 0, rSTR1
-	sld	rWORD8_SHIFT, rWORD8, rSHL
-	or	rWORD8, r12, rWORD6_SHIFT
-	blt	cr7, L(duP1x)
-L(duP1e):
-	LD	rWORD1, rOFF8, rSTR1
-	LD	rWORD2, rOFF8, rSTR2
-	cmpld	cr5, rWORD7, rWORD8
-	srd	r0, rWORD2, rSHR
-	sld	rWORD2_SHIFT, rWORD2, rSHL
-	or	rWORD2, r0, rWORD8_SHIFT
-	LD	rWORD3, rOFF16, rSTR1
-	LD	rWORD4, rOFF16, rSTR2
-	cmpld	cr7, rWORD1, rWORD2
-	srd	r12, rWORD4, rSHR
-	sld	rWORD4_SHIFT, rWORD4, rSHL
-	bne	cr5, L(duLcr5)
-	or	rWORD4, r12, rWORD2_SHIFT
-	LD	rWORD5, rOFF24, rSTR1
-	LD	rWORD6, rOFF24, rSTR2
-	cmpld	cr1, rWORD3, rWORD4
-	srd	r0, rWORD6, rSHR
-	sld	rWORD6_SHIFT, rWORD6, rSHL
-	bne	cr7, L(duLcr7)
-	or	rWORD6, r0, rWORD4_SHIFT
-	cmpld	cr6, rWORD5, rWORD6
-	b	L(duLoop3)
-	.align	4
-/* At this point we exit early with the first double word compare
-   complete and remainder of 0 to 7 bytes.  See L(du14) for details on
-   how we handle the remaining bytes.  */
-L(duP1x):
-	cmpld	cr5, rWORD7, rWORD8
-	sldi.	rN, rN, 3
-	bne	cr5, L(duLcr5)
-	cmpld	cr7, rN, rSHR
-	beq	L(duZeroReturn)
-	li	r0, 0
-	ble	cr7, L(dutrim)
-	LD	rWORD2, rOFF8, rSTR2
-	srd	r0, rWORD2, rSHR
-	b	L(dutrim)
-/* Remainder is 16 */
-	.align	4
-L(duP2):
-	srd	r0, rWORD8, rSHR
-	LD	rWORD5, 0, rSTR1
-	or	rWORD6, r0, rWORD6_SHIFT
-	sld	rWORD6_SHIFT, rWORD8, rSHL
-L(duP2e):
-	LD	rWORD7, rOFF8, rSTR1
-	LD	rWORD8, rOFF8, rSTR2
-	cmpld	cr6, rWORD5, rWORD6
-	srd	r12, rWORD8, rSHR
-	sld	rWORD8_SHIFT, rWORD8, rSHL
-	or	rWORD8, r12, rWORD6_SHIFT
-	blt	cr7, L(duP2x)
-	LD	rWORD1, rOFF16, rSTR1
-	LD	rWORD2, rOFF16, rSTR2
-	cmpld	cr5, rWORD7, rWORD8
-	bne	cr6, L(duLcr6)
-	srd	r0, rWORD2, rSHR
-	sld	rWORD2_SHIFT, rWORD2, rSHL
-	or	rWORD2, r0, rWORD8_SHIFT
-	LD	rWORD3, rOFF24, rSTR1
-	LD	rWORD4, rOFF24, rSTR2
-	cmpld	cr7, rWORD1, rWORD2
-	bne	cr5, L(duLcr5)
-	srd	r12, rWORD4, rSHR
-	sld	rWORD4_SHIFT, rWORD4, rSHL
-	or	rWORD4, r12, rWORD2_SHIFT
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-	cmpld	cr1, rWORD3, rWORD4
-	b	L(duLoop2)
-	.align	4
-L(duP2x):
-	cmpld	cr5, rWORD7, rWORD8
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-	bne	cr6, L(duLcr6)
-	sldi.	rN, rN, 3
-	bne	cr5, L(duLcr5)
-	cmpld	cr7, rN, rSHR
-	beq	L(duZeroReturn)
-	li	r0, 0
-	ble	cr7, L(dutrim)
-	LD	rWORD2, rOFF8, rSTR2
-	srd	r0, rWORD2, rSHR
-	b	L(dutrim)
-
-/* Remainder is 24 */
-	.align	4
-L(duP3):
-	srd	r12, rWORD8, rSHR
-	LD	rWORD3, 0, rSTR1
-	sld	rWORD4_SHIFT, rWORD8, rSHL
-	or	rWORD4, r12, rWORD6_SHIFT
-L(duP3e):
-	LD	rWORD5, rOFF8, rSTR1
-	LD	rWORD6, rOFF8, rSTR2
-	cmpld	cr1, rWORD3, rWORD4
-	srd	r0, rWORD6, rSHR
-	sld	rWORD6_SHIFT, rWORD6, rSHL
-	or	rWORD6, r0, rWORD4_SHIFT
-	LD	rWORD7, rOFF16, rSTR1
-	LD	rWORD8, rOFF16, rSTR2
-	cmpld	cr6, rWORD5, rWORD6
-	bne	cr1, L(duLcr1)
-	srd	r12, rWORD8, rSHR
-	sld	rWORD8_SHIFT, rWORD8, rSHL
-	or	rWORD8, r12, rWORD6_SHIFT
-	blt	cr7, L(duP3x)
-	LD	rWORD1, rOFF24, rSTR1
-	LD	rWORD2, rOFF24, rSTR2
-	cmpld	cr5, rWORD7, rWORD8
-	bne	cr6, L(duLcr6)
-	srd	r0, rWORD2, rSHR
-	sld	rWORD2_SHIFT, rWORD2, rSHL
-	or	rWORD2, r0, rWORD8_SHIFT
-	addi	rSTR1, rSTR1, 16
-	addi	rSTR2, rSTR2, 16
-	cmpld	cr7, rWORD1, rWORD2
-	b	L(duLoop1)
-	.align	4
-L(duP3x):
-	addi	rSTR1, rSTR1, 16
-	addi	rSTR2, rSTR2, 16
-	cmpld	cr5, rWORD7, rWORD8
-	bne	cr6, L(duLcr6)
-	sldi.	rN, rN, 3
-	bne	cr5, L(duLcr5)
-	cmpld	cr7, rN, rSHR
-	beq	L(duZeroReturn)
-	li	r0, 0
-	ble	cr7, L(dutrim)
-	LD	rWORD2, rOFF8, rSTR2
-	srd	r0, rWORD2, rSHR
-	b	L(dutrim)
-
-/* Count is a multiple of 32, remainder is 0 */
-	.align	4
-L(duP4):
-	mtctr	r0
-	srd	r0, rWORD8, rSHR
-	LD	rWORD1, 0, rSTR1
-	sld	rWORD2_SHIFT, rWORD8, rSHL
-	or	rWORD2, r0, rWORD6_SHIFT
-L(duP4e):
-	LD	rWORD3, rOFF8, rSTR1
-	LD	rWORD4, rOFF8, rSTR2
-	cmpld	cr7, rWORD1, rWORD2
-	srd	r12, rWORD4, rSHR
-	sld	rWORD4_SHIFT, rWORD4, rSHL
-	or	rWORD4, r12, rWORD2_SHIFT
-	LD	rWORD5, rOFF16, rSTR1
-	LD	rWORD6, rOFF16, rSTR2
-	cmpld	cr1, rWORD3, rWORD4
-	bne	cr7, L(duLcr7)
-	srd	r0, rWORD6, rSHR
-	sld	rWORD6_SHIFT, rWORD6, rSHL
-	or	rWORD6, r0, rWORD4_SHIFT
-	LD	rWORD7, rOFF24, rSTR1
-	LD	rWORD8, rOFF24, rSTR2
-	addi	rSTR1, rSTR1, 24
-	addi	rSTR2, rSTR2, 24
-	cmpld	cr6, rWORD5, rWORD6
-	bne	cr1, L(duLcr1)
-	srd	r12, rWORD8, rSHR
-	sld	rWORD8_SHIFT, rWORD8, rSHL
-	or	rWORD8, r12, rWORD6_SHIFT
-	cmpld	cr5, rWORD7, rWORD8
-	bdz	L(du24)		/* Adjust CTR as we start with +4 */
-/* This is the primary loop */
-	.align	4
-L(duLoop):
-	LD	rWORD1, rOFF8, rSTR1
-	LD	rWORD2, rOFF8, rSTR2
-	cmpld	cr1, rWORD3, rWORD4
-	bne	cr6, L(duLcr6)
-	srd	r0, rWORD2, rSHR
-	sld	rWORD2_SHIFT, rWORD2, rSHL
-	or	rWORD2, r0, rWORD8_SHIFT
-L(duLoop1):
-	LD	rWORD3, rOFF16, rSTR1
-	LD	rWORD4, rOFF16, rSTR2
-	cmpld	cr6, rWORD5, rWORD6
-	bne	cr5, L(duLcr5)
-	srd	r12, rWORD4, rSHR
-	sld	rWORD4_SHIFT, rWORD4, rSHL
-	or	rWORD4, r12, rWORD2_SHIFT
-L(duLoop2):
-	LD	rWORD5, rOFF24, rSTR1
-	LD	rWORD6, rOFF24, rSTR2
-	cmpld	cr5, rWORD7, rWORD8
-	bne	cr7, L(duLcr7)
-	srd	r0, rWORD6, rSHR
-	sld	rWORD6_SHIFT, rWORD6, rSHL
-	or	rWORD6, r0, rWORD4_SHIFT
-L(duLoop3):
-	LD	rWORD7, rOFF32, rSTR1
-	LD	rWORD8, rOFF32, rSTR2
-	addi	rSTR1, rSTR1, 32
-	addi	rSTR2, rSTR2, 32
-	cmpld	cr7, rWORD1, rWORD2
-	bne	cr1, L(duLcr1)
-	srd	r12, rWORD8, rSHR
-	sld	rWORD8_SHIFT, rWORD8, rSHL
-	or	rWORD8, r12, rWORD6_SHIFT
-	bdnz	L(duLoop)
-
-L(duL4):
-	cmpld	cr1, rWORD3, rWORD4
-	bne	cr6, L(duLcr6)
-	cmpld	cr6, rWORD5, rWORD6
-	bne	cr5, L(duLcr5)
-	cmpld	cr5, rWORD7, rWORD8
-L(du44):
-	bne	cr7, L(duLcr7)
-L(du34):
-	bne	cr1, L(duLcr1)
-L(du24):
-	bne	cr6, L(duLcr6)
-L(du14):
-	sldi.	rN, rN, 3
-	bne	cr5, L(duLcr5)
-/* At this point we have a remainder of 1 to 7 bytes to compare.  We use
-   shift right double to eliminate bits beyond the compare length.
-
-   However it may not be safe to load rWORD2 which may be beyond the
-   string length. So we compare the bit length of the remainder to
-   the right shift count (rSHR). If the bit count is less than or equal
-   we do not need to load rWORD2 (all significant bits are already in
-   rWORD8_SHIFT).  */
-	cmpld	cr7, rN, rSHR
-	beq	L(duZeroReturn)
-	li	r0, 0
-	ble	cr7, L(dutrim)
-	LD	rWORD2, rOFF8, rSTR2
-	srd	r0, rWORD2, rSHR
-	.align	4
-L(dutrim):
-	LD	rWORD1, rOFF8, rSTR1
-	ld	rWORD8, -8(r1)
-	subfic	rN, rN, 64	/* Shift count is 64 - (rN * 8).  */
-	or	rWORD2, r0, rWORD8_SHIFT
-	ld	rWORD7, rWORD7SAVE(r1)
-	ld	rSHL, rSHLSAVE(r1)
-	srd	rWORD1, rWORD1, rN
-	srd	rWORD2, rWORD2, rN
-	ld	rSHR, rSHRSAVE(r1)
-	ld	rWORD8_SHIFT, rWORD8SHIFTSAVE(r1)
-	li	rRTN, 0
-	cmpld	cr7, rWORD1, rWORD2
-	ld	rWORD2_SHIFT, rWORD2SHIFTSAVE(r1)
-	ld	rWORD4_SHIFT, rWORD4SHIFTSAVE(r1)
-	beq	cr7, L(dureturn24)
-	li	rRTN, 1
-	ld	rWORD6_SHIFT, rWORD6SHIFTSAVE(r1)
-	ld	rOFF8,  rOFF8SAVE(r1)
-	ld	rOFF16, rOFF16SAVE(r1)
-	ld	rOFF24, rOFF24SAVE(r1)
-	ld	rOFF32, rOFF32SAVE(r1)
-	bgtlr	cr7
-	li	rRTN, -1
-	blr
-	.align	4
-L(duLcr7):
-	ld	rWORD8, rWORD8SAVE(r1)
-	ld	rWORD7, rWORD7SAVE(r1)
-	li	rRTN, 1
-	bgt	cr7, L(dureturn29)
-	ld	rSHL, rSHLSAVE(r1)
-	ld	rSHR, rSHRSAVE(r1)
-	li	rRTN, -1
-	b	L(dureturn27)
-	.align	4
-L(duLcr1):
-	ld	rWORD8, rWORD8SAVE(r1)
-	ld	rWORD7, rWORD7SAVE(r1)
-	li	rRTN, 1
-	bgt	cr1, L(dureturn29)
-	ld	rSHL, rSHLSAVE(r1)
-	ld	rSHR, rSHRSAVE(r1)
-	li	rRTN, -1
-	b	L(dureturn27)
-	.align	4
-L(duLcr6):
-	ld	rWORD8, rWORD8SAVE(r1)
-	ld	rWORD7, rWORD7SAVE(r1)
-	li	rRTN, 1
-	bgt	cr6, L(dureturn29)
-	ld	rSHL, rSHLSAVE(r1)
-	ld	rSHR, rSHRSAVE(r1)
-	li	rRTN, -1
-	b	L(dureturn27)
-	.align	4
-L(duLcr5):
-	ld	rWORD8, rWORD8SAVE(r1)
-	ld	rWORD7, rWORD7SAVE(r1)
-	li	rRTN, 1
-	bgt	cr5, L(dureturn29)
-	ld	rSHL, rSHLSAVE(r1)
-	ld	rSHR, rSHRSAVE(r1)
-	li	rRTN, -1
-	b	L(dureturn27)
-
-	.align	3
-L(duZeroReturn):
-	li	rRTN, 0
-	.align	4
-L(dureturn):
-	ld	rWORD8, rWORD8SAVE(r1)
-	ld	rWORD7, rWORD7SAVE(r1)
-L(dureturn29):
-	ld	rSHL, rSHLSAVE(r1)
-	ld	rSHR, rSHRSAVE(r1)
-L(dureturn27):
-	ld	rWORD8_SHIFT, rWORD8SHIFTSAVE(r1)
-	ld	rWORD2_SHIFT, rWORD2SHIFTSAVE(r1)
-	ld	rWORD4_SHIFT, rWORD4SHIFTSAVE(r1)
-L(dureturn24):
-	ld	rWORD6_SHIFT, rWORD6SHIFTSAVE(r1)
-	ld	rOFF8,  rOFF8SAVE(r1)
-	ld	rOFF16, rOFF16SAVE(r1)
-	ld	rOFF24, rOFF24SAVE(r1)
-	ld	rOFF32, rOFF32SAVE(r1)
-	blr
-
-L(duzeroLength):
-	ld	rOFF8,  rOFF8SAVE(r1)
-	ld	rOFF16, rOFF16SAVE(r1)
-	ld	rOFF24, rOFF24SAVE(r1)
-	ld	rOFF32, rOFF32SAVE(r1)
-	li	rRTN, 0
-	blr
-
-END (MEMCMP)
-libc_hidden_builtin_def (memcmp)
-weak_alias (memcmp, bcmp)
diff --git a/sysdeps/powerpc/powerpc64/power7/memcpy.S b/sysdeps/powerpc/powerpc64/power7/memcpy.S
deleted file mode 100644
index 3d8629c..0000000
--- a/sysdeps/powerpc/powerpc64/power7/memcpy.S
+++ /dev/null
@@ -1,430 +0,0 @@
-/* Optimized memcpy implementation for PowerPC64/POWER7.
-   Copyright (C) 2010-2018 Free Software Foundation, Inc.
-   Contributed by Luis Machado <luisgpm@br.ibm.com>.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-
-/* void * [r3] memcpy (void *dst [r3], void *src [r4], size_t len [r5]);
-   Returns 'dst'.  */
-
-#ifndef MEMCPY
-# define MEMCPY memcpy
-#endif
-
-#define dst 11		/* Use r11 so r3 kept unchanged.  */
-#define src 4
-#define cnt 5
-
-	.machine power7
-ENTRY_TOCLESS (MEMCPY, 5)
-	CALL_MCOUNT 3
-
-	cmpldi	cr1,cnt,31
-	neg	0,3
-	ble	cr1, L(copy_LT_32)  /* If move < 32 bytes use short move
-				    code.  */
-
-/* Align copies using VSX instructions to quadword. It is to avoid alignment
-   traps when memcpy is used on non-cacheable memory (for instance, memory
-   mapped I/O).  */
-	andi.	10,3,15
-	clrldi	11,4,60
-	cmpld	cr6,10,11	/* SRC and DST alignments match?  */
-
-	mr	dst,3
-	bne	cr6,L(copy_GE_32_unaligned)
-	beq	L(aligned_copy)
-
-	mtocrf	0x01,0
-	clrldi	0,0,60
-
-/* Get the DST and SRC aligned to 16 bytes.  */
-1:
-	bf	31,2f
-	lbz	6,0(src)
-	addi	src,src,1
-	stb	6,0(dst)
-	addi	dst,dst,1
-2:
-	bf	30,4f
-	lhz	6,0(src)
-	addi	src,src,2
-	sth	6,0(dst)
-	addi	dst,dst,2
-4:
-	bf	29,8f
-	lwz	6,0(src)
-	addi	src,src,4
-	stw	6,0(dst)
-	addi	dst,dst,4
-8:
-	bf	28,16f
-	ld	6,0(src)
-	addi	src,src,8
-	std	6,0(dst)
-	addi	dst,dst,8
-16:
-	subf	cnt,0,cnt
-
-/* Main aligned copy loop. Copies 128 bytes at a time. */
-L(aligned_copy):
-	li	6,16
-	li	7,32
-	li	8,48
-	mtocrf	0x02,cnt
-	srdi	12,cnt,7
-	cmpdi	12,0
-	beq	L(aligned_tail)
-	lvx	6,0,src
-	lvx	7,src,6
-	mtctr	12
-	b	L(aligned_128loop)
-
-	.align  4
-L(aligned_128head):
-	/* for the 2nd + iteration of this loop. */
-	lvx	6,0,src
-	lvx	7,src,6
-L(aligned_128loop):
-	lvx	8,src,7
-	lvx	9,src,8
-	stvx	6,0,dst
-	addi	src,src,64
-	stvx	7,dst,6
-	stvx	8,dst,7
-	stvx	9,dst,8
-	lvx	6,0,src
-	lvx	7,src,6
-	addi	dst,dst,64
-	lvx	8,src,7
-	lvx	9,src,8
-	addi	src,src,64
-	stvx	6,0,dst
-	stvx	7,dst,6
-	stvx	8,dst,7
-	stvx	9,dst,8
-	addi	dst,dst,64
-	bdnz	L(aligned_128head)
-
-L(aligned_tail):
-	mtocrf	0x01,cnt
-	bf	25,32f
-	lvx	6,0,src
-	lvx	7,src,6
-	lvx	8,src,7
-	lvx	9,src,8
-	addi	src,src,64
-	stvx	6,0,dst
-	stvx	7,dst,6
-	stvx	8,dst,7
-	stvx	9,dst,8
-	addi	dst,dst,64
-32:
-	bf	26,16f
-	lvx	6,0,src
-	lvx	7,src,6
-	addi	src,src,32
-	stvx	6,0,dst
-	stvx	7,dst,6
-	addi	dst,dst,32
-16:
-	bf	27,8f
-	lvx	6,0,src
-	addi	src,src,16
-	stvx	6,0,dst
-	addi	dst,dst,16
-8:
-	bf	28,4f
-	ld	6,0(src)
-	addi	src,src,8
-	std     6,0(dst)
-	addi	dst,dst,8
-4:	/* Copies 4~7 bytes.  */
-	bf	29,L(tail2)
-	lwz	6,0(src)
-	stw     6,0(dst)
-	bf      30,L(tail5)
-	lhz     7,4(src)
-	sth     7,4(dst)
-	bflr	31
-	lbz     8,6(src)
-	stb     8,6(dst)
-	/* Return original DST pointer.  */
-	blr
-
-
-/* Handle copies of 0~31 bytes.  */
-	.align	4
-L(copy_LT_32):
-	mr	dst,3
-	cmpldi	cr6,cnt,8
-	mtocrf	0x01,cnt
-	ble	cr6,L(copy_LE_8)
-
-	/* At least 9 bytes to go.  */
-	neg	8,4
-	andi.	0,8,3
-	cmpldi	cr1,cnt,16
-	beq	L(copy_LT_32_aligned)
-
-	/* Force 4-byte alignment for SRC.  */
-	mtocrf	0x01,0
-	subf	cnt,0,cnt
-2:
-	bf	30,1f
-	lhz	6,0(src)
-	addi	src,src,2
-	sth	6,0(dst)
-	addi	dst,dst,2
-1:
-	bf	31,L(end_4bytes_alignment)
-	lbz	6,0(src)
-	addi	src,src,1
-	stb	6,0(dst)
-	addi	dst,dst,1
-
-	.align	4
-L(end_4bytes_alignment):
-	cmpldi	cr1,cnt,16
-	mtocrf	0x01,cnt
-
-L(copy_LT_32_aligned):
-	/* At least 6 bytes to go, and SRC is word-aligned.  */
-	blt	cr1,8f
-
-	/* Copy 16 bytes.  */
-	lwz	6,0(src)
-	lwz	7,4(src)
-	stw	6,0(dst)
-	lwz	8,8(src)
-	stw	7,4(dst)
-	lwz	6,12(src)
-	addi	src,src,16
-	stw	8,8(dst)
-	stw	6,12(dst)
-	addi	dst,dst,16
-8:	/* Copy 8 bytes.  */
-	bf	28,L(tail4)
-	lwz	6,0(src)
-	lwz	7,4(src)
-	addi	src,src,8
-	stw	6,0(dst)
-	stw	7,4(dst)
-	addi	dst,dst,8
-
-	.align	4
-/* Copies 4~7 bytes.  */
-L(tail4):
-	bf	29,L(tail2)
-	lwz	6,0(src)
-	stw	6,0(dst)
-	bf	30,L(tail5)
-	lhz	7,4(src)
-	sth	7,4(dst)
-	bflr	31
-	lbz	8,6(src)
-	stb	8,6(dst)
-	/* Return original DST pointer.  */
-	blr
-
-	.align	4
-/* Copies 2~3 bytes.  */
-L(tail2):
-	bf	30,1f
-	lhz	6,0(src)
-	sth	6,0(dst)
-	bflr	31
-	lbz	7,2(src)
-	stb	7,2(dst)
-	blr
-
-	.align	4
-L(tail5):
-	bflr	31
-	lbz	6,4(src)
-	stb	6,4(dst)
-	blr
-
-	.align	4
-1:
-	bflr	31
-	lbz	6,0(src)
-	stb	6,0(dst)
-	/* Return original DST pointer.  */
-	blr
-
-
-/* Handles copies of 0~8 bytes.  */
-	.align	4
-L(copy_LE_8):
-	bne	cr6,L(tail4)
-
-	/* Though we could've used ld/std here, they are still
-	slow for unaligned cases.  */
-
-	lwz	6,0(src)
-	lwz	7,4(src)
-	stw	6,0(dst)
-	stw	7,4(dst)
-	blr
-
-
-/* Handle copies of 32+ bytes where DST is aligned (to quadword) but
-   SRC is not.	Use aligned quadword loads from SRC, shifted to realign
-   the data, allowing for aligned DST stores.  */
-	.align	4
-L(copy_GE_32_unaligned):
-	clrldi	0,0,60	      /* Number of bytes until the 1st dst quadword.  */
-	srdi	9,cnt,4	      /* Number of full quadwords remaining.  */
-
-	beq	L(copy_GE_32_unaligned_cont)
-
-	/* DST is not quadword aligned, get it aligned.  */
-
-	mtocrf	0x01,0
-	subf	cnt,0,cnt
-
-	/* Vector instructions work best when proper alignment (16-bytes)
-	is present.  Move 0~15 bytes as needed to get DST quadword-aligned.  */
-1:
-	bf	31,2f
-	lbz	6,0(src)
-	addi	src,src,1
-	stb	6,0(dst)
-	addi	dst,dst,1
-2:
-	bf	30,4f
-	lhz	6,0(src)
-	addi	src,src,2
-	sth	6,0(dst)
-	addi	dst,dst,2
-4:
-	bf	29,8f
-	lwz	6,0(src)
-	addi	src,src,4
-	stw	6,0(dst)
-	addi	dst,dst,4
-8:
-	bf	28,0f
-	ld	6,0(src)
-	addi	src,src,8
-	std	6,0(dst)
-	addi	dst,dst,8
-0:
-	srdi	9,cnt,4	      /* Number of full quadwords remaining.  */
-
-	/* The proper alignment is present, it is OK to copy the bytes now.  */
-L(copy_GE_32_unaligned_cont):
-
-	/* Setup two indexes to speed up the indexed vector operations.  */
-	clrldi	10,cnt,60
-	li	6,16	      /* Index for 16-bytes offsets.  */
-	li	7,32	      /* Index for 32-bytes offsets.  */
-	cmpldi	cr1,10,0
-	srdi	8,cnt,5	      /* Setup the loop counter.  */
-	mtocrf	0x01,9
-	cmpldi	cr6,9,1
-#ifdef __LITTLE_ENDIAN__
-	lvsr	5,0,src
-#else
-	lvsl	5,0,src
-#endif
-	lvx	3,0,src
-	li	0,0
-	bf	31,L(setup_unaligned_loop)
-
-	/* Copy another 16 bytes to align to 32-bytes due to the loop.  */
-	lvx	4,src,6
-#ifdef __LITTLE_ENDIAN__
-	vperm	6,4,3,5
-#else
-	vperm	6,3,4,5
-#endif
-	addi	src,src,16
-	stvx	6,0,dst
-	addi	dst,dst,16
-	vor	3,4,4
-	clrrdi	0,src,60
-
-L(setup_unaligned_loop):
-	mtctr	8
-	ble	cr6,L(end_unaligned_loop)
-
-	/* Copy 32 bytes at a time using vector instructions.  */
-	.align	4
-L(unaligned_loop):
-
-	/* Note: vr6/vr10 may contain data that was already copied,
-	but in order to get proper alignment, we may have to copy
-	some portions again. This is faster than having unaligned
-	vector instructions though.  */
-
-	lvx	4,src,6
-#ifdef __LITTLE_ENDIAN__
-	vperm	6,4,3,5
-#else
-	vperm	6,3,4,5
-#endif
-	lvx	3,src,7
-#ifdef __LITTLE_ENDIAN__
-	vperm	10,3,4,5
-#else
-	vperm	10,4,3,5
-#endif
-	addi	src,src,32
-	stvx	6,0,dst
-	stvx	10,dst,6
-	addi	dst,dst,32
-	bdnz	L(unaligned_loop)
-
-	clrrdi	0,src,60
-
-	.align	4
-L(end_unaligned_loop):
-
-	/* Check for tail bytes.  */
-	mtocrf	0x01,cnt
-	beqlr	cr1
-
-	add	src,src,0
-
-	/*  We have 1~15 tail bytes to copy, and DST is quadword aligned.  */
-	/* Copy 8 bytes.  */
-	bf	28,4f
-	lwz	6,0(src)
-	lwz	7,4(src)
-	addi	src,src,8
-	stw	6,0(dst)
-	stw	7,4(dst)
-	addi	dst,dst,8
-4:	/* Copy 4~7 bytes.  */
-	bf	29,L(tail2)
-	lwz	6,0(src)
-	stw	6,0(dst)
-	bf	30,L(tail5)
-	lhz	7,4(src)
-	sth	7,4(dst)
-	bflr	31
-	lbz	8,6(src)
-	stb	8,6(dst)
-	/* Return original DST pointer.  */
-	blr
-
-END_GEN_TB (MEMCPY,TB_TOCLESS)
-libc_hidden_builtin_def (memcpy)
diff --git a/sysdeps/powerpc/powerpc64/power7/memmove.S b/sysdeps/powerpc/powerpc64/power7/memmove.S
deleted file mode 100644
index b7f3dc2..0000000
--- a/sysdeps/powerpc/powerpc64/power7/memmove.S
+++ /dev/null
@@ -1,835 +0,0 @@
-/* Optimized memmove implementation for PowerPC64/POWER7.
-   Copyright (C) 2014-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-
-/* void* [r3] memmove (void *dest [r3], const void *src [r4], size_t len [r5])
-
-   This optimization check if memory 'dest'  overlaps with 'src'. If it does
-   not then it calls an optimized memcpy call (similar to memcpy for POWER7,
-   embedded here to gain some cycles).
-   If source and destiny overlaps, a optimized backwards memcpy is used
-   instead.  */
-
-#ifndef MEMMOVE
-# define MEMMOVE memmove
-#endif
-	.machine power7
-ENTRY_TOCLESS (MEMMOVE, 5)
-	CALL_MCOUNT 3
-
-L(_memmove):
-	subf    r9,r4,r3
-	cmpld   cr7,r9,r5
-	blt	cr7,L(memmove_bwd)
-
-	cmpldi	cr1,r5,31
-	neg	0,3
-	ble	cr1, L(copy_LT_32)  /* If move < 32 bytes use short move
-				       code.  */
-
-	andi.	10,3,15
-	clrldi	11,4,60
-	cmpld	cr6,10,11	/* SRC and DST alignments match?  */
-
-	mr	r11,3
-	bne	cr6,L(copy_GE_32_unaligned)
-	beq	L(aligned_copy)
-
-	mtocrf	0x01,0
-	clrldi	0,0,60
-
-/* Get the DST and SRC aligned to 8 bytes (16 for little-endian).  */
-1:
-	bf	31,2f
-	lbz	6,0(r4)
-	addi	r4,r4,1
-	stb	6,0(r11)
-	addi	r11,r11,1
-2:
-	bf	30,4f
-	lhz	6,0(r4)
-	addi	r4,r4,2
-	sth	6,0(r11)
-	addi	r11,r11,2
-4:
-	bf	29,8f
-	lwz	6,0(r4)
-	addi	r4,r4,4
-	stw	6,0(r11)
-	addi	r11,r11,4
-8:
-	bf	28,16f
-	ld	6,0(r4)
-	addi	r4,r4,8
-	std	6,0(r11)
-	addi	r11,r11,8
-16:
-	subf	r5,0,r5
-
-/* Main aligned copy loop. Copies 128 bytes at a time. */
-L(aligned_copy):
-	li	6,16
-	li	7,32
-	li	8,48
-	mtocrf	0x02,r5
-	srdi	12,r5,7
-	cmpdi	12,0
-	beq	L(aligned_tail)
-	lvx	6,0,r4
-	lvx	7,r4,6
-	mtctr	12
-	b	L(aligned_128loop)
-
-	.align  4
-L(aligned_128head):
-	/* for the 2nd + iteration of this loop. */
-	lvx	6,0,r4
-	lvx	7,r4,6
-L(aligned_128loop):
-	lvx	8,r4,7
-	lvx	9,r4,8
-	stvx	6,0,r11
-	addi	r4,r4,64
-	stvx	7,r11,6
-	stvx	8,r11,7
-	stvx	9,r11,8
-	lvx	6,0,r4
-	lvx	7,r4,6
-	addi	r11,r11,64
-	lvx	8,r4,7
-	lvx	9,r4,8
-	addi	r4,r4,64
-	stvx	6,0,r11
-	stvx	7,r11,6
-	stvx	8,r11,7
-	stvx	9,r11,8
-	addi	r11,r11,64
-	bdnz	L(aligned_128head)
-
-L(aligned_tail):
-	mtocrf	0x01,r5
-	bf	25,32f
-	lvx	6,0,r4
-	lvx	7,r4,6
-	lvx	8,r4,7
-	lvx	9,r4,8
-	addi	r4,r4,64
-	stvx	6,0,r11
-	stvx	7,r11,6
-	stvx	8,r11,7
-	stvx	9,r11,8
-	addi	r11,r11,64
-32:
-	bf	26,16f
-	lvx	6,0,r4
-	lvx	7,r4,6
-	addi	r4,r4,32
-	stvx	6,0,r11
-	stvx	7,r11,6
-	addi	r11,r11,32
-16:
-	bf	27,8f
-	lvx	6,0,r4
-	addi	r4,r4,16
-	stvx	6,0,r11
-	addi	r11,r11,16
-8:
-	bf	28,4f
-	ld	6,0(r4)
-	addi	r4,r4,8
-	std     6,0(r11)
-	addi	r11,r11,8
-4:	/* Copies 4~7 bytes.  */
-	bf	29,L(tail2)
-	lwz	6,0(r4)
-	stw     6,0(r11)
-	bf      30,L(tail5)
-	lhz     7,4(r4)
-	sth     7,4(r11)
-	bflr	31
-	lbz     8,6(r4)
-	stb     8,6(r11)
-	/* Return original DST pointer.  */
-	blr
-
-/* Handle copies of 0~31 bytes.  */
-	.align	4
-L(copy_LT_32):
-	mr	r11,3
-	cmpldi	cr6,r5,8
-	mtocrf	0x01,r5
-	ble	cr6,L(copy_LE_8)
-
-	/* At least 9 bytes to go.  */
-	neg	8,4
-	andi.	0,8,3
-	cmpldi	cr1,r5,16
-	beq	L(copy_LT_32_aligned)
-
-	/* Force 4-byte alignment for SRC.  */
-	mtocrf	0x01,0
-	subf	r5,0,r5
-2:
-	bf	30,1f
-	lhz	6,0(r4)
-	addi	r4,r4,2
-	sth	6,0(r11)
-	addi	r11,r11,2
-1:
-	bf	31,L(end_4bytes_alignment)
-	lbz	6,0(r4)
-	addi	r4,r4,1
-	stb	6,0(r11)
-	addi	r11,r11,1
-
-	.align	4
-L(end_4bytes_alignment):
-	cmpldi	cr1,r5,16
-	mtocrf	0x01,r5
-
-L(copy_LT_32_aligned):
-	/* At least 6 bytes to go, and SRC is word-aligned.  */
-	blt	cr1,8f
-
-	/* Copy 16 bytes.  */
-	lwz	6,0(r4)
-	lwz	7,4(r4)
-	stw	6,0(r11)
-	lwz	8,8(r4)
-	stw	7,4(r11)
-	lwz	6,12(r4)
-	addi	r4,r4,16
-	stw	8,8(r11)
-	stw	6,12(r11)
-	addi	r11,r11,16
-8:	/* Copy 8 bytes.  */
-	bf	28,L(tail4)
-	lwz	6,0(r4)
-	lwz	7,4(r4)
-	addi	r4,r4,8
-	stw	6,0(r11)
-	stw	7,4(r11)
-	addi	r11,r11,8
-
-	.align	4
-/* Copies 4~7 bytes.  */
-L(tail4):
-	bf	29,L(tail2)
-	lwz	6,0(r4)
-	stw	6,0(r11)
-	bf	30,L(tail5)
-	lhz	7,4(r4)
-	sth	7,4(r11)
-	bflr	31
-	lbz	8,6(r4)
-	stb	8,6(r11)
-	/* Return original DST pointer.  */
-	blr
-
-	.align	4
-/* Copies 2~3 bytes.  */
-L(tail2):
-	bf	30,1f
-	lhz	6,0(r4)
-	sth	6,0(r11)
-	bflr	31
-	lbz	7,2(r4)
-	stb	7,2(r11)
-	blr
-
-	.align	4
-L(tail5):
-	bflr	31
-	lbz	6,4(r4)
-	stb	6,4(r11)
-	blr
-
-	.align	4
-1:
-	bflr	31
-	lbz	6,0(r4)
-	stb	6,0(r11)
-	/* Return original DST pointer.  */
-	blr
-
-/* Handles copies of 0~8 bytes.  */
-	.align	4
-L(copy_LE_8):
-	bne	cr6,L(tail4)
-
-	/* Though we could've used ld/std here, they are still
-	slow for unaligned cases.  */
-
-	lwz	6,0(r4)
-	lwz	7,4(r4)
-	stw	6,0(r11)
-	stw	7,4(r11)
-	blr
-
-
-/* Handle copies of 32+ bytes where DST is aligned (to quadword) but
-   SRC is not.	Use aligned quadword loads from SRC, shifted to realign
-   the data, allowing for aligned DST stores.  */
-	.align	4
-L(copy_GE_32_unaligned):
-	clrldi	0,0,60	      /* Number of bytes until the 1st r11 quadword.  */
-	srdi	9,r5,4	      /* Number of full quadwords remaining.  */
-
-	beq	L(copy_GE_32_unaligned_cont)
-
-	/* DST is not quadword aligned, get it aligned.  */
-
-	mtocrf	0x01,0
-	subf	r5,0,r5
-
-	/* Vector instructions work best when proper alignment (16-bytes)
-	is present.  Move 0~15 bytes as needed to get DST quadword-aligned.  */
-1:
-	bf	31,2f
-	lbz	6,0(r4)
-	addi	r4,r4,1
-	stb	6,0(r11)
-	addi	r11,r11,1
-2:
-	bf	30,4f
-	lhz	6,0(r4)
-	addi	r4,r4,2
-	sth	6,0(r11)
-	addi	r11,r11,2
-4:
-	bf	29,8f
-	lwz	6,0(r4)
-	addi	r4,r4,4
-	stw	6,0(r11)
-	addi	r11,r11,4
-8:
-	bf	28,0f
-	ld	6,0(r4)
-	addi	r4,r4,8
-	std	6,0(r11)
-	addi	r11,r11,8
-0:
-	srdi	9,r5,4	      /* Number of full quadwords remaining.  */
-
-	/* The proper alignment is present, it is OK to copy the bytes now.  */
-L(copy_GE_32_unaligned_cont):
-
-	/* Setup two indexes to speed up the indexed vector operations.  */
-	clrldi	10,r5,60
-	li	6,16	      /* Index for 16-bytes offsets.  */
-	li	7,32	      /* Index for 32-bytes offsets.  */
-	cmpldi	cr1,10,0
-	srdi	8,r5,5	      /* Setup the loop counter.  */
-	mtocrf	0x01,9
-	cmpldi	cr6,9,1
-#ifdef __LITTLE_ENDIAN__
-	lvsr	5,0,r4
-#else
-	lvsl	5,0,r4
-#endif
-	lvx	3,0,r4
-	li	0,0
-	bf	31,L(setup_unaligned_loop)
-
-	/* Copy another 16 bytes to align to 32-bytes due to the loop.  */
-	lvx	4,r4,6
-#ifdef __LITTLE_ENDIAN__
-	vperm	6,4,3,5
-#else
-	vperm	6,3,4,5
-#endif
-	addi	r4,r4,16
-	stvx	6,0,r11
-	addi	r11,r11,16
-	vor	3,4,4
-	clrrdi	0,r4,60
-
-L(setup_unaligned_loop):
-	mtctr	8
-	ble	cr6,L(end_unaligned_loop)
-
-	/* Copy 32 bytes at a time using vector instructions.  */
-	.align	4
-L(unaligned_loop):
-
-	/* Note: vr6/vr10 may contain data that was already copied,
-	but in order to get proper alignment, we may have to copy
-	some portions again. This is faster than having unaligned
-	vector instructions though.  */
-
-	lvx	4,r4,6
-#ifdef __LITTLE_ENDIAN__
-	vperm	6,4,3,5
-#else
-	vperm	6,3,4,5
-#endif
-	lvx	3,r4,7
-#ifdef __LITTLE_ENDIAN__
-	vperm	10,3,4,5
-#else
-	vperm	10,4,3,5
-#endif
-	addi	r4,r4,32
-	stvx	6,0,r11
-	stvx	10,r11,6
-	addi	r11,r11,32
-	bdnz	L(unaligned_loop)
-
-	clrrdi	0,r4,60
-
-	.align	4
-L(end_unaligned_loop):
-
-	/* Check for tail bytes.  */
-	mtocrf	0x01,r5
-	beqlr	cr1
-
-	add	r4,r4,0
-
-	/*  We have 1~15 tail bytes to copy, and DST is quadword aligned.  */
-	/* Copy 8 bytes.  */
-	bf	28,4f
-	lwz	6,0(r4)
-	lwz	7,4(r4)
-	addi	r4,r4,8
-	stw	6,0(r11)
-	stw	7,4(r11)
-	addi	r11,r11,8
-4:	/* Copy 4~7 bytes.  */
-	bf	29,L(tail2)
-	lwz	6,0(r4)
-	stw	6,0(r11)
-	bf	30,L(tail5)
-	lhz	7,4(r4)
-	sth	7,4(r11)
-	bflr	31
-	lbz	8,6(r4)
-	stb	8,6(r11)
-	/* Return original DST pointer.  */
-	blr
-
-	/* Start to memcpy backward implementation: the algorith first check if
-	   src and dest have the same alignment and if it does align both to 16
-	   bytes and copy using VSX instructions.
-	   If does not, align dest to 16 bytes and use VMX (altivec) instruction
-	   to read two 16 bytes at time, shift/permute the bytes read and write
-	   aligned to dest.  */
-L(memmove_bwd):
-	cmpldi	cr1,r5,31
-	/* Copy is done backwards: update the pointers and check alignment.  */
-	add	r11,r3,r5
-	add	r4,r4,r5
-	mr	r0,r11
-	ble	cr1, L(copy_LT_32_bwd)  /* If move < 32 bytes use short move
-				           code.  */
-
-	andi.	r10,r11,15	    /* Check if r11 is aligned to 16 bytes  */
-	clrldi	r9,r4,60	    /* Check if r4 is aligned to 16 bytes  */
-	cmpld	cr6,r10,r9	    /* SRC and DST alignments match?  */
-
-	bne     cr6,L(copy_GE_32_unaligned_bwd)
-	beq     L(aligned_copy_bwd)
-
-	mtocrf	0x01,r0
-	clrldi	r0,r0,60
-
-/* Get the DST and SRC aligned to 16 bytes.  */
-1:
-	bf	31,2f
-	lbz	r6,-1(r4)
-	subi	r4,r4,1
-	stb	r6,-1(r11)
-	subi	r11,r11,1
-2:
-	bf	30,4f
-	lhz	r6,-2(r4)
-	subi	r4,r4,2
-	sth	r6,-2(r11)
-	subi	r11,r11,2
-4:
-	bf	29,8f
-	lwz	r6,-4(r4)
-	subi	r4,r4,4
-	stw	r6,-4(r11)
-	subi	r11,r11,4
-8:
-	bf	28,16f
-	ld	r6,-8(r4)
-	subi	r4,r4,8
-	std	r6,-8(r11)
-	subi	r11,r11,8
-16:
-	subf	r5,0,r5
-
-/* Main aligned copy loop. Copies 128 bytes at a time. */
-L(aligned_copy_bwd):
-	li	r6,-16
-	li	r7,-32
-	li	r8,-48
-	li	r9,-64
-	mtocrf	0x02,r5
-	srdi	r12,r5,7
-	cmpdi	r12,0
-	beq	L(aligned_tail_bwd)
-	lvx	v6,r4,r6
-	lvx	v7,r4,r7
-	mtctr	12
-	b	L(aligned_128loop_bwd)
-
-	.align  4
-L(aligned_128head_bwd):
-	/* for the 2nd + iteration of this loop. */
-	lvx	v6,r4,r6
-	lvx	v7,r4,r7
-L(aligned_128loop_bwd):
-	lvx	v8,r4,r8
-	lvx	v9,r4,r9
-	stvx	v6,r11,r6
-	subi	r4,r4,64
-	stvx	v7,r11,r7
-	stvx	v8,r11,r8
-	stvx	v9,r11,r9
-	lvx	v6,r4,r6
-	lvx	v7,r4,7
-	subi	r11,r11,64
-	lvx	v8,r4,r8
-	lvx	v9,r4,r9
-	subi	r4,r4,64
-	stvx	v6,r11,r6
-	stvx	v7,r11,r7
-	stvx	v8,r11,r8
-	stvx	v9,r11,r9
-	subi	r11,r11,64
-	bdnz	L(aligned_128head_bwd)
-
-L(aligned_tail_bwd):
-	mtocrf	0x01,r5
-	bf	25,32f
-	lvx	v6,r4,r6
-	lvx	v7,r4,r7
-	lvx	v8,r4,r8
-	lvx	v9,r4,r9
-	subi	r4,r4,64
-	stvx	v6,r11,r6
-	stvx	v7,r11,r7
-	stvx	v8,r11,r8
-	stvx	v9,r11,r9
-	subi	r11,r11,64
-32:
-	bf	26,16f
-	lvx	v6,r4,r6
-	lvx	v7,r4,r7
-	subi	r4,r4,32
-	stvx	v6,r11,r6
-	stvx	v7,r11,r7
-	subi	r11,r11,32
-16:
-	bf	27,8f
-	lvx	v6,r4,r6
-	subi	r4,r4,16
-	stvx	v6,r11,r6
-	subi	r11,r11,16
-8:
-	bf	28,4f
-	ld	r6,-8(r4)
-	subi	r4,r4,8
-	std     r6,-8(r11)
-	subi	r11,r11,8
-4:	/* Copies 4~7 bytes.  */
-	bf	29,L(tail2_bwd)
-	lwz	r6,-4(r4)
-	stw     r6,-4(r11)
-	bf      30,L(tail5_bwd)
-	lhz     r7,-6(r4)
-	sth     r7,-6(r11)
-	bflr	31
-	lbz     r8,-7(r4)
-	stb     r8,-7(r11)
-	/* Return original DST pointer.  */
-	blr
-
-/* Handle copies of 0~31 bytes.  */
-	.align	4
-L(copy_LT_32_bwd):
-	cmpldi	cr6,r5,8
-	mtocrf	0x01,r5
-	ble	cr6,L(copy_LE_8_bwd)
-
-	/* At least 9 bytes to go.  */
-	neg	r8,r4
-	andi.	r0,r8,3
-	cmpldi	cr1,r5,16
-	beq	L(copy_LT_32_aligned_bwd)
-
-	/* Force 4-byte alignment for SRC.  */
-	mtocrf	0x01,0
-	subf	r5,0,r5
-2:
-	bf	30,1f
-	lhz	r6,-2(r4)
-	subi	r4,r4,2
-	sth	r6,-2(r11)
-	subi	r11,r11,2
-1:
-	bf	31,L(end_4bytes_alignment_bwd)
-	lbz	6,-1(r4)
-	subi	r4,r4,1
-	stb	6,-1(r11)
-	subi	r11,r11,1
-
-	.align	4
-L(end_4bytes_alignment_bwd):
-	cmpldi	cr1,r5,16
-	mtocrf	0x01,r5
-
-L(copy_LT_32_aligned_bwd):
-	/* At least 6 bytes to go, and SRC is word-aligned.  */
-	blt	cr1,8f
-
-	/* Copy 16 bytes.  */
-	lwz	r6,-4(r4)
-	lwz	r7,-8(r4)
-	stw	r6,-4(r11)
-	lwz	r8,-12(r4)
-	stw	r7,-8(r11)
-	lwz	r6,-16(r4)
-	subi	r4,r4,16
-	stw	r8,-12(r11)
-	stw	r6,-16(r11)
-	subi	r11,r11,16
-8:	/* Copy 8 bytes.  */
-	bf	28,L(tail4_bwd)
-	lwz	r6,-4(r4)
-	lwz	r7,-8(r4)
-	subi	r4,r4,8
-	stw	r6,-4(r11)
-	stw	r7,-8(r11)
-	subi	r11,r11,8
-
-	.align	4
-/* Copies 4~7 bytes.  */
-L(tail4_bwd):
-	bf	29,L(tail2_bwd)
-	lwz	6,-4(r4)
-	stw	6,-4(r11)
-	bf	30,L(tail5_bwd)
-	lhz	7,-6(r4)
-	sth	7,-6(r11)
-	bflr	31
-	lbz	8,-7(r4)
-	stb	8,-7(r11)
-	/* Return original DST pointer.  */
-	blr
-
-	.align	4
-/* Copies 2~3 bytes.  */
-L(tail2_bwd):
-	bf	30,1f
-	lhz	6,-2(r4)
-	sth	6,-2(r11)
-	bflr	31
-	lbz	7,-3(r4)
-	stb	7,-3(r11)
-	blr
-
-	.align	4
-L(tail5_bwd):
-	bflr	31
-	lbz	6,-5(r4)
-	stb	6,-5(r11)
-	blr
-
-	.align	4
-1:
-	bflr	31
-	lbz	6,-1(r4)
-	stb	6,-1(r11)
-	/* Return original DST pointer.  */
-	blr
-
-
-/* Handles copies of 0~8 bytes.  */
-	.align	4
-L(copy_LE_8_bwd):
-	bne	cr6,L(tail4_bwd)
-
-	/* Though we could've used ld/std here, they are still
-	   slow for unaligned cases.  */
-	lwz	6,-8(r4)
-	lwz	7,-4(r4)
-	stw	6,-8(r11)
-	stw	7,-4(r11)
-	blr
-
-
-/* Handle copies of 32+ bytes where DST is aligned (to quadword) but
-   SRC is not.	Use aligned quadword loads from SRC, shifted to realign
-   the data, allowing for aligned DST stores.  */
-	.align	4
-L(copy_GE_32_unaligned_bwd):
-	andi.	r10,r11,15      /* Check alignment of DST against 16 bytes..  */
-	srdi	r9,r5,4		/* Number of full quadwords remaining.  */
-
-	beq	L(copy_GE_32_unaligned_cont_bwd)
-
-	/* DST is not quadword aligned and r10 holds the address masked to
-           compare alignments.  */
-	mtocrf	0x01,r10
-	subf	r5,r10,r5
-
-	/* Vector instructions work best when proper alignment (16-bytes)
-	is present.  Move 0~15 bytes as needed to get DST quadword-aligned.  */
-1:
-	bf	31,2f
-	lbz	r6,-1(r4)
-	subi	r4,r4,1
-	stb	r6,-1(r11)
-	subi	r11,r11,1
-2:
-	bf	30,4f
-	lhz	r6,-2(r4)
-	subi	r4,r4,2
-	sth	r6,-2(r11)
-	subi	r11,r11,2
-4:
-	bf	29,8f
-	lwz	r6,-4(r4)
-	subi	r4,r4,4
-	stw	r6,-4(r11)
-	subi	r11,r11,4
-8:
-	bf	28,0f
-	ld	r6,-8(r4)
-	subi	r4,r4,8
-	std	r6,-8(r11)
-	subi	r11,r11,8
-0:
-	srdi	r9,r5,4	      /* Number of full quadwords remaining.  */
-
-	/* The proper alignment is present, it is OK to copy the bytes now.  */
-L(copy_GE_32_unaligned_cont_bwd):
-
-	/* Setup two indexes to speed up the indexed vector operations.  */
-	clrldi	r10,r5,60
-	li	r6,-16	      /* Index for 16-bytes offsets.  */
-	li	r7,-32	      /* Index for 32-bytes offsets.  */
-	cmpldi	cr1,10,0
-	srdi	r8,r5,5	      /* Setup the loop counter.  */
-	mtocrf	0x01,9
-	cmpldi	cr6,r9,1
-#ifdef __LITTLE_ENDIAN__
-	lvsr	v5,r0,r4
-#else
-	lvsl	v5,r0,r4
-#endif
-	lvx	v3,0,r4
-	li	r0,0
-	bf	31,L(setup_unaligned_loop_bwd)
-
-	/* Copy another 16 bytes to align to 32-bytes due to the loop.  */
-	lvx	v4,r4,r6
-#ifdef __LITTLE_ENDIAN__
-	vperm	v6,v3,v4,v5
-#else
-	vperm	v6,v4,v3,v5
-#endif
-	subi	r4,r4,16
-	stvx	v6,r11,r6
-	subi	r11,r11,16
-	vor	v3,v4,v4
-	clrrdi	r0,r4,60
-
-L(setup_unaligned_loop_bwd):
-	mtctr	r8
-	ble	cr6,L(end_unaligned_loop_bwd)
-
-	/* Copy 32 bytes at a time using vector instructions.  */
-	.align	4
-L(unaligned_loop_bwd):
-
-	/* Note: vr6/vr10 may contain data that was already copied,
-	but in order to get proper alignment, we may have to copy
-	some portions again. This is faster than having unaligned
-	vector instructions though.  */
-
-	lvx	v4,r4,r6
-#ifdef __LITTLE_ENDIAN__
-	vperm	v6,v3,v4,v5
-#else
-	vperm	v6,v4,v3,v5
-#endif
-	lvx	v3,r4,r7
-#ifdef __LITTLE_ENDIAN__
-	vperm	v10,v4,v3,v5
-#else
-	vperm	v10,v3,v4,v5
-#endif
-	subi	r4,r4,32
-	stvx	v6,r11,r6
-	stvx	v10,r11,r7
-	subi	r11,r11,32
-	bdnz	L(unaligned_loop_bwd)
-
-	clrrdi	r0,r4,60
-
-	.align	4
-L(end_unaligned_loop_bwd):
-
-	/* Check for tail bytes.  */
-	mtocrf	0x01,r5
-	beqlr	cr1
-
-	add	r4,r4,0
-
-	/*  We have 1~15 tail bytes to copy, and DST is quadword aligned.  */
-	/* Copy 8 bytes.  */
-	bf	28,4f
-	lwz	r6,-4(r4)
-	lwz	r7,-8(r4)
-	subi	r4,r4,8
-	stw	r6,-4(r11)
-	stw	r7,-8(r11)
-	subi	r11,r11,8
-4:	/* Copy 4~7 bytes.  */
-	bf	29,L(tail2_bwd)
-	lwz	r6,-4(r4)
-	stw	r6,-4(r11)
-	bf	30,L(tail5_bwd)
-	lhz	r7,-6(r4)
-	sth	r7,-6(r11)
-	bflr	31
-	lbz	r8,-7(r4)
-	stb	r8,-7(r11)
-	/* Return original DST pointer.  */
-	blr
-END_GEN_TB (MEMMOVE, TB_TOCLESS)
-libc_hidden_builtin_def (memmove)
-
-
-/* void bcopy(const void *src [r3], void *dest [r4], size_t n [r5])
-   Implemented in this file to avoid linker create a stub function call
-   in the branch to '_memmove'.  */
-ENTRY_TOCLESS (__bcopy)
-	mr	r6,r3
-	mr	r3,r4
-	mr	r4,r6
-	b	L(_memmove)
-END (__bcopy)
-weak_alias (__bcopy, bcopy)
diff --git a/sysdeps/powerpc/powerpc64/power7/mempcpy.S b/sysdeps/powerpc/powerpc64/power7/mempcpy.S
deleted file mode 100644
index 7f5a474..0000000
--- a/sysdeps/powerpc/powerpc64/power7/mempcpy.S
+++ /dev/null
@@ -1,472 +0,0 @@
-/* Optimized mempcpy implementation for POWER7.
-   Copyright (C) 2010-2018 Free Software Foundation, Inc.
-   Contributed by Luis Machado <luisgpm@br.ibm.com>.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-
-/* void * [r3] __mempcpy (void *dst [r3], void *src [r4], size_t len [r5]);
-    Returns 'dst' + 'len'.  */
-
-#ifndef MEMPCPY
-# define MEMPCPY __mempcpy
-#endif
-	.machine  power7
-ENTRY_TOCLESS (MEMPCPY, 5)
-	CALL_MCOUNT 3
-
-	cmpldi	cr1,5,31
-	neg	0,3
-	std	3,-16(1)
-	std	31,-8(1)
-	cfi_offset(31,-8)
-	ble	cr1,L(copy_LT_32)   /* If move < 32 bytes use short move
-				       code.  */
-
-	andi.	11,3,7	      /* Check alignment of DST.  */
-
-
-	clrldi	10,4,61	      /* Check alignment of SRC.  */
-	cmpld	cr6,10,11     /* SRC and DST alignments match?  */
-	mr	12,4
-	mr	31,5
-	bne	cr6,L(copy_GE_32_unaligned)
-
-	srdi	9,5,3	      /* Number of full quadwords remaining.  */
-
-	beq	L(copy_GE_32_aligned_cont)
-
-	clrldi	0,0,61
-	mtcrf	0x01,0
-	subf	31,0,5
-
-	/* Get the SRC aligned to 8 bytes.  */
-
-1:	bf	31,2f
-	lbz	6,0(12)
-	addi	12,12,1
-	stb	6,0(3)
-	addi	3,3,1
-2:	bf	30,4f
-	lhz	6,0(12)
-	addi	12,12,2
-	sth	6,0(3)
-	addi	3,3,2
-4:	bf	29,0f
-	lwz	6,0(12)
-	addi	12,12,4
-	stw	6,0(3)
-	addi	3,3,4
-0:
-	clrldi	10,12,61      /* Check alignment of SRC again.  */
-	srdi	9,31,3	      /* Number of full doublewords remaining.  */
-
-L(copy_GE_32_aligned_cont):
-
-	clrldi	11,31,61
-	mtcrf	0x01,9
-
-	srdi	8,31,5
-	cmpldi	cr1,9,4
-	cmpldi	cr6,11,0
-	mr	11,12
-
-	/* Copy 1~3 doublewords so the main loop starts
-	at a multiple of 32 bytes.  */
-
-	bf	30,1f
-	ld	6,0(12)
-	ld	7,8(12)
-	addi	11,12,16
-	mtctr	8
-	std	6,0(3)
-	std	7,8(3)
-	addi	10,3,16
-	bf	31,4f
-	ld	0,16(12)
-	std	0,16(3)
-	blt	cr1,3f
-	addi	11,12,24
-	addi	10,3,24
-	b	4f
-
-	.align	4
-1:	/* Copy 1 doubleword and set the counter.  */
-	mr	10,3
-	mtctr	8
-	bf	31,4f
-	ld	6,0(12)
-	addi	11,12,8
-	std	6,0(3)
-	addi	10,3,8
-
-	/* Main aligned copy loop. Copies 32-bytes at a time.  */
-	.align	4
-4:
-	ld	6,0(11)
-	ld	7,8(11)
-	ld	8,16(11)
-	ld	0,24(11)
-	addi	11,11,32
-
-	std	6,0(10)
-	std	7,8(10)
-	std	8,16(10)
-	std	0,24(10)
-	addi	10,10,32
-	bdnz	4b
-3:
-
-	/* Check for tail bytes.  */
-	rldicr	0,31,0,60
-	mtcrf	0x01,31
-	beq	cr6,0f
-
-.L9:
-	add	3,3,0
-	add	12,12,0
-
-	/*  At this point we have a tail of 0-7 bytes and we know that the
-	destination is doubleword-aligned.  */
-4:	/* Copy 4 bytes.  */
-	bf	29,2f
-
-	lwz	6,0(12)
-	addi	12,12,4
-	stw	6,0(3)
-	addi	3,3,4
-2:	/* Copy 2 bytes.  */
-	bf	30,1f
-
-	lhz	6,0(12)
-	addi	12,12,2
-	sth	6,0(3)
-	addi	3,3,2
-1:	/* Copy 1 byte.  */
-	bf	31,0f
-
-	lbz	6,0(12)
-	stb	6,0(3)
-0:	/* Return DST + LEN pointer.  */
-	ld	31,-8(1)
-	ld	3,-16(1)
-	add	3,3,5
-	blr
-
-	/* Handle copies of 0~31 bytes.  */
-	.align	4
-L(copy_LT_32):
-	cmpldi	cr6,5,8
-	mr	12,4
-	mtcrf	0x01,5
-	ble	cr6,L(copy_LE_8)
-
-	/* At least 9 bytes to go.  */
-	neg	8,4
-	clrrdi	11,4,2
-	andi.	0,8,3
-	cmpldi	cr1,5,16
-	mr	10,5
-	beq	L(copy_LT_32_aligned)
-
-	/* Force 4-bytes alignment for SRC.  */
-	mtocrf  0x01,0
-	subf	10,0,5
-2:	bf	30,1f
-
-	lhz	6,0(12)
-	addi	12,12,2
-	sth	6,0(3)
-	addi	3,3,2
-1:	bf	31,L(end_4bytes_alignment)
-
-	lbz	6,0(12)
-	addi	12,12,1
-	stb	6,0(3)
-	addi	3,3,1
-
-	.align	4
-L(end_4bytes_alignment):
-	cmpldi	cr1,10,16
-	mtcrf	0x01,10
-
-L(copy_LT_32_aligned):
-	/* At least 6 bytes to go, and SRC is word-aligned.  */
-	blt	cr1,8f
-
-	/* Copy 16 bytes.  */
-	lwz	6,0(12)
-	lwz	7,4(12)
-	stw	6,0(3)
-	lwz	8,8(12)
-	stw	7,4(3)
-	lwz	6,12(12)
-	addi	12,12,16
-	stw	8,8(3)
-	stw	6,12(3)
-	addi	3,3,16
-8:	/* Copy 8 bytes.  */
-	bf	28,4f
-
-	lwz	6,0(12)
-	lwz	7,4(12)
-	addi	12,12,8
-	stw	6,0(3)
-	stw	7,4(3)
-	addi	3,3,8
-4:	/* Copy 4 bytes.  */
-	bf	29,2f
-
-	lwz	6,0(12)
-	addi	12,12,4
-	stw	6,0(3)
-	addi	3,3,4
-2:	/* Copy 2-3 bytes.  */
-	bf	30,1f
-
-	lhz	6,0(12)
-	sth	6,0(3)
-	bf	31,0f
-	lbz	7,2(12)
-	stb	7,2(3)
-	ld	3,-16(1)
-	add	3,3,5
-	blr
-
-	.align	4
-1:	/* Copy 1 byte.  */
-	bf	31,0f
-
-	lbz	6,0(12)
-	stb	6,0(3)
-0:	/* Return DST + LEN pointer.  */
-	ld	3,-16(1)
-	add	3,3,5
-	blr
-
-	/* Handles copies of 0~8 bytes.  */
-	.align	4
-L(copy_LE_8):
-	bne	cr6,4f
-
-	/* Though we could've used ld/std here, they are still
-	slow for unaligned cases.  */
-
-	lwz	6,0(4)
-	lwz	7,4(4)
-	stw	6,0(3)
-	stw	7,4(3)
-	ld	3,-16(1)      /* Return DST + LEN pointer.  */
-	add	3,3,5
-	blr
-
-	.align	4
-4:	/* Copies 4~7 bytes.  */
-	bf	29,2b
-
-	lwz	6,0(4)
-	stw	6,0(3)
-	bf	30,5f
-	lhz	7,4(4)
-	sth	7,4(3)
-	bf	31,0f
-	lbz	8,6(4)
-	stb	8,6(3)
-	ld	3,-16(1)
-	add	3,3,5
-	blr
-
-	.align	4
-5:	/* Copy 1 byte.  */
-	bf	31,0f
-
-	lbz	6,4(4)
-	stb	6,4(3)
-
-0:	/* Return DST + LEN pointer.  */
-	ld	3,-16(1)
-	add	3,3,5
-	blr
-
-	/* Handle copies of 32+ bytes where DST is aligned (to quadword) but
-	SRC is not.  Use aligned quadword loads from SRC, shifted to realign
-	the data, allowing for aligned DST stores.  */
-	.align	4
-L(copy_GE_32_unaligned):
-	clrldi	0,0,60	      /* Number of bytes until the 1st
-				 quadword.  */
-	andi.	11,3,15	      /* Check alignment of DST (against
-				 quadwords).  */
-	srdi	9,5,4	      /* Number of full quadwords remaining.  */
-
-	beq	L(copy_GE_32_unaligned_cont)
-
-	/* SRC is not quadword aligned, get it aligned.  */
-
-	mtcrf	0x01,0
-	subf	31,0,5
-
-	/* Vector instructions work best when proper alignment (16-bytes)
-	is present.  Move 0~15 bytes as needed to get DST quadword-aligned.  */
-1:	/* Copy 1 byte.  */
-	bf	31,2f
-
-	lbz	6,0(12)
-	addi	12,12,1
-	stb	6,0(3)
-	addi	3,3,1
-2:	/* Copy 2 bytes.  */
-	bf	30,4f
-
-	lhz	6,0(12)
-	addi	12,12,2
-	sth	6,0(3)
-	addi	3,3,2
-4:	/* Copy 4 bytes.  */
-	bf	29,8f
-
-	lwz	6,0(12)
-	addi	12,12,4
-	stw	6,0(3)
-	addi	3,3,4
-8:	/* Copy 8 bytes.  */
-	bf	28,0f
-
-	ld	6,0(12)
-	addi	12,12,8
-	std	6,0(3)
-	addi	3,3,8
-0:
-	clrldi	10,12,60      /* Check alignment of SRC.  */
-	srdi	9,31,4	      /* Number of full quadwords remaining.  */
-
-	/* The proper alignment is present, it is OK to copy the bytes now.  */
-L(copy_GE_32_unaligned_cont):
-
-	/* Setup two indexes to speed up the indexed vector operations.  */
-	clrldi	11,31,60
-	li	6,16	      /* Index for 16-bytes offsets.  */
-	li	7,32	      /* Index for 32-bytes offsets.  */
-	cmpldi	cr1,11,0
-	srdi	8,31,5	      /* Setup the loop counter.  */
-	mr	10,3
-	mr	11,12
-	mtcrf	0x01,9
-	cmpldi	cr6,9,1
-#ifdef __LITTLE_ENDIAN__
-	lvsr    5,0,12
-#else
-	lvsl    5,0,12
-#endif
-	lvx	3,0,12
-	bf	31,L(setup_unaligned_loop)
-
-	/* Copy another 16 bytes to align to 32-bytes due to the loop .  */
-	lvx	4,12,6
-#ifdef __LITTLE_ENDIAN__
-	vperm   6,4,3,5
-#else
-	vperm   6,3,4,5
-#endif
-	addi	11,12,16
-	addi	10,3,16
-	stvx	6,0,3
-	vor	3,4,4
-
-L(setup_unaligned_loop):
-	mtctr	8
-	ble	cr6,L(end_unaligned_loop)
-
-	/* Copy 32 bytes at a time using vector instructions.  */
-	.align	4
-L(unaligned_loop):
-
-	/* Note: vr6/vr10 may contain data that was already copied,
-	but in order to get proper alignment, we may have to copy
-	some portions again. This is faster than having unaligned
-	vector instructions though.  */
-
-	lvx	4,11,6	      /* vr4 = r11+16.  */
-#ifdef __LITTLE_ENDIAN__
-	vperm   6,4,3,5
-#else
-	vperm   6,3,4,5
-#endif
-	lvx	3,11,7	      /* vr3 = r11+32.  */
-#ifdef __LITTLE_ENDIAN__
-	vperm   10,3,4,5
-#else
-	vperm   10,4,3,5
-#endif
-	addi	11,11,32
-	stvx	6,0,10
-	stvx	10,10,6
-	addi	10,10,32
-
-	bdnz	L(unaligned_loop)
-
-	.align	4
-L(end_unaligned_loop):
-
-	/* Check for tail bytes.  */
-	rldicr	0,31,0,59
-	mtcrf	0x01,31
-	beq	cr1,0f
-
-	add	3,3,0
-	add	12,12,0
-
-	/*  We have 1~15 tail bytes to copy, and DST is quadword aligned.  */
-8:	/* Copy 8 bytes.  */
-	bf	28,4f
-
-	lwz	6,0(12)
-	lwz	7,4(12)
-	addi	12,12,8
-	stw	6,0(3)
-	stw	7,4(3)
-	addi	3,3,8
-4:	/* Copy 4 bytes.  */
-	bf	29,2f
-
-	lwz	6,0(12)
-	addi	12,12,4
-	stw	6,0(3)
-	addi	3,3,4
-2:	/* Copy 2~3 bytes.  */
-	bf	30,1f
-
-	lhz	6,0(12)
-	addi	12,12,2
-	sth	6,0(3)
-	addi	3,3,2
-1:	/* Copy 1 byte.  */
-	bf	31,0f
-
-	lbz	6,0(12)
-	stb	6,0(3)
-0:	/* Return DST + LEN pointer.  */
-	ld	31,-8(1)
-	ld	3,-16(1)
-	add	3,3,5
-	blr
-
-END_GEN_TB (MEMPCPY,TB_TOCLESS)
-libc_hidden_def (__mempcpy)
-weak_alias (__mempcpy, mempcpy)
-libc_hidden_builtin_def (mempcpy)
diff --git a/sysdeps/powerpc/powerpc64/power7/memrchr.S b/sysdeps/powerpc/powerpc64/power7/memrchr.S
deleted file mode 100644
index 583d513..0000000
--- a/sysdeps/powerpc/powerpc64/power7/memrchr.S
+++ /dev/null
@@ -1,201 +0,0 @@
-/* Optimized memrchr implementation for PowerPC64/POWER7 using cmpb insn.
-   Copyright (C) 2010-2018 Free Software Foundation, Inc.
-   Contributed by Luis Machado <luisgpm@br.ibm.com>.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* int [r3] memrchr (char *s [r3], int byte [r4], int size [r5])  */
-
-#ifndef MEMRCHR
-# define MEMRCHR __memrchr
-#endif
-	.machine  power7
-ENTRY_TOCLESS (MEMRCHR)
-	CALL_MCOUNT 3
-	add	r7,r3,r5      /* Calculate the last acceptable address.  */
-	neg	r0,r7
-	addi	r7,r7,-1
-	mr	r10,r3
-	clrrdi	r6,r7,7
-	li	r9,3<<5
-	dcbt	r9,r6,8       /* Stream hint, decreasing addresses.  */
-
-	/* Replicate BYTE to doubleword.  */
-	insrdi	r4,r4,8,48
-	insrdi	r4,r4,16,32
-	insrdi  r4,r4,32,0
-	li	r6,-8
-	li	r9,-1
-	rlwinm	r0,r0,3,26,28 /* Calculate padding.  */
-	clrrdi	r8,r7,3
-	srd	r9,r9,r0
-	cmpldi	r5,32
-	clrrdi	r0,r10,3
-	ble	L(small_range)
-
-#ifdef __LITTLE_ENDIAN__
-	ldx	r12,0,r8
-#else
-	ldbrx	r12,0,r8      /* Load reversed doubleword from memory.  */
-#endif
-	cmpb	r3,r12,r4     /* Check for BYTE in DWORD1.  */
-	and	r3,r3,r9
-	cmpldi	cr7,r3,0      /* If r3 == 0, no BYTEs have been found.  */
-	bne	cr7,L(done)
-
-	mtcrf   0x01,r8
-	/* Are we now aligned to a quadword boundary?  If so, skip to
-	   the main loop.  Otherwise, go through the alignment code.  */
-	bf	28,L(loop_setup)
-
-	/* Handle DWORD2 of pair.  */
-#ifdef __LITTLE_ENDIAN__
-	ldx	r12,r8,r6
-#else
-	ldbrx	r12,r8,r6
-#endif
-	addi	r8,r8,-8
-	cmpb	r3,r12,r4
-	cmpldi	cr7,r3,0
-	bne	cr7,L(done)
-
-L(loop_setup):
-	/* The last dword we want to read in the loop below is the one
-	   containing the first byte of the string, ie. the dword at
-	   s & ~7, or r0.  The first dword read is at r8 - 8, we
-	   read 2 * cnt dwords, so the last dword read will be at
-	   r8 - 8 - 16 * cnt + 8.  Solving for cnt gives
-	   cnt = (r8 - r0) / 16  */
-	sub	r5,r8,r0
-	addi	r8,r8,-8
-	srdi	r9,r5,4       /* Number of loop iterations.  */
-	mtctr	r9	      /* Setup the counter.  */
-
-	/* Main loop to look for BYTE backwards in the string.
-	   FIXME: Investigate whether 32 byte align helps with this
-	   9 instruction loop.  */
-	.align	5
-L(loop):
-	/* Load two doublewords, compare and merge in a
-	   single register for speed.  This is an attempt
-	   to speed up the byte-checking process for bigger strings.  */
-
-#ifdef __LITTLE_ENDIAN__
-	ldx	r12,0,r8
-	ldx	r11,r8,r6
-#else
-	ldbrx	r12,0,r8
-	ldbrx	r11,r8,r6
-#endif
-	cmpb	r3,r12,r4
-	cmpb	r9,r11,r4
-	or	r5,r9,r3      /* Merge everything in one doubleword.  */
-	cmpldi	cr7,r5,0
-	bne	cr7,L(found)
-	addi	r8,r8,-16
-	bdnz	L(loop)
-
-	/* We may have one more word to read.  */
-	cmpld	r8,r0
-	bnelr
-
-#ifdef __LITTLE_ENDIAN__
-	ldx	r12,0,r8
-#else
-	ldbrx	r12,0,r8
-#endif
-	cmpb	r3,r12,r4
-	cmpldi	cr7,r3,0
-	bne	cr7,L(done)
-	blr
-
-	.align	4
-L(found):
-	/* OK, one (or both) of the dwords contains BYTE.  Check
-	   the first dword.  */
-	cmpldi	cr6,r3,0
-	bne	cr6,L(done)
-
-	/* BYTE must be in the second word.  Adjust the address
-	   again and move the result of cmpb to r3 so we can calculate the
-	   pointer.  */
-
-	mr	r3,r9
-	addi	r8,r8,-8
-
-	/* r3 has the output of the cmpb instruction, that is, it contains
-	   0xff in the same position as BYTE in the original
-	   word from the string.  Use that to calculate the pointer.
-	   We need to make sure BYTE is *before* the end of the
-	   range.  */
-L(done):
-	cntlzd	r9,r3	      /* Count leading zeros before the match.  */
-	cmpld	r8,r0         /* Are we on the last word?  */
-	srdi	r6,r9,3	      /* Convert leading zeros to bytes.  */
-	addi	r0,r6,-7
-	sub	r3,r8,r0
-	cmpld	cr7,r3,r10
-	bnelr
-	bgelr	cr7
-	li	r3,0
-	blr
-
-	.align	4
-L(null):
-	li	r3,0
-	blr
-
-/* Deals with size <= 32.  */
-	.align	4
-L(small_range):
-	cmpldi	r5,0
-	beq	L(null)
-
-#ifdef __LITTLE_ENDIAN__
-	ldx	r12,0,r8
-#else
-	ldbrx	r12,0,r8      /* Load reversed doubleword from memory.  */
-#endif
-	cmpb	r3,r12,r4     /* Check for BYTE in DWORD1.  */
-	and	r3,r3,r9
-	cmpldi	cr7,r3,0
-	bne	cr7,L(done)
-
-	/* Are we done already?  */
-	cmpld	r8,r0
-	addi	r8,r8,-8
-	beqlr
-
-	.align	5
-L(loop_small):
-#ifdef __LITTLE_ENDIAN__
-	ldx	r12,0,r8
-#else
-	ldbrx	r12,0,r8
-#endif
-	cmpb	r3,r12,r4
-	cmpld	r8,r0
-	cmpldi	cr7,r3,0
-	bne	cr7,L(done)
-	addi	r8,r8,-8
-	bne	L(loop_small)
-	blr
-
-END (MEMRCHR)
-weak_alias (__memrchr, memrchr)
-libc_hidden_builtin_def (memrchr)
diff --git a/sysdeps/powerpc/powerpc64/power7/memset.S b/sysdeps/powerpc/powerpc64/power7/memset.S
deleted file mode 100644
index acd0adf..0000000
--- a/sysdeps/powerpc/powerpc64/power7/memset.S
+++ /dev/null
@@ -1,399 +0,0 @@
-/* Optimized memset implementation for PowerPC64/POWER7.
-   Copyright (C) 2010-2018 Free Software Foundation, Inc.
-   Contributed by Luis Machado <luisgpm@br.ibm.com>.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* void * [r3] memset (void *s [r3], int c [r4], size_t n [r5]));
-   Returns 's'.  */
-
-#ifndef MEMSET
-# define MEMSET memset
-#endif
-	.machine power7
-ENTRY_TOCLESS (MEMSET, 5)
-	CALL_MCOUNT 3
-
-L(_memset):
-	cmpldi	cr7,5,31
-	cmpldi	cr6,5,8
-	mr	10,3
-
-	/* Replicate byte to word.  */
-	insrdi	4,4,8,48
-	insrdi	4,4,16,32
-	ble	cr6,L(small)	/* If length <= 8, use short copy code.  */
-
-	neg	0,3
-	ble	cr7,L(medium)	/* If length < 32, use medium copy code.  */
-
-	andi.	11,10,7		/* Check alignment of SRC.  */
-	insrdi	4,4,32,0	/* Replicate word to double word.  */
-
-	mr	12,5
-	beq	L(big_aligned)
-
-	clrldi	0,0,61
-	mtocrf	0x01,0
-	subf	5,0,5
-
-	/* Get DST aligned to 8 bytes.  */
-1:	bf	31,2f
-
-	stb	4,0(10)
-	addi	10,10,1
-2:	bf	30,4f
-
-	sth	4,0(10)
-	addi	10,10,2
-4:	bf	29,L(big_aligned)
-
-	stw	4,0(10)
-	addi	10,10,4
-
-	.align	4
-L(big_aligned):
-
-	cmpldi	cr5,5,255
-	li	0,32
-	dcbtst	0,10
-	cmpldi	cr6,4,0
-	srdi	9,5,3	/* Number of full doublewords remaining.  */
-	crand	27,26,21
-	mtocrf	0x01,9
-	bt	27,L(huge)
-
-	/* From this point on, we'll copy 32+ bytes and the value
-	   isn't 0 (so we can't use dcbz).  */
-
-	srdi	8,5,5
-	clrldi	11,5,61
-	cmpldi	cr6,11,0
-	cmpldi	cr1,9,4
-	mtctr	8
-
-	/* Copy 1~3 doublewords so the main loop starts
-	at a multiple of 32 bytes.  */
-
-	bf	30,1f
-
-	std	4,0(10)
-	std	4,8(10)
-	addi	10,10,16
-	bf	31,L(big_loop)
-
-	std	4,0(10)
-	addi	10,10,8
-	mr	12,10
-	blt	cr1,L(tail_bytes)
-	b	L(big_loop)
-
-	.align	4
-1:	/* Copy 1 doubleword.  */
-	bf	31,L(big_loop)
-
-	std	4,0(10)
-	addi	10,10,8
-
-	/* Main aligned copy loop.  Copies 32-bytes at a time and
-	   ping-pong through r10 and r12 to avoid AGEN delays.  */
-	.align	4
-L(big_loop):
-	addi	12,10,32
-	std	4,0(10)
-	std	4,8(10)
-	std	4,16(10)
-	std	4,24(10)
-	bdz	L(tail_bytes)
-
-	addi	10,10,64
-	std	4,0(12)
-	std	4,8(12)
-	std	4,16(12)
-	std	4,24(12)
-	bdnz	L(big_loop)
-
-	mr	12,10
-	b	L(tail_bytes)
-
-	.align	4
-L(tail_bytes):
-
-	/* Check for tail bytes.  */
-	beqlr	cr6
-
-	clrldi	0,5,61
-	mtocrf	0x01,0
-
-	/*  At this point we have a tail of 0-7 bytes and we know that the
-	destination is doubleword-aligned.  */
-4:	/* Copy 4 bytes.  */
-	bf	29,2f
-
-	stw	4,0(12)
-	addi	12,12,4
-2:	/* Copy 2 bytes.  */
-	bf	30,1f
-
-	sth	4,0(12)
-	addi	12,12,2
-1:	/* Copy 1 byte.  */
-	bflr	31
-
-	stb	4,0(12)
-	blr
-
-	/* Special case when value is 0 and we have a long length to deal
-	   with.  Use dcbz to zero out 128-bytes at a time.  Before using
-	   dcbz though, we need to get the destination 128-bytes aligned.  */
-	.align	4
-L(huge):
-	andi.	11,10,127
-	neg	0,10
-	beq	L(huge_aligned)
-
-	clrldi	0,0,57
-	subf	5,0,5
-	srdi	0,0,3
-	mtocrf	0x01,0
-
-	/* Get DST aligned to 128 bytes.  */
-8:	bf	28,4f
-
-	std	4,0(10)
-	std	4,8(10)
-	std	4,16(10)
-	std	4,24(10)
-	std	4,32(10)
-	std	4,40(10)
-	std	4,48(10)
-	std	4,56(10)
-	addi	10,10,64
-	.align	4
-4:	bf	29,2f
-
-	std	4,0(10)
-	std	4,8(10)
-	std	4,16(10)
-	std	4,24(10)
-	addi	10,10,32
-	.align	4
-2:	bf	30,1f
-
-	std	4,0(10)
-	std	4,8(10)
-	addi	10,10,16
-	.align	4
-1:	bf	31,L(huge_aligned)
-
-	std	4,0(10)
-	addi	10,10,8
-
-
-L(huge_aligned):
-	srdi	8,5,7
-	clrldi	11,5,57
-	cmpldi	cr6,11,0
-	mtctr	8
-
-	.align	4
-L(huge_loop):
-	dcbz	0,10
-	addi	10,10,128
-	bdnz	L(huge_loop)
-
-	/* Check how many bytes are still left.  */
-	beqlr	cr6
-
-	subf	9,3,10
-	subf	5,9,12
-	srdi	8,5,3
-	cmpldi	cr6,8,0
-	mtocrf	0x01,8
-
-	/* We have a tail o 1~127 bytes.  Copy up to 15 doublewords for
-	speed.  We'll handle the resulting tail bytes later.  */
-	beq	cr6,L(tail)
-
-8:	bf	28,4f
-
-	std	4,0(10)
-	std	4,8(10)
-	std	4,16(10)
-	std	4,24(10)
-	std	4,32(10)
-	std	4,40(10)
-	std	4,48(10)
-	std	4,56(10)
-	addi	10,10,64
-	.align	4
-4:	bf	29,2f
-
-	std	4,0(10)
-	std	4,8(10)
-	std	4,16(10)
-	std	4,24(10)
-	addi	10,10,32
-	.align	4
-2:	bf	30,1f
-
-	std	4,0(10)
-	std	4,8(10)
-	addi	10,10,16
-	.align	4
-1:	bf	31,L(tail)
-
-	std	4,0(10)
-	addi	10,10,8
-
-	/* Handle the rest of the tail bytes here.  */
-L(tail):
-	mtocrf	0x01,5
-
-	.align	4
-4:	bf	29,2f
-
-	stw	4,0(10)
-	addi	10,10,4
-	.align	4
-2:	bf	30,1f
-
-	sth	4,0(10)
-	addi	10,10,2
-	.align	4
-1:	bflr	31
-
-	stb	4,0(10)
-	blr
-
-	/* Expanded tree to copy tail bytes without increments.  */
-	.align	4
-L(copy_tail):
-	bf	29,L(FXX)
-
-	stw	4,0(10)
-	bf	30,L(TFX)
-
-	sth	4,4(10)
-	bflr	31
-
-	stb	4,6(10)
-	blr
-
-	.align	4
-L(FXX):	bf	30,L(FFX)
-
-	sth	4,0(10)
-	bflr	31
-
-	stb	4,2(10)
-	blr
-
-	.align	4
-L(TFX):	bflr	31
-
-	stb	4,4(10)
-	blr
-
-	.align	4
-L(FFX):	bflr	31
-
-	stb	4,0(10)
-	blr
-
-	/* Handle copies of 9~31 bytes.  */
-	.align	4
-L(medium):
-	/* At least 9 bytes to go.  */
-	andi.	11,10,3
-	clrldi	0,0,62
-	beq	L(medium_aligned)
-
-	/* Force 4-bytes alignment for DST.  */
-	mtocrf	0x01,0
-	subf	5,0,5
-1:	/* Copy 1 byte.  */
-	bf	31,2f
-
-	stb	4,0(10)
-	addi	10,10,1
-2:	/* Copy 2 bytes.  */
-	bf	30,L(medium_aligned)
-
-	sth	4,0(10)
-	addi	10,10,2
-
-	.align	4
-L(medium_aligned):
-	/* At least 6 bytes to go, and DST is word-aligned.  */
-	cmpldi	cr1,5,16
-	mtocrf	0x01,5
-	blt	cr1,8f
-
-	/* Copy 16 bytes.  */
-	stw	4,0(10)
-	stw	4,4(10)
-	stw	4,8(10)
-	stw	4,12(10)
-	addi	10,10,16
-8:	/* Copy 8 bytes.  */
-	bf	28,4f
-
-	stw	4,0(10)
-	stw	4,4(10)
-	addi	10,10,8
-4:	/* Copy 4 bytes.  */
-	bf	29,2f
-
-	stw	4,0(10)
-	addi	10,10,4
-2:	/* Copy 2-3 bytes.  */
-	bf	30,1f
-
-	sth	4,0(10)
-	addi	10,10,2
-1:	/* Copy 1 byte.  */
-	bflr	31
-
-	stb	4,0(10)
-	blr
-
-	/* Handles copies of 0~8 bytes.  */
-	.align	4
-L(small):
-	mtocrf	0x01,5
-	bne	cr6,L(copy_tail)
-
-	stw	4,0(10)
-	stw	4,4(10)
-	blr
-
-END_GEN_TB (MEMSET,TB_TOCLESS)
-libc_hidden_builtin_def (memset)
-
-/* Copied from bzero.S to prevent the linker from inserting a stub
-   between bzero and memset.  */
-ENTRY_TOCLESS (__bzero)
-	CALL_MCOUNT 3
-	mr	r5,r4
-	li	r4,0
-	b	L(_memset)
-END (__bzero)
-#ifndef __bzero
-weak_alias (__bzero, bzero)
-#endif
diff --git a/sysdeps/powerpc/powerpc64/power7/rawmemchr.S b/sysdeps/powerpc/powerpc64/power7/rawmemchr.S
deleted file mode 100644
index 6ada0eb..0000000
--- a/sysdeps/powerpc/powerpc64/power7/rawmemchr.S
+++ /dev/null
@@ -1,115 +0,0 @@
-/* Optimized rawmemchr implementation for PowerPC64/POWER7 using cmpb insn.
-   Copyright (C) 2010-2018 Free Software Foundation, Inc.
-   Contributed by Luis Machado <luisgpm@br.ibm.com>.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* int [r3] rawmemchr (void *s [r3], int c [r4])  */
-
-#ifndef RAWMEMCHR
-# define RAWMEMCHR __rawmemchr
-#endif
-	.machine  power7
-ENTRY_TOCLESS (RAWMEMCHR)
-	CALL_MCOUNT 2
-	dcbt	0,r3
-	clrrdi	r8,r3,3	      /* Align the address to doubleword boundary.  */
-
-	/* Replicate byte to doubleword.  */
-	insrdi	r4,r4,8,48
-	insrdi	r4,r4,16,32
-	insrdi	r4,r4,32,0
-
-	/* Now r4 has a doubleword of c bytes.  */
-
-	rlwinm	r6,r3,3,26,28 /* Calculate padding.  */
-	ld	r12,0(r8)     /* Load doubleword from memory.  */
-	cmpb	r5,r12,r4     /* Compare each byte against c byte.  */
-#ifdef __LITTLE_ENDIAN__
-	srd	r5,r5,r6
-	sld	r5,r5,r6
-#else
-	sld	r5,r5,r6      /* Move left to discard ignored bits.  */
-	srd	r5,r5,r6      /* Bring the bits back as zeros.  */
-#endif
-	cmpdi	cr7,r5,0      /* If r5 == 0, no c bytes have been found.  */
-	bne	cr7,L(done)
-
-	mtcrf   0x01,r8
-
-	/* Are we now aligned to a quadword boundary?  If so, skip to
-	   the main loop.  Otherwise, go through the alignment code.  */
-
-	bt	28,L(loop)
-
-	/* Handle DWORD2 of pair.  */
-	ldu	r12,8(r8)
-	cmpb	r5,r12,r4
-	cmpdi	cr7,r5,0
-	bne	cr7,L(done)
-	b	L(loop)	      /* We branch here (rather than falling through)
-				 to skip the nops due to heavy alignment
-				 of the loop below.  */
-
-	/* Main loop to look for the end of the string.  Since it's a
-	   small loop (< 8 instructions), align it to 32-bytes.  */
-	.p2align  5
-L(loop):
-	/* Load two doublewords, compare and merge in a
-	   single register for speed.  This is an attempt
-	   to speed up the byte-checking process for bigger strings.  */
-	ld	r12,8(r8)
-	ldu     r11,16(r8)
-	cmpb	r5,r12,r4
-	cmpb	r6,r11,r4
-	or	r7,r5,r6
-	cmpdi	cr7,r7,0
-	beq	cr7,L(loop)
-
-	/* OK, one (or both) of the doublewords contains a 'c' byte.  Check
-	   the first doubleword and decrement the address in case the first
-	   doubleword really contains a c byte.  */
-
-	cmpdi	cr6,r5,0
-	addi	r8,r8,-8
-	bne	cr6,L(done)
-
-	/* The 'c' byte must be in the second doubleword.  Adjust the address
-	   again and move the result of cmpb to r10 so we can calculate the
-	   pointer.  */
-	mr	r5,r6
-	addi	r8,r8,8
-
-	/* r5 has the output of the cmpb instruction, that is, it contains
-	   0xff in the same position as the 'c' byte in the original
-	   doubleword from the string.  Use that fact to find out what is
-	   the position of the byte inside the string.  */
-L(done):
-#ifdef __LITTLE_ENDIAN__
-	addi    r0,r5,-1
-	andc    r0,r0,r5
-	popcntd	r0,r0	      /* Count trailing zeros.  */
-#else
-	cntlzd	r0,r5	      /* Count leading zeros before the match.  */
-#endif
-	srdi	r0,r0,3	      /* Convert leading zeros to bytes.  */
-	add	r3,r8,r0      /* Return address of the matching char.  */
-	blr
-END (RAWMEMCHR)
-weak_alias (__rawmemchr,rawmemchr)
-libc_hidden_builtin_def (__rawmemchr)
diff --git a/sysdeps/powerpc/powerpc64/power7/strcasecmp.S b/sysdeps/powerpc/powerpc64/power7/strcasecmp.S
deleted file mode 100644
index 1d4bc61..0000000
--- a/sysdeps/powerpc/powerpc64/power7/strcasecmp.S
+++ /dev/null
@@ -1,127 +0,0 @@
-/* Optimized strcasecmp implementation for PowerPC64.
-   Copyright (C) 2011-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-#include <locale-defines.h>
-
-/* int [r3] strcasecmp (const char *s1 [r3], const char *s2 [r4] )
-
-   or if defined USE_IN_EXTENDED_LOCALE_MODEL:
-
-   int [r3] strcasecmp_l (const char *s1 [r3], const char *s2 [r4],
-                          locale_t loc [r5]) */
-
-#ifndef STRCMP
-# define __STRCMP __strcasecmp
-# define STRCMP   strcasecmp
-#endif
-
-#ifndef USE_IN_EXTENDED_LOCALE_MODEL
-ENTRY (__STRCMP)
-	CALL_MCOUNT 2
-#else
-ENTRY_TOCLESS (__STRCMP)
-	CALL_MCOUNT 3
-#endif
-
-#define rRTN	r3	/* Return value */
-#define rSTR1	r5	/* 1st string */
-#define rSTR2	r4	/* 2nd string */
-#define rLOCARG	r5	/* 3rd argument: locale_t */
-#define rCHAR1	r6	/* Byte read from 1st string */
-#define rCHAR2	r7	/* Byte read from 2nd string */
-#define rADDR1	r8	/* Address of tolower(rCHAR1) */
-#define rADDR2	r12	/* Address of tolower(rCHAR2) */
-#define rLWR1	r8	/* Word tolower(rCHAR1) */
-#define rLWR2	r12	/* Word tolower(rCHAR2) */
-#define rTMP	r9
-#define rLOC	r11	/* Default locale address */
-
-	cmpd	cr7, r3, r4
-#ifndef USE_IN_EXTENDED_LOCALE_MODEL
-	ld 	rTMP, __libc_tsd_LOCALE@got@tprel(r2)
-	add 	rLOC, rTMP, __libc_tsd_LOCALE@tls
-	ld	rLOC, 0(rLOC)
-#else
-	mr	rLOC, rLOCARG
-#endif
-	ld	rLOC, LOCALE_CTYPE_TOLOWER(rLOC)
-	mr	rSTR1, rRTN
-	li	rRTN, 0
-	beqlr	cr7
-
-
-	/* Unrolling loop for POWER: loads are done with 'lbz' plus
-	offset and string descriptors are only updated in the end
-	of loop unrolling. */
-
-	lbz	rCHAR1, 0(rSTR1)	/* Load char from s1 */
-	lbz	rCHAR2, 0(rSTR2)	/* Load char from s2 */
-L(loop):
-	cmpdi	rCHAR1, 0		/* *s1 == '\0' ? */
-	sldi	rADDR1, rCHAR1, 2	/* Calculate address for tolower(*s1) */
-	sldi	rADDR2, rCHAR2, 2	/* Calculate address for tolower(*s2) */
-	lwzx	rLWR1, rLOC, rADDR1	/* Load tolower(*s1) */
-	lwzx	rLWR2, rLOC, rADDR2	/* Load tolower(*s2) */
-	cmpw	cr1, rLWR1, rLWR2	/* r = tolower(*s1) == tolower(*s2) ? */
-	crorc	4*cr1+eq,eq,4*cr1+eq	/* (*s1 != '\0') || (r == 1) */
-	beq	cr1, L(done)
-	lbz	rCHAR1, 1(rSTR1)
-	lbz	rCHAR2, 1(rSTR2)
-	cmpdi	rCHAR1, 0
-	sldi	rADDR1, rCHAR1, 2
-	sldi	rADDR2, rCHAR2, 2
-	lwzx	rLWR1, rLOC, rADDR1
-	lwzx	rLWR2, rLOC, rADDR2
-	cmpw	cr1, rLWR1, rLWR2
-	crorc	4*cr1+eq,eq,4*cr1+eq
-	beq	cr1, L(done)
-	lbz	rCHAR1, 2(rSTR1)
-	lbz	rCHAR2, 2(rSTR2)
-	cmpdi	rCHAR1, 0
-	sldi	rADDR1, rCHAR1, 2
-	sldi	rADDR2, rCHAR2, 2
-	lwzx	rLWR1, rLOC, rADDR1
-	lwzx	rLWR2, rLOC, rADDR2
-	cmpw	cr1, rLWR1, rLWR2
-	crorc	4*cr1+eq,eq,4*cr1+eq
-	beq	cr1, L(done)
-	lbz	rCHAR1, 3(rSTR1)
-	lbz	rCHAR2, 3(rSTR2)
-	cmpdi	rCHAR1, 0
-	/* Increment both string descriptors */
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-	sldi	rADDR1, rCHAR1, 2
-	sldi	rADDR2, rCHAR2, 2
-	lwzx	rLWR1, rLOC, rADDR1
-	lwzx	rLWR2, rLOC, rADDR2
-	cmpw	cr1, rLWR1, rLWR2
-	crorc	4*cr1+eq,eq,4*cr1+eq
-	beq     cr1,L(done)
-	lbz	rCHAR1, 0(rSTR1)	/* Load char from s1 */
-	lbz	rCHAR2, 0(rSTR2)	/* Load char from s2 */
-	b	L(loop)
-L(done):
-	subf	r0, rLWR2, rLWR1
-	extsw	rRTN, r0
-	blr
-END (__STRCMP)
-
-weak_alias (__STRCMP, STRCMP)
-libc_hidden_builtin_def (__STRCMP)
diff --git a/sysdeps/powerpc/powerpc64/power7/strcasecmp_l.S b/sysdeps/powerpc/powerpc64/power7/strcasecmp_l.S
deleted file mode 100644
index c13c4eb..0000000
--- a/sysdeps/powerpc/powerpc64/power7/strcasecmp_l.S
+++ /dev/null
@@ -1,5 +0,0 @@
-#define USE_IN_EXTENDED_LOCALE_MODEL
-#define STRCMP   strcasecmp_l
-#define __STRCMP __strcasecmp_l
-
-#include "strcasecmp.S"
diff --git a/sysdeps/powerpc/powerpc64/power7/strchr.S b/sysdeps/powerpc/powerpc64/power7/strchr.S
deleted file mode 100644
index da648b2..0000000
--- a/sysdeps/powerpc/powerpc64/power7/strchr.S
+++ /dev/null
@@ -1,230 +0,0 @@
-/* Optimized strchr implementation for PowerPC64/POWER7 using cmpb insn.
-   Copyright (C) 2010-2018 Free Software Foundation, Inc.
-   Contributed by Luis Machado <luisgpm@br.ibm.com>.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-#ifndef STRCHR
-# define STRCHR strchr
-#endif
-
-/* int [r3] strchr (char *s [r3], int c [r4])  */
-	.machine  power7
-ENTRY_TOCLESS (STRCHR)
-	CALL_MCOUNT 2
-	dcbt	0,r3
-	clrrdi	r8,r3,3	      /* Align the address to doubleword boundary.  */
-	cmpdi	cr7,r4,0
-	ld	r12,0(r8)     /* Load doubleword from memory.  */
-	li	r0,0	      /* Doubleword with null chars to use
-				 with cmpb.  */
-
-	rlwinm	r6,r3,3,26,28 /* Calculate padding.  */
-
-	beq	cr7,L(null_match)
-
-	/* Replicate byte to doubleword.  */
-	insrdi	r4,r4,8,48
-	insrdi	r4,r4,16,32
-	insrdi  r4,r4,32,0
-
-	/* Now r4 has a doubleword of c bytes and r0 has
-	   a doubleword of null bytes.  */
-
-	cmpb	r10,r12,r4     /* Compare each byte against c byte.  */
-	cmpb	r11,r12,r0     /* Compare each byte against null byte.  */
-
-	/* Move the doublewords left and right to discard the bits that are
-	   not part of the string and bring them back as zeros.  */
-#ifdef __LITTLE_ENDIAN__
-	srd	r10,r10,r6
-	srd	r11,r11,r6
-	sld	r10,r10,r6
-	sld	r11,r11,r6
-#else
-	sld	r10,r10,r6
-	sld	r11,r11,r6
-	srd	r10,r10,r6
-	srd	r11,r11,r6
-#endif
-	or	r5,r10,r11    /* OR the results to speed things up.  */
-	cmpdi	cr7,r5,0      /* If r5 == 0, no c or null bytes
-				 have been found.  */
-	bne	cr7,L(done)
-
-	mtcrf   0x01,r8
-
-	/* Are we now aligned to a doubleword boundary?  If so, skip to
-	   the main loop.  Otherwise, go through the alignment code.  */
-
-	bt	28,L(loop)
-
-	/* Handle WORD2 of pair.  */
-	ldu	r12,8(r8)
-	cmpb    r10,r12,r4
-	cmpb	r11,r12,r0
-	or	r5,r10,r11
-	cmpdi	cr7,r5,0
-	bne	cr7,L(done)
-	b	L(loop)	      /* We branch here (rather than falling through)
-				 to skip the nops due to heavy alignment
-				 of the loop below.  */
-
-	.p2align  5
-L(loop):
-	/* Load two doublewords, compare and merge in a
-	   single register for speed.  This is an attempt
-	   to speed up the null-checking process for bigger strings.  */
-	ld	r12,8(r8)
-	ldu	r9,16(r8)
-	cmpb	r10,r12,r4
-	cmpb	r11,r12,r0
-	cmpb	r6,r9,r4
-	cmpb	r7,r9,r0
-	or	r12,r10,r11
-	or	r9,r6,r7
-	or	r5,r12,r9
-	cmpdi	cr7,r5,0
-	beq	cr7,L(loop)
-
-	/* OK, one (or both) of the doublewords contains a c/null byte.  Check
-	   the first doubleword and decrement the address in case the first
-	   doubleword really contains a c/null byte.  */
-
-	cmpdi	cr6,r12,0
-	addi	r8,r8,-8
-	bne	cr6,L(done)
-
-	/* The c/null byte must be in the second doubleword.  Adjust the
-	   address again and move the result of cmpb to r10 so we can calculate
-	   the pointer.  */
-
-	mr	r10,r6
-	mr	r11,r7
-	addi	r8,r8,8
-
-	/* r10/r11 have the output of the cmpb instructions, that is,
-	   0xff in the same position as the c/null byte in the original
-	   doubleword from the string.  Use that to calculate the pointer.  */
-L(done):
-#ifdef __LITTLE_ENDIAN__
-	addi    r3,r10,-1
-	andc    r3,r3,r10
-	popcntd	r0,r3
-	addi    r4,r11,-1
-	andc    r4,r4,r11
-	cmpld	cr7,r3,r4
-	bgt	cr7,L(no_match)
-#else
-	cntlzd	r0,r10	      /* Count leading zeros before c matches.  */
-	cmpld	cr7,r11,r10
-	bgt	cr7,L(no_match)
-#endif
-	srdi	r0,r0,3	      /* Convert leading zeros to bytes.  */
-	add	r3,r8,r0      /* Return address of the matching c byte
-				 or null in case c was not found.  */
-	blr
-
-	.align	4
-L(no_match):
-	li	r3,0
-	blr
-
-/* We are here because strchr was called with a null byte.  */
-	.align	4
-L(null_match):
-	/* r0 has a doubleword of null bytes.  */
-
-	cmpb	r5,r12,r0     /* Compare each byte against null bytes.  */
-
-	/* Move the doublewords left and right to discard the bits that are
-	   not part of the string and bring them back as zeros.  */
-#ifdef __LITTLE_ENDIAN__
-	srd	r5,r5,r6
-	sld	r5,r5,r6
-#else
-	sld	r5,r5,r6
-	srd	r5,r5,r6
-#endif
-	cmpdi	cr7,r5,0      /* If r10 == 0, no c or null bytes
-				 have been found.  */
-	bne	cr7,L(done_null)
-
-	mtcrf   0x01,r8
-
-	/* Are we now aligned to a quadword boundary?  If so, skip to
-	   the main loop.  Otherwise, go through the alignment code.  */
-
-	bt	28,L(loop_null)
-
-	/* Handle WORD2 of pair.  */
-	ldu	r12,8(r8)
-	cmpb    r5,r12,r0
-	cmpdi	cr7,r5,0
-	bne	cr7,L(done_null)
-	b	L(loop_null)  /* We branch here (rather than falling through)
-				 to skip the nops due to heavy alignment
-				 of the loop below.  */
-
-	/* Main loop to look for the end of the string.  Since it's a
-	   small loop (< 8 instructions), align it to 32-bytes.  */
-	.p2align  5
-L(loop_null):
-	/* Load two doublewords, compare and merge in a
-	   single register for speed.  This is an attempt
-	   to speed up the null-checking process for bigger strings.  */
-	ld	r12,8(r8)
-	ldu     r11,16(r8)
-	cmpb	r5,r12,r0
-	cmpb	r10,r11,r0
-	or	r6,r5,r10
-	cmpdi	cr7,r6,0
-	beq	cr7,L(loop_null)
-
-	/* OK, one (or both) of the doublewords contains a null byte.  Check
-	   the first doubleword and decrement the address in case the first
-	   doubleword really contains a null byte.  */
-
-	cmpdi	cr6,r5,0
-	addi	r8,r8,-8
-	bne	cr6,L(done_null)
-
-	/* The null byte must be in the second doubleword.  Adjust the address
-	   again and move the result of cmpb to r10 so we can calculate the
-	   pointer.  */
-
-	mr	r5,r10
-	addi	r8,r8,8
-
-	/* r5 has the output of the cmpb instruction, that is, it contains
-	   0xff in the same position as the null byte in the original
-	   doubleword from the string.  Use that to calculate the pointer.  */
-L(done_null):
-#ifdef __LITTLE_ENDIAN__
-	addi    r0,r5,-1
-	andc    r0,r0,r5
-	popcntd	r0,r0
-#else
-	cntlzd	r0,r5	      /* Count leading zeros before the match.  */
-#endif
-	srdi	r0,r0,3	      /* Convert leading zeros to bytes.  */
-	add	r3,r8,r0      /* Return address of the matching null byte.  */
-	blr
-END (STRCHR)
-weak_alias (strchr, index)
-libc_hidden_builtin_def (strchr)
diff --git a/sysdeps/powerpc/powerpc64/power7/strchrnul.S b/sysdeps/powerpc/powerpc64/power7/strchrnul.S
deleted file mode 100644
index f137174..0000000
--- a/sysdeps/powerpc/powerpc64/power7/strchrnul.S
+++ /dev/null
@@ -1,131 +0,0 @@
-/* Optimized strchrnul implementation for PowerPC64/POWER7 using cmpb insn.
-   Copyright (C) 2010-2018 Free Software Foundation, Inc.
-   Contributed by Luis Machado <luisgpm@br.ibm.com>.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-#ifndef STRCHRNUL
-# define STRCHRNUL __strchrnul
-#endif
-/* int [r3] strchrnul (char *s [r3], int c [r4])  */
-	.machine  power7
-ENTRY_TOCLESS (STRCHRNUL)
-	CALL_MCOUNT 2
-	dcbt	0,r3
-	clrrdi	r8,r3,3	      /* Align the address to doubleword boundary.  */
-
-	/* Replicate byte to doubleword.  */
-	insrdi	r4,r4,8,48
-	insrdi	r4,r4,16,32
-	insrdi	r4,r4,32,0
-
-	rlwinm	r6,r3,3,26,28 /* Calculate padding.  */
-	ld	r12,0(r8)     /* Load doubleword from memory.  */
-	li	r0,0	      /* Doubleword with null chars to use
-				 with cmpb.  */
-
-	/* Now r4 has a doubleword of c bytes and r0 has
-	   a doubleword of null bytes.  */
-
-	cmpb	r10,r12,r0    /* Compare each byte against c byte.  */
-	cmpb	r9,r12,r4     /* Compare each byte against null byte.  */
-
-	/* Move the doublewords left and right to discard the bits that are
-	   not part of the string and to bring them back as zeros.  */
-#ifdef __LITTLE_ENDIAN__
-	srd	r10,r10,r6
-	srd	r9,r9,r6
-	sld	r10,r10,r6
-	sld	r9,r9,r6
-#else
-	sld	r10,r10,r6
-	sld	r9,r9,r6
-	srd	r10,r10,r6
-	srd	r9,r9,r6
-#endif
-	or	r5,r9,r10     /* OR the results to speed things up.  */
-	cmpdi	cr7,r5,0      /* If r5 == 0, no c or null bytes
-				 have been found.  */
-	bne	cr7,L(done)
-
-	mtcrf   0x01,r8
-
-	/* Are we now aligned to a quadword boundary?  If so, skip to
-	   the main loop.  Otherwise, go through the alignment code.  */
-
-	bt	28,L(loop)
-
-	/* Handle DWORD2 of pair.  */
-	ldu	r12,8(r8)
-	cmpb	r10,r12,r0
-	cmpb	r9,r12,r4
-	or	r5,r9,r10
-	cmpdi	cr7,r5,0
-	bne	cr7,L(done)
-	b	L(loop)	      /* We branch here (rather than falling through)
-				 to skip the nops due to heavy alignment
-				 of the loop below.  */
-
-	.p2align  5
-L(loop):
-	/* Load two doublewords, compare and merge in a
-	   single register for speed.  This is an attempt
-	   to speed up the null-checking process for bigger strings.  */
-	ld	r12,8(r8)
-	ldu     r11,16(r8)
-	cmpb	r10,r12,r0
-	cmpb	r9,r12,r4
-	cmpb	r6,r11,r0
-	cmpb	r7,r11,r4
-	or	r5,r9,r10
-	or	r10,r6,r7
-	or	r11,r5,r10
-	cmpdi	cr7,r11,0
-	beq	cr7,L(loop)
-
-	/* OK, one (or both) of the doublewords contains a c/null byte.  Check
-	   the first doubleword and decrement the address in case the first
-	   doubleword really contains a c/null byte.  */
-
-	cmpdi	cr6,r5,0
-	addi	r8,r8,-8
-	bne	cr6,L(done)
-
-	/* The c/null byte must be in the second doubleword.  Adjust the
-	   address again and move the result of cmpb to r5 so we can calculate
-	   the pointer.  */
-	mr	r5,r10
-	addi	r8,r8,8
-
-	/* r5 has the output of the cmpb instruction, that is, it contains
-	   0xff in the same position as the c/null byte in the original
-	   doubleword from the string.  Use that to calculate the pointer.  */
-L(done):
-#ifdef __LITTLE_ENDIAN__
-	addi    r0,r5,-1
-	andc    r0,r0,r5
-	popcntd	r0,r0
-#else
-	cntlzd	r0,r5	      /* Count leading zeros before the match.  */
-#endif
-	srdi	r0,r0,3	      /* Convert leading zeros to bytes.  */
-	add	r3,r8,r0      /* Return address of matching c/null byte.  */
-	blr
-END (STRCHRNUL)
-weak_alias (STRCHRNUL, strchrnul)
-libc_hidden_builtin_def (STRCHRNUL)
diff --git a/sysdeps/powerpc/powerpc64/power7/strcmp.S b/sysdeps/powerpc/powerpc64/power7/strcmp.S
deleted file mode 100644
index c3d5ec1..0000000
--- a/sysdeps/powerpc/powerpc64/power7/strcmp.S
+++ /dev/null
@@ -1,168 +0,0 @@
-/* Optimized strcmp implementation for Power7 using 'cmpb' instruction
-   Copyright (C) 2014-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-/* The optimization is achieved here through cmpb instruction.
-   8byte aligned strings are processed with double word comparision
-   and unaligned strings are handled effectively with loop unrolling
-   technique  */
-
-#include <sysdep.h>
-
-#ifndef STRCMP
-# define STRCMP strcmp
-#endif
-
-/* int [r3] strcmp (const char *s1 [r3], const char *s2 [r4])  */
-
-	.machine	power7
-ENTRY_TOCLESS (STRCMP, 4)
-	CALL_MCOUNT 2
-
-	or r9, r3, r4
-	rldicl. r10, r9, 0, 61	/* are s1 and s2 8 byte aligned..?  */
-	bne cr0, L(process_unaligned_bytes)
-	li	r5, 0
-
-	.align 4
-/* process input parameters on double word aligned boundary  */
-L(unrollDword):
-	ld	r8,0(r3)
-	ld	r10,0(r4)
-	cmpb	r7,r8,r5
-	cmpdi	cr7,r7,0
-	mr	r9,r7
-	bne 	cr7,L(null_found)
-	cmpld	cr7,r8,r10
-	bne	cr7,L(different)
-
-	ld	r8,8(r3)
-	ld	r10,8(r4)
-	cmpb	r7,r8,r5
-	cmpdi	cr7,r7,0
-	mr	r9,r7
-	bne 	cr7,L(null_found)
-	cmpld	cr7,r8,r10
-	bne	cr7,L(different)
-
-	ld	r8,16(r3)
-	ld	r10,16(r4)
-	cmpb	r7,r8,r5
-	cmpdi	cr7,r7,0
-	mr	r9,r7
-	bne 	cr7,L(null_found)
-	cmpld	cr7,r8,r10
-	bne	cr7,L(different)
-
-	ld	r8,24(r3)
-	ld	r10,24(r4)
-	cmpb	r7,r8,r5
-	cmpdi	cr7,r7,0
-	mr	r9,r7
-	bne 	cr7,L(null_found)
-	cmpld	cr7,r8,r10
-	bne	cr7,L(different)
-
-	addi r3, r3, 32
-	addi r4, r4, 32
-	beq cr7, L(unrollDword)
-
-	.align 4
-L(null_found):
-#ifdef __LITTLE_ENDIAN__
-	neg	r7,r9
-	and	r9,r9,r7
-	li	r7,-1
-	cntlzd	r9,r9
-	subfic	r9,r9,71
-	sld	r9,r7,r9
-#else
-	cntlzd	r9,r9
-	li	r7,-1
-	addi	r9,r9,8
-	srd	r9,r7,r9
-#endif
-	or	r8,r8,r9
-	or	r10,r10,r9
-
-L(different):
-	cmpb	r9,r8,r10
-#ifdef __LITTLE_ENDIAN__
-	addi	r7,r9,1
-	andc	r9,r7,r9
-	cntlzd	r9,r9
-	subfic	r9,r9,63
-#else
-	not	r9,r9
-	cntlzd	r9,r9
-	subfic	r9,r9,56
-#endif
-	srd	r3,r8,r9
-	srd	r10,r10,r9
-	rldicl	r10,r10,0,56
-	rldicl	r3,r3,0,56
-	subf	r3,r10,r3
-	blr
-
-	.align 4
-L(process_unaligned_bytes):
-	lbz r9, 0(r3)		/* load byte from s1  */
-	lbz r10, 0(r4)		/* load byte from s2  */
-	cmpdi cr7, r9, 0	/* compare *s1 with NULL  */
-	beq cr7, L(diffOfNULL)	/* if *s1 is NULL , return *s1 - *s2  */
-	cmplw cr7, r9, r10	/* compare *s1 and *s2  */
-	bne cr7, L(ComputeDiff)	/* branch to compute difference and return  */
-
-	lbz r9, 1(r3)		/* load next byte from s1  */
-	lbz r10, 1(r4)		/* load next byte from s2  */
-	cmpdi cr7, r9, 0	/* compare *s1 with NULL  */
-	beq cr7, L(diffOfNULL)	/* if *s1 is NULL , return *s1 - *s2  */
-	cmplw cr7, r9, r10	/* compare *s1 and *s2  */
-	bne cr7, L(ComputeDiff)	/* branch to compute difference and return  */
-
-	lbz r9, 2(r3)		/* unroll 3rd byte here  */
-	lbz r10, 2(r4)
-	cmpdi cr7, r9, 0
-	beq cr7, L(diffOfNULL)
-	cmplw cr7, r9, r10
-	bne 7, L(ComputeDiff)
-
-	lbz r9, 3(r3)		/* unroll 4th byte now  */
-	lbz r10, 3(r4)
-	addi r3, r3, 4		/* increment s1 by unroll factor  */
-	cmpdi cr7, r9, 0
-	cmplw cr6, 9, r10
-	beq cr7, L(diffOfNULL)
-	addi r4, r4, 4		/* increment s2 by unroll factor  */
-	beq cr6, L(process_unaligned_bytes)	/* unroll byte processing  */
-
-	.align 4
-L(ComputeDiff):
-	extsw r9, r9
-	subf r10, r10, r9	/* compute s1 - s2  */
-	extsw r3, r10
-	blr			/* return  */
-
-	.align 4
-L(diffOfNULL):
-	li r9, 0
-	subf r10, r10, r9	/* compute s1 - s2  */
-	extsw r3, r10		/* sign extend result  */
-	blr			/* return  */
-
-END (STRCMP)
-libc_hidden_builtin_def (strcmp)
diff --git a/sysdeps/powerpc/powerpc64/power7/strlen.S b/sysdeps/powerpc/powerpc64/power7/strlen.S
deleted file mode 100644
index 9758089..0000000
--- a/sysdeps/powerpc/powerpc64/power7/strlen.S
+++ /dev/null
@@ -1,107 +0,0 @@
-/* Optimized strlen implementation for PowerPC64/POWER7 using cmpb insn.
-   Copyright (C) 2010-2018 Free Software Foundation, Inc.
-   Contributed by Luis Machado <luisgpm@br.ibm.com>.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* int [r3] strlen (char *s [r3])  */
-
-#ifndef STRLEN
-# define STRLEN strlen
-#endif
-	.machine  power7
-ENTRY_TOCLESS (STRLEN)
-	CALL_MCOUNT 1
-	dcbt	0,r3
-	clrrdi	r4,r3,3	      /* Align the address to doubleword boundary.  */
-	rlwinm	r6,r3,3,26,28 /* Calculate padding.  */
-	li	r0,0	      /* Doubleword with null chars to use
-				 with cmpb.  */
-	li	r5,-1	      /* MASK = 0xffffffffffffffff.  */
-	ld	r12,0(r4)     /* Load doubleword from memory.  */
-#ifdef __LITTLE_ENDIAN__
-	sld	r5,r5,r6
-#else
-	srd	r5,r5,r6      /* MASK = MASK >> padding.  */
-#endif
-	orc	r9,r12,r5     /* Mask bits that are not part of the string.  */
-	cmpb	r10,r9,r0     /* Check for null bytes in DWORD1.  */
-	cmpdi	cr7,r10,0     /* If r10 == 0, no null's have been found.  */
-	bne	cr7,L(done)
-
-	mtcrf   0x01,r4
-
-	/* Are we now aligned to a quadword boundary?  If so, skip to
-	   the main loop.  Otherwise, go through the alignment code.  */
-
-	bt	28,L(loop)
-
-	/* Handle DWORD2 of pair.  */
-	ldu	r12,8(r4)
-	cmpb	r10,r12,r0
-	cmpdi	cr7,r10,0
-	bne	cr7,L(done)
-
-	/* Main loop to look for the end of the string.  Since it's a
-	   small loop (< 8 instructions), align it to 32-bytes.  */
-	.p2align  5
-L(loop):
-	/* Load two doublewords, compare and merge in a
-	   single register for speed.  This is an attempt
-	   to speed up the null-checking process for bigger strings.  */
-
-	ld	r12, 8(r4)
-	ldu	r11, 16(r4)
-	cmpb	r10,r12,r0
-	cmpb	r9,r11,r0
-	or	r8,r9,r10     /* Merge everything in one doubleword.  */
-	cmpdi	cr7,r8,0
-	beq	cr7,L(loop)
-
-	/* OK, one (or both) of the doublewords contains a null byte.  Check
-	   the first doubleword and decrement the address in case the first
-	   doubleword really contains a null byte.  */
-
-	cmpdi	cr6,r10,0
-	addi	r4,r4,-8
-	bne	cr6,L(done)
-
-	/* The null byte must be in the second doubleword.  Adjust the address
-	   again and move the result of cmpb to r10 so we can calculate the
-	   length.  */
-
-	mr	r10,r9
-	addi	r4,r4,8
-
-	/* r10 has the output of the cmpb instruction, that is, it contains
-	   0xff in the same position as the null byte in the original
-	   doubleword from the string.  Use that to calculate the length.  */
-L(done):
-#ifdef __LITTLE_ENDIAN__
-	addi	r9, r10, -1   /* Form a mask from trailing zeros.  */
-	andc	r9, r9, r10
-	popcntd r0, r9	      /* Count the bits in the mask.  */
-#else
-	cntlzd	r0,r10	      /* Count leading zeros before the match.  */
-#endif
-	subf	r5,r3,r4
-	srdi	r0,r0,3	      /* Convert leading/trailing zeros to bytes.  */
-	add	r3,r5,r0      /* Compute final length.  */
-	blr
-END (STRLEN)
-libc_hidden_builtin_def (strlen)
diff --git a/sysdeps/powerpc/powerpc64/power7/strncmp.S b/sysdeps/powerpc/powerpc64/power7/strncmp.S
deleted file mode 100644
index 0c7429d..0000000
--- a/sysdeps/powerpc/powerpc64/power7/strncmp.S
+++ /dev/null
@@ -1,227 +0,0 @@
-/* Optimized strcmp implementation for POWER7/PowerPC64.
-   Copyright (C) 2010-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-#ifndef STRNCMP
-# define STRNCMP strncmp
-#endif
-
-/* See strlen.s for comments on how the end-of-string testing works.  */
-
-/* int [r3] strncmp (const char *s1 [r3],
-		     const char *s2 [r4],
-		     size_t size [r5])  */
-
-ENTRY_TOCLESS (STRNCMP, 5)
-	CALL_MCOUNT 3
-
-#define rTMP2	r0
-#define rRTN	r3
-#define rSTR1	r3	/* first string arg */
-#define rSTR2	r4	/* second string arg */
-#define rN	r5	/* max string length */
-#define rWORD1	r6	/* current word in s1 */
-#define rWORD2	r7	/* current word in s2 */
-#define rWORD3  r10
-#define rWORD4  r11
-#define rFEFE	r8	/* constant 0xfefefefefefefeff (-0x0101010101010101) */
-#define r7F7F	r9	/* constant 0x7f7f7f7f7f7f7f7f */
-#define rNEG	r10	/* ~(word in s1 | 0x7f7f7f7f7f7f7f7f) */
-#define rBITDIF	r11	/* bits that differ in s1 & s2 words */
-#define rTMP	r12
-
-	dcbt	0,rSTR1
-	nop
-	or	rTMP,rSTR2,rSTR1
-	lis	r7F7F,0x7f7f
-	dcbt	0,rSTR2
-	nop
-	clrldi.	rTMP,rTMP,61
-	cmpldi	cr1,rN,0
-	lis	rFEFE,-0x101
-	bne	L(unaligned)
-/* We are doubleword aligned so set up for two loops.  first a double word
-   loop, then fall into the byte loop if any residual.  */
-	srdi.	rTMP,rN,3
-	clrldi	rN,rN,61
-	addi	rFEFE,rFEFE,-0x101
-	addi	r7F7F,r7F7F,0x7f7f
-	cmpldi	cr1,rN,0
-	beq	L(unaligned)
-
-	mtctr	rTMP
-	ld	rWORD1,0(rSTR1)
-	ld	rWORD2,0(rSTR2)
-	sldi	rTMP,rFEFE,32
-	insrdi	r7F7F,r7F7F,32,0
-	add	rFEFE,rFEFE,rTMP
-	b	L(g1)
-
-L(g0):
-	ldu	rWORD1,8(rSTR1)
-	bne	cr1,L(different)
-	ldu	rWORD2,8(rSTR2)
-L(g1):	add	rTMP,rFEFE,rWORD1
-	nor	rNEG,r7F7F,rWORD1
-	bdz	L(tail)
-	and.	rTMP,rTMP,rNEG
-	cmpd	cr1,rWORD1,rWORD2
-	beq	L(g0)
-
-/* OK. We've hit the end of the string. We need to be careful that
-   we don't compare two strings as different because of gunk beyond
-   the end of the strings...  */
-
-#ifdef __LITTLE_ENDIAN__
-L(endstring):
-	addi    rTMP2, rTMP, -1
-	beq	cr1, L(equal)
-	andc    rTMP2, rTMP2, rTMP
-	rldimi	rTMP2, rTMP2, 1, 0
-	and	rWORD2, rWORD2, rTMP2	/* Mask off gunk.  */
-	and	rWORD1, rWORD1, rTMP2
-	cmpd	cr1, rWORD1, rWORD2
-	beq	cr1, L(equal)
-	cmpb	rBITDIF, rWORD1, rWORD2	/* 0xff on equal bytes.  */
-	addi	rNEG, rBITDIF, 1
-	orc	rNEG, rNEG, rBITDIF	/* 0's below LS differing byte.  */
-	sldi	rNEG, rNEG, 8		/* 1's above LS differing byte.  */
-	andc	rWORD1, rWORD1, rNEG	/* mask off MS bytes.  */
-	andc	rWORD2, rWORD2, rNEG
-	xor.	rBITDIF, rWORD1, rWORD2
-	sub	rRTN, rWORD1, rWORD2
-	blt	L(highbit)
-	sradi	rRTN, rRTN, 63		/* must return an int.  */
-	ori	rRTN, rRTN, 1
-	blr
-L(equal):
-	li	rRTN, 0
-	blr
-
-L(different):
-	ld	rWORD1, -8(rSTR1)
-	cmpb	rBITDIF, rWORD1, rWORD2	/* 0xff on equal bytes.  */
-	addi	rNEG, rBITDIF, 1
-	orc	rNEG, rNEG, rBITDIF	/* 0's below LS differing byte.  */
-	sldi	rNEG, rNEG, 8		/* 1's above LS differing byte.  */
-	andc	rWORD1, rWORD1, rNEG	/* mask off MS bytes.  */
-	andc	rWORD2, rWORD2, rNEG
-	xor.	rBITDIF, rWORD1, rWORD2
-	sub	rRTN, rWORD1, rWORD2
-	blt	L(highbit)
-	sradi	rRTN, rRTN, 63
-	ori	rRTN, rRTN, 1
-	blr
-L(highbit):
-	sradi	rRTN, rWORD2, 63
-	ori	rRTN, rRTN, 1
-	blr
-
-#else
-L(endstring):
-	and	rTMP,r7F7F,rWORD1
-	beq	cr1,L(equal)
-	add	rTMP,rTMP,r7F7F
-	xor.	rBITDIF,rWORD1,rWORD2
-	andc	rNEG,rNEG,rTMP
-	blt	L(highbit)
-	cntlzd	rBITDIF,rBITDIF
-	cntlzd	rNEG,rNEG
-	addi	rNEG,rNEG,7
-	cmpd	cr1,rNEG,rBITDIF
-	sub	rRTN,rWORD1,rWORD2
-	blt	cr1,L(equal)
-	sradi	rRTN,rRTN,63		/* must return an int.  */
-	ori	rRTN,rRTN,1
-	blr
-L(equal):
-	li	rRTN,0
-	blr
-
-L(different):
-	ld	rWORD1,-8(rSTR1)
-	xor.	rBITDIF,rWORD1,rWORD2
-	sub	rRTN,rWORD1,rWORD2
-	blt	L(highbit)
-	sradi	rRTN,rRTN,63
-	ori	rRTN,rRTN,1
-	blr
-L(highbit):
-	sradi	rRTN,rWORD2,63
-	ori	rRTN,rRTN,1
-	blr
-#endif
-
-/* Oh well.  In this case, we just do a byte-by-byte comparison.  */
-	.align	4
-L(tail):
-	and.	rTMP,rTMP,rNEG
-	cmpd	cr1,rWORD1,rWORD2
-	bne	L(endstring)
-	addi	rSTR1,rSTR1,8
-	bne	cr1,L(different)
-	addi	rSTR2,rSTR2,8
-	cmpldi	cr1,rN,0
-L(unaligned):
-	mtctr	rN
-	ble	cr1,L(ux)
-L(uz):
-	lbz	rWORD1,0(rSTR1)
-	lbz	rWORD2,0(rSTR2)
-	.align	4
-L(u1):
-	cmpdi	cr1,rWORD1,0
-	bdz	L(u4)
-	cmpd	rWORD1,rWORD2
-	beq	cr1,L(u4)
-	bne	L(u4)
-	lbzu	rWORD3,1(rSTR1)
-	lbzu	rWORD4,1(rSTR2)
-	cmpdi	cr1,rWORD3,0
-	bdz	L(u3)
-	cmpd	rWORD3,rWORD4
-	beq	cr1,L(u3)
-	bne	L(u3)
-	lbzu	rWORD1,1(rSTR1)
-	lbzu	rWORD2,1(rSTR2)
-	cmpdi	cr1,rWORD1,0
-	bdz	L(u4)
-	cmpd	rWORD1,rWORD2
-	beq	cr1,L(u4)
-	bne	L(u4)
-	lbzu	rWORD3,1(rSTR1)
-	lbzu	rWORD4,1(rSTR2)
-	cmpdi	cr1,rWORD3,0
-	bdz	L(u3)
-	cmpd	rWORD3,rWORD4
-	beq	cr1,L(u3)
-	bne	L(u3)
-	lbzu	rWORD1,1(rSTR1)
-	lbzu	rWORD2,1(rSTR2)
-	b	L(u1)
-
-L(u3):  sub	rRTN,rWORD3,rWORD4
-	blr
-L(u4):	sub	rRTN,rWORD1,rWORD2
-	blr
-L(ux):
-	li	rRTN,0
-	blr
-END (STRNCMP)
-libc_hidden_builtin_def (strncmp)
diff --git a/sysdeps/powerpc/powerpc64/power7/strncpy.S b/sysdeps/powerpc/powerpc64/power7/strncpy.S
deleted file mode 100644
index 1965f82..0000000
--- a/sysdeps/powerpc/powerpc64/power7/strncpy.S
+++ /dev/null
@@ -1,732 +0,0 @@
-/* Copyright (C) 2014-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* Implements the functions
-
-   char * [r3] strncpy (char *dst [r3], const char *src [r4], size_t n [r5])
-
-   AND
-
-   char * [r3] stpncpy (char *dst [r3], const char *src [r4], size_t n [r5])
-
-   The algorithm is as follows:
-   > if src and dest are 8 byte aligned, perform double word copy
-     else
-   > copy byte by byte on unaligned addresses.
-
-   The aligned comparison are made using cmpb instructions.  */
-
-/* The focus on optimization for performance improvements are as follows:
-   1. data alignment [gain from aligned memory access on read/write]
-   2. POWER7 gains performance with loop unrolling/unwinding
-      [gain by reduction of branch penalty].
-   3. The final pad with null bytes is done by calling an optimized
-      memset.  */
-
-#ifdef USE_AS_STPNCPY
-# ifndef STPNCPY
-#  define FUNC_NAME __stpncpy
-# else
-#  define FUNC_NAME STPNCPY
-# endif
-#else
-# ifndef STRNCPY
-#  define FUNC_NAME strncpy
-# else
-#  define FUNC_NAME STRNCPY
-# endif
-#endif  /* !USE_AS_STPNCPY  */
-
-#define		FRAMESIZE	(FRAME_MIN_SIZE+16)
-
-#ifndef MEMSET
-/* For builds with no IFUNC support, local calls should be made to internal
-   GLIBC symbol (created by libc_hidden_builtin_def).  */
-# ifdef SHARED
-#  define MEMSET_is_local
-#  define MEMSET   __GI_memset
-# else
-#  define MEMSET   memset
-# endif
-#endif
-
-	.machine  power7
-#ifdef MEMSET_is_local
-ENTRY_TOCLESS (FUNC_NAME, 4)
-#else
-ENTRY (FUNC_NAME, 4)
-#endif
-	CALL_MCOUNT 3
-
-	or r10, r3, r4		/* to verify source and destination  */
-	rldicl. r8, r10, 0, 61	/* is double word aligned .. ?  */
-
-	std r19, -8(r1)		/* save callers register , r19  */
-	std r18, -16(r1)	/* save callers register , r18  */
-	cfi_offset(r19, -8)
-	cfi_offset(r18, -16)
-
-	mr r9, r3		/* save r3 into r9 for use  */
-	mr r18, r3		/* save r3 for retCode of strncpy  */
-	bne 0, L(unaligned)
-
-L(aligned):
-	srdi r11, r5, 3		/* compute count for CTR ; count = n/8  */
-	cmpldi cr7, r11, 3	/* if count > 4 ; perform unrolling 4 times  */
-	ble 7, L(update1)
-
-	ld r10, 0(r4)		/* load doubleWord from src  */
-	cmpb r8, r10, r8	/* compare src with NULL ,we read just now  */
-	cmpdi cr7, r8, 0	/* if cmpb returned NULL ; we continue  */
-	bne cr7, L(update3)
-
-	std r10, 0(r3)		/* copy doubleword at offset=0  */
-	ld r10, 8(r4)		/* load next doubleword from offset=8  */
-	cmpb r8, r10, r8	/* compare src with NULL , we read just now  */
-	cmpdi cr7, r8, 0	/* if cmpb returned NULL ; we continue  */
-	bne 7,L(HopBy8)
-
-	addi r8, r11, -4
-	mr r7, r3
-	srdi r8, r8, 2
-	mr r6, r4
-	addi r8, r8, 1
-	li r12, 0
-	mtctr r8
-	b L(dwordCopy)
-
-	.p2align 4
-L(dWordUnroll):
-	std r8, 16(r9)
-	ld r8, 24(r4)		/* load dword,perform loop unrolling again  */
-	cmpb r10, r8, r10
-	cmpdi cr7, r10, 0
-	bne cr7, L(HopBy24)
-
-	std r8, 24(r7)		/* copy dword at offset=24  */
-	addi r9, r9, 32
-	addi r4, r4, 32
-	bdz  L(leftDwords)	/* continue with loop on counter  */
-
-	ld r3, 32(r6)
-	cmpb r8, r3, r10
-	cmpdi cr7, r8, 0
-	bne cr7, L(update2)
-
-	std r3, 32(r7)
-	ld r10, 40(r6)
-	cmpb r8, r10, r8
-	cmpdi cr7, r8, 0
-	bne cr7, L(HopBy40)
-
-	mr r6, r4		/* update values  */
-	mr r7, r9
-	mr r11, r0
-	mr r5, r19
-
-L(dwordCopy):
-	std r10, 8(r9)		/* copy dword at offset=8  */
-	addi r19, r5, -32
-	addi r0, r11, -4
-	ld r8, 16(r4)
-	cmpb r10, r8, r12
-	cmpdi cr7, r10, 0
-	beq cr7, L(dWordUnroll)
-
-	addi r9, r9, 16		/* increment dst by 16  */
-	addi r4, r4, 16		/* increment src by 16  */
-	addi r5, r5, -16	/* decrement length 'n' by 16  */
-	addi r0, r11, -2	/* decrement loop counter  */
-
-L(dWordUnrollOFF):
-	ld r10, 0(r4)		/* load first dword  */
-	li r8, 0		/* load mask  */
-	cmpb r8, r10, r8
-	cmpdi cr7, r8, 0
-	bne cr7, L(byte_by_byte)
-	mtctr r0
-	li r7, 0
-	b L(CopyDword)
-
-	.p2align 4
-L(loadDWordandCompare):
-	ld r10, 0(r4)
-	cmpb r8, r10, r7
-	cmpdi cr7, r8, 0
-	bne cr7, L(byte_by_byte)
-
-L(CopyDword):
-	addi r9, r9, 8
-	std r10, -8(r9)
-	addi r4, r4, 8
-	addi r5, r5, -8
-	bdnz L(loadDWordandCompare)
-
-L(byte_by_byte):
-	cmpldi cr7, r5, 3
-	ble cr7, L(verifyByte)
-	srdi r10, r5, 2
-	mr r19, r9
-	mtctr r10
-	b L(firstByteUnroll)
-
-	.p2align 4
-L(bytes_unroll):
-	lbz r10, 1(r4)		/* load byte from src  */
-	cmpdi cr7, r10, 0	/* compare for NULL  */
-	stb r10, 1(r19)		/* store byte to dst  */
-	beq cr7, L(updtDestComputeN2ndByte)
-
-	addi r4, r4, 4		/* advance src  */
-
-	lbz r10, -2(r4)		/* perform loop unrolling for byte r/w  */
-	cmpdi cr7, r10, 0
-	stb r10, 2(r19)
-	beq cr7, L(updtDestComputeN3rdByte)
-
-	lbz r10, -1(r4)		/* perform loop unrolling for byte r/w  */
-	addi r19, r19, 4
-	cmpdi cr7, r10, 0
-	stb r10, -1(r19)
-	beq cr7, L(ComputeNByte)
-
-	bdz L(update0)
-
-L(firstByteUnroll):
-	lbz r10, 0(r4)		/* perform loop unrolling for byte r/w  */
-	cmpdi cr7, 10, 0
-	stb r10, 0(r19)
-	bne cr7, L(bytes_unroll)
-	addi r19, r19, 1
-
-L(ComputeNByte):
-	subf r9, r19, r9	/* compute 'n'n bytes to fill  */
-	add r8, r9, r5
-
-L(zeroFill):
-	cmpdi cr7, r8, 0	/* compare if length is zero  */
-	beq cr7, L(update3return)
-
-	mflr r0			/* load link register LR to r0  */
-	std r0, 16(r1)		/* store the link register  */
-	stdu r1, -FRAMESIZE(r1)	/* create the stack frame  */
-	cfi_adjust_cfa_offset(FRAMESIZE)
-	cfi_offset(lr, 16)
-	mr r3, r19		/* fill buffer with  */
-	li r4, 0		/* zero fill buffer  */
-	mr r5, r8		/* how many bytes to fill buffer with  */
-	bl MEMSET		/* call optimized memset  */
-#ifndef MEMSET_is_local
-	nop
-#endif
-	ld r0, FRAMESIZE+16(r1) /* read the saved link register  */
-	addi r1, r1, FRAMESIZE	/* restore stack pointer  */
-	cfi_adjust_cfa_offset(-FRAMESIZE)
-	mtlr r0
-	cfi_restore(lr)
-
-L(update3return):
-#ifdef USE_AS_STPNCPY
-	addi r3, r19, -1	/* update return value  */
-#endif
-
-L(hop2return):
-#ifndef USE_AS_STPNCPY
-	mr r3, r18		/* set return value  */
-#endif
-	ld r18, -16(r1)		/* restore callers save register, r18  */
-	ld r19, -8(r1)		/* restore callers save register, r19  */
-	blr			/* return  */
-
-	.p2align 4
-L(update0):
-	mr r9, r19
-
-	.p2align 4
-L(verifyByte):
-	rldicl. r8, r5, 0, 62
-#ifdef USE_AS_STPNCPY
-	mr r3, r9
-#endif
-	beq cr0, L(hop2return)
-	mtctr r8
-	addi r4, r4, -1
-	mr r19, r9
-	b L(oneBYone)
-
-	.p2align 4
-L(proceed):
-	bdz L(done)
-
-L(oneBYone):
-	lbzu r10, 1(r4)		/* copy byte  */
-	addi r19, r19, 1
-	addi r8, r8, -1
-	cmpdi cr7, r10, 0
-	stb r10, -1(r19)
-	bne cr7, L(proceed)
-	b L(zeroFill)
-
-	.p2align 4
-L(done):
-#ifdef USE_AS_STPNCPY
-	mr r3, r19		/* set the return value  */
-#else
-	mr r3, r18		/* set the return value  */
-#endif
-	ld r18, -16(r1)		/* restore callers save register, r18  */
-	ld r19, -8(r1)		/* restore callers save register, r19  */
-	blr			/* return  */
-
-L(update1):
-	mr r0, r11
-	mr r19, r5
-
-	.p2align 4
-L(leftDwords):
-	cmpdi cr7, r0, 0
-	mr r5, r19
-	bne cr7, L(dWordUnrollOFF)
-	b L(byte_by_byte)
-
-	.p2align 4
-L(updtDestComputeN2ndByte):
-	addi r19, r19, 2	/* update dst by 2  */
-	subf r9, r19, r9	/* compute distance covered  */
-	add r8, r9, r5
-	b L(zeroFill)
-
-	.p2align 4
-L(updtDestComputeN3rdByte):
-	addi r19, r19, 3	/* update dst by 3  */
-	subf r9, r19, r9	/* compute distance covered  */
-	add r8, r9, r5
-	b L(zeroFill)
-
-	.p2align 4
-L(HopBy24):
-	addi r9, r9, 24		/* increment dst by 24  */
-	addi r4, r4, 24		/* increment src by 24  */
-	addi r5, r5, -24	/* decrement length 'n' by 24  */
-	addi r0, r11, -3	/* decrement loop counter  */
-	b L(dWordUnrollOFF)
-
-	.p2align 4
-L(update2):
-	mr r5, r19
-	b L(dWordUnrollOFF)
-
-	.p2align 4
-L(HopBy40):
-	addi r9, r7, 40		/* increment dst by 40  */
-	addi r4, r6, 40		/* increment src by 40  */
-	addi r5, r5, -40	/* decrement length 'n' by 40  */
-	addi r0, r11, -5	/* decrement loop counter  */
-	b L(dWordUnrollOFF)
-
-L(update3):
-	mr r0, r11
-	b L(dWordUnrollOFF)
-
-L(HopBy8):
-	addi r9, r3, 8		/* increment dst by 8  */
-	addi r4, r4, 8		/* increment src by 8  */
-	addi r5, r5, -8		/* decrement length 'n' by 8  */
-	addi r0, r11, -1	/* decrement loop counter  */
-	b L(dWordUnrollOFF)
-
-L(unaligned):
-	cmpdi	r5, 16		/* Proceed byte by byte for less than 16  */
-	ble	L(byte_by_byte)
-	rldicl	r7, r3, 0, 61
-	rldicl	r6, r4, 0, 61
-	cmpdi	r6, 0	/* Check src alignment */
-	beq	L(srcaligndstunalign)
-	/* src is unaligned */
-	rlwinm	r10, r4, 3,26,28	/* Calculate padding.  */
-	clrrdi	r4, r4, 3	/* Align the addr to dw boundary */
-	ld	r8, 0(r4)	/* Load doubleword from memory.  */
-	li	r0, 0
-	/* Discard bits not part of the string */
-#ifdef __LITTLE_ENDIAN__
-	srd	r7, r8, r10
-#else
-	sld	r7, r8, r10
-#endif
-	cmpb	r0, r7, r0	/* Compare each byte against null */
-	/* Discard bits not part of the string */
-#ifdef __LITTLE_ENDIAN__
-	sld	r0, r0, r10
-#else
-	srd	r0, r0, r10
-#endif
-	cmpdi	r0, 0
-	bne     L(bytebybyte)	/* if it has null, copy byte by byte */
-	subfic	r6, r6, 8
-	rlwinm	r12, r3, 3,26,28	/* Calculate padding in bits.  */
-	rldicl	r9, r3, 0, 61	/* Calculate padding in bytes. */
-	addi	r3, r3, -1
-
-	cmpdi	r12, 0	/* check dest alignment */
-	beq     L(srcunaligndstalign)
-
-	/* both src and dst unaligned */
-#ifdef __LITTLE_ENDIAN__
-	sld	r8, r7, r10
-	mr	r11, r10
-	addi	r11, r11, -8	/* Adjust byte pointer on loaded dw */
-#else
-	srd	r8, r7, r10
-	subfic	r11, r10, 64
-#endif
-	/* dst alignment is greater then src alignment? */
-	cmpd    cr7, r12, r10
-	ble     cr7, L(dst_align_small)
-	/* src alignment is less than dst */
-
-	/* Calculate the dst alignment difference  */
-	subfic	r7, r9, 8
-	mtctr	r7
-
-	/* Write until dst is aligned  */
-	cmpdi	r0, r7, 4
-	blt     L(storebyte1)	/* less than 4, store byte by byte  */
-	beq     L(equal1)	/* if its 4, store word  */
-	addi	r0, r7, -4	/* greater than 4, so stb and stw  */
-	mtctr	r0
-L(storebyte1):
-#ifdef __LITTLE_ENDIAN__
-	addi	r11, r11, 8	/* Adjust byte pointer on loaded dw  */
-#else
-	addi	r11, r11, -8
-#endif
-	srd	r7, r8, r11
-	stbu	r7, 1(r3)
-	addi	r5, r5, -1
-	bdnz    L(storebyte1)
-
-	subfic	r7, r9, 8	/* Check the remaining bytes  */
-	cmpdi	r0, r7, 4
-	blt     L(proceed1)
-
-	.align 4
-L(equal1):
-#ifdef __LITTLE_ENDIAN__
-	addi	r11, r11, 8	/* Adjust byte pointer on loaded dw  */
-	srd	r7, r8, r11
-#else
-	subfic	r11, r11, 64
-	sld	r7, r8, r11
-	srdi	r7, r7, 32
-#endif
-	stw	r7, 1(r3)
-	addi	r3, r3, 4
-	addi	r5, r5, -4
-
-L(proceed1):
-	mr	r7, r8
-	/* calculate the Left over bytes to be written  */
-	subfic	r11, r10, 64
-	subfic	r12, r12, 64
-	subf	r12, r12, r11	/* remaining bytes on second dw  */
-	subfic	r10, r12, 64	/* remaining bytes on first dw  */
-	subfic	r9, r9, 8
-	subf	r6, r9, r6	/* recalculate padding  */
-L(srcunaligndstalign):
-	addi	r3, r3, 1
-	subfic	r12, r10, 64	/* remaining bytes on second dw  */
-	addi	r4, r4, 8
-	li	r0,0
-	b       L(storedouble)
-
-	.align 4
-L(dst_align_small):
-	mtctr	r6
-	/* Write until src is aligned  */
-L(storebyte2):
-#ifdef __LITTLE_ENDIAN__
-	addi	r11, r11, 8	/* Adjust byte pointer on dw  */
-#else
-	addi	r11, r11, -8
-#endif
-	srd	r7, r8, r11
-	stbu	r7, 1(r3)
-	addi	r5, r5, -1
-	bdnz    L(storebyte2)
-
-	addi	r4, r4, 8	/* Increment src pointer  */
-	addi	r3, r3, 1	/* Increment dst pointer  */
-	mr	r9, r3
-	li	r8, 0
-	cmpd    cr7, r12, r10
-	beq     cr7, L(aligned)
-	rldicl	r6, r3, 0, 61	/* Recalculate padding */
-	mr	r7, r6
-
-	/* src is algined */
-L(srcaligndstunalign):
-	mr	r9, r3
-	mr	r6, r7
-	ld	r8, 0(r4)
-	subfic	r10, r7, 8
-	mr	r7, r8
-	li	r0, 0	/* Check null */
-	cmpb	r0, r8, r0
-	cmpdi	r0, 0
-	bne     L(byte_by_byte)	/* Do byte by byte if there is NULL  */
-	rlwinm	r12, r3, 3,26,28	/* Calculate padding  */
-	addi	r3, r3, -1
-	/* write byte by byte until aligned  */
-#ifdef __LITTLE_ENDIAN__
-	li	r11, -8
-#else
-	li	r11, 64
-#endif
-	mtctr	r10
-	cmpdi	r0, r10, 4
-	blt     L(storebyte)
-	beq     L(equal)
-	addi	r0, r10, -4
-	mtctr	r0
-L(storebyte):
-#ifdef __LITTLE_ENDIAN__
-	addi	r11, r11, 8	/* Adjust byte pointer on  dw  */
-#else
-	addi	r11, r11, -8
-#endif
-	srd	r7, r8, r11
-	stbu	r7, 1(r3)
-	addi	r5, r5, -1
-	bdnz    L(storebyte)
-
-	cmpdi	r0, r10, 4
-	blt     L(align)
-
-	.align 4
-L(equal):
-#ifdef __LITTLE_ENDIAN__
-	addi	r11, r11, 8
-	srd	r7, r8, r11
-#else
-	subfic	r11, r11, 64
-	sld	r7, r8, r11
-	srdi	r7, r7, 32
-#endif
-	stw	r7, 1(r3)
-	addi	r5, r5, -4
-	addi	r3, r3, 4
-L(align):
-	addi	r3, r3, 1
-	addi	r4, r4, 8	/* Increment src pointer  */
-	subfic	r10, r12, 64
-	li	r0, 0
-	/* dst addr aligned to 8 */
-L(storedouble):
-	cmpdi	r5, 8
-	ble	L(null1)
-	ld	r7, 0(r4)	/* load next dw  */
-	cmpb	r0, r7, r0
-	cmpdi	r0, 0	/* check for null on each new dw  */
-	bne     L(null)
-#ifdef __LITTLE_ENDIAN__
-	srd	r9, r8, r10	/* bytes from first dw  */
-	sld	r11, r7, r12	/* bytes from second dw  */
-#else
-	sld	r9, r8, r10
-	srd	r11, r7, r12
-#endif
-	or	r11, r9, r11	/* make as a single dw  */
-	std	r11, 0(r3)	/* store as std on aligned addr  */
-	mr	r8, r7		/* still few bytes left to be written  */
-	addi	r3, r3, 8	/* increment dst addr  */
-	addi	r4, r4, 8	/* increment src addr  */
-	addi	r5, r5, -8
-	b       L(storedouble)	/* Loop until NULL  */
-
-	.align 4
-
-/* We've hit the end of the string.  Do the rest byte-by-byte.  */
-L(null):
-	addi	r3, r3, -1
-	mr	r10, r12
-	mtctr	r6
-#ifdef __LITTLE_ENDIAN__
-	subfic	r10, r10, 64
-	addi	r10, r10, -8
-#endif
-	cmpdi	r0, r5, 4
-	blt	L(loop)
-	cmpdi	r0, r6, 4
-	blt     L(loop)
-
-	/* we can still use stw if leftover >= 4  */
-#ifdef __LITTLE_ENDIAN__
-	addi	r10, r10, 8
-	srd	r11, r8, r10
-#else
-	subfic	r10, r10, 64
-	sld	r11, r8, r10
-	srdi	r11, r11, 32
-#endif
-	stw	r11, 1(r3)
-	addi	r5, r5, -4
-	addi	r3, r3, 4
-	cmpdi	r0, r5, 0
-	beq	L(g1)
-	cmpdi	r0, r6, 4
-	beq     L(bytebybyte1)
-	addi	r10, r10, 32
-#ifdef __LITTLE_ENDIAN__
-	addi	r10, r10, -8
-#else
-	subfic	r10, r10, 64
-#endif
-	addi	r0, r6, -4
-	mtctr	r0
-	/* remaining byte by byte part of first dw  */
-L(loop):
-#ifdef __LITTLE_ENDIAN__
-	addi	r10, r10, 8
-#else
-	addi	r10, r10, -8
-#endif
-	srd	r0, r8, r10
-	stbu	r0, 1(r3)
-	addi	r5, r5, -1
-	cmpdi	r0, r5, 0
-	beq	L(g1)
-	bdnz    L(loop)
-L(bytebybyte1):
-	addi	r3, r3, 1
-	/* remaining byte by byte part of second dw   */
-L(bytebybyte):
-	addi	r3, r3, -8
-	addi	r4, r4, -1
-
-#ifdef __LITTLE_ENDIAN__
-	extrdi. r0, r7, 8, 56
-	stbu	r7, 8(r3)
-	addi	r5, r5, -1
-	beq	L(g2)
-	cmpdi	r5, 0
-	beq	L(g1)
-	extrdi. r0, r7, 8, 48
-	stbu	r0, 1(r3)
-	addi	r5, r5, -1
-	beq	L(g2)
-	cmpdi	r5, 0
-	beq	L(g1)
-	extrdi. r0, r7, 8, 40
-	stbu	r0, 1(r3)
-	addi	r5, r5, -1
-	beq	L(g2)
-	cmpdi	r5, 0
-	beq	L(g1)
-	extrdi. r0, r7, 8, 32
-	stbu	r0, 1(r3)
-	addi	r5, r5, -1
-	beq	L(g2)
-	cmpdi	r5, 0
-	beq	L(g1)
-	extrdi. r0, r7, 8, 24
-	stbu	r0, 1(r3)
-	addi	r5, r5, -1
-	beq	L(g2)
-	cmpdi	r5, 0
-	beq	L(g1)
-	extrdi. r0, r7, 8, 16
-	stbu	r0, 1(r3)
-	addi	r5, r5, -1
-	beq	L(g2)
-	cmpdi	r5, 0
-	beq	L(g1)
-	extrdi. r0, r7, 8, 8
-	stbu	r0, 1(r3)
-	addi	r5, r5, -1
-	beq	L(g2)
-	cmpdi	r5, 0
-	beq	L(g1)
-	extrdi	r0, r7, 8, 0
-	stbu	r0, 1(r3)
-	addi	r5, r5, -1
-	b	L(g2)
-#else
-	extrdi. r0, r7, 8, 0
-	stbu	r0, 8(r3)
-	addi	r5, r5, -1
-	beq	L(g2)
-	cmpdi	r5, 0
-	beq	L(g1)
-	extrdi. r0, r7, 8, 8
-	stbu	r0, 1(r3)
-	addi	r5, r5, -1
-	beq	L(g2)
-	cmpdi	r5, 0
-	beq	L(g1)
-	extrdi. r0, r7, 8, 16
-	stbu	r0, 1(r3)
-	addi	r5, r5, -1
-	beq	L(g2)
-	cmpdi	r5, 0
-	beq	L(g1)
-	extrdi. r0, r7, 8, 24
-	stbu	r0, 1(r3)
-	addi	r5, r5, -1
-	beq	L(g2)
-	cmpdi	r5, 0
-	beq	L(g1)
-	extrdi. r0, r7, 8, 32
-	stbu	r0, 1(r3)
-	addi	r5, r5, -1
-	beq	L(g2)
-	cmpdi	r5, 0
-	beq	L(g1)
-	extrdi. r0, r7, 8, 40
-	stbu	r0, 1(r3)
-	addi	r5, r5, -1
-	beq	L(g2)
-	cmpdi	r5, 0
-	beq	L(g1)
-	extrdi. r0, r7, 8, 48
-	stbu	r0, 1(r3)
-	addi	r5, r5, -1
-	beq	L(g2)
-	cmpdi	r5, 0
-	beq	L(g1)
-	stbu	r7, 1(r3)
-	addi	r5, r5, -1
-	b	L(g2)
-#endif
-L(g1):
-#ifdef USE_AS_STPNCPY
-	addi	r3, r3, 1
-#endif
-L(g2):
-	addi	r3, r3, 1
-	mr	r19, r3
-	mr	r8, r5
-	b	L(zeroFill)
-L(null1):
-	mr	r9, r3
-	subf	r4, r6, r4
-	b	L(byte_by_byte)
-END(FUNC_NAME)
-#ifndef USE_AS_STPNCPY
-libc_hidden_builtin_def (strncpy)
-#endif
diff --git a/sysdeps/powerpc/powerpc64/power7/strnlen.S b/sysdeps/powerpc/powerpc64/power7/strnlen.S
deleted file mode 100644
index 3097cac..0000000
--- a/sysdeps/powerpc/powerpc64/power7/strnlen.S
+++ /dev/null
@@ -1,182 +0,0 @@
-/* Optimized strnlen implementation for PowerPC64/POWER7 using cmpb insn.
-   Copyright (C) 2010-2018 Free Software Foundation, Inc.
-   Contributed by Luis Machado <luisgpm@br.ibm.com>.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-#ifndef STRNLEN
-# define STRNLEN __strnlen
-#endif
-
-/* int [r3] strnlen (char *s [r3], int size [r4])  */
-	.machine  power7
-ENTRY_TOCLESS (STRNLEN)
-	CALL_MCOUNT 2
-	dcbt	0,r3
-	clrrdi	r8,r3,3
-	add	r7,r3,r4      /* Calculate the last acceptable address.  */
-	cmpldi	r4,32
-	li	r0,0	      /* Doubleword with null chars.  */
-	addi	r7,r7,-1
-
-	/* If we have less than 33 bytes to search, skip to a faster code.  */
-	ble	L(small_range)
-
-	rlwinm	r6,r3,3,26,28 /* Calculate padding.  */
-	ld	r12,0(r8)     /* Load doubleword from memory.  */
-	cmpb	r10,r12,r0    /* Check for null bytes in DWORD1.  */
-#ifdef __LITTLE_ENDIAN__
-	srd	r10,r10,r6
-	sld	r10,r10,r6
-#else
-	sld	r10,r10,r6
-	srd	r10,r10,r6
-#endif
-	cmpldi	cr7,r10,0     /* If r10 == 0, no null's have been found.  */
-	bne	cr7,L(done)
-
-	clrrdi	r7,r7,3       /* Address of last doubleword.  */
-	mtcrf   0x01,r8
-	/* Are we now aligned to a quadword boundary?  If so, skip to
-	   the main loop.  Otherwise, go through the alignment code.  */
-
-	bt	28,L(loop_setup)
-
-	/* Handle DWORD2 of pair.  */
-	ldu	r12,8(r8)
-	cmpb	r10,r12,r0
-	cmpldi	cr7,r10,0
-	bne	cr7,L(done)
-
-L(loop_setup):
-	/* The last dword we want to read in the loop below is the one
-	   containing the last byte of the string, ie. the dword at
-	   (s + size - 1) & ~7, or r7.  The first dword read is at
-	   r8 + 8, we read 2 * cnt dwords, so the last dword read will
-	   be at r8 + 8 + 16 * cnt - 8.  Solving for cnt gives
-	   cnt = (r7 - r8) / 16  */
-	sub	r5,r7,r8
-	srdi	r6,r5,4	      /* Number of loop iterations.  */
-	mtctr	r6	      /* Setup the counter.  */
-
-	/* Main loop to look for the null byte in the string.  Since
-	   it's a small loop (< 8 instructions), align it to 32-bytes.  */
-	.p2align  5
-L(loop):
-	/* Load two doublewords, compare and merge in a
-	   single register for speed.  This is an attempt
-	   to speed up the null-checking process for bigger strings.  */
-
-	ld	r12,8(r8)
-	ldu	r11,16(r8)
-	cmpb	r10,r12,r0
-	cmpb	r9,r11,r0
-	or	r5,r9,r10     /* Merge everything in one doubleword.  */
-	cmpldi	cr7,r5,0
-	bne	cr7,L(found)
-	bdnz	L(loop)
-
-	/* We may have one more dword to read.  */
-	cmpld	cr6,r8,r7
-	beq	cr6,L(end_max)
-
-	ldu	r12,8(r8)
-	cmpb	r10,r12,r0
-	cmpldi	cr6,r10,0
-	bne	cr6,L(done)
-
-L(end_max):
-	mr	r3,r4
-	blr
-
-	/* OK, one (or both) of the doublewords contains a null byte.  Check
-	   the first doubleword and decrement the address in case the first
-	   doubleword really contains a null byte.  */
-	.align	4
-L(found):
-	cmpldi	cr6,r10,0
-	addi	r8,r8,-8
-	bne	cr6,L(done)
-
-	/* The null byte must be in the second doubleword.  Adjust the address
-	   again and move the result of cmpb to r10 so we can calculate the
-	   length.  */
-
-	mr	r10,r9
-	addi	r8,r8,8
-
-	/* r10 has the output of the cmpb instruction, that is, it contains
-	   0xff in the same position as the null byte in the original
-	   doubleword from the string.  Use that to calculate the length.
-	   We need to make sure the null char is *before* the end of the
-	   range.  */
-L(done):
-#ifdef __LITTLE_ENDIAN__
-	addi	r0,r10,-1
-	andc	r0,r0,r10
-	popcntd	r0,r0
-#else
-	cntlzd	r0,r10	      /* Count leading zeros before the match.  */
-#endif
-	sub	r3,r8,r3
-	srdi	r0,r0,3	      /* Convert leading/trailing zeros to bytes.  */
-	add	r3,r3,r0      /* Length until the match.  */
-	cmpld	r3,r4
-	blelr
-	mr	r3,r4
-	blr
-
-/* Deals with size <= 32.  */
-	.align	4
-L(small_range):
-	cmpldi	r4,0
-	beq	L(end_max)
-
-	clrrdi	r7,r7,3       /* Address of last doubleword.  */
-
-	rlwinm	r6,r3,3,26,28 /* Calculate padding.  */
-	ld	r12,0(r8)     /* Load doubleword from memory.  */
-	cmpb	r10,r12,r0    /* Check for null bytes in DWORD1.  */
-#ifdef __LITTLE_ENDIAN__
-	srd	r10,r10,r6
-	sld	r10,r10,r6
-#else
-	sld	r10,r10,r6
-	srd	r10,r10,r6
-#endif
-	cmpldi	cr7,r10,0
-	bne	cr7,L(done)
-
-	cmpld	r8,r7
-	beq	L(end_max)
-
-	.p2align  5
-L(loop_small):
-	ldu	r12,8(r8)
-	cmpb	r10,r12,r0
-	cmpldi	cr6,r10,0
-	bne	cr6,L(done)
-	cmpld	r8,r7
-	bne	L(loop_small)
-	mr	r3,r4
-	blr
-
-END (STRNLEN)
-libc_hidden_def (__strnlen)
-weak_alias (__strnlen, strnlen)
-libc_hidden_def (strnlen)
diff --git a/sysdeps/powerpc/powerpc64/power7/strrchr.S b/sysdeps/powerpc/powerpc64/power7/strrchr.S
deleted file mode 100644
index e47e3d4..0000000
--- a/sysdeps/powerpc/powerpc64/power7/strrchr.S
+++ /dev/null
@@ -1,260 +0,0 @@
-/* Optimized strrchr implementation for PowerPC64/POWER7 using cmpb insn.
-   Copyright (C) 2014-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* int [r3] strrchr (char *s [r3], int c [r4])  */
-
-#ifndef STRRCHR
-# define STRRCHR strrchr
-#endif
-
-	.machine  power7
-ENTRY_TOCLESS (STRRCHR)
-	CALL_MCOUNT 2
-	dcbt	0,r3
-	clrrdi	r8,r3,3	      /* Align the address to doubleword boundary.  */
-	cmpdi	cr7,r4,0
-	ld	r12,0(r8)     /* Load doubleword from memory.  */
-	li	r9,0	      /* used to store last occurence */
-	li	r0,0	      /* Doubleword with null chars to use
-				 with cmpb.  */
-
-	rlwinm	r6,r3,3,26,28 /* Calculate padding.  */
-
-	beq	cr7,L(null_match)
-
-	/* Replicate byte to doubleword.  */
-	insrdi	r4,r4,8,48
-	insrdi	r4,r4,16,32
-	insrdi	r4,r4,32,0
-
-	/* r4 is changed now ,if its passed as more chars
-	   check for null again */
-	cmpdi	cr7,r4,0
-	beq	cr7,L(null_match)
-	/* Now r4 has a doubleword of c bytes and r0 has
-	   a doubleword of null bytes.  */
-
-	cmpb	r10,r12,r4     /* Compare each byte against c byte.  */
-	cmpb	r11,r12,r0     /* Compare each byte against null byte.  */
-
-	/* Move the doublewords left and right to discard the bits that are
-	   not part of the string and bring them back as zeros.  */
-#ifdef __LITTLE_ENDIAN__
-	srd	r10,r10,r6
-	srd	r11,r11,r6
-	sld	r10,r10,r6
-	sld	r11,r11,r6
-#else
-	sld	r10,r10,r6
-	sld	r11,r11,r6
-	srd	r10,r10,r6
-	srd	r11,r11,r6
-#endif
-	or	r5,r10,r11    /* OR the results to speed things up.  */
-	cmpdi	cr7,r5,0      /* If r5 == 0, no c or null bytes
-				 have been found.  */
-	bne	cr7,L(done)
-
-L(align):
-	mtcrf	0x01,r8
-
-	/* Are we now aligned to a doubleword boundary?  If so, skip to
-	   the main loop.  Otherwise, go through the alignment code.  */
-
-	bt	28,L(loop)
-
-	/* Handle WORD2 of pair.  */
-	ldu	r12,8(r8)
-	cmpb	r10,r12,r4
-	cmpb	r11,r12,r0
-	or	r5,r10,r11
-	cmpdi	cr7,r5,0
-	bne	cr7,L(done)
-	b	L(loop)	      /* We branch here (rather than falling through)
-				 to skip the nops due to heavy alignment
-				 of the loop below.  */
-	.p2align  5
-L(loop):
-	/* Load two doublewords, compare and merge in a
-	   single register for speed.  This is an attempt
-	   to speed up the null-checking process for bigger strings.  */
-	ld	r12,8(r8)
-	ldu	r7,16(r8)
-	cmpb	r10,r12,r4
-	cmpb	r11,r12,r0
-	cmpb	r6,r7,r4
-	cmpb	r7,r7,r0
-	or	r12,r10,r11
-	or	r5,r6,r7
-	or	r5,r12,r5
-	cmpdi	cr7,r5,0
-	beq	cr7,L(loop)
-
-	/* OK, one (or both) of the doublewords contains a c/null byte.  Check
-	   the first doubleword and decrement the address in case the first
-	   doubleword really contains a c/null byte.  */
-	cmpdi	cr6,r12,0
-	addi	r8,r8,-8
-	bne	cr6,L(done)
-
-	/* The c/null byte must be in the second doubleword.  Adjust the
-	   address again and move the result of cmpb to r10 so we can calculate
-	   the pointer.  */
-
-	mr	r10,r6
-	mr	r11,r7
-	addi	r8,r8,8
-
-	/* r10/r11 have the output of the cmpb instructions, that is,
-	   0xff in the same position as the c/null byte in the original
-	   doubleword from the string.  Use that to calculate the pointer.  */
-
-L(done):
-	/* if there are more than one 0xff in r11, find the first pos of ff
-	   in r11 and fill r10 with 0 from that position */
-	cmpdi	cr7,r11,0
-	beq	cr7,L(no_null)
-#ifdef __LITTLE_ENDIAN__
-	addi	r3,r11,-1
-	andc	r3,r3,r11
-	popcntd r0,r3
-#else
-	cntlzd	r0,r11
-#endif
-	subfic	r0,r0,63
-	li	r6,-1
-#ifdef __LITTLE_ENDIAN__
-	srd	r0,r6,r0
-#else
-	sld	r0,r6,r0
-#endif
-	and	r10,r0,r10
-L(no_null):
-#ifdef __LITTLE_ENDIAN__
-	cntlzd	r0,r10		/* Count leading zeros before c matches.  */
-	addi	r3,r10,-1
-	andc	r3,r3,r10
-	addi	r10,r11,-1
-	andc	r10,r10,r11
-	cmpld	cr7,r3,r10
-	bgt	cr7,L(no_match)
-#else
-	addi	r3,r10,-1	/* Count trailing zeros before c matches.  */
-	andc	r3,r3,r10
-	popcntd	r0,r3
-	cmpld	cr7,r11,r10
-	bgt	cr7,L(no_match)
-#endif
-	srdi	r0,r0,3		/* Convert trailing zeros to bytes.  */
-	subfic	r0,r0,7
-	add	r9,r8,r0      /* Return address of the matching c byte
-				 or null in case c was not found.  */
-	li	r0,0
-	cmpdi	cr7,r11,0     /* If r11 == 0, no null's have been found.  */
-	beq	cr7,L(align)
-
-	.align	4
-L(no_match):
-	mr	r3,r9
-	blr
-
-/* We are here because strrchr was called with a null byte.  */
-	.align	4
-L(null_match):
-	/* r0 has a doubleword of null bytes.  */
-
-	cmpb	r5,r12,r0     /* Compare each byte against null bytes.  */
-
-	/* Move the doublewords left and right to discard the bits that are
-	   not part of the string and bring them back as zeros.  */
-#ifdef __LITTLE_ENDIAN__
-	srd	r5,r5,r6
-	sld	r5,r5,r6
-#else
-	sld	r5,r5,r6
-	srd	r5,r5,r6
-#endif
-	cmpdi	cr7,r5,0      /* If r10 == 0, no c or null bytes
-				 have been found.  */
-	bne	cr7,L(done_null)
-
-	mtcrf	0x01,r8
-
-	/* Are we now aligned to a quadword boundary?  If so, skip to
-	   the main loop.  Otherwise, go through the alignment code.  */
-
-	bt	28,L(loop_null)
-
-	/* Handle WORD2 of pair.  */
-	ldu	r12,8(r8)
-	cmpb	r5,r12,r0
-	cmpdi	cr7,r5,0
-	bne	cr7,L(done_null)
-	b	L(loop_null)  /* We branch here (rather than falling through)
-				 to skip the nops due to heavy alignment
-				 of the loop below.  */
-
-	/* Main loop to look for the end of the string.  Since it's a
-	   small loop (< 8 instructions), align it to 32-bytes.  */
-	.p2align  5
-L(loop_null):
-	/* Load two doublewords, compare and merge in a
-	   single register for speed.  This is an attempt
-	   to speed up the null-checking process for bigger strings.  */
-	ld	r12,8(r8)
-	ldu	r11,16(r8)
-	cmpb	r5,r12,r0
-	cmpb	r10,r11,r0
-	or	r6,r5,r10
-	cmpdi	cr7,r6,0
-	beq	cr7,L(loop_null)
-
-	/* OK, one (or both) of the doublewords contains a null byte.  Check
-	   the first doubleword and decrement the address in case the first
-	   doubleword really contains a null byte.  */
-
-	cmpdi	cr6,r5,0
-	addi	r8,r8,-8
-	bne	cr6,L(done_null)
-
-	/* The null byte must be in the second doubleword.  Adjust the address
-	   again and move the result of cmpb to r10 so we can calculate the
-	   pointer.  */
-
-	mr	r5,r10
-	addi	r8,r8,8
-
-	/* r5 has the output of the cmpb instruction, that is, it contains
-	   0xff in the same position as the null byte in the original
-	   doubleword from the string.  Use that to calculate the pointer.  */
-L(done_null):
-#ifdef __LITTLE_ENDIAN__
-	addi	r0,r5,-1
-	andc	r0,r0,r5
-	popcntd	r0,r0
-#else
-	cntlzd	r0,r5	      /* Count leading zeros before the match.  */
-#endif
-	srdi	r0,r0,3	      /* Convert trailing zeros to bytes.  */
-	add	r3,r8,r0      /* Return address of the matching null byte.  */
-	blr
-END (STRRCHR)
-weak_alias (strrchr, rindex)
-libc_hidden_builtin_def (strrchr)
diff --git a/sysdeps/powerpc/powerpc64/power7/strstr-ppc64.c b/sysdeps/powerpc/powerpc64/power7/strstr-ppc64.c
deleted file mode 100644
index 7559733..0000000
--- a/sysdeps/powerpc/powerpc64/power7/strstr-ppc64.c
+++ /dev/null
@@ -1,27 +0,0 @@
-/* Optimized strstr implementation for PowerPC64/POWER7.
-   Copyright (C) 2015-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <string.h>
-
-#define STRSTR __strstr_ppc
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(__name)
-
-extern __typeof (strstr) __strstr_ppc attribute_hidden;
-
-#include <string/strstr.c>
diff --git a/sysdeps/powerpc/powerpc64/power7/strstr.S b/sysdeps/powerpc/powerpc64/power7/strstr.S
deleted file mode 100644
index ac92f9c..0000000
--- a/sysdeps/powerpc/powerpc64/power7/strstr.S
+++ /dev/null
@@ -1,535 +0,0 @@
-/* Optimized strstr implementation for PowerPC64/POWER7.
-   Copyright (C) 2015-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* Char * [r3] strstr (char *s [r3], char * pat[r4])  */
-
-/* The performance gain is obtained using aligned memory access, load
- * doubleword and usage of cmpb instruction for quicker comparison.  */
-
-#define ITERATIONS	64
-
-#ifndef STRSTR
-# define STRSTR strstr
-#endif
-
-#ifndef STRLEN
-/* For builds with no IFUNC support, local calls should be made to internal
-   GLIBC symbol (created by libc_hidden_builtin_def).  */
-# ifdef SHARED
-#  define STRLEN   __GI_strlen
-#  define STRLEN_is_local
-# else
-#  define STRLEN   strlen
-# endif
-#endif
-
-#ifndef STRNLEN
-/* For builds with no IFUNC support, local calls should be made to internal
-   GLIBC symbol (created by libc_hidden_builtin_def).  */
-# ifdef SHARED
-#  define STRNLEN   __GI_strnlen
-#  define STRNLEN_is_local
-# else
-#  define STRNLEN  __strnlen
-# endif
-#endif
-
-#ifndef STRCHR
-# ifdef SHARED
-#  define STRCHR   __GI_strchr
-#  define STRCHR_is_local
-# else
-#  define STRCHR   strchr
-# endif
-#endif
-
-#define	FRAMESIZE	(FRAME_MIN_SIZE+32)
-	.machine  power7
-/* Can't be ENTRY_TOCLESS due to calling __strstr_ppc which uses r2.  */
-ENTRY (STRSTR, 4)
-	CALL_MCOUNT 2
-	mflr	r0			/* Load link register LR to r0.  */
-	std	r31, -8(r1)		/* Save callers register r31.  */
-	std	r30, -16(r1)		/* Save callers register r30.  */
-	std	r29, -24(r1)		/* Save callers register r29.  */
-	std	r28, -32(r1)		/* Save callers register r28.  */
-	std	r0, 16(r1)		/* Store the link register.  */
-	cfi_offset(r31, -8)
-	cfi_offset(r30, -16)
-	cfi_offset(r28, -32)
-	cfi_offset(r29, -24)
-	cfi_offset(lr, 16)
-	stdu	r1, -FRAMESIZE(r1)	/* Create the stack frame.  */
-	cfi_adjust_cfa_offset(FRAMESIZE)
-
-	dcbt	0, r3
-	dcbt	0, r4
-	cmpdi	cr7, r3, 0
-	beq	cr7, L(retnull)
-	cmpdi	cr7, r4, 0
-	beq	cr7, L(retnull)
-
-	mr	r29, r3
-	mr	r30, r4
-	mr	r3, r4
-	bl	STRLEN
-#ifndef STRLEN_is_local
-	nop
-#endif
-
-	cmpdi	cr7, r3, 0	/* If search str is null.  */
-	beq	cr7, L(ret_r3)
-
-	mr	r31, r3
-	mr	r4, r3
-	mr	r3, r29
-	bl	STRNLEN
-#ifndef STRNLEN_is_local
-	nop
-#endif
-
-	cmpd	cr7, r3, r31 	/* If len(r3) < len(r4).  */
-	blt	cr7, L(retnull)
-	mr	r3, r29
-	lbz	r4, 0(r30)
-	bl	STRCHR
-#ifndef STRCHR_is_local
-	nop
-#endif
-
-	mr	r11, r3
-	/* If first char of search str is not present.  */
-	cmpdi	cr7, r3, 0
-	ble	cr7, L(end)
-	/* Reg r28 is used to count the number of iterations. */
-	li	r28, 0
-	rldicl	r8, r3, 0, 52	/* Page cross check.  */
-	cmpldi	cr7, r8, 4096-16
-	bgt	cr7, L(bytebybyte)
-
-	rldicl	r8, r30, 0, 52
-	cmpldi	cr7, r8, 4096-16
-	bgt	cr7, L(bytebybyte)
-
-	/* If len(r4) < 8 handle in a different way.  */
-	/* Shift position based on null and use cmpb.  */
-	cmpdi	cr7, r31, 8
-	blt	cr7, L(lessthan8)
-
-	/* Len(r4) >= 8 reaches here.  */
-	mr	r8, r3		/* Save r3 for future use.  */
-	mr	r4, r30		/* Restore r4.  */
-	li	r0, 0
-	rlwinm	r10, r30, 3, 26, 28	/* Calculate padding in bits.  */
-	clrrdi	r4, r4, 3	/* Make r4 aligned to 8.  */
-	ld	r6, 0(r4)
-	addi	r4, r4, 8
-	cmpdi	cr7, r10, 0	/* Check if its already aligned?  */
-	beq	cr7, L(begin1)
-#ifdef __LITTLE_ENDIAN__
-	srd	r6, r6, r10	/* Discard unwanted bits.  */
-#else
-	sld	r6, r6, r10
-#endif
-	ld	r9, 0(r4)
-	subfic	r10, r10, 64
-#ifdef __LITTLE_ENDIAN__
-	sld	r9, r9, r10	/* Discard unwanted bits.  */
-#else
-	srd	r9, r9, r10
-#endif
-	or	r6, r6, r9	/* Form complete search str.  */
-L(begin1):
-	mr	r29, r6
-	rlwinm	r10, r3, 3, 26, 28
-	clrrdi	r3, r3, 3
-	ld	r5, 0(r3)
-	cmpb	r9, r0, r6	/* Check if input has null.  */
-	cmpdi	cr7, r9, 0
-	bne	cr7, L(return3)
-	cmpb	r9, r0, r5	/* Check if input has null.  */
-#ifdef __LITTLE_ENDIAN__
-	srd	r9, r9, r10
-#else
-	sld	r9, r9, r10
-#endif
-	cmpdi	cr7, r9, 0
-	bne	cr7, L(retnull)
-
-	li	r12, -8		/* Shift values.  */
-	li	r11, 72		/* Shift values.  */
-	cmpdi	cr7, r10, 0
-	beq	cr7, L(nextbyte1)
-	mr	r12, r10
-	addi	r12, r12, -8
-	subfic	r11, r12, 64
-
-L(nextbyte1):
-	ldu	r7, 8(r3) 	/* Load next dw.  */
-	addi	r12, r12, 8	/* Shift one byte and compare.  */
-	addi	r11, r11, -8
-#ifdef __LITTLE_ENDIAN__
-	srd	r9, r5, r12	/* Rotate based on mask.  */
-	sld	r10, r7, r11
-#else
-	sld	r9, r5, r12
-	srd	r10, r7, r11
-#endif
-	/* Form single dw from few bytes on first load and second load.  */
-	or	r10, r9, r10
-	/* Check for null in the formed dw.  */
-	cmpb	r9, r0, r10
-	cmpdi	cr7, r9, 0
-	bne	cr7, L(retnull)
-	/* Cmpb search str and input str.  */
-	cmpb	r9, r10, r6
-	cmpdi	cr7, r9, -1
-	beq	cr7, L(match)
-	addi	r8, r8, 1
-	b	L(begin)
-
-	.align	4
-L(match):
-	/* There is a match of 8 bytes, check next bytes.  */
-	cmpdi	cr7, r31, 8
-	beq	cr7, L(return)
-	/* Update next starting point r8.  */
-	srdi	r9, r11, 3
-	subf	r9, r9, r3
-	mr	r8, r9
-
-L(secondmatch):
-	mr	r5, r7
-	rlwinm	r10, r30, 3, 26, 28	/* Calculate padding in bits.  */
-	ld	r6, 0(r4)
-	addi	r4, r4, 8
-	cmpdi	cr7, r10, 0	/* Check if its already aligned?  */
-	beq	cr7, L(proceed3)
-#ifdef __LITTLE_ENDIAN__
-	srd	r6, r6, r10	/* Discard unwanted bits.  */
-	cmpb	r9, r0, r6
-	sld	r9, r9, r10
-#else
-	sld	r6, r6, r10
-	cmpb	r9, r0, r6
-	srd	r9, r9, r10
-#endif
-	cmpdi	cr7, r9, 0
-	bne	cr7, L(proceed3)
-	ld	r9, 0(r4)
-	subfic	r10, r10, 64
-#ifdef __LITTLE_ENDIAN__
-	sld	r9, r9, r10	/* Discard unwanted bits.  */
-#else
-	srd	r9, r9, r10
-#endif
-	or	r6, r6, r9	/* Form complete search str.  */
-
-L(proceed3):
-	li	r7, 0
-	addi	r3, r3, 8
-	cmpb	r9, r0, r5
-	cmpdi	cr7, r9, 0
-	bne	cr7, L(proceed4)
-	ld	r7, 0(r3)
-L(proceed4):
-#ifdef __LITTLE_ENDIAN__
-	srd	r9, r5, r12
-	sld	r10, r7, r11
-#else
-	sld	r9, r5, r12
-	srd	r10, r7, r11
-#endif
-	/* Form single dw with few bytes from first and second load.  */
-	or	r10, r9, r10
-	cmpb	r9, r0, r6
-	cmpdi	cr7, r9, 0
-	bne	cr7, L(return4)
-	/* Check for null in the formed dw.  */
-	cmpb	r9, r0, r10
-	cmpdi	cr7, r9, 0
-	bne	cr7, L(retnull)
-	/* If the next 8 bytes dont match, start search again.  */
-	cmpb	r9, r10, r6
-	cmpdi	cr7, r9, -1
-	bne	cr7, L(reset)
-	/* If the next 8 bytes match, load and compare next 8.  */
-	b	L(secondmatch)
-
-	.align	4
-L(reset):
-	/* Start the search again.  */
-	addi	r8, r8, 1
-	b	L(begin)
-
-	.align	4
-L(return3):
-	/* Count leading zeros and compare partial dw.  */
-#ifdef __LITTLE_ENDIAN__
-	addi	r7, r9, -1
-	andc	r7, r7, r9
-	popcntd	r7, r7
-	subfic	r7, r7, 64
-	sld	r10, r5, r7
-	sld	r6, r6, r7
-#else
-	cntlzd	r7, r9
-	subfic	r7, r7, 64
-	srd	r10, r5, r7
-	srd	r6, r6, r7
-#endif
-	cmpb	r9, r10, r6
-	cmpdi	cr7, r9, -1
-	addi	r8, r8, 1
-	/* Start search again if there is no match.  */
-	bne	cr7, L(begin)
-	/* If the words match, update return values.  */
-	subfic	r7, r7, 64
-	srdi	r7, r7, 3
-	add	r3, r3, r7
-	subf	r3, r31, r3
-	b	L(end)
-
-	.align	4
-L(return4):
-	/* Count leading zeros and compare partial dw.  */
-#ifdef __LITTLE_ENDIAN__
-	addi	r7, r9, -1
-	andc	r7, r7, r9
-	popcntd	r7, r7
-	subfic	r7, r7, 64
-	sld	r10, r10, r7
-	sld	r6, r6, r7
-#else
-	cntlzd	r7, r9
-	subfic	r7, r7, 64
-	srd	r10, r10, r7
-	srd	r6, r6, r7
-#endif
-	cmpb	r9, r10, r6
-	cmpdi	cr7, r9, -1
-	addi	r8, r8, 1
-	bne	cr7, L(begin)
-	subfic	r7, r7, 64
-	srdi	r11, r11, 3
-	subf	r3, r11, r3
-	srdi	r7, r7, 3
-	add	r3, r3, r7
-	subf	r3, r31, r3
-	b	L(end)
-
-	.align	4
-L(begin):
-	mr	r3, r8
-	/* When our iterations exceed ITERATIONS,fall back to default. */
-	addi	r28, r28, 1
-	cmpdi	cr7, r28, ITERATIONS
-	beq	cr7, L(default)
-	lbz	r4, 0(r30)
-	bl	STRCHR
-#ifndef STRCHR_is_local
-	nop
-#endif
-	/* If first char of search str is not present.  */
-	cmpdi	cr7, r3, 0
-	ble	cr7, L(end)
-	mr	r8, r3
-	mr	r4, r30		/* Restore r4.  */
-	li	r0, 0
-	mr	r6, r29
-	clrrdi	r4, r4, 3
-	addi	r4, r4, 8
-	b	L(begin1)
-
-	/* Handle less than 8 search string.  */
-	.align	4
-L(lessthan8):
-	mr	r4, r3
-	mr	r9, r30
-	li	r0, 0
-
-	rlwinm	r10, r9, 3, 26, 28	/* Calculate padding in bits.  */
-	srdi	r8, r10, 3	/* Padding in bytes.  */
-	clrrdi	r9, r9, 3	/* Make r4 aligned to 8.  */
-	ld	r6, 0(r9)
-	cmpdi	cr7, r10, 0	/* Check if its already aligned?  */
-	beq	cr7, L(proceed2)
-#ifdef __LITTLE_ENDIAN__
-	srd	r6, r6, r10	/* Discard unwanted bits.  */
-#else
-	sld	r6, r6, r10
-#endif
-	subfic	r8, r8, 8
-	cmpd	cr7, r8, r31	/* Next load needed?  */
-	bge	cr7, L(proceed2)
-	ld	r7, 8(r9)
-	subfic	r10, r10, 64
-#ifdef __LITTLE_ENDIAN__
-	sld	r7, r7, r10	/* Discard unwanted bits.  */
-#else
-	srd	r7, r7, r10
-#endif
-	or	r6, r6, r7	/* Form complete search str.  */
-L(proceed2):
-	mr	r29, r6
-	rlwinm	r10, r3, 3, 26, 28
-	clrrdi	r7, r3, 3	/* Make r3 aligned.  */
-	ld	r5, 0(r7)
-	sldi	r8, r31, 3
-	subfic	r8, r8, 64
-#ifdef __LITTLE_ENDIAN__
-	sld	r6, r6, r8
-	cmpb	r9, r0, r5
-	srd	r9, r9, r10
-#else
-	srd	r6, r6, r8
-	cmpb	r9, r0, r5
-	sld	r9, r9, r10
-#endif
-	cmpdi	cr7, r9, 0
-	bne	cr7, L(noload)
-	cmpdi	cr7, r10, 0
-	beq	cr7, L(continue)
-	ld	r7, 8(r7)
-L(continue1):
-	mr	r12, r10
-	addi	r12, r12, -8
-	subfic	r11, r12, 64
-	b	L(nextbyte)
-
-	.align	4
-L(continue):
-	ld	r7, 8(r7)
-	li	r12, -8		/* Shift values.  */
-	li	r11, 72		/* Shift values.  */
-L(nextbyte):
-	addi	r12, r12, 8	/* Mask for rotation.  */
-	addi	r11, r11, -8
-#ifdef __LITTLE_ENDIAN__
-	srd	r9, r5, r12
-	sld	r10, r7, r11
-	or	r10, r9, r10
-	sld	r10, r10, r8
-	cmpb	r9, r0, r10
-	srd	r9, r9, r8
-#else
-	sld	r9, r5, r12
-	srd	r10, r7, r11
-	or	r10, r9, r10
-	srd	r10, r10, r8
-	cmpb	r9, r0, r10
-	sld	r9, r9, r8
-#endif
-	cmpdi	cr7, r9, 0
-	bne	cr7, L(retnull)
-	cmpb	r9, r10, r6
-	cmpdi	cr7, r9, -1
-	beq	cr7, L(end)
-	addi	r3, r4, 1
-	/* When our iterations exceed ITERATIONS,fall back to default. */
-	addi	r28, r28, 1
-	cmpdi	cr7, r28, ITERATIONS
-	beq	cr7, L(default)
-	lbz	r4, 0(r30)
-	bl	STRCHR
-#ifndef STRCHR_is_local
-	nop
-#endif
-	/* If first char of search str is not present.  */
-	cmpdi	cr7, r3, 0
-	ble	cr7, L(end)
-	mr	r4, r3
-	mr	r6, r29
-	li	r0, 0
-	b	L(proceed2)
-
-	.align	4
-L(noload):
-	/* Reached null in r3, so skip next load.  */
-	li 	r7, 0
-	b	L(continue1)
-
-	.align	4
-L(return):
-	/* Update return values.  */
-	srdi	r9, r11, 3
-	subf	r3, r9, r3
-	b	L(end)
-
-	/* Handling byte by byte.  */
-	.align	4
-L(bytebybyte):
-	mr	r8, r3
-	addi	r8, r8, -1
-L(loop1):
-	addi	r8, r8, 1
-	mr	r3, r8
-	mr	r4, r30
-	lbz	r6, 0(r4)
-	cmpdi	cr7, r6, 0
-	beq	cr7, L(updater3)
-L(loop):
-	lbz	r5, 0(r3)
-	cmpdi	cr7, r5, 0
-	beq	cr7, L(retnull)
-	cmpld	cr7, r6, r5
-	bne	cr7, L(loop1)
-	addi	r3, r3, 1
-	addi	r4, r4, 1
-	lbz	r6, 0(r4)
-	cmpdi	cr7, r6, 0
-	beq	cr7, L(updater3)
-	b	L(loop)
-
-	/* Handling return values.  */
-	.align	4
-L(updater3):
-	subf	r3, r31, r3	/* Reduce len of r4 from r3.  */
-	b	L(end)
-
-	.align	4
-L(ret_r3):
-	mr	r3, r29		/* Return r3.  */
-	b	L(end)
-
-	.align	4
-L(retnull):
-	li	r3, 0		/* Return NULL.  */
-	b	L(end)
-
-	.align	4
-L(default):
-	mr	r4, r30
-	bl	__strstr_ppc
-	nop
-
-	.align	4
-L(end):
-	addi	r1, r1, FRAMESIZE	/* Restore stack pointer.  */
-	cfi_adjust_cfa_offset(-FRAMESIZE)
-	ld	r0, 16(r1)	/* Restore the saved link register.  */
-	ld	r28, -32(r1)	/* Restore callers save register r28.  */
-	ld	r29, -24(r1)	/* Restore callers save register r29.  */
-	ld	r30, -16(r1)	/* Restore callers save register r30.  */
-	ld	r31, -8(r1)	/* Restore callers save register r31.  */
-	mtlr	r0		/* Branch to link register.  */
-	blr
-END (STRSTR)
-libc_hidden_builtin_def (strstr)
diff --git a/sysdeps/powerpc/powerpc64/power8/memchr.S b/sysdeps/powerpc/powerpc64/power8/memchr.S
deleted file mode 100644
index 45ba1b4..0000000
--- a/sysdeps/powerpc/powerpc64/power8/memchr.S
+++ /dev/null
@@ -1,335 +0,0 @@
-/* Optimized memchr implementation for POWER8.
-   Copyright (C) 2017-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* void *[r3] memchr (const void *s [r3], int c [r4], size_t n [r5])  */
-
-/* TODO: change these to the actual instructions when the minimum required
-   binutils allows it.  */
-#define MTVRD(v, r) .long (0x7c000167 | ((v)<<(32-11)) | ((r)<<(32-16)))
-#define MFVRD(r, v) .long (0x7c000067 | ((v)<<(32-11)) | ((r)<<(32-16)))
-#define VBPERMQ(t, a, b)  .long (0x1000054c \
-				| ((t)<<(32-11)) \
-				| ((a)<<(32-16)) \
-				| ((b)<<(32-21)) )
-
-#ifndef MEMCHR
-# define MEMCHR __memchr
-#endif
-/* TODO: change this to .machine power8 when the minimum required binutils
-   allows it.  */
-	.machine  power7
-ENTRY_TOCLESS (MEMCHR)
-	CALL_MCOUNT 3
-	dcbt	0, r3
-	clrrdi  r8, r3, 3
-	insrdi	r4, r4, 8, 48
-
-	/* Calculate the last acceptable address and check for possible
-	   addition overflow by using satured math:
-	   r7 = r3 + r5
-	   r7 |= -(r7 < x)  */
-	add     r7, r3, r5
-	subfc   r6, r3, r7
-	subfe   r9, r9, r9
-	extsw   r6, r9
-	or      r7, r7, r6
-
-	insrdi	r4, r4, 16, 32
-	cmpldi	r5, 32
-	li	r9, -1
-	rlwinm	r6, r3, 3, 26, 28 /* Calculate padding.  */
-	insrdi  r4, r4, 32, 0
-	mr	r10, r7
-	addi	r7, r7, -1
-#ifdef __LITTLE_ENDIAN__
-	sld	r9, r9, r6
-#else
-	srd	r9, r9, r6
-#endif
-	ble	L(small_range)
-	andi.	r11, r3, 63
-	beq	cr0, L(align_qw)
-	clrldi	r11, r3, 61
-	ld	r12, 0(r8)     /* Load doubleword from memory.  */
-	cmpb	r3, r12, r4     /* Check for BYTEs in DWORD1.  */
-	and	r3, r3, r9
-	clrldi	r6, r7, 61      /* Byte count - 1 in last dword.  */
-	clrrdi	r7, r7, 3       /* Address of last doubleword.  */
-	cmpldi	cr7, r3, 0      /* Does r3 indicate we got a hit?  */
-	bne	cr7, L(done)
-	addi	r8, r8, 8
-	addi	r5, r5, -8
-	add	r5, r5, r11
-
-	/* Are we now aligned to a quadword boundary?  */
-	andi.	r11, r8, 15
-	beq	cr0, L(align_qw)
-
-	/* Handle DWORD to make it QW aligned.  */
-	ld	r12, 0(r8)
-	cmpb	r3, r12, r4
-	cmpldi	cr7, r3, 0
-	bne	cr7, L(done)
-	addi	r5, r5, -8
-	addi	r8, r8, 8
-	/* At this point, r8 is 16B aligned.  */
-L(align_qw):
-	vspltisb	v0, 0
-	/* Precompute vbpermq constant.  */
-	vspltisb	v10, 3
-	li	r0, 0
-	lvsl	v11, r0, r0
-	vslb	v10, v11, v10
-	MTVRD(v1, r4)
-	vspltb	v1, v1, 7
-	cmpldi	r5, 64
-	ble	L(tail64)
-	/* Are we 64-byte aligned? If so, jump to the vectorized loop.
-	   Note: aligning to 64-byte will necessarily slow down performance for
-	   strings around 64 bytes in length due to the extra comparisons
-	   required to check alignment for the vectorized loop.  This is a
-	   necessary tradeoff we are willing to take in order to speed up the
-	   calculation for larger strings.  */
-	andi.	r11, r8, 63
-	beq	cr0, L(preloop_64B)
-	/* In order to begin the 64B loop, it needs to be 64
-	   bytes aligned.  So read until it is 64B aligned.  */
-	lvx	v4, 0, r8
-	vcmpequb	v6, v1, v4
-	vcmpequb.	v11, v0, v6
-	bnl	cr6, L(found_16B)
-	addi	r8, r8, 16
-	addi	r5, r5, -16
-
-	andi.	r11, r8, 63
-	beq	cr0, L(preloop_64B)
-	lvx	v4, 0, r8
-	vcmpequb	v6, v1, v4
-	vcmpequb.	v11, v0, v6
-	bnl	cr6, L(found_16B)
-	addi	r8, r8, 16
-	addi	r5, r5, -16
-
-	andi.	r11, r8, 63
-	beq	cr0, L(preloop_64B)
-	lvx	v4, 0, r8
-	vcmpequb	v6, v1, v4
-	vcmpequb.	v11, v0, v6
-	bnl	cr6, L(found_16B)
-	addi	r8, r8, 16
-	addi	r5, r5, -16
-	/* At this point it should be 64B aligned.
-	   Prepare for the 64B loop.  */
-L(preloop_64B):
-	cmpldi	r5, 64		/* Check if r5 < 64.  */
-	ble	L(tail64)
-	sub	r6, r10, r8
-	srdi	r9, r6, 6	/* Number of loop iterations.  */
-	mtctr	r9		/* Setup the counter.  */
-	li	r11, 16		/* Load required offsets.  */
-	li	r9, 32
-	li	r7, 48
-
-	/* Handle r5 > 64.  Loop over the bytes in strides of 64B.  */
-	.align 4
-L(loop):
-	lvx	v2, 0, r8	/* Load 4 quadwords.  */
-	lvx	v3, r8, r11
-	lvx	v4, v8, r9
-	lvx	v5, v8, r7
-	vcmpequb	v6, v1, v2
-	vcmpequb	v7, v1, v3
-	vcmpequb	v8, v1, v4
-	vcmpequb	v9, v1, v5
-	vor	v11, v6, v7
-	vor	v12, v8, v9
-	vor	v11, v11, v12	/* Compare and merge into one VR for speed.  */
-	vcmpequb.	v11, v0, v11
-	bnl	cr6, L(found)
-	addi	r8, r8, 64	/* Adjust address for the next iteration.  */
-	bdnz	L(loop)
-	clrldi	r5, r6, 58
-
-	/* Handle remainder of 64B loop or r5 > 64.  */
-	.align	4
-L(tail64):
-	cmpldi	r5, 0
-	beq	L(null)
-	lvx	v4, 0, r8
-	vcmpequb	v6, v1, v4
-	vcmpequb.	v11, v0, v6
-	bnl	cr6, L(found_16B)
-	addi	r8, r8, 16
-	cmpldi	cr6, r5, 16
-	ble	cr6, L(null)
-	addi	r5, r5, -16
-
-	lvx	v4, 0, r8
-	vcmpequb	v6, v1, v4
-	vcmpequb.	v11, v0, v6
-	bnl	cr6, L(found_16B)
-	addi	r8, r8, 16
-	cmpldi	cr6, r5, 16
-	ble	cr6, L(null)
-	addi	r5, r5, -16
-
-	lvx	v4, 0, r8
-	vcmpequb	v6, v1, v4
-	vcmpequb.	v11, v0, v6
-	bnl	cr6, L(found_16B)
-	addi	r8, r8, 16
-	cmpldi	cr6, r5, 16
-	ble	cr6, L(null)
-	addi	r5, r5, -16
-
-	lvx	v4, 0, r8
-	vcmpequb	v6, v1, v4
-	vcmpequb.	v11, v0, v6
-	bnl	cr6, L(found_16B)
-	li	r3, 0
-	blr
-
-	/* Found a match in 64B loop.  */
-	.align	4
-L(found):
-	/* Permute the first bit of each byte into bits 48-63.  */
-	VBPERMQ(v6, v6, v10)
-	VBPERMQ(v7, v7, v10)
-	VBPERMQ(v8, v8, v10)
-	VBPERMQ(v9, v9, v10)
-	/* Shift each component into its correct position for merging.  */
-#ifdef __LITTLE_ENDIAN__
-	vsldoi	v7, v7, v7, 2
-	vsldoi	v8, v8, v8, 4
-	vsldoi	v9, v9, v9, 6
-#else
-	vsldoi	v6, v6, v6, 6
-	vsldoi	v7, v7, v7, 4
-	vsldoi	v8, v8, v8, 2
-#endif
-	/* Merge the results and move to a GPR.  */
-	vor	v11, v6, v7
-	vor	v4, v9, v8
-	vor	v4, v11, v4
-	MFVRD(r5, v4)
-#ifdef __LITTLE_ENDIAN__
-	addi	r6, r5, -1
-	andc	r6, r6, r5
-	popcntd	r6, r6
-#else
-	cntlzd	r6, r5	/* Count leading zeros before the match.  */
-#endif
-	add	r3, r8, r6	/* Compute final length.  */
-	blr
-
-	/* Found a match in last 16 bytes.  */
-	.align	4
-L(found_16B):
-	/* Permute the first bit of each byte into bits 48-63.  */
-	VBPERMQ(v6, v6, v10)
-	/* Shift each component into its correct position for merging.  */
-#ifdef __LITTLE_ENDIAN__
-	MFVRD(r7, v6)
-	addi	r6, r7, -1
-	andc	r6, r6, r7
-	popcntd	r6, r6
-#else
-	vsldoi	v6, v6, v6, 6
-	MFVRD(r7, v6)
-	cntlzd	r6, r7	/* Count leading zeros before the match.  */
-#endif
-	add	r3, r8, r6	/* Compute final length.  */
-	cmpld	r6, r5
-	bltlr
-	li	r3, 0
-	blr
-
-	.align	4
-	/* r3 has the output of the cmpb instruction, that is, it contains
-	   0xff in the same position as BYTE in the original
-	   doubleword from the string.  Use that to calculate the pointer.
-	   We need to make sure BYTE is *before* the end of the range.  */
-L(done):
-#ifdef __LITTLE_ENDIAN__
-	addi	r0, r3, -1
-	andc	r0, r0, r3
-	popcntd	r0, r0	      /* Count trailing zeros.  */
-#else
-	cntlzd	r0, r3	      /* Count leading zeros before the match.  */
-#endif
-	cmpld	r8, r7         /* Are we on the last dword?  */
-	srdi	r0, r0, 3	/* Convert leading/trailing zeros to bytes.  */
-	add	r3, r8, r0
-	cmpld	cr7, r0, r6     /* If on the last dword, check byte offset.  */
-	bnelr
-	blelr	cr7
-	li	r3, 0
-	blr
-
-	.align	4
-L(null):
-	li	r3, 0
-	blr
-
-/* Deals with size <= 32.  */
-	.align	4
-L(small_range):
-	cmpldi	r5, 0
-	beq	L(null)
-	ld	r12, 0(r8)     /* Load word from memory.  */
-	cmpb	r3, r12, r4     /* Check for BYTE in DWORD1.  */
-	and	r3, r3, r9
-	cmpldi	cr7, r3, 0
-	clrldi	r6, r7, 61      /* Byte count - 1 in last dword.  */
-	clrrdi	r7, r7, 3       /* Address of last doubleword.  */
-	cmpld	r8, r7         /* Are we done already?  */
-	bne	cr7, L(done)
-	beqlr
-
-	ldu	r12, 8(r8)
-	cmpb	r3, r12, r4
-	cmpldi	cr6, r3, 0
-	cmpld	r8, r7
-	bne	cr6, L(done)   /* Found something.  */
-	beqlr		      /* Hit end of string (length).  */
-
-	ldu	r12, 8(r8)
-	cmpb	r3, r12, r4
-	cmpldi	cr6, r3, 0
-	cmpld	r8, r7
-	bne	cr6, L(done)
-	beqlr
-
-	ldu	r12, 8(r8)
-	cmpb	r3, r12, r4
-	cmpldi	cr6, r3, 0
-	cmpld	r8, r7
-	bne	cr6, L(done)
-	beqlr
-
-	ldu	r12, 8(r8)
-	cmpb	r3, r12, r4
-	cmpldi	cr6, r3, 0
-	bne	cr6, L(done)
-	blr
-
-END (MEMCHR)
-weak_alias (__memchr, memchr)
-libc_hidden_builtin_def (memchr)
diff --git a/sysdeps/powerpc/powerpc64/power8/memcmp.S b/sysdeps/powerpc/powerpc64/power8/memcmp.S
deleted file mode 100644
index ec4ccf3..0000000
--- a/sysdeps/powerpc/powerpc64/power8/memcmp.S
+++ /dev/null
@@ -1,1447 +0,0 @@
-/* Optimized memcmp implementation for POWER7/PowerPC64.
-   Copyright (C) 2010-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* int [r3] memcmp (const char *s1 [r3],
-		    const char *s2 [r4],
-		    size_t size [r5])  */
-
-/* TODO: change these to the actual instructions when the minimum required
-   binutils allows it.  */
-#define MFVRD(r,v)	.long (0x7c000067 | ((v)<<(32-11)) | ((r)<<(32-16)))
-#ifndef MEMCMP
-# define MEMCMP memcmp
-#endif
-	.machine power7
-ENTRY_TOCLESS (MEMCMP, 4)
-	CALL_MCOUNT 3
-
-#define rRTN		r3
-#define rSTR1		r3	/* First string arg.  */
-#define rSTR2		r4	/* Second string arg.  */
-#define rN		r5	/* Max string length.  */
-#define rWORD1		r6	/* Current word in s1.  */
-#define rWORD2		r7	/* Current word in s2.  */
-#define rWORD3		r8	/* Next word in s1.  */
-#define rWORD4		r9	/* Next word in s2.  */
-#define rWORD5		r10	/* Next word in s1.  */
-#define rWORD6		r11	/* Next word in s2.  */
-
-#define rOFF8		r20	/* 8 bytes offset.  */
-#define rOFF16  	r21	/* 16 bytes offset.  */
-#define rOFF24		r22	/* 24 bytes offset.  */
-#define rOFF32		r23	/* 24 bytes offset.  */
-#define rWORD6_SHIFT	r24	/* Left rotation temp for rWORD8.  */
-#define rWORD4_SHIFT	r25	/* Left rotation temp for rWORD6.  */
-#define rWORD2_SHIFT	r26	/* Left rotation temp for rWORD4.  */
-#define rWORD8_SHIFT	r27	/* Left rotation temp for rWORD2.  */
-#define rSHR		r28	/* Unaligned shift right count.  */
-#define rSHL		r29	/* Unaligned shift left count.  */
-#define rWORD7		r30	/* Next word in s1.  */
-#define rWORD8		r31	/* Next word in s2.  */
-
-#define rWORD8SAVE	(-8)
-#define rWORD7SAVE	(-16)
-#define rOFF8SAVE	(-24)
-#define rOFF16SAVE	(-32)
-#define rOFF24SAVE	(-40)
-#define rOFF32SAVE	(-48)
-#define rSHRSAVE	(-56)
-#define rSHLSAVE	(-64)
-#define rWORD8SHIFTSAVE	(-72)
-#define rWORD2SHIFTSAVE	(-80)
-#define rWORD4SHIFTSAVE	(-88)
-#define rWORD6SHIFTSAVE	(-96)
-
-#ifdef __LITTLE_ENDIAN__
-# define LD	ldbrx
-#else
-# define LD	ldx
-#endif
-
-	xor	r10, rSTR2, rSTR1
-	cmpldi	cr6, rN, 0
-	cmpldi	cr1, rN, 8
-	clrldi.	r0, r10, 61
-	clrldi	r12, rSTR1, 61
-	cmpldi	cr5, r12, 0
-	beq-	cr6, L(zeroLength)
-	dcbt	0, rSTR1
-	dcbt	0, rSTR2
-	/* If less than 8 bytes or not aligned, use the unaligned
-	   byte loop.  */
-	blt	cr1, L(bytealigned)
-	bne	L(unalignedqw)
-/* At this point we know both strings have the same alignment and the
-   compare length is at least 8 bytes.  r12 contains the low order
-   3 bits of rSTR1 and cr5 contains the result of the logical compare
-   of r12 to 0.  If r12 == 0 then we are already double word
-   aligned and can perform the DW aligned loop.  */
-
-	.align	4
-L(samealignment):
-	or	r11, rSTR2, rSTR1
-	clrldi.	r11, r11, 60
-	beq	L(qw_align)
-	/* Try to align to QW else proceed to DW loop.  */
-	clrldi.	r10, r10, 60
-	bne	L(DW)
-	/* For the difference to reach QW alignment, load as DW.  */
-	clrrdi	rSTR1, rSTR1, 3
-	clrrdi	rSTR2, rSTR2, 3
-	subfic	r10, r12, 8
-	LD	rWORD1, 0, rSTR1
-	LD	rWORD2, 0, rSTR2
-	sldi	r9, r10, 3
-	subfic	r9, r9, 64
-	sld	rWORD1, rWORD1, r9
-	sld	rWORD2, rWORD2, r9
-	cmpld	cr6, rWORD1, rWORD2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-	bne	cr6, L(ret_diff)
-	subf	rN, r10, rN
-
-	cmpld	cr6, r11, r12
-	bgt	cr6, L(qw_align)
-	LD	rWORD1, 0, rSTR1
-	LD	rWORD2, 0, rSTR2
-	cmpld	cr6, rWORD1, rWORD2
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-	bne	cr6, L(different)
-	cmpldi	cr6, rN, 8
-	ble	cr6, L(zeroLength)
-	addi	rN, rN, -8
-	/* Now both rSTR1 and rSTR2 are aligned to QW.  */
-	.align	4
-L(qw_align):
-	vspltisb	v0, 0
-	srdi.	r6, rN, 6
-	li	r8, 16
-	li	r10, 32
-	li	r11, 48
-	ble	cr0, L(lessthan64)
-	mtctr	r6
-	vspltisb	v8, 0
-	vspltisb	v6, 0
-	/* Aligned vector loop.  */
-	.align	4
-L(aligned_loop):
-	lvx	v4, 0, rSTR1
-	lvx	v5, 0, rSTR2
-	vcmpequb.	v7, v6, v8
-	bnl	cr6, L(different3)
-	lvx	v6, rSTR1, r8
-	lvx	v8, rSTR2, r8
-	vcmpequb.	v7, v5, v4
-	bnl	cr6, L(different2)
-	lvx	v4, rSTR1, r10
-	lvx	v5, rSTR2, r10
-	vcmpequb.	v7, v6, v8
-	bnl	cr6, L(different3)
-	lvx	v6, rSTR1, r11
-	lvx	v8, rSTR2, r11
-	vcmpequb.	v7, v5, v4
-	bnl	cr6, L(different2)
-	addi	rSTR1, rSTR1, 64
-	addi	rSTR2, rSTR2, 64
-	bdnz	L(aligned_loop)
-	vcmpequb.	v7, v6, v8
-	bnl	cr6, L(different3)
-	clrldi	rN, rN, 58
-	/* Handle remainder for aligned loop.  */
-	.align	4
-L(lessthan64):
-	mr	r9, rSTR1
-	cmpdi	cr6, rN, 0
-	li	rSTR1, 0
-	blelr	cr6
-	lvx	v4, 0, r9
-	lvx	v5, 0, rSTR2
-	vcmpequb.	v7, v5, v4
-	bnl	cr6, L(different1)
-	addi	rN, rN, -16
-
-	cmpdi	cr6, rN, 0
-	blelr	cr6
-	lvx	v4, r9, r8
-	lvx	v5, rSTR2, r8
-	vcmpequb.	v7, v5, v4
-	bnl	cr6, L(different1)
-	addi	rN, rN, -16
-
-	cmpdi	cr6, rN, 0
-	blelr	cr6
-	lvx	v4, r9, r10
-	lvx	v5, rSTR2, r10
-	vcmpequb.	v7, v5, v4
-	bnl	cr6, L(different1)
-	addi	rN, rN, -16
-
-	cmpdi	cr6, rN, 0
-	blelr	cr6
-	lvx	v4, r9, r11
-	lvx	v5, rSTR2, r11
-	vcmpequb.	v7, v5, v4
-	bnl	cr6, L(different1)
-	blr
-
-	/* Calculate and return the difference.  */
-	.align 4
-L(different1):
-	cmpdi	cr6, rN, 16
-	bge	cr6, L(different2)
-	/* Discard unwanted bytes.  */
-#ifdef __LITTLE_ENDIAN__
-	lvsr	v1, 0, rN
-	vperm	v4, v4, v0, v1
-	vperm	v5, v5, v0, v1
-#else
-	lvsl	v1, 0, rN
-	vperm	v4, v0, v4, v1
-	vperm	v5, v0, v5, v1
-#endif
-	vcmpequb.	v7, v4, v5
-	li	rRTN, 0
-	bltlr	cr6
-	.align 4
-L(different2):
-#ifdef __LITTLE_ENDIAN__
-	/* Reverse bytes for direct comparison.  */
-	lvsl	v10, r0, r0
-	vspltisb	v8, 15
-	vsububm	v9, v8, v10
-	vperm	v4, v4, v0, v9
-	vperm	v5, v5, v0, v9
-#endif
-	MFVRD(r7, v4)
-	MFVRD(r9, v5)
-	cmpld	cr6, r7, r9
-	bne	cr6, L(ret_diff)
-	/* Difference in second DW.  */
-	vsldoi	v4, v4, v4, 8
-	vsldoi	v5, v5, v5, 8
-	MFVRD(r7, v4)
-	MFVRD(r9, v5)
-	cmpld	cr6, r7, r9
-L(ret_diff):
-	li	rRTN, 1
-	bgtlr	cr6
-	li	rRTN, -1
-	blr
-	.align	4
-L(different3):
-#ifdef __LITTLE_ENDIAN__
-	/* Reverse bytes for direct comparison.  */
-	vspltisb	v9, 15
-	lvsl	v10, r0, r0
-	vsububm	v9, v9, v10
-	vperm	v6, v6, v0, v9
-	vperm	v8, v8, v0, v9
-#endif
-	MFVRD(r7, v6)
-	MFVRD(r9, v8)
-	cmpld	cr6, r7, r9
-	bne	cr6, L(ret_diff)
-	/* Difference in second DW.  */
-	vsldoi	v6, v6, v6, 8
-	vsldoi	v8, v8, v8, 8
-	MFVRD(r7, v6)
-	MFVRD(r9, v8)
-	cmpld	cr6, r7, r9
-	li	rRTN, 1
-	bgtlr	cr6
-	li	rRTN, -1
-	blr
-
-	.align 4
-L(different):
-	cmpldi	cr7, rN, 8
-	bgt	cr7, L(end)
-	/* Skip unwanted bytes.  */
-	sldi	r8, rN, 3
-	subfic	r8, r8, 64
-	srd	rWORD1, rWORD1, r8
-	srd	rWORD2, rWORD2, r8
-	cmpld	cr6, rWORD1, rWORD2
-	li	rRTN, 0
-	beqlr	cr6
-L(end):
-	li	rRTN, 1
-	bgtlr	cr6
-	li	rRTN, -1
-	blr
-
-	.align	4
-L(unalignedqw):
-	/* Proceed to DW unaligned loop,if there is a chance of pagecross.  */
-	rldicl	r9, rSTR1, 0, 52
-	add	r9, r9, rN
-	cmpldi	cr0, r9, 4096-16
-	bgt	cr0, L(unaligned)
-	rldicl	r9, rSTR2, 0, 52
-	add	r9, r9, rN
-	cmpldi	cr0, r9, 4096-16
-	bgt	cr0, L(unaligned)
-	li	r0, 0
-	li	r8, 16
-	vspltisb	v0, 0
-	/* Check if rSTR1 is aligned to QW.  */
-	andi.	r11, rSTR1, 0xF
-	beq	L(s1_align)
-
-	/* Compare 16B and align S1 to QW.  */
-#ifdef __LITTLE_ENDIAN__
-	lvsr	v10, 0, rSTR1	/* Compute mask.  */
-	lvsr	v6, 0, rSTR2	/* Compute mask.  */
-#else
-	lvsl	v10, 0, rSTR1	/* Compute mask.  */
-	lvsl	v6, 0, rSTR2	/* Compute mask.  */
-#endif
-	lvx	v5, 0, rSTR2
-	lvx	v9, rSTR2, r8
-#ifdef __LITTLE_ENDIAN__
-	vperm	v5, v9, v5, v6
-#else
-	vperm	v5, v5, v9, v6
-#endif
-	lvx	v4, 0, rSTR1
-	lvx	v9, rSTR1, r8
-#ifdef __LITTLE_ENDIAN__
-	vperm	v4, v9, v4, v10
-#else
-	vperm	v4, v4, v9, v10
-#endif
-	vcmpequb.	v7, v5, v4
-	bnl	cr6, L(different1)
-	cmpldi	cr6, rN, 16
-	ble	cr6, L(zeroLength)
-	subfic	r11, r11, 16
-	subf	rN, r11, rN
-	add	rSTR1, rSTR1, r11
-	add	rSTR2, rSTR2, r11
-
-	/* As s1 is QW aligned prepare for unaligned loop.  */
-	.align	4
-L(s1_align):
-#ifdef __LITTLE_ENDIAN__
-	lvsr	v6, 0, rSTR2
-#else
-	lvsl	v6, 0, rSTR2
-#endif
-	lvx	v5, 0, rSTR2
-	srdi.	r6, rN, 6
-	li	r10, 32
-	li	r11, 48
-	ble	cr0, L(lessthan64_unalign)
-	mtctr	r6
-	li 	r9, 64
-	/* Unaligned vector loop.  */
-	.align	4
-L(unalign_qwloop):
-	lvx	v4, 0, rSTR1
-	lvx	v10, rSTR2, r8
-#ifdef __LITTLE_ENDIAN__
-	vperm	v5, v10, v5, v6
-#else
-	vperm	v5, v5, v10, v6
-#endif
-	vcmpequb.	v7, v5, v4
-	bnl	cr6, L(different2)
-	vor	v5, v10, v10
-	lvx	v4, rSTR1, r8
-	lvx	v10, rSTR2, r10
-#ifdef __LITTLE_ENDIAN__
-	vperm	v5, v10, v5, v6
-#else
-	vperm	v5, v5, v10, v6
-#endif
-	vcmpequb.	v7, v5, v4
-	bnl	cr6, L(different2)
-	vor	v5, v10, v10
-	lvx	v4, rSTR1, r10
-	lvx	v10, rSTR2, r11
-#ifdef __LITTLE_ENDIAN__
-	vperm	v5, v10, v5, v6
-#else
-	vperm	v5, v5, v10, v6
-#endif
-	vcmpequb.	v7, v5, v4
-	bnl	cr6, L(different2)
-	vor	v5, v10, v10
-	lvx	v4, rSTR1, r11
-	lvx	v10, rSTR2, r9
-#ifdef __LITTLE_ENDIAN__
-	vperm	v5, v10, v5, v6
-#else
-	vperm	v5, v5, v10, v6
-#endif
-	vcmpequb.	v7, v5, v4
-	bnl	cr6, L(different2)
-	vor	v5, v10, v10
-	addi	rSTR1, rSTR1, 64
-	addi	rSTR2, rSTR2, 64
-	bdnz	L(unalign_qwloop)
-	clrldi	rN, rN, 58
-	/* Handle remainder for unaligned loop.  */
-	.align	4
-L(lessthan64_unalign):
-	mr	r9, rSTR1
-	cmpdi	cr6, rN, 0
-	li	rSTR1, 0
-	blelr	cr6
-	lvx	v4, 0, r9
-	lvx     v10, rSTR2, r8
-#ifdef __LITTLE_ENDIAN__
-	vperm	v5, v10, v5, v6
-#else
-	vperm	v5, v5, v10, v6
-#endif
-	vcmpequb.	v7, v5, v4
-	bnl	cr6, L(different1)
-	vor	v5, v10, v10
-	addi	rN, rN, -16
-
-	cmpdi	cr6, rN, 0
-	blelr	cr6
-	lvx	v4, r9, r8
-	lvx	v10, rSTR2, r10
-#ifdef __LITTLE_ENDIAN__
-	vperm	v5, v10, v5, v6
-#else
-	vperm	v5, v5, v10, v6
-#endif
-	vcmpequb.	v7, v5, v4
-	bnl	cr6, L(different1)
-	vor	v5, v10, v10
-	addi	rN, rN, -16
-
-	cmpdi	cr6, rN, 0
-	blelr	cr6
-	lvx	v4, r9, r10
-	lvx	v10, rSTR2, r11
-#ifdef __LITTLE_ENDIAN__
-	vperm	v5, v10, v5, v6
-#else
-	vperm	v5, v5, v10, v6
-#endif
-	vcmpequb.	v7, v5, v4
-	bnl	cr6, L(different1)
-	vor	v5, v10, v10
-	addi	rN, rN, -16
-
-	cmpdi	cr6, rN, 0
-	blelr	cr6
-	lvx	v4, r9, r11
-	addi	r11, r11, 16
-	lvx	v10, rSTR2, r11
-#ifdef __LITTLE_ENDIAN__
-	vperm	v5, v10, v5, v6
-#else
-	vperm	v5, v5, v10, v6
-#endif
-	vcmpequb.	v7, v5, v4
-	bnl	cr6, L(different1)
-	blr
-
-/* Otherwise we know the two strings have the same alignment (but not
-   yet DW).  So we force the string addresses to the next lower DW
-   boundary and special case this first DW using shift left to
-   eliminate bits preceding the first byte.  Since we want to join the
-   normal (DW aligned) compare loop, starting at the second double word,
-   we need to adjust the length (rN) and special case the loop
-   versioning for the first DW.  This ensures that the loop count is
-   correct and the first DW (shifted) is in the expected register pair.  */
-	.align	4
-L(DW):
-	std	rWORD8, rWORD8SAVE(r1)
-	std	rWORD7, rWORD7SAVE(r1)
-	std	rOFF8, rOFF8SAVE(r1)
-	std	rOFF16, rOFF16SAVE(r1)
-	std	rOFF24, rOFF24SAVE(r1)
-	std	rOFF32, rOFF32SAVE(r1)
-	cfi_offset(rWORD8, rWORD8SAVE)
-	cfi_offset(rWORD7, rWORD7SAVE)
-	cfi_offset(rOFF8, rOFF8SAVE)
-	cfi_offset(rOFF16, rOFF16SAVE)
-	cfi_offset(rOFF24, rOFF24SAVE)
-	cfi_offset(rOFF32, rOFF32SAVE)
-
-	li	rOFF8,8
-	li	rOFF16,16
-	li	rOFF24,24
-	li	rOFF32,32
-	clrrdi	rSTR1, rSTR1, 3
-	clrrdi	rSTR2, rSTR2, 3
-	beq	cr5, L(DWaligned)
-	add	rN, rN, r12
-	sldi	rWORD6, r12, 3
-	srdi	r0, rN, 5	/* Divide by 32.  */
-	andi.	r12, rN, 24	/* Get the DW remainder.  */
-	LD	rWORD1, 0, rSTR1
-	LD	rWORD2, 0, rSTR2
-	cmpldi	cr1, r12, 16
-	cmpldi	cr7, rN, 32
-	clrldi	rN, rN, 61
-	beq	L(dPs4)
-	mtctr	r0
-	bgt	cr1, L(dPs3)
-	beq	cr1, L(dPs2)
-
-/* Remainder is 8.  */
-	.align	3
-L(dsP1):
-	sld	rWORD5, rWORD1, rWORD6
-	sld	rWORD6, rWORD2, rWORD6
-	cmpld	cr5, rWORD5, rWORD6
-	blt	cr7, L(dP1x)
-/* Do something useful in this cycle since we have to branch anyway.  */
-	LD	rWORD1, rOFF8, rSTR1
-	LD	rWORD2, rOFF8, rSTR2
-	cmpld	cr7, rWORD1, rWORD2
-	b	L(dP1e)
-/* Remainder is 16.  */
-	.align	4
-L(dPs2):
-	sld	rWORD5, rWORD1, rWORD6
-	sld	rWORD6, rWORD2, rWORD6
-	cmpld	cr6, rWORD5, rWORD6
-	blt	cr7, L(dP2x)
-/* Do something useful in this cycle since we have to branch anyway.  */
-	LD	rWORD7, rOFF8, rSTR1
-	LD	rWORD8, rOFF8, rSTR2
-	cmpld	cr5, rWORD7, rWORD8
-	b	L(dP2e)
-/* Remainder is 24.  */
-	.align	4
-L(dPs3):
-	sld	rWORD3, rWORD1, rWORD6
-	sld	rWORD4, rWORD2, rWORD6
-	cmpld	cr1, rWORD3, rWORD4
-	b	L(dP3e)
-/* Count is a multiple of 32, remainder is 0.  */
-	.align	4
-L(dPs4):
-	mtctr	r0
-	sld	rWORD1, rWORD1, rWORD6
-	sld	rWORD2, rWORD2, rWORD6
-	cmpld	cr7, rWORD1, rWORD2
-	b	L(dP4e)
-
-/* At this point we know both strings are double word aligned and the
-   compare length is at least 8 bytes.  */
-	.align	4
-L(DWaligned):
-	andi.	r12, rN, 24	/* Get the DW remainder.  */
-	srdi	r0, rN, 5	/* Divide by 32.  */
-	cmpldi	cr1, r12, 16
-	cmpldi	cr7, rN, 32
-	clrldi	rN, rN, 61
-	beq	L(dP4)
-	bgt	cr1, L(dP3)
-	beq	cr1, L(dP2)
-
-/* Remainder is 8.  */
-	.align	4
-L(dP1):
-	mtctr	r0
-/* Normally we'd use rWORD7/rWORD8 here, but since we might exit early
-   (8-15 byte compare), we want to use only volatile registers.  This
-   means we can avoid restoring non-volatile registers since we did not
-   change any on the early exit path.  The key here is the non-early
-   exit path only cares about the condition code (cr5), not about which
-   register pair was used.  */
-	LD	rWORD5, 0, rSTR1
-	LD	rWORD6, 0, rSTR2
-	cmpld	cr5, rWORD5, rWORD6
-	blt	cr7, L(dP1x)
-	LD	rWORD1, rOFF8, rSTR1
-	LD	rWORD2, rOFF8, rSTR2
-	cmpld	cr7, rWORD1, rWORD2
-L(dP1e):
-	LD	rWORD3, rOFF16, rSTR1
-	LD	rWORD4, rOFF16, rSTR2
-	cmpld	cr1, rWORD3, rWORD4
-	LD	rWORD5, rOFF24, rSTR1
-	LD	rWORD6, rOFF24, rSTR2
-	cmpld	cr6, rWORD5, rWORD6
-	bne	cr5, L(dLcr5x)
-	bne	cr7, L(dLcr7x)
-
-	LD	rWORD7, rOFF32, rSTR1
-	LD	rWORD8, rOFF32, rSTR2
-	addi	rSTR1, rSTR1, 32
-	addi	rSTR2, rSTR2, 32
-	bne	cr1, L(dLcr1)
-	cmpld	cr5, rWORD7, rWORD8
-	bdnz	L(dLoop)
-	bne	cr6, L(dLcr6)
-	ld	rWORD8, rWORD8SAVE(r1)
-	ld	rWORD7, rWORD7SAVE(r1)
-	.align	3
-L(dP1x):
-	sldi.	r12, rN, 3
-	bne	cr5, L(dLcr5x)
-	subfic	rN, r12, 64	/* Shift count is 64 - (rN * 8).  */
-	bne	L(d00)
-	ld	rOFF8,  rOFF8SAVE(r1)
-	ld	rOFF16, rOFF16SAVE(r1)
-	ld	rOFF24, rOFF24SAVE(r1)
-	ld	rOFF32, rOFF32SAVE(r1)
-	li	rRTN, 0
-	blr
-
-/* Remainder is 16.  */
-	.align	4
-L(dP2):
-	mtctr	r0
-	LD	rWORD5, 0, rSTR1
-	LD	rWORD6, 0, rSTR2
-	cmpld	cr6, rWORD5, rWORD6
-	blt	cr7, L(dP2x)
-	LD	rWORD7, rOFF8, rSTR1
-	LD	rWORD8, rOFF8, rSTR2
-	cmpld	cr5, rWORD7, rWORD8
-L(dP2e):
-	LD	rWORD1, rOFF16, rSTR1
-	LD	rWORD2, rOFF16, rSTR2
-	cmpld	cr7, rWORD1, rWORD2
-	LD	rWORD3, rOFF24, rSTR1
-	LD	rWORD4, rOFF24, rSTR2
-	cmpld	cr1, rWORD3, rWORD4
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-	bne	cr6, L(dLcr6)
-	bne	cr5, L(dLcr5)
-	b	L(dLoop2)
-	.align	4
-L(dP2x):
-	LD	rWORD3, rOFF8, rSTR1
-	LD	rWORD4, rOFF8, rSTR2
-	cmpld	cr1, rWORD3, rWORD4
-	sldi.	r12, rN, 3
-	bne	cr6, L(dLcr6x)
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-	bne	cr1, L(dLcr1x)
-	subfic	rN, r12, 64	/* Shift count is 64 - (rN * 8).  */
-	bne	L(d00)
-	ld	rOFF8,  rOFF8SAVE(r1)
-	ld	rOFF16, rOFF16SAVE(r1)
-	ld	rOFF24, rOFF24SAVE(r1)
-	ld	rOFF32, rOFF32SAVE(r1)
-	li	rRTN, 0
-	blr
-
-/* Remainder is 24.  */
-	.align	4
-L(dP3):
-	mtctr	r0
-	LD	rWORD3, 0, rSTR1
-	LD	rWORD4, 0, rSTR2
-	cmpld	cr1, rWORD3, rWORD4
-L(dP3e):
-	LD	rWORD5, rOFF8, rSTR1
-	LD	rWORD6, rOFF8, rSTR2
-	cmpld	cr6, rWORD5, rWORD6
-	blt	cr7, L(dP3x)
-	LD	rWORD7, rOFF16, rSTR1
-	LD	rWORD8, rOFF16, rSTR2
-	cmpld	cr5, rWORD7, rWORD8
-	LD	rWORD1, rOFF24, rSTR1
-	LD	rWORD2, rOFF24, rSTR2
-	cmpld	cr7, rWORD1, rWORD2
-	addi	rSTR1, rSTR1, 16
-	addi	rSTR2, rSTR2, 16
-	bne	cr1, L(dLcr1)
-	bne	cr6, L(dLcr6)
-	b	L(dLoop1)
-/* Again we are on a early exit path (24-31 byte compare), we want to
-   only use volatile registers and avoid restoring non-volatile
-   registers.  */
-	.align	4
-L(dP3x):
-	LD	rWORD1, rOFF16, rSTR1
-	LD	rWORD2, rOFF16, rSTR2
-	cmpld	cr7, rWORD1, rWORD2
-	sldi.	r12, rN, 3
-	bne	cr1, L(dLcr1x)
-	addi	rSTR1, rSTR1, 16
-	addi	rSTR2, rSTR2, 16
-	bne	cr6, L(dLcr6x)
-	subfic	rN, r12, 64	/* Shift count is 64 - (rN * 8).  */
-	bne	cr7, L(dLcr7x)
-	bne	L(d00)
-	ld	rOFF8,  rOFF8SAVE(r1)
-	ld	rOFF16, rOFF16SAVE(r1)
-	ld	rOFF24, rOFF24SAVE(r1)
-	ld	rOFF32, rOFF32SAVE(r1)
-	li	rRTN, 0
-	blr
-
-/* Count is a multiple of 32, remainder is 0.  */
-	.align	4
-L(dP4):
-	mtctr	r0
-	LD	rWORD1, 0, rSTR1
-	LD	rWORD2, 0, rSTR2
-	cmpld	cr7, rWORD1, rWORD2
-L(dP4e):
-	LD	rWORD3, rOFF8, rSTR1
-	LD	rWORD4, rOFF8, rSTR2
-	cmpld	cr1, rWORD3, rWORD4
-	LD	rWORD5, rOFF16, rSTR1
-	LD	rWORD6, rOFF16, rSTR2
-	cmpld	cr6, rWORD5, rWORD6
-	LD	rWORD7, rOFF24, rSTR1
-	LD	rWORD8, rOFF24, rSTR2
-	addi	rSTR1, rSTR1, 24
-	addi	rSTR2, rSTR2, 24
-	cmpld	cr5, rWORD7, rWORD8
-	bne	cr7, L(dLcr7)
-	bne	cr1, L(dLcr1)
-	bdz-	L(d24)		/* Adjust CTR as we start with +4.  */
-/* This is the primary loop.  */
-	.align	4
-L(dLoop):
-	LD	rWORD1, rOFF8, rSTR1
-	LD	rWORD2, rOFF8, rSTR2
-	cmpld	cr1, rWORD3, rWORD4
-	bne	cr6, L(dLcr6)
-L(dLoop1):
-	LD	rWORD3, rOFF16, rSTR1
-	LD	rWORD4, rOFF16, rSTR2
-	cmpld	cr6, rWORD5, rWORD6
-	bne	cr5, L(dLcr5)
-L(dLoop2):
-	LD	rWORD5, rOFF24, rSTR1
-	LD	rWORD6, rOFF24, rSTR2
-	cmpld	cr5, rWORD7, rWORD8
-	bne	cr7, L(dLcr7)
-L(dLoop3):
-	LD	rWORD7, rOFF32, rSTR1
-	LD	rWORD8, rOFF32, rSTR2
-	addi	rSTR1, rSTR1, 32
-	addi	rSTR2, rSTR2, 32
-	bne	cr1, L(dLcr1)
-	cmpld	cr7, rWORD1, rWORD2
-	bdnz	L(dLoop)
-
-L(dL4):
-	cmpld	cr1, rWORD3, rWORD4
-	bne	cr6, L(dLcr6)
-	cmpld	cr6, rWORD5, rWORD6
-	bne	cr5, L(dLcr5)
-	cmpld	cr5, rWORD7, rWORD8
-L(d44):
-	bne	cr7, L(dLcr7)
-L(d34):
-	bne	cr1, L(dLcr1)
-L(d24):
-	bne	cr6, L(dLcr6)
-L(d14):
-	sldi.	r12, rN, 3
-	bne	cr5, L(dLcr5)
-L(d04):
-	ld	rWORD8, rWORD8SAVE(r1)
-	ld	rWORD7, rWORD7SAVE(r1)
-	subfic	rN, r12, 64	/* Shift count is 64 - (rN * 8).  */
-	beq	L(duzeroLength)
-/* At this point we have a remainder of 1 to 7 bytes to compare.  Since
-   we are aligned it is safe to load the whole double word, and use
-   shift right double to eliminate bits beyond the compare length.  */
-L(d00):
-	LD	rWORD1, rOFF8, rSTR1
-	LD	rWORD2, rOFF8, rSTR2
-	srd	rWORD1, rWORD1, rN
-	srd	rWORD2, rWORD2, rN
-	cmpld	cr7, rWORD1, rWORD2
-	bne	cr7, L(dLcr7x)
-	ld	rOFF8,  rOFF8SAVE(r1)
-	ld	rOFF16, rOFF16SAVE(r1)
-	ld	rOFF24, rOFF24SAVE(r1)
-	ld	rOFF32, rOFF32SAVE(r1)
-	li	rRTN, 0
-	blr
-
-	.align	4
-L(dLcr7):
-	ld	rWORD8, rWORD8SAVE(r1)
-	ld	rWORD7, rWORD7SAVE(r1)
-L(dLcr7x):
-	ld	rOFF8,  rOFF8SAVE(r1)
-	ld	rOFF16, rOFF16SAVE(r1)
-	ld	rOFF24, rOFF24SAVE(r1)
-	ld	rOFF32, rOFF32SAVE(r1)
-	li	rRTN, 1
-	bgtlr	cr7
-	li	rRTN, -1
-	blr
-	.align	4
-L(dLcr1):
-	ld	rWORD8, rWORD8SAVE(r1)
-	ld	rWORD7, rWORD7SAVE(r1)
-L(dLcr1x):
-	ld	rOFF8,  rOFF8SAVE(r1)
-	ld	rOFF16, rOFF16SAVE(r1)
-	ld	rOFF24, rOFF24SAVE(r1)
-	ld	rOFF32, rOFF32SAVE(r1)
-	li	rRTN, 1
-	bgtlr	cr1
-	li	rRTN, -1
-	blr
-	.align	4
-L(dLcr6):
-	ld	rWORD8, rWORD8SAVE(r1)
-	ld	rWORD7, rWORD7SAVE(r1)
-L(dLcr6x):
-	ld	rOFF8,  rOFF8SAVE(r1)
-	ld	rOFF16, rOFF16SAVE(r1)
-	ld	rOFF24, rOFF24SAVE(r1)
-	ld	rOFF32, rOFF32SAVE(r1)
-	li	rRTN, 1
-	bgtlr	cr6
-	li	rRTN, -1
-	blr
-	.align	4
-L(dLcr5):
-	ld	rWORD8, rWORD8SAVE(r1)
-	ld	rWORD7, rWORD7SAVE(r1)
-L(dLcr5x):
-	ld	rOFF8,  rOFF8SAVE(r1)
-	ld	rOFF16, rOFF16SAVE(r1)
-	ld	rOFF24, rOFF24SAVE(r1)
-	ld	rOFF32, rOFF32SAVE(r1)
-	li	rRTN, 1
-	bgtlr	cr5
-	li	rRTN, -1
-	blr
-
-	.align	4
-L(bytealigned):
-	mtctr	rN
-
-/* We need to prime this loop.  This loop is swing modulo scheduled
-   to avoid pipe delays.  The dependent instruction latencies (load to
-   compare to conditional branch) is 2 to 3 cycles.  In this loop each
-   dispatch group ends in a branch and takes 1 cycle.  Effectively
-   the first iteration of the loop only serves to load operands and
-   branches based on compares are delayed until the next loop.
-
-   So we must precondition some registers and condition codes so that
-   we don't exit the loop early on the first iteration.  */
-
-	lbz	rWORD1, 0(rSTR1)
-	lbz	rWORD2, 0(rSTR2)
-	bdz	L(b11)
-	cmpld	cr7, rWORD1, rWORD2
-	lbz	rWORD3, 1(rSTR1)
-	lbz	rWORD4, 1(rSTR2)
-	bdz	L(b12)
-	cmpld	cr1, rWORD3, rWORD4
-	lbzu	rWORD5, 2(rSTR1)
-	lbzu	rWORD6, 2(rSTR2)
-	bdz	L(b13)
-	.align	4
-L(bLoop):
-	lbzu	rWORD1, 1(rSTR1)
-	lbzu	rWORD2, 1(rSTR2)
-	bne	cr7, L(bLcr7)
-
-	cmpld	cr6, rWORD5, rWORD6
-	bdz	L(b3i)
-
-	lbzu	rWORD3, 1(rSTR1)
-	lbzu	rWORD4, 1(rSTR2)
-	bne	cr1, L(bLcr1)
-
-	cmpld	cr7, rWORD1, rWORD2
-	bdz	L(b2i)
-
-	lbzu	rWORD5, 1(rSTR1)
-	lbzu	rWORD6, 1(rSTR2)
-	bne	cr6, L(bLcr6)
-
-	cmpld	cr1, rWORD3, rWORD4
-	bdnz	L(bLoop)
-
-/* We speculatively loading bytes before we have tested the previous
-   bytes.  But we must avoid overrunning the length (in the ctr) to
-   prevent these speculative loads from causing a segfault.  In this
-   case the loop will exit early (before the all pending bytes are
-   tested.  In this case we must complete the pending operations
-   before returning.  */
-L(b1i):
-	bne	cr7, L(bLcr7)
-	bne	cr1, L(bLcr1)
-	b	L(bx56)
-	.align	4
-L(b2i):
-	bne	cr6, L(bLcr6)
-	bne	cr7, L(bLcr7)
-	b	L(bx34)
-	.align	4
-L(b3i):
-	bne	cr1, L(bLcr1)
-	bne	cr6, L(bLcr6)
-	b	L(bx12)
-	.align	4
-L(bLcr7):
-	li	rRTN, 1
-	bgtlr	cr7
-	li	rRTN, -1
-	blr
-L(bLcr1):
-	li	rRTN, 1
-	bgtlr	cr1
-	li	rRTN, -1
-	blr
-L(bLcr6):
-	li	rRTN, 1
-	bgtlr	cr6
-	li	rRTN, -1
-	blr
-
-L(b13):
-	bne	cr7, L(bx12)
-	bne	cr1, L(bx34)
-L(bx56):
-	sub	rRTN, rWORD5, rWORD6
-	blr
-	nop
-L(b12):
-	bne	cr7, L(bx12)
-L(bx34):
-	sub	rRTN, rWORD3, rWORD4
-	blr
-L(b11):
-L(bx12):
-	sub	rRTN, rWORD1, rWORD2
-	blr
-
-	.align	4
-L(zeroLength):
-	li	rRTN, 0
-	blr
-
-	.align	4
-/* At this point we know the strings have different alignment and the
-   compare length is at least 8 bytes.  r12 contains the low order
-   3 bits of rSTR1 and cr5 contains the result of the logical compare
-   of r12 to 0.  If r12 == 0 then rStr1 is double word
-   aligned and can perform the DWunaligned loop.
-
-   Otherwise we know that rSTR1 is not already DW aligned yet.
-   So we can force the string addresses to the next lower DW
-   boundary and special case this first DW using shift left to
-   eliminate bits preceding the first byte.  Since we want to join the
-   normal (DWaligned) compare loop, starting at the second double word,
-   we need to adjust the length (rN) and special case the loop
-   versioning for the first DW.  This ensures that the loop count is
-   correct and the first DW (shifted) is in the expected resister pair.  */
-L(unaligned):
-	std	rWORD8, rWORD8SAVE(r1)
-	std	rWORD7, rWORD7SAVE(r1)
-	std	rOFF8, rOFF8SAVE(r1)
-	std	rOFF16, rOFF16SAVE(r1)
-	std	rOFF24, rOFF24SAVE(r1)
-	std	rOFF32, rOFF32SAVE(r1)
-	cfi_offset(rWORD8, rWORD8SAVE)
-	cfi_offset(rWORD7, rWORD7SAVE)
-	cfi_offset(rOFF8, rOFF8SAVE)
-	cfi_offset(rOFF16, rOFF16SAVE)
-	cfi_offset(rOFF24, rOFF24SAVE)
-	cfi_offset(rOFF32, rOFF32SAVE)
-	li	rOFF8,8
-	li	rOFF16,16
-	li	rOFF24,24
-	li	rOFF32,32
-	std	rSHL, rSHLSAVE(r1)
-	cfi_offset(rSHL, rSHLSAVE)
-	clrldi	rSHL, rSTR2, 61
-	beq	cr6, L(duzeroLength)
-	std	rSHR, rSHRSAVE(r1)
-	cfi_offset(rSHR, rSHRSAVE)
-	beq	cr5, L(DWunaligned)
-	std	rWORD8_SHIFT, rWORD8SHIFTSAVE(r1)
-	cfi_offset(rWORD8_SHIFT, rWORD8SHIFTSAVE)
-/* Adjust the logical start of rSTR2 to compensate for the extra bits
-   in the 1st rSTR1 DW.  */
-	sub	rWORD8_SHIFT, rSTR2, r12
-/* But do not attempt to address the DW before that DW that contains
-   the actual start of rSTR2.  */
-	clrrdi	rSTR2, rSTR2, 3
-	std	rWORD2_SHIFT, rWORD2SHIFTSAVE(r1)
-/* Compute the left/right shift counts for the unaligned rSTR2,
-   compensating for the logical (DW aligned) start of rSTR1.  */
-	clrldi	rSHL, rWORD8_SHIFT, 61
-	clrrdi	rSTR1, rSTR1, 3
-	std	rWORD4_SHIFT, rWORD4SHIFTSAVE(r1)
-	sldi	rSHL, rSHL, 3
-	cmpld	cr5, rWORD8_SHIFT, rSTR2
-	add	rN, rN, r12
-	sldi	rWORD6, r12, 3
-	std	rWORD6_SHIFT, rWORD6SHIFTSAVE(r1)
-	cfi_offset(rWORD2_SHIFT, rWORD2SHIFTSAVE)
-	cfi_offset(rWORD4_SHIFT, rWORD4SHIFTSAVE)
-	cfi_offset(rWORD6_SHIFT, rWORD6SHIFTSAVE)
-	subfic	rSHR, rSHL, 64
-	srdi	r0, rN, 5	/* Divide by 32.  */
-	andi.	r12, rN, 24	/* Get the DW remainder.  */
-/* We normally need to load 2 DWs to start the unaligned rSTR2, but in
-   this special case those bits may be discarded anyway.  Also we
-   must avoid loading a DW where none of the bits are part of rSTR2 as
-   this may cross a page boundary and cause a page fault.  */
-	li	rWORD8, 0
-	blt	cr5, L(dus0)
-	LD	rWORD8, 0, rSTR2
-	addi	rSTR2, rSTR2, 8
-	sld	rWORD8, rWORD8, rSHL
-
-L(dus0):
-	LD	rWORD1, 0, rSTR1
-	LD	rWORD2, 0, rSTR2
-	cmpldi	cr1, r12, 16
-	cmpldi	cr7, rN, 32
-	srd	r12, rWORD2, rSHR
-	clrldi	rN, rN, 61
-	beq	L(duPs4)
-	mtctr	r0
-	or	rWORD8, r12, rWORD8
-	bgt	cr1, L(duPs3)
-	beq	cr1, L(duPs2)
-
-/* Remainder is 8.  */
-	.align	4
-L(dusP1):
-	sld	rWORD8_SHIFT, rWORD2, rSHL
-	sld	rWORD7, rWORD1, rWORD6
-	sld	rWORD8, rWORD8, rWORD6
-	bge	cr7, L(duP1e)
-/* At this point we exit early with the first double word compare
-   complete and remainder of 0 to 7 bytes.  See L(du14) for details on
-   how we handle the remaining bytes.  */
-	cmpld	cr5, rWORD7, rWORD8
-	sldi.	rN, rN, 3
-	bne	cr5, L(duLcr5)
-	cmpld	cr7, rN, rSHR
-	beq	L(duZeroReturn)
-	li	r0, 0
-	ble	cr7, L(dutrim)
-	LD	rWORD2, rOFF8, rSTR2
-	srd	r0, rWORD2, rSHR
-	b	L(dutrim)
-/* Remainder is 16.  */
-	.align	4
-L(duPs2):
-	sld	rWORD6_SHIFT, rWORD2, rSHL
-	sld	rWORD5, rWORD1, rWORD6
-	sld	rWORD6, rWORD8, rWORD6
-	b	L(duP2e)
-/* Remainder is 24.  */
-	.align	4
-L(duPs3):
-	sld	rWORD4_SHIFT, rWORD2, rSHL
-	sld	rWORD3, rWORD1, rWORD6
-	sld	rWORD4, rWORD8, rWORD6
-	b	L(duP3e)
-/* Count is a multiple of 32, remainder is 0.  */
-	.align	4
-L(duPs4):
-	mtctr	r0
-	or	rWORD8, r12, rWORD8
-	sld	rWORD2_SHIFT, rWORD2, rSHL
-	sld	rWORD1, rWORD1, rWORD6
-	sld	rWORD2, rWORD8, rWORD6
-	b	L(duP4e)
-
-/* At this point we know rSTR1 is double word aligned and the
-   compare length is at least 8 bytes.  */
-	.align	4
-L(DWunaligned):
-	std	rWORD8_SHIFT, rWORD8SHIFTSAVE(r1)
-	clrrdi	rSTR2, rSTR2, 3
-	std	rWORD2_SHIFT, rWORD2SHIFTSAVE(r1)
-	srdi	r0, rN, 5	/* Divide by 32.  */
-	std	rWORD4_SHIFT, rWORD4SHIFTSAVE(r1)
-	andi.	r12, rN, 24	/* Get the DW remainder.  */
-	std	rWORD6_SHIFT, rWORD6SHIFTSAVE(r1)
-	cfi_offset(rWORD8_SHIFT, rWORD8SHIFTSAVE)
-	cfi_offset(rWORD2_SHIFT, rWORD2SHIFTSAVE)
-	cfi_offset(rWORD4_SHIFT, rWORD4SHIFTSAVE)
-	cfi_offset(rWORD6_SHIFT, rWORD6SHIFTSAVE)
-	sldi	rSHL, rSHL, 3
-	LD	rWORD6, 0, rSTR2
-	LD	rWORD8, rOFF8, rSTR2
-	addi	rSTR2, rSTR2, 8
-	cmpldi	cr1, r12, 16
-	cmpldi	cr7, rN, 32
-	clrldi	rN, rN, 61
-	subfic	rSHR, rSHL, 64
-	sld	rWORD6_SHIFT, rWORD6, rSHL
-	beq	L(duP4)
-	mtctr	r0
-	bgt	cr1, L(duP3)
-	beq	cr1, L(duP2)
-
-/* Remainder is 8.  */
-	.align	4
-L(duP1):
-	srd	r12, rWORD8, rSHR
-	LD	rWORD7, 0, rSTR1
-	sld	rWORD8_SHIFT, rWORD8, rSHL
-	or	rWORD8, r12, rWORD6_SHIFT
-	blt	cr7, L(duP1x)
-L(duP1e):
-	LD	rWORD1, rOFF8, rSTR1
-	LD	rWORD2, rOFF8, rSTR2
-	cmpld	cr5, rWORD7, rWORD8
-	srd	r0, rWORD2, rSHR
-	sld	rWORD2_SHIFT, rWORD2, rSHL
-	or	rWORD2, r0, rWORD8_SHIFT
-	LD	rWORD3, rOFF16, rSTR1
-	LD	rWORD4, rOFF16, rSTR2
-	cmpld	cr7, rWORD1, rWORD2
-	srd	r12, rWORD4, rSHR
-	sld	rWORD4_SHIFT, rWORD4, rSHL
-	bne	cr5, L(duLcr5)
-	or	rWORD4, r12, rWORD2_SHIFT
-	LD	rWORD5, rOFF24, rSTR1
-	LD	rWORD6, rOFF24, rSTR2
-	cmpld	cr1, rWORD3, rWORD4
-	srd	r0, rWORD6, rSHR
-	sld	rWORD6_SHIFT, rWORD6, rSHL
-	bne	cr7, L(duLcr7)
-	or	rWORD6, r0, rWORD4_SHIFT
-	cmpld	cr6, rWORD5, rWORD6
-	b	L(duLoop3)
-	.align	4
-/* At this point we exit early with the first double word compare
-   complete and remainder of 0 to 7 bytes.  See L(du14) for details on
-   how we handle the remaining bytes.  */
-L(duP1x):
-	cmpld	cr5, rWORD7, rWORD8
-	sldi.	rN, rN, 3
-	bne	cr5, L(duLcr5)
-	cmpld	cr7, rN, rSHR
-	beq	L(duZeroReturn)
-	li	r0, 0
-	ble	cr7, L(dutrim)
-	LD	rWORD2, rOFF8, rSTR2
-	srd	r0, rWORD2, rSHR
-	b	L(dutrim)
-/* Remainder is 16.  */
-	.align	4
-L(duP2):
-	srd	r0, rWORD8, rSHR
-	LD	rWORD5, 0, rSTR1
-	or	rWORD6, r0, rWORD6_SHIFT
-	sld	rWORD6_SHIFT, rWORD8, rSHL
-L(duP2e):
-	LD	rWORD7, rOFF8, rSTR1
-	LD	rWORD8, rOFF8, rSTR2
-	cmpld	cr6, rWORD5, rWORD6
-	srd	r12, rWORD8, rSHR
-	sld	rWORD8_SHIFT, rWORD8, rSHL
-	or	rWORD8, r12, rWORD6_SHIFT
-	blt	cr7, L(duP2x)
-	LD	rWORD1, rOFF16, rSTR1
-	LD	rWORD2, rOFF16, rSTR2
-	cmpld	cr5, rWORD7, rWORD8
-	bne	cr6, L(duLcr6)
-	srd	r0, rWORD2, rSHR
-	sld	rWORD2_SHIFT, rWORD2, rSHL
-	or	rWORD2, r0, rWORD8_SHIFT
-	LD	rWORD3, rOFF24, rSTR1
-	LD	rWORD4, rOFF24, rSTR2
-	cmpld	cr7, rWORD1, rWORD2
-	bne	cr5, L(duLcr5)
-	srd	r12, rWORD4, rSHR
-	sld	rWORD4_SHIFT, rWORD4, rSHL
-	or	rWORD4, r12, rWORD2_SHIFT
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-	cmpld	cr1, rWORD3, rWORD4
-	b	L(duLoop2)
-	.align	4
-L(duP2x):
-	cmpld	cr5, rWORD7, rWORD8
-	addi	rSTR1, rSTR1, 8
-	addi	rSTR2, rSTR2, 8
-	bne	cr6, L(duLcr6)
-	sldi.	rN, rN, 3
-	bne	cr5, L(duLcr5)
-	cmpld	cr7, rN, rSHR
-	beq	L(duZeroReturn)
-	li	r0, 0
-	ble	cr7, L(dutrim)
-	LD	rWORD2, rOFF8, rSTR2
-	srd	r0, rWORD2, rSHR
-	b	L(dutrim)
-
-/* Remainder is 24.  */
-	.align	4
-L(duP3):
-	srd	r12, rWORD8, rSHR
-	LD	rWORD3, 0, rSTR1
-	sld	rWORD4_SHIFT, rWORD8, rSHL
-	or	rWORD4, r12, rWORD6_SHIFT
-L(duP3e):
-	LD	rWORD5, rOFF8, rSTR1
-	LD	rWORD6, rOFF8, rSTR2
-	cmpld	cr1, rWORD3, rWORD4
-	srd	r0, rWORD6, rSHR
-	sld	rWORD6_SHIFT, rWORD6, rSHL
-	or	rWORD6, r0, rWORD4_SHIFT
-	LD	rWORD7, rOFF16, rSTR1
-	LD	rWORD8, rOFF16, rSTR2
-	cmpld	cr6, rWORD5, rWORD6
-	bne	cr1, L(duLcr1)
-	srd	r12, rWORD8, rSHR
-	sld	rWORD8_SHIFT, rWORD8, rSHL
-	or	rWORD8, r12, rWORD6_SHIFT
-	blt	cr7, L(duP3x)
-	LD	rWORD1, rOFF24, rSTR1
-	LD	rWORD2, rOFF24, rSTR2
-	cmpld	cr5, rWORD7, rWORD8
-	bne	cr6, L(duLcr6)
-	srd	r0, rWORD2, rSHR
-	sld	rWORD2_SHIFT, rWORD2, rSHL
-	or	rWORD2, r0, rWORD8_SHIFT
-	addi	rSTR1, rSTR1, 16
-	addi	rSTR2, rSTR2, 16
-	cmpld	cr7, rWORD1, rWORD2
-	b	L(duLoop1)
-	.align	4
-L(duP3x):
-	addi	rSTR1, rSTR1, 16
-	addi	rSTR2, rSTR2, 16
-	cmpld	cr5, rWORD7, rWORD8
-	bne	cr6, L(duLcr6)
-	sldi.	rN, rN, 3
-	bne	cr5, L(duLcr5)
-	cmpld	cr7, rN, rSHR
-	beq	L(duZeroReturn)
-	li	r0, 0
-	ble	cr7, L(dutrim)
-	LD	rWORD2, rOFF8, rSTR2
-	srd	r0, rWORD2, rSHR
-	b	L(dutrim)
-
-/* Count is a multiple of 32, remainder is 0.  */
-	.align	4
-L(duP4):
-	mtctr	r0
-	srd	r0, rWORD8, rSHR
-	LD	rWORD1, 0, rSTR1
-	sld	rWORD2_SHIFT, rWORD8, rSHL
-	or	rWORD2, r0, rWORD6_SHIFT
-L(duP4e):
-	LD	rWORD3, rOFF8, rSTR1
-	LD	rWORD4, rOFF8, rSTR2
-	cmpld	cr7, rWORD1, rWORD2
-	srd	r12, rWORD4, rSHR
-	sld	rWORD4_SHIFT, rWORD4, rSHL
-	or	rWORD4, r12, rWORD2_SHIFT
-	LD	rWORD5, rOFF16, rSTR1
-	LD	rWORD6, rOFF16, rSTR2
-	cmpld	cr1, rWORD3, rWORD4
-	bne	cr7, L(duLcr7)
-	srd	r0, rWORD6, rSHR
-	sld	rWORD6_SHIFT, rWORD6, rSHL
-	or	rWORD6, r0, rWORD4_SHIFT
-	LD	rWORD7, rOFF24, rSTR1
-	LD	rWORD8, rOFF24, rSTR2
-	addi	rSTR1, rSTR1, 24
-	addi	rSTR2, rSTR2, 24
-	cmpld	cr6, rWORD5, rWORD6
-	bne	cr1, L(duLcr1)
-	srd	r12, rWORD8, rSHR
-	sld	rWORD8_SHIFT, rWORD8, rSHL
-	or	rWORD8, r12, rWORD6_SHIFT
-	cmpld	cr5, rWORD7, rWORD8
-	bdz	L(du24)		/* Adjust CTR as we start with +4.  */
-/* This is the primary loop.  */
-	.align	4
-L(duLoop):
-	LD	rWORD1, rOFF8, rSTR1
-	LD	rWORD2, rOFF8, rSTR2
-	cmpld	cr1, rWORD3, rWORD4
-	bne	cr6, L(duLcr6)
-	srd	r0, rWORD2, rSHR
-	sld	rWORD2_SHIFT, rWORD2, rSHL
-	or	rWORD2, r0, rWORD8_SHIFT
-L(duLoop1):
-	LD	rWORD3, rOFF16, rSTR1
-	LD	rWORD4, rOFF16, rSTR2
-	cmpld	cr6, rWORD5, rWORD6
-	bne	cr5, L(duLcr5)
-	srd	r12, rWORD4, rSHR
-	sld	rWORD4_SHIFT, rWORD4, rSHL
-	or	rWORD4, r12, rWORD2_SHIFT
-L(duLoop2):
-	LD	rWORD5, rOFF24, rSTR1
-	LD	rWORD6, rOFF24, rSTR2
-	cmpld	cr5, rWORD7, rWORD8
-	bne	cr7, L(duLcr7)
-	srd	r0, rWORD6, rSHR
-	sld	rWORD6_SHIFT, rWORD6, rSHL
-	or	rWORD6, r0, rWORD4_SHIFT
-L(duLoop3):
-	LD	rWORD7, rOFF32, rSTR1
-	LD	rWORD8, rOFF32, rSTR2
-	addi	rSTR1, rSTR1, 32
-	addi	rSTR2, rSTR2, 32
-	cmpld	cr7, rWORD1, rWORD2
-	bne	cr1, L(duLcr1)
-	srd	r12, rWORD8, rSHR
-	sld	rWORD8_SHIFT, rWORD8, rSHL
-	or	rWORD8, r12, rWORD6_SHIFT
-	bdnz	L(duLoop)
-
-L(duL4):
-	cmpld	cr1, rWORD3, rWORD4
-	bne	cr6, L(duLcr6)
-	cmpld	cr6, rWORD5, rWORD6
-	bne	cr5, L(duLcr5)
-	cmpld	cr5, rWORD7, rWORD8
-L(du44):
-	bne	cr7, L(duLcr7)
-L(du34):
-	bne	cr1, L(duLcr1)
-L(du24):
-	bne	cr6, L(duLcr6)
-L(du14):
-	sldi.	rN, rN, 3
-	bne	cr5, L(duLcr5)
-/* At this point we have a remainder of 1 to 7 bytes to compare.  We use
-   shift right double to eliminate bits beyond the compare length.
-
-   However it may not be safe to load rWORD2 which may be beyond the
-   string length.  So we compare the bit length of the remainder to
-   the right shift count (rSHR).  If the bit count is less than or equal
-   we do not need to load rWORD2 (all significant bits are already in
-   rWORD8_SHIFT).  */
-	cmpld	cr7, rN, rSHR
-	beq	L(duZeroReturn)
-	li	r0, 0
-	ble	cr7, L(dutrim)
-	LD	rWORD2, rOFF8, rSTR2
-	srd	r0, rWORD2, rSHR
-	.align	4
-L(dutrim):
-	LD	rWORD1, rOFF8, rSTR1
-	ld	rWORD8, -8(r1)
-	subfic	rN, rN, 64	/* Shift count is 64 - (rN * 8).  */
-	or	rWORD2, r0, rWORD8_SHIFT
-	ld	rWORD7, rWORD7SAVE(r1)
-	ld	rSHL, rSHLSAVE(r1)
-	srd	rWORD1, rWORD1, rN
-	srd	rWORD2, rWORD2, rN
-	ld	rSHR, rSHRSAVE(r1)
-	ld	rWORD8_SHIFT, rWORD8SHIFTSAVE(r1)
-	li	rRTN, 0
-	cmpld	cr7, rWORD1, rWORD2
-	ld	rWORD2_SHIFT, rWORD2SHIFTSAVE(r1)
-	ld	rWORD4_SHIFT, rWORD4SHIFTSAVE(r1)
-	beq	cr7, L(dureturn24)
-	li	rRTN, 1
-	ld	rWORD6_SHIFT, rWORD6SHIFTSAVE(r1)
-	ld	rOFF8,  rOFF8SAVE(r1)
-	ld	rOFF16, rOFF16SAVE(r1)
-	ld	rOFF24, rOFF24SAVE(r1)
-	ld	rOFF32, rOFF32SAVE(r1)
-	bgtlr	cr7
-	li	rRTN, -1
-	blr
-	.align	4
-L(duLcr7):
-	ld	rWORD8, rWORD8SAVE(r1)
-	ld	rWORD7, rWORD7SAVE(r1)
-	li	rRTN, 1
-	bgt	cr7, L(dureturn29)
-	ld	rSHL, rSHLSAVE(r1)
-	ld	rSHR, rSHRSAVE(r1)
-	li	rRTN, -1
-	b	L(dureturn27)
-	.align	4
-L(duLcr1):
-	ld	rWORD8, rWORD8SAVE(r1)
-	ld	rWORD7, rWORD7SAVE(r1)
-	li	rRTN, 1
-	bgt	cr1, L(dureturn29)
-	ld	rSHL, rSHLSAVE(r1)
-	ld	rSHR, rSHRSAVE(r1)
-	li	rRTN, -1
-	b	L(dureturn27)
-	.align	4
-L(duLcr6):
-	ld	rWORD8, rWORD8SAVE(r1)
-	ld	rWORD7, rWORD7SAVE(r1)
-	li	rRTN, 1
-	bgt	cr6, L(dureturn29)
-	ld	rSHL, rSHLSAVE(r1)
-	ld	rSHR, rSHRSAVE(r1)
-	li	rRTN, -1
-	b	L(dureturn27)
-	.align	4
-L(duLcr5):
-	ld	rWORD8, rWORD8SAVE(r1)
-	ld	rWORD7, rWORD7SAVE(r1)
-	li	rRTN, 1
-	bgt	cr5, L(dureturn29)
-	ld	rSHL, rSHLSAVE(r1)
-	ld	rSHR, rSHRSAVE(r1)
-	li	rRTN, -1
-	b	L(dureturn27)
-
-	.align	3
-L(duZeroReturn):
-	li	rRTN, 0
-	.align	4
-L(dureturn):
-	ld	rWORD8, rWORD8SAVE(r1)
-	ld	rWORD7, rWORD7SAVE(r1)
-L(dureturn29):
-	ld	rSHL, rSHLSAVE(r1)
-	ld	rSHR, rSHRSAVE(r1)
-L(dureturn27):
-	ld	rWORD8_SHIFT, rWORD8SHIFTSAVE(r1)
-	ld	rWORD2_SHIFT, rWORD2SHIFTSAVE(r1)
-	ld	rWORD4_SHIFT, rWORD4SHIFTSAVE(r1)
-L(dureturn24):
-	ld	rWORD6_SHIFT, rWORD6SHIFTSAVE(r1)
-	ld	rOFF8,  rOFF8SAVE(r1)
-	ld	rOFF16, rOFF16SAVE(r1)
-	ld	rOFF24, rOFF24SAVE(r1)
-	ld	rOFF32, rOFF32SAVE(r1)
-	blr
-
-L(duzeroLength):
-	ld	rOFF8,  rOFF8SAVE(r1)
-	ld	rOFF16, rOFF16SAVE(r1)
-	ld	rOFF24, rOFF24SAVE(r1)
-	ld	rOFF32, rOFF32SAVE(r1)
-	li	rRTN, 0
-	blr
-
-END (MEMCMP)
-libc_hidden_builtin_def (memcmp)
-weak_alias (memcmp, bcmp)
diff --git a/sysdeps/powerpc/powerpc64/power8/memrchr.S b/sysdeps/powerpc/powerpc64/power8/memrchr.S
deleted file mode 100644
index 54de656..0000000
--- a/sysdeps/powerpc/powerpc64/power8/memrchr.S
+++ /dev/null
@@ -1,345 +0,0 @@
-/* Optimized memrchr implementation for PowerPC64/POWER8.
-   Copyright (C) 2017-2018 Free Software Foundation, Inc.
-   Contributed by Luis Machado <luisgpm@br.ibm.com>.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* int [r3] memrchr (char *s [r3], int byte [r4], int size [r5])  */
-
-/* TODO: change these to the actual instructions when the minimum required
-   binutils allows it.  */
-#define MTVRD(v, r) .long (0x7c000167 | ((v)<<(32-11)) | ((r)<<(32-16)))
-#define MFVRD(r, v) .long (0x7c000067 | ((v)<<(32-11)) | ((r)<<(32-16)))
-#define VBPERMQ(t, a, b)  .long (0x1000054c \
-				| ((t)<<(32-11)) \
-				| ((a)<<(32-16)) \
-				| ((b)<<(32-21)) )
-#ifndef MEMRCHR
-# define MEMRCHR __memrchr
-#endif
-	.machine  power7
-ENTRY_TOCLESS (MEMRCHR)
-	CALL_MCOUNT 3
-	add	r7, r3, r5      /* Calculate the last acceptable address.  */
-	neg	r0, r7
-	addi	r7, r7, -1
-	mr	r10, r3
-	clrrdi	r6, r7, 7
-	li	r9, 3<<5
-	dcbt	r9, r6, 8       /* Stream hint, decreasing addresses.  */
-
-	/* Replicate BYTE to doubleword.  */
-	insrdi	r4, r4, 8, 48
-	insrdi	r4, r4, 16, 32
-	insrdi	r4, r4, 32, 0
-	li	r6, -8
-	li	r9, -1
-	rlwinm	r0, r0, 3, 26, 28 /* Calculate padding.  */
-	clrrdi	r8, r7, 3
-	srd	r9, r9, r0
-	cmpldi	r5, 32
-	clrrdi	r0, r10, 3
-	ble	L(small_range)
-
-#ifdef __LITTLE_ENDIAN__
-	ldx	r12, 0, r8
-#else
-	ldbrx	r12, 0, r8      /* Load reversed doubleword from memory.  */
-#endif
-	cmpb	r3, r12, r4     /* Check for BYTE in DWORD1.  */
-	and	r3, r3, r9
-	cmpldi	cr7, r3, 0      /* If r3 == 0, no BYTEs have been found.  */
-	bne	cr7, L(done)
-
-	/* Are we now aligned to a quadword boundary?  If so, skip to
-	   the main loop.  Otherwise, go through the alignment code.  */
-	andi.	r12, r8, 15
-	beq	cr0, L(align_qw)
-
-	/* Handle DWORD2 of pair.  */
-#ifdef __LITTLE_ENDIAN__
-	ldx	r12, r8, r6
-#else
-	ldbrx	r12, r8, r6
-#endif
-	addi	r8, r8, -8
-	cmpb	r3, r12, r4
-	cmpldi	cr7, r3, 0
-	bne	cr7, L(done)
-
-	.align	4
-	/* At this point, r8 is 16B aligned.  */
-L(align_qw):
-	sub	r5, r8, r0
-	vspltisb	v0, 0
-	/* Precompute vbpermq constant.  */
-	vspltisb	v10, 3
-	li	r0, 0
-	lvsl	v11, r0, r0
-	vslb	v10, v11, v10
-	MTVRD(v1, r4)
-	vspltb	v1, v1, 7
-	cmpldi	r5, 64
-	ble	L(tail64)
-	/* Are we 64-byte aligned? If so, jump to the vectorized loop.
-	   Note: aligning to 64-byte will necessarily slow down performance for
-	   strings around 64 bytes in length due to the extra comparisons
-	   required to check alignment for the vectorized loop.  This is a
-	   necessary tradeoff we are willing to take in order to speed up the
-	   calculation for larger strings.  */
-	andi.	r11, r8, 63
-	beq	cr0, L(preloop_64B)
-	/* In order to begin the 64B loop, it needs to be 64
-	   bytes aligned.  So read until it is 64B aligned.  */
-	addi	r8, r8, -16
-	lvx	v4, 0, r8
-	vcmpequb	v6, v1, v4
-	vcmpequb.	v11, v0, v6
-	bnl	cr6, L(found_16B)
-	addi	r5, r5, -16
-
-	andi.	r11, r8, 63
-	beq	cr0, L(preloop_64B)
-	addi	r8, r8, -16
-	lvx	v4, 0, r8
-	vcmpequb	v6, v1, v4
-	vcmpequb.	v11, v0, v6
-	bnl	cr6, L(found_16B)
-	addi	r5, r5, -16
-
-	andi.	r11, r8, 63
-	beq	cr0, L(preloop_64B)
-	addi	r8, r8, -16
-	lvx	v4, 0, r8
-	vcmpequb	v6, v1, v4
-	vcmpequb.	v11, v0, v6
-	bnl	cr6, L(found_16B)
-	addi	r5, r5, -16
-	/* At this point it should be 64B aligned.
-	   Prepare for the 64B loop.  */
-L(preloop_64B):
-	cmpldi	r5, 64		/* Check if r5 < 64.  */
-	ble	L(tail64)
-	srdi	r9, r5, 6	/* Number of loop iterations.  */
-	mtctr	r9		/* Setup the counter.  */
-	li	r11, 16		/* Load required offsets.  */
-	li	r9, 32
-	li	r7, 48
-
-	/* Handle r5 > 64.  Loop over the bytes in strides of 64B.  */
-	.align 4
-L(loop):
-	addi	r8, r8, -64	/* Adjust address for the next iteration.  */
-	lvx	v2, 0, r8	/* Load 4 quadwords.  */
-	lvx	v3, r8, r11
-	lvx	v4, v8, r9
-	lvx	v5, v8, r7
-	vcmpequb	v6, v1, v2
-	vcmpequb	v7, v1, v3
-	vcmpequb	v8, v1, v4
-	vcmpequb	v9, v1, v5
-	vor	v11, v6, v7
-	vor	v12, v8, v9
-	vor	v11, v11, v12	/* Compare and merge into one VR for speed.  */
-	vcmpequb.	v11, v0, v11
-	bnl	cr6, L(found)
-	bdnz	L(loop)
-	clrldi	r5, r5, 58
-
-	/* Handle remainder of 64B loop or r5 > 64.  */
-	.align	4
-L(tail64):
-	cmpldi	r5, 0
-	beq	L(null)
-	addi	r8, r8, -16
-	lvx	v4, 0, r8
-	vcmpequb	v6, v1, v4
-	vcmpequb.	v11, v0, v6
-	bnl	cr6, L(found_16B)
-	cmpldi	cr6, r5, 16
-	ble	cr6, L(null)
-	addi	r5, r5, -16
-
-	addi	r8, r8, -16
-	lvx	v4, 0, r8
-	vcmpequb	v6, v1, v4
-	vcmpequb.	v11, v0, v6
-	bnl	cr6, L(found_16B)
-	cmpldi	cr6, r5, 16
-	ble	cr6, L(null)
-	addi	r5, r5, -16
-
-	addi	r8, r8, -16
-	lvx	v4, 0, r8
-	vcmpequb	v6, v1, v4
-	vcmpequb.	v11, v0, v6
-	bnl	cr6, L(found_16B)
-	cmpldi	cr6, r5, 16
-	ble	cr6, L(null)
-	addi	r5, r5, -16
-
-	addi	r8, r8, -16
-	lvx	v4, 0, r8
-	vcmpequb	v6, v1, v4
-	vcmpequb.	v11, v0, v6
-	bnl	cr6, L(found_16B)
-	li	r3, 0
-	blr
-
-	/* Found a match in 64B loop.  */
-	.align	4
-L(found):
-	/* Permute the first bit of each byte into bits 48-63.  */
-	VBPERMQ(v6, v6, v10)
-	VBPERMQ(v7, v7, v10)
-	VBPERMQ(v8, v8, v10)
-	VBPERMQ(v9, v9, v10)
-	/* Shift each component into its correct position for merging.  */
-#ifdef __LITTLE_ENDIAN__
-	vsldoi	v7, v7, v7, 2
-	vsldoi	v8, v8, v8, 4
-	vsldoi	v9, v9, v9, 6
-#else
-	vsldoi	v6, v6, v6, 6
-	vsldoi	v7, v7, v7, 4
-	vsldoi	v8, v8, v8, 2
-#endif
-	/* Merge the results and move to a GPR.  */
-	vor	v11, v6, v7
-	vor	v4, v9, v8
-	vor	v4, v11, v4
-	MFVRD(r5, v4)
-#ifdef __LITTLE_ENDIAN__
-	cntlzd	r6, r5	/* Count leading zeros before the match.  */
-#else
-	addi	r6, r5, -1
-	andc	r6, r6, r5
-	popcntd	r6, r6
-#endif
-	addi	r8, r8, 63
-	sub	r3, r8, r6	/* Compute final address.  */
-	cmpld	cr7, r3, r10
-	bgelr	cr7
-	li	r3, 0
-	blr
-
-	/* Found a match in last 16 bytes.  */
-	.align	4
-L(found_16B):
-	cmpld	r8, r10		/* Are we on the last QW?  */
-	bge	L(last)
-	/* Now discard bytes before starting address.  */
-	sub	r9, r10, r8
-	MTVRD(v9, r9)
-	vspltisb	v8, 3
-	/* Mask unwanted bytes.  */
-#ifdef __LITTLE_ENDIAN__
-	lvsr	v7, 0, r10
-	vperm   v6, v0, v6, v7
-	vsldoi	v9, v0, v9, 8
-	vsl	v9, v9, v8
-	vslo	v6, v6, v9
-#else
-	lvsl	v7, 0, r10
-	vperm   v6, v6, v0, v7
-	vsldoi	v9, v0, v9, 8
-	vsl	v9, v9, v8
-	vsro	v6, v6, v9
-#endif
-L(last):
-	/* Permute the first bit of each byte into bits 48-63.  */
-	VBPERMQ(v6, v6, v10)
-	/* Shift each component into its correct position for merging.  */
-#ifdef __LITTLE_ENDIAN__
-	vsldoi	v6, v6, v6, 6
-	MFVRD(r7, v6)
-	cntlzd	r6, r7	/* Count leading zeros before the match.  */
-#else
-	MFVRD(r7, v6)
-	addi	r6, r7, -1
-	andc	r6, r6, r7
-	popcntd	r6, r6
-#endif
-	addi	r8, r8, 15
-	sub	r3, r8, r6	/* Compute final address.  */
-	cmpld	r6, r5
-	bltlr
-	li	r3, 0
-	blr
-
-	/* r3 has the output of the cmpb instruction, that is, it contains
-	   0xff in the same position as BYTE in the original
-	   word from the string.  Use that to calculate the pointer.
-	   We need to make sure BYTE is *before* the end of the
-	   range.  */
-L(done):
-	cntlzd	r9, r3	      /* Count leading zeros before the match.  */
-	cmpld	r8, r0         /* Are we on the last word?  */
-	srdi	r6, r9, 3	      /* Convert leading zeros to bytes.  */
-	addi	r0, r6, -7
-	sub	r3, r8, r0
-	cmpld	cr7, r3, r10
-	bnelr
-	bgelr	cr7
-	li	r3, 0
-	blr
-
-	.align	4
-L(null):
-	li	r3, 0
-	blr
-
-/* Deals with size <= 32.  */
-	.align	4
-L(small_range):
-	cmpldi	r5, 0
-	beq	L(null)
-
-#ifdef __LITTLE_ENDIAN__
-	ldx	r12, 0, r8
-#else
-	ldbrx	r12, 0, r8      /* Load reversed doubleword from memory.  */
-#endif
-	cmpb	r3, r12, r4     /* Check for BYTE in DWORD1.  */
-	and	r3, r3, r9
-	cmpldi	cr7, r3, 0
-	bne	cr7, L(done)
-
-	/* Are we done already?  */
-	cmpld	r8, r0
-	addi	r8, r8, -8
-	beqlr
-
-	.align	5
-L(loop_small):
-#ifdef __LITTLE_ENDIAN__
-	ldx	r12, 0, r8
-#else
-	ldbrx	r12, 0, r8
-#endif
-	cmpb	r3, r12, r4
-	cmpld	r8, r0
-	cmpldi	cr7, r3, 0
-	bne	cr7, L(done)
-	addi	r8, r8, -8
-	bne	L(loop_small)
-	blr
-
-END (MEMRCHR)
-weak_alias (__memrchr, memrchr)
-libc_hidden_builtin_def (memrchr)
diff --git a/sysdeps/powerpc/powerpc64/power8/memset.S b/sysdeps/powerpc/powerpc64/power8/memset.S
deleted file mode 100644
index a42232b..0000000
--- a/sysdeps/powerpc/powerpc64/power8/memset.S
+++ /dev/null
@@ -1,524 +0,0 @@
-/* Optimized memset implementation for PowerPC64/POWER8.
-   Copyright (C) 2014-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-#define MTVSRD_V1_R4  .long 0x7c240166     /* mtvsrd  v1,r4  */
-
-/* void * [r3] memset (void *s [r3], int c [r4], size_t n [r5]));
-   Returns 's'.  */
-
-#ifndef MEMSET
-# define MEMSET memset
-#endif
-
-	/* No need to use .machine power8 since mtvsrd is already
-	   handled by the define.  It avoid breakage on binutils
-	   that does not support this machine specifier.  */
-	.machine power7
-ENTRY_TOCLESS (MEMSET, 5)
-	CALL_MCOUNT 3
-
-L(_memset):
-	cmpldi	cr7,r5,31
-	neg	r0,r3
-	mr	r10,r3
-
-	insrdi	r4,r4,8,48
-	insrdi	r4,r4,16,32	/* Replicate byte to word.  */
-	ble	cr7,L(write_LT_32)
-
-	andi.	r11,r10,15	/* Check alignment of DST.  */
-	insrdi	r4,r4,32,0	/* Replicate word to double word.  */
-
-	beq	L(big_aligned)
-
-	mtocrf	0x01,r0
-	clrldi	r0,r0,60
-
-	/* Get DST aligned to 16 bytes.  */
-1:	bf	31,2f
-	stb	r4,0(r10)
-	addi	r10,r10,1
-
-2:	bf	30,4f
-	sth	r4,0(r10)
-	addi	r10,r10,2
-
-4:	bf	29,8f
-	stw	r4,0(r10)
-	addi	r10,r10,4
-
-8:	bf      28,16f
-	std     r4,0(r10)
-	addi    r10,r10,8
-
-16:	subf	r5,r0,r5
-
-	.align	4
-L(big_aligned):
-	/* For sizes larger than 255 two possible paths:
-	   - if constant is '0', zero full cache lines with dcbz
-	   - otherwise uses vector instructions.  */
-	cmpldi	cr5,r5,255
-	dcbtst	0,r10
-	cmpldi	cr6,r4,0
-	crand	27,26,21
-	bt	27,L(huge_dcbz)
-	bge	cr5,L(huge_vector)
-
-
-	/* Size between 32 and 255 bytes with constant different than 0, use
-	   doubleword store instruction to achieve best throughput.  */
-	srdi    r8,r5,5
-	clrldi  r11,r5,59
-	cmpldi  cr6,r11,0
-	cmpdi	r8,0
-	beq     L(tail_bytes)
-	mtctr   r8
-
-	/* Main aligned write loop, writes 32-bytes at a time.  */
-	.align  4
-L(big_loop):
-	std     r4,0(r10)
-	std     r4,8(r10)
-	std     r4,16(r10)
-	std     r4,24(r10)
-	addi    r10,r10,32
-	bdz     L(tail_bytes)
-
-	std     r4,0(r10)
-	std     r4,8(r10)
-	std     r4,16(r10)
-	std     r4,24(r10)
-	addi    r10,10,32
-	bdnz    L(big_loop)
-
-	b       L(tail_bytes)
-
-	/* Write remaining 1~31 bytes.  */
-	.align  4
-L(tail_bytes):
-	beqlr   cr6
-
-	srdi    r7,r11,4
-	clrldi  r8,r11,60
-	mtocrf  0x01,r7
-
-	.align	4
-	bf	31,8f
-	std	r4,0(r10)
-	std	r4,8(r10)
-	addi	r10,r10,16
-
-	.align	4
-8:	mtocrf	0x1,r8
-	bf	28,4f
-	std	r4,0(r10)
-	addi	r10,r10,8
-
-	.align	4
-4:	bf      29,2f
-	stw     4,0(10)
-	addi    10,10,4
-
-	.align 	4
-2:	bf      30,1f
-	sth     4,0(10)
-	addi    10,10,2
-
-	.align  4
-1:      bflr    31
-	stb     4,0(10)
-	blr
-
-	/* Size larger than 255 bytes with constant different than 0, use
-	   vector instruction to achieve best throughput.  */
-L(huge_vector):
-	/* Replicate set byte to quadword in VMX register.  */
-	MTVSRD_V1_R4
-	xxpermdi 32,v0,v1,0
-	vspltb	 v2,v0,15
-
-	/* Main aligned write loop: 128 bytes at a time.  */
-	li	r6,16
-	li	r7,32
-	li	r8,48
-	mtocrf	0x02,r5
-	srdi	r12,r5,7
-	cmpdi	r12,0
-	beq	L(aligned_tail)
-	mtctr	r12
-	b	L(aligned_128loop)
-
-	.align  4
-L(aligned_128loop):
-	stvx	v2,0,r10
-	stvx	v2,r10,r6
-	stvx	v2,r10,r7
-	stvx	v2,r10,r8
-	addi	r10,r10,64
-	stvx	v2,0,r10
-	stvx	v2,r10,r6
-	stvx	v2,r10,r7
-	stvx	v2,r10,r8
-	addi	r10,r10,64
-	bdnz	L(aligned_128loop)
-
-	/* Write remaining 1~127 bytes.  */
-L(aligned_tail):
-	mtocrf	0x01,r5
-	bf	25,32f
-	stvx	v2,0,r10
-	stvx	v2,r10,r6
-	stvx	v2,r10,r7
-	stvx	v2,r10,r8
-	addi	r10,r10,64
-
-32:	bf	26,16f
-	stvx	v2,0,r10
-	stvx	v2,r10,r6
-	addi	r10,r10,32
-
-16:	bf	27,8f
-	stvx	v2,0,r10
-	addi	r10,r10,16
-
-8:	bf	28,4f
-	std     r4,0(r10)
-	addi	r10,r10,8
-
-	/* Copies 4~7 bytes.  */
-4:	bf	29,L(tail2)
-	stw     r4,0(r10)
-	bf      30,L(tail5)
-	sth     r4,4(r10)
-	bflr	31
-	stb     r4,6(r10)
-	/* Return original DST pointer.  */
-	blr
-
-	/* Special case when value is 0 and we have a long length to deal
-	   with.  Use dcbz to zero out a full cacheline of 128 bytes at a time.
-	   Before using dcbz though, we need to get the destination 128-byte
-	   aligned.  */
-	.align	4
-L(huge_dcbz):
-	andi.	r11,r10,127
-	neg	r0,r10
-	beq	L(huge_dcbz_aligned)
-
-	clrldi	r0,r0,57
-	subf	r5,r0,r5
-	srdi	r0,r0,3
-	mtocrf	0x01,r0
-
-	/* Write 1~128 bytes until DST is aligned to 128 bytes.  */
-8:	bf	28,4f
-
-	std	r4,0(r10)
-	std	r4,8(r10)
-	std	r4,16(r10)
-	std	r4,24(r10)
-	std	r4,32(r10)
-	std	r4,40(r10)
-	std	r4,48(r10)
-	std	r4,56(r10)
-	addi	r10,r10,64
-
-	.align	4
-4:	bf	29,2f
-	std	r4,0(r10)
-	std	r4,8(r10)
-	std	r4,16(r10)
-	std	r4,24(r10)
-	addi	r10,r10,32
-
-	.align	4
-2:	bf	30,1f
-	std	r4,0(r10)
-	std	r4,8(r10)
-	addi	r10,r10,16
-
-	.align	4
-1:	bf	31,L(huge_dcbz_aligned)
-	std	r4,0(r10)
-	addi	r10,r10,8
-
-L(huge_dcbz_aligned):
-	/* Setup dcbz unroll offsets and count numbers.  */
-	srdi	r8,r5,9
-	clrldi	r11,r5,55
-	cmpldi	cr6,r11,0
-	li	r9,128
-	cmpdi	r8,0
-	beq     L(huge_tail)
-	li	r7,256
-	li	r6,384
-	mtctr	r8
-
-	.align	4
-L(huge_loop):
-	/* Sets 512 bytes to zero in each iteration, the loop unrolling shows
-	   a throughput boost for large sizes (2048 bytes or higher).  */
-	dcbz	0,r10
-	dcbz	r9,r10
-	dcbz	r7,r10
-	dcbz	r6,r10
-	addi	r10,r10,512
-	bdnz	L(huge_loop)
-
-	beqlr	cr6
-
-L(huge_tail):
-	srdi    r6,r11,8
-	srdi    r7,r11,4
-	clrldi  r8,r11,4
-	cmpldi  cr6,r8,0
-	mtocrf  0x01,r6
-
-	beq	cr6,L(tail)
-
-	/* We have 1~511 bytes remaining.  */
-	.align	4
-32:	bf	31,16f
-	dcbz	0,r10
-	dcbz	r9,r10
-	addi	r10,r10,256
-
-	.align	4
-16:	mtocrf  0x01,r7
-	bf	28,8f
-	dcbz	0,r10
-	addi	r10,r10,128
-
-	.align 	4
-8:	bf	29,4f
-	std	r4,0(r10)
-	std	r4,8(r10)
-	std	r4,16(r10)
-	std	r4,24(r10)
-	std	r4,32(r10)
-	std	r4,40(r10)
-	std	r4,48(r10)
-	std	r4,56(r10)
-	addi	r10,r10,64
-
-	.align	4
-4:	bf	30,2f
-	std	r4,0(r10)
-	std	r4,8(r10)
-	std	r4,16(r10)
-	std	r4,24(r10)
-	addi	r10,r10,32
-
-	.align	4
-2:	bf	31,L(tail)
-	std	r4,0(r10)
-	std	r4,8(r10)
-	addi	r10,r10,16
-	.align	4
-
-	/* Remaining 1~15 bytes.  */
-L(tail):
-	mtocrf  0x01,r8
-
-	.align
-8:	bf	28,4f
-	std	r4,0(r10)
-	addi	r10,r10,8
-
-	.align	4
-4:	bf	29,2f
-	stw	r4,0(r10)
-	addi	r10,r10,4
-
-	.align	4
-2:	bf	30,1f
-	sth	r4,0(r10)
-	addi	r10,r10,2
-
-	.align	4
-1:	bflr	31
-	stb	r4,0(r10)
-	blr
-
-	/* Handle short copies of 0~31 bytes.  Best throughput is achieved
-	   by just unrolling all operations.  */
-	.align	4
-L(write_LT_32):
-	cmpldi	cr6,5,8
-	mtocrf	0x01,r5
-	ble	cr6,L(write_LE_8)
-
-	/* At least 9 bytes to go.  */
-	neg	r8,r4
-	andi.	r0,r8,3
-	cmpldi	cr1,r5,16
-	beq	L(write_LT_32_aligned)
-
-	/* Force 4-byte alignment for SRC.  */
-	mtocrf	0x01,r0
-	subf	r5,r0,r5
-
-2:	bf	30,1f
-	/* Use stb instead of sth because it doesn't generate
-	   alignment interrupts on cache-inhibited storage.  */
-	stb	r4,0(r10)
-	stb	r4,1(r10)
-	addi	r10,r10,2
-
-1:	bf	31,L(end_4bytes_alignment)
-	stb	r4,0(r10)
-	addi	r10,r10,1
-
-	.align	4
-L(end_4bytes_alignment):
-	cmpldi	cr1,r5,16
-	mtocrf	0x01,r5
-
-L(write_LT_32_aligned):
-	blt	cr1,8f
-
-	stw	r4,0(r10)
-	stw	r4,4(r10)
-	stw	r4,8(r10)
-	stw	r4,12(r10)
-	addi	r10,r10,16
-
-8:	bf	28,L(tail4)
-	stw	r4,0(r10)
-	stw	r4,4(r10)
-	addi	r10,r10,8
-
-	.align	4
-	/* Copies 4~7 bytes.  */
-L(tail4):
-	bf	29,L(tail2)
-	stw	r4,0(r10)
-	bf	30,L(tail5)
-	sth	r4,4(r10)
-	bflr	31
-	stb	r4,6(r10)
-	blr
-
-	.align	4
-	/* Copies 2~3 bytes.  */
-L(tail2):
-	bf	30,1f
-	sth	r4,0(r10)
-	bflr	31
-	stb	r4,2(r10)
-	blr
-
-	.align	4
-L(tail5):
-	bflr	31
-	stb	r4,4(r10)
-	blr
-
-	.align	4
-1: 	bflr	31
-	stb	r4,0(r10)
-	blr
-
-	/* Handles copies of 0~8 bytes.  */
-	.align	4
-L(write_LE_8):
-	bne	cr6,L(LE7_tail4)
-	/* If input is word aligned, use stw, else use stb.  */
-	andi.	r0,r10,3
-	bne	L(8_unalign)
-
-	stw	r4,0(r10)
-	stw	r4,4(r10)
-	blr
-
-	/* Unaligned input and size is 8.  */
-	.align	4
-L(8_unalign):
-	andi.	r0,r10,1
-	beq	L(8_hwalign)
-	stb	r4,0(r10)
-	sth	r4,1(r10)
-	sth	r4,3(r10)
-	sth	r4,5(r10)
-	stb	r4,7(r10)
-	blr
-
-	/* Halfword aligned input and size is 8.  */
-	.align	4
-L(8_hwalign):
-	sth	r4,0(r10)
-	sth	r4,2(r10)
-	sth	r4,4(r10)
-	sth	r4,6(r10)
-	blr
-
-	.align	4
-	/* Copies 4~7 bytes.  */
-L(LE7_tail4):
-	/* Use stb instead of sth because it doesn't generate
-	   alignment interrupts on cache-inhibited storage.  */
-	bf	29,L(LE7_tail2)
-	stb	r4,0(r10)
-	stb	r4,1(r10)
-	stb	r4,2(r10)
-	stb	r4,3(r10)
-	bf	30,L(LE7_tail5)
-	stb	r4,4(r10)
-	stb	r4,5(r10)
-	bflr	31
-	stb	r4,6(r10)
-	blr
-
-	.align	4
-	/* Copies 2~3 bytes.  */
-L(LE7_tail2):
-	bf	30,1f
-	stb	r4,0(r10)
-	stb	r4,1(r10)
-	bflr	31
-	stb	r4,2(r10)
-	blr
-
-	.align	4
-L(LE7_tail5):
-	bflr	31
-	stb	r4,4(r10)
-	blr
-
-	.align	4
-1: 	bflr	31
-	stb	r4,0(r10)
-	blr
-
-END_GEN_TB (MEMSET,TB_TOCLESS)
-libc_hidden_builtin_def (memset)
-
-/* Copied from bzero.S to prevent the linker from inserting a stub
-   between bzero and memset.  */
-ENTRY_TOCLESS (__bzero)
-	CALL_MCOUNT 3
-	mr	r5,r4
-	li	r4,0
-	b	L(_memset)
-END (__bzero)
-#ifndef __bzero
-weak_alias (__bzero, bzero)
-#endif
diff --git a/sysdeps/powerpc/powerpc64/power8/strcasecmp.S b/sysdeps/powerpc/powerpc64/power8/strcasecmp.S
deleted file mode 100644
index 3a2efe2..0000000
--- a/sysdeps/powerpc/powerpc64/power8/strcasecmp.S
+++ /dev/null
@@ -1,457 +0,0 @@
-/* Optimized strcasecmp implementation for PowerPC64.
-   Copyright (C) 2016-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-#include <locale-defines.h>
-
-/* int [r3] strcasecmp (const char *s1 [r3], const char *s2 [r4] ) */
-
-#ifndef USE_AS_STRNCASECMP
-#  define __STRCASECMP __strcasecmp
-#  define STRCASECMP   strcasecmp
-#else
-#  define __STRCASECMP __strncasecmp
-#  define STRCASECMP   strncasecmp
-#endif
-/* Convert 16 bytes to lowercase and compare */
-#define TOLOWER()     \
-	vaddubm	v8, v4, v1; \
-	vaddubm	v7, v4, v3; \
-	vcmpgtub	v8, v8, v2; \
-	vsel	v4, v7, v4, v8; \
-	vaddubm	v8, v5, v1; \
-	vaddubm	v7, v5, v3; \
-	vcmpgtub	v8, v8, v2; \
-	vsel	v5, v7, v5, v8; \
-	vcmpequb.	v7, v5, v4;
-
-/*
- * Get 16 bytes for unaligned case.
- * reg1: Vector to hold next 16 bytes.
- * reg2: Address to read from.
- * reg3: Permute control vector.
- * v8: Tmp vector used to mask unwanted bytes.
- * v9: Tmp vector,0 when null is found on first 16 bytes
- */
-#ifdef __LITTLE_ENDIAN__
-#define GET16BYTES(reg1, reg2, reg3) \
-	lvx	reg1, 0, reg2; \
-	vspltisb	v8, -1; \
-	vperm	v8, v8, reg1, reg3; \
-	vcmpequb.	v8, v0, v8; \
-	beq	cr6, 1f; \
-	vspltisb	v9, 0; \
-	b	2f; \
-	.align 4; \
-1: \
-	addi	r6, reg2, 16; \
-	lvx	v9, 0, r6; \
-2: \
-	vperm	reg1, v9, reg1, reg3;
-#else
-#define GET16BYTES(reg1, reg2, reg3) \
-	lvx	reg1, 0, reg2; \
-	vspltisb	 v8, -1; \
-	vperm	v8, reg1, v8,  reg3; \
-	vcmpequb.	v8, v0, v8; \
-	beq	cr6, 1f; \
-	vspltisb	v9, 0; \
-	b	2f; \
-	.align 4; \
-1: \
-	addi	r6, reg2, 16; \
-	lvx	v9, 0, r6; \
-2: \
-	vperm	reg1, reg1, v9, reg3;
-#endif
-
-/* Check null in v4, v5 and convert to lower.  */
-#define CHECKNULLANDCONVERT() \
-	vcmpequb.	v7, v0, v5; \
-	beq	cr6, 3f; \
-	vcmpequb.	v7, v0, v4; \
-	beq	cr6, 3f; \
-	b	L(null_found); \
-	.align  4; \
-3: \
-	TOLOWER()
-
-#ifdef _ARCH_PWR8
-#  define VCLZD_V8_v7	vclzd	v8, v7;
-#  define MFVRD_R3_V1	mfvrd	r3, v1;
-#  define VSUBUDM_V9_V8	vsubudm	v9, v9, v8;
-#  define VPOPCNTD_V8_V8	vpopcntd v8, v8;
-#  define VADDUQM_V7_V8	vadduqm	v9, v7, v8;
-#else
-#  define VCLZD_V8_v7	.long	0x11003fc2
-#  define MFVRD_R3_V1	.long	0x7c230067
-#  define VSUBUDM_V9_V8	.long	0x112944c0
-#  define VPOPCNTD_V8_V8	.long	0x110047c3
-#  define VADDUQM_V7_V8	.long	0x11274100
-#endif
-
-	.machine  power7
-
-ENTRY (__STRCASECMP)
-#ifdef USE_AS_STRNCASECMP
-	CALL_MCOUNT 3
-#else
-	CALL_MCOUNT 2
-#endif
-#define rRTN	r3	/* Return value */
-#define rSTR1	r10	/* 1st string */
-#define rSTR2	r4	/* 2nd string */
-#define rCHAR1	r6	/* Byte read from 1st string */
-#define rCHAR2	r7	/* Byte read from 2nd string */
-#define rADDR1	r8	/* Address of tolower(rCHAR1) */
-#define rADDR2	r12	/* Address of tolower(rCHAR2) */
-#define rLWR1	r8	/* Word tolower(rCHAR1) */
-#define rLWR2	r12	/* Word tolower(rCHAR2) */
-#define rTMP	r9
-#define rLOC	r11	/* Default locale address */
-
-	cmpd	cr7, rRTN, rSTR2
-
-	/* Get locale address.  */
-	ld 	rTMP, __libc_tsd_LOCALE@got@tprel(r2)
-	add 	rLOC, rTMP, __libc_tsd_LOCALE@tls
-	ld	rLOC, 0(rLOC)
-
-	mr	rSTR1, rRTN
-	li	rRTN, 0
-	beqlr	cr7
-#ifdef USE_AS_STRNCASECMP
-	cmpdi	cr7, r5, 0
-	beq	cr7, L(retnull)
-	cmpdi	cr7, r5, 16
-	blt	cr7, L(bytebybyte)
-#endif
-	vspltisb	v0, 0
-	vspltisb	v8, -1
-	/* Check for null in initial characters.
-	   Check max of 16 char depending on the alignment.
-	   If null is present, proceed byte by byte.  */
-	lvx	v4, 0, rSTR1
-#ifdef  __LITTLE_ENDIAN__
-	lvsr	v10, 0, rSTR1	/* Compute mask.  */
-	vperm	v9, v8, v4, v10	/* Mask bits that are not part of string.  */
-#else
-	lvsl	v10, 0, rSTR1
-	vperm	v9, v4, v8, v10
-#endif
-	vcmpequb.	v9, v0, v9	/* Check for null bytes.  */
-	bne	cr6, L(bytebybyte)
-	lvx	v5, 0, rSTR2
-	/* Calculate alignment.  */
-#ifdef __LITTLE_ENDIAN__
-	lvsr	v6, 0, rSTR2
-	vperm	v9, v8, v5, v6	/* Mask bits that are not part of string.  */
-#else
-	lvsl	v6, 0, rSTR2
-	vperm	v9, v5, v8, v6
-#endif
-	vcmpequb.	v9, v0, v9	/* Check for null bytes.  */
-	bne	cr6, L(bytebybyte)
-	/* Check if locale has non ascii characters.  */
-	ld	rTMP, 0(rLOC)
-	addi r6, rTMP,LOCALE_DATA_VALUES+_NL_CTYPE_NONASCII_CASE*SIZEOF_VALUES
-	lwz	rTMP, 0(r6)
-	cmpdi	cr7, rTMP, 1
-	beq	cr7, L(bytebybyte)
-
-	/* Load vector registers with values used for TOLOWER.  */
-	/* Load v1 = 0xbf, v2 = 0x19 v3 = 0x20 in each byte.  */
-	vspltisb	v3, 2
-	vspltisb	v9, 4
-	vsl	v3, v3, v9
-	vaddubm	v1, v3, v3
-	vnor	v1, v1, v1
-	vspltisb	v2, 7
-	vsububm	v2, v3, v2
-
-	andi.	rADDR1, rSTR1, 0xF
-	beq	cr0, L(align)
-	addi	r6, rSTR1, 16
-	lvx	v9, 0, r6
-	/* Compute 16 bytes from previous two loads.  */
-#ifdef __LITTLE_ENDIAN__
-	vperm	v4, v9, v4, v10
-#else
-	vperm	v4, v4, v9, v10
-#endif
-L(align):
-	andi.	rADDR2, rSTR2, 0xF
-	beq	cr0, L(align1)
-	addi	r6, rSTR2, 16
-	lvx	v9, 0, r6
-	/* Compute 16 bytes from previous two loads.  */
-#ifdef __LITTLE_ENDIAN__
-	vperm	v5, v9, v5, v6
-#else
-	vperm	v5, v5, v9, v6
-#endif
-L(align1):
-	CHECKNULLANDCONVERT()
-	blt	cr6, L(match)
-	b	L(different)
-	.align 	4
-L(match):
-	clrldi	r6, rSTR1, 60
-	subfic	r7, r6, 16
-#ifdef USE_AS_STRNCASECMP
-	sub	r5, r5, r7
-#endif
-	add	rSTR1, rSTR1, r7
-	add	rSTR2, rSTR2, r7
-	andi.	rADDR2, rSTR2, 0xF
-	addi	rSTR1, rSTR1, -16
-	addi	rSTR2, rSTR2, -16
-	beq	cr0, L(aligned)
-#ifdef __LITTLE_ENDIAN__
-	lvsr	v6, 0, rSTR2
-#else
-	lvsl	v6, 0, rSTR2
-#endif
-	/* There are 2 loops depending on the input alignment.
-	   Each loop gets 16 bytes from s1 and s2, check for null,
-	   convert to lowercase and compare. Loop till difference
-	   or null occurs. */
-L(s1_align):
-	addi	rSTR1, rSTR1, 16
-	addi	rSTR2, rSTR2, 16
-#ifdef USE_AS_STRNCASECMP
-	cmpdi	cr7, r5, 16
-	blt	cr7, L(bytebybyte)
-	addi	r5, r5, -16
-#endif
-	lvx	v4, 0, rSTR1
-	GET16BYTES(v5, rSTR2, v6)
-	CHECKNULLANDCONVERT()
-	blt	cr6, L(s1_align)
-	b	L(different)
-	.align 	4
-L(aligned):
-	addi	rSTR1, rSTR1, 16
-	addi	rSTR2, rSTR2, 16
-#ifdef USE_AS_STRNCASECMP
-	cmpdi	cr7, r5, 16
-	blt	cr7, L(bytebybyte)
-	addi	r5, r5, -16
-#endif
-	lvx	v4, 0, rSTR1
-	lvx	v5, 0, rSTR2
-	CHECKNULLANDCONVERT()
-	blt	cr6, L(aligned)
-
-	/* Calculate and return the difference. */
-L(different):
-	vaddubm	v1, v3, v3
-	vcmpequb	v7, v0, v7
-#ifdef __LITTLE_ENDIAN__
-	/* Count trailing zero.  */
-	vspltisb	v8, -1
-	VADDUQM_V7_V8
-	vandc	v8, v9, v7
-	VPOPCNTD_V8_V8
-	vspltb	v6, v8, 15
-	vcmpequb.	v6, v6, v1
-	blt	cr6, L(shift8)
-#else
-	/* Count leading zero.  */
-	VCLZD_V8_v7
-	vspltb	v6, v8, 7
-	vcmpequb.	v6, v6, v1
-	blt	cr6, L(shift8)
-	vsro	v8, v8, v1
-#endif
-	b	L(skipsum)
-	.align  4
-L(shift8):
-	vsumsws		v8, v8, v0
-L(skipsum):
-#ifdef __LITTLE_ENDIAN__
-	/* Shift registers based on leading zero count.  */
-	vsro	v6, v5, v8
-	vsro	v7, v4, v8
-	/* Merge and move to GPR.  */
-	vmrglb	v6, v6, v7
-	vslo	v1, v6, v1
-	MFVRD_R3_V1
-	/* Place the characters that are different in first position.  */
-	sldi	rSTR2, rRTN, 56
-	srdi	rSTR2, rSTR2, 56
-	sldi	rSTR1, rRTN, 48
-	srdi	rSTR1, rSTR1, 56
-#else
-	vslo	v6, v5, v8
-	vslo	v7, v4, v8
-	vmrghb	v1, v6, v7
-	MFVRD_R3_V1
-	srdi	rSTR2, rRTN, 48
-	sldi	rSTR2, rSTR2, 56
-	srdi	rSTR2, rSTR2, 56
-	srdi	rSTR1, rRTN, 56
-#endif
-	subf  	rRTN, rSTR1, rSTR2
-	extsw 	rRTN, rRTN
-	blr
-
-	.align  4
-	/* OK. We've hit the end of the string. We need to be careful that
-	   we don't compare two strings as different because of junk beyond
-	   the end of the strings...  */
-L(null_found):
-	vaddubm	v10, v3, v3
-#ifdef __LITTLE_ENDIAN__
-	/* Count trailing zero.  */
-	vspltisb	v8, -1
-	VADDUQM_V7_V8
-	vandc	v8, v9, v7
-	VPOPCNTD_V8_V8
-	vspltb	v6, v8, 15
-	vcmpequb.	v6, v6, v10
-	blt	cr6, L(shift_8)
-#else
-	/* Count leading zero.  */
-	VCLZD_V8_v7
-	vspltb	v6, v8, 7
-	vcmpequb.	v6, v6, v10
-	blt	cr6, L(shift_8)
-	vsro	v8, v8, v10
-#endif
-	b	L(skipsum1)
-	.align  4
-L(shift_8):
-	vsumsws	v8, v8, v0
-L(skipsum1):
-	/* Calculate shift count based on count of zero.  */
-	vspltisb	v10, 7
-	vslb	v10, v10, v10
-	vsldoi	v9, v0, v10, 1
-	VSUBUDM_V9_V8
-	vspltisb	v8, 8
-	vsldoi	v8, v0, v8, 1
-	VSUBUDM_V9_V8
-	/* Shift and remove junk after null character.  */
-#ifdef __LITTLE_ENDIAN__
-	vslo	v5, v5, v9
-	vslo	v4, v4, v9
-#else
-	vsro	v5, v5, v9
-	vsro	v4, v4, v9
-#endif
-	/* Convert and compare 16 bytes.  */
-	TOLOWER()
-	blt	cr6, L(retnull)
-	b	L(different)
-	.align  4
-L(retnull):
-	li	rRTN, 0
-	blr
-	.align  4
-L(bytebybyte):
-	/* Unrolling loop for POWER: loads are done with 'lbz' plus
-	offset and string descriptors are only updated in the end
-	of loop unrolling. */
-	ld	rLOC, LOCALE_CTYPE_TOLOWER(rLOC)
-	lbz	rCHAR1, 0(rSTR1)	/* Load char from s1 */
-	lbz	rCHAR2, 0(rSTR2)	/* Load char from s2 */
-#ifdef USE_AS_STRNCASECMP
-	rldicl	rTMP, r5, 62, 2
-	cmpdi	cr7, rTMP, 0
-	beq	cr7, L(lessthan4)
-	mtctr	rTMP
-#endif
-L(loop):
-	cmpdi	rCHAR1, 0		/* *s1 == '\0' ? */
-	sldi	rADDR1, rCHAR1, 2	/* Calculate address for tolower(*s1) */
-	sldi	rADDR2, rCHAR2, 2	/* Calculate address for tolower(*s2) */
-	lwzx	rLWR1, rLOC, rADDR1	/* Load tolower(*s1) */
-	lwzx	rLWR2, rLOC, rADDR2	/* Load tolower(*s2) */
-	cmpw	cr1, rLWR1, rLWR2	/* r = tolower(*s1) == tolower(*s2) ? */
-	crorc	4*cr1+eq,eq,4*cr1+eq	/* (*s1 != '\0') || (r == 1) */
-	beq	cr1, L(done)
-	lbz	rCHAR1, 1(rSTR1)
-	lbz	rCHAR2, 1(rSTR2)
-	cmpdi	rCHAR1, 0
-	sldi	rADDR1, rCHAR1, 2
-	sldi	rADDR2, rCHAR2, 2
-	lwzx	rLWR1, rLOC, rADDR1
-	lwzx	rLWR2, rLOC, rADDR2
-	cmpw	cr1, rLWR1, rLWR2
-	crorc	4*cr1+eq,eq,4*cr1+eq
-	beq	cr1, L(done)
-	lbz	rCHAR1, 2(rSTR1)
-	lbz	rCHAR2, 2(rSTR2)
-	cmpdi	rCHAR1, 0
-	sldi	rADDR1, rCHAR1, 2
-	sldi	rADDR2, rCHAR2, 2
-	lwzx	rLWR1, rLOC, rADDR1
-	lwzx	rLWR2, rLOC, rADDR2
-	cmpw	cr1, rLWR1, rLWR2
-	crorc	4*cr1+eq,eq,4*cr1+eq
-	beq	cr1, L(done)
-	lbz	rCHAR1, 3(rSTR1)
-	lbz	rCHAR2, 3(rSTR2)
-	cmpdi	rCHAR1, 0
-	/* Increment both string descriptors */
-	addi	rSTR1, rSTR1, 4
-	addi	rSTR2, rSTR2, 4
-	sldi	rADDR1, rCHAR1, 2
-	sldi	rADDR2, rCHAR2, 2
-	lwzx	rLWR1, rLOC, rADDR1
-	lwzx	rLWR2, rLOC, rADDR2
-	cmpw	cr1, rLWR1, rLWR2
-	crorc	4*cr1+eq,eq,4*cr1+eq
-	beq     cr1, L(done)
-	lbz	rCHAR1, 0(rSTR1)	/* Load char from s1 */
-	lbz	rCHAR2, 0(rSTR2)	/* Load char from s2 */
-#ifdef USE_AS_STRNCASECMP
-	bdnz	L(loop)
-#else
-	b	L(loop)
-#endif
-#ifdef USE_AS_STRNCASECMP
-L(lessthan4):
-	clrldi	r5, r5, 62
-	cmpdi	cr7, r5, 0
-	beq	cr7, L(retnull)
-	mtctr	r5
-L(loop1):
-	cmpdi	rCHAR1, 0
-	sldi	rADDR1, rCHAR1, 2
-	sldi	rADDR2, rCHAR2, 2
-	lwzx	rLWR1, rLOC, rADDR1
-	lwzx	rLWR2, rLOC, rADDR2
-	cmpw	cr1, rLWR1, rLWR2
-	crorc	4*cr1+eq,eq,4*cr1+eq
-	beq	cr1, L(done)
-	addi	rSTR1, rSTR1, 1
-	addi	rSTR2, rSTR2, 1
-	lbz	rCHAR1, 0(rSTR1)
-	lbz	rCHAR2, 0(rSTR2)
-	bdnz	L(loop1)
-#endif
-L(done):
-	subf	r0, rLWR2, rLWR1
-	extsw	rRTN, r0
-	blr
-END (__STRCASECMP)
-
-weak_alias (__STRCASECMP, STRCASECMP)
-libc_hidden_builtin_def (__STRCASECMP)
diff --git a/sysdeps/powerpc/powerpc64/power8/strcasestr-ppc64.c b/sysdeps/powerpc/powerpc64/power8/strcasestr-ppc64.c
deleted file mode 100644
index 221d473..0000000
--- a/sysdeps/powerpc/powerpc64/power8/strcasestr-ppc64.c
+++ /dev/null
@@ -1,29 +0,0 @@
-/* Optimized strcasestr implementation for PowerPC64/POWER8.
-   Copyright (C) 2016-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <string.h>
-
-#define STRCASESTR __strcasestr_ppc
-#undef libc_hidden_builtin_def
-#define libc_hidden_builtin_def(__name)
-
-#undef weak_alias
-#define weak_alias(a,b)
-extern __typeof (strcasestr) __strcasestr_ppc attribute_hidden;
-
-#include <string/strcasestr.c>
diff --git a/sysdeps/powerpc/powerpc64/power8/strcasestr.S b/sysdeps/powerpc/powerpc64/power8/strcasestr.S
deleted file mode 100644
index 9fc24c2..0000000
--- a/sysdeps/powerpc/powerpc64/power8/strcasestr.S
+++ /dev/null
@@ -1,538 +0,0 @@
-/* Optimized strcasestr implementation for PowerPC64/POWER8.
-   Copyright (C) 2016-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-#include <locale-defines.h>
-
-/* Char * [r3] strcasestr (char *s [r3], char * pat[r4])  */
-
-/* The performance gain is obtained by comparing 16 bytes.  */
-
-/* When the first char of r4 is hit ITERATIONS times in r3
-   fallback to default.  */
-#define ITERATIONS	64
-
-#ifndef STRCASESTR
-# define STRCASESTR __strcasestr
-#endif
-
-#ifndef STRLEN
-/* For builds without IFUNC support, local calls should be made to internal
-   GLIBC symbol (created by libc_hidden_builtin_def).  */
-# ifdef SHARED
-#  define STRLEN   __GI_strlen
-# else
-#  define STRLEN   strlen
-# endif
-#endif
-
-#ifndef STRNLEN
-/* For builds without IFUNC support, local calls should be made to internal
-   GLIBC symbol (created by libc_hidden_builtin_def).  */
-# ifdef SHARED
-#  define STRNLEN   __GI_strnlen
-# else
-#  define STRNLEN    __strnlen
-# endif
-#endif
-
-#ifndef STRCHR
-# ifdef SHARED
-#  define STRCHR   __GI_strchr
-# else
-#  define STRCHR   strchr
-# endif
-#endif
-
-/* Convert 16 bytes of v4 and reg to lowercase and compare.  */
-#define TOLOWER(reg)     \
-	vcmpgtub	v6, v4, v1; \
-	vcmpgtub	v7, v2, v4; \
-	vand	v8, v7, v6; \
-	vand	v8, v8, v3; \
-	vor	v4, v8, v4; \
-	vcmpgtub	v6, reg, v1; \
-	vcmpgtub	v7, v2, reg; \
-	vand	v8, v7, v6; \
-	vand	v8, v8, v3; \
-	vor	reg, v8, reg; \
-	vcmpequb.	v6, reg, v4;
-
-/* TODO: change these to the actual instructions when the minimum required
-   binutils allows it.  */
-#ifdef _ARCH_PWR8
-#define VCLZD_V8_v7	vclzd	v8, v7;
-#else
-#define VCLZD_V8_v7	.long	0x11003fc2
-#endif
-
-#define	FRAMESIZE	(FRAME_MIN_SIZE+48)
-/* TODO: change this to .machine power8 when the minimum required binutils
-   allows it.  */
-	.machine  power7
-ENTRY (STRCASESTR, 4)
-	CALL_MCOUNT 2
-	mflr	r0			/* Load link register LR to r0.  */
-	std	r31, -8(r1)		/* Save callers register r31.  */
-	std	r30, -16(r1)		/* Save callers register r30.  */
-	std	r29, -24(r1)		/* Save callers register r29.  */
-	std	r28, -32(r1)		/* Save callers register r28.  */
-	std	r27, -40(r1)		/* Save callers register r27.  */
-	std	r0, 16(r1)		/* Store the link register.  */
-	cfi_offset(r31, -8)
-	cfi_offset(r30, -16)
-	cfi_offset(r29, -24)
-	cfi_offset(r28, -32)
-	cfi_offset(r27, -40)
-	cfi_offset(lr, 16)
-	stdu	r1, -FRAMESIZE(r1)	/* Create the stack frame.  */
-	cfi_adjust_cfa_offset(FRAMESIZE)
-
-	dcbt	0, r3
-	dcbt	0, r4
-	cmpdi	cr7, r3, 0		/* Input validation.  */
-	beq	cr7, L(retnull)
-	cmpdi	cr7, r4, 0
-	beq	cr7, L(retnull)
-
-	mr	r29, r3
-	mr	r30, r4
-	/* Load first byte from r4 and check if its null.  */
-	lbz	r6, 0(r4)
-	cmpdi	cr7, r6, 0
-	beq	cr7, L(ret_r3)
-
-	ld	r10, __libc_tsd_LOCALE@got@tprel(r2)
-	add	r9, r10, __libc_tsd_LOCALE@tls
-	ld	r9, 0(r9)
-	ld	r9, LOCALE_CTYPE_TOUPPER(r9)
-	sldi	r10, r6, 2		/* Convert to upper case.  */
-	lwzx	r28, r9, r10
-
-	ld	r10, __libc_tsd_LOCALE@got@tprel(r2)
-	add	r11, r10, __libc_tsd_LOCALE@tls
-	ld	r11, 0(r11)
-	ld	r11, LOCALE_CTYPE_TOLOWER(r11)
-	sldi	r10, r6, 2              /* Convert to lower case.  */
-	lwzx	r27, r11, r10
-
-	/* Check if the first char is present.  */
-	mr	r4, r27
-	bl	STRCHR
-	nop
-	mr	r5, r3
-	mr	r3, r29
-	mr	r29, r5
-	mr	r4, r28
-	bl	STRCHR
-	nop
-	cmpdi	cr7, r29, 0
-	beq	cr7, L(firstpos)
-	cmpdi	cr7, r3, 0
-	beq	cr7, L(skipcheck)
-	cmpw	cr7, r3, r29
-	ble 	cr7, L(firstpos)
-	/* Move r3 to the first occurence.  */
-L(skipcheck):
-	mr	r3, r29
-L(firstpos):
-	mr	r29, r3
-
-	sldi	r9, r27, 8
-	or	r28, r9, r28
-	/* Reg r27 is used to count the number of iterations.  */
-	li	r27, 0
-	/* If first char of search str is not present.  */
-	cmpdi	cr7, r3, 0
-	ble	cr7, L(end)
-
-	/* Find the length of pattern.  */
-	mr	r3, r30
-	bl	STRLEN
-	nop
-
-	cmpdi	cr7, r3, 0	/* If search str is null.  */
-	beq	cr7, L(ret_r3)
-
-	mr	r31, r3
-	mr	r4, r3
-	mr	r3, r29
-	bl	STRNLEN
-	nop
-
-	cmpd	cr7, r3, r31 	/* If len(r3) < len(r4).  */
-	blt	cr7, L(retnull)
-
-	mr	r3, r29
-
-	/* Locales not matching ASCII for single bytes.  */
-	ld	r10, __libc_tsd_LOCALE@got@tprel(r2)
-	add	r9, r10, __libc_tsd_LOCALE@tls
-	ld	r9, 0(r9)
-	ld	r7, 0(r9)
-	addi	r7, r7, LOCALE_DATA_VALUES+_NL_CTYPE_NONASCII_CASE*SIZEOF_VALUES
-	lwz	r8, 0(r7)
-	cmpdi	cr7, r8, 1
-	beq	cr7, L(bytebybyte)
-
-	/* If len(r4) < 16 handle byte by byte.  */
-	/* For shorter strings we will not use vector registers.  */
-	cmpdi	cr7, r31, 16
-	blt	cr7, L(bytebybyte)
-
-	/* Comparison values used for TOLOWER.  */
-	/* Load v1 = 64('A' - 1), v2 = 91('Z' + 1), v3 = 32 in each byte.  */
-	vspltish	v0, 0
-	vspltisb	v5, 2
-	vspltisb	v4, 4
-	vsl	v3, v5, v4
-	vaddubm	v1, v3, v3
-	vspltisb	v5, 15
-	vaddubm	v2, v5, v5
-	vaddubm	v2, v1, v2
-	vspltisb	v4, -3
-	vaddubm	v2, v2, v4
-
-	/*
-	1. Load 16 bytes from r3 and r4
-	2. Check if there is null, If yes, proceed byte by byte path.
-	3. Else,Convert both to lowercase and compare.
-	4. If they are same proceed to 1.
-	5. If they dont match, find if first char of r4 is present in the
-	   loaded 16 byte of r3.
-	6. If yes, move position, load next 16 bytes of r3 and proceed to 2.
-	*/
-
-	mr	r8, r3		/* Save r3 for future use.  */
-	mr	r4, r30		/* Restore r4.  */
-	clrldi	r10, r4, 60
-	lvx	v5, 0, r4	/* Load 16 bytes from r4.  */
-	cmpdi	cr7, r10, 0
-	beq	cr7, L(begin2)
-	/* If r4 is unaligned, load another 16 bytes.  */
-#ifdef __LITTLE_ENDIAN__
-	lvsr	v7, 0, r4
-#else
-	lvsl	v7, 0, r4
-#endif
-	addi	r5, r4, 16
-	lvx	v9, 0, r5
-#ifdef __LITTLE_ENDIAN__
-	vperm	v5, v9, v5, v7
-#else
-	vperm	v5, v5, v9, v7
-#endif
-L(begin2):
-	lvx	v4, 0, r3
-	vcmpequb.	v7, v0, v4	/* Check for null.  */
-	beq	cr6, L(nullchk6)
-	b	L(trailcheck)
-
-        .align  4
-L(nullchk6):
-	clrldi	r10, r3, 60
-	cmpdi	cr7, r10, 0
-	beq	cr7, L(next16)
-#ifdef __LITTLE_ENDIAN__
-	lvsr	v7, 0, r3
-#else
-	lvsl	v7, 0, r3
-#endif
-	addi	r5, r3, 16
-	/* If r3 is unaligned, load another 16 bytes.  */
-	lvx	v10, 0, r5
-#ifdef __LITTLE_ENDIAN__
-	vperm	v4, v10, v4, v7
-#else
-	vperm	v4, v4, v10, v7
-#endif
-L(next16):
-	vcmpequb.	v6, v0, v5	/* Check for null.  */
-	beq	cr6, L(nullchk)
-	b	L(trailcheck)
-
-	.align	4
-L(nullchk):
-	vcmpequb.	v6, v0, v4
-	beq	cr6, L(nullchk1)
-	b	L(retnull)
-
-	.align	4
-L(nullchk1):
-	/* Convert both v3 and v4 to lower.  */
-	TOLOWER(v5)
-	/* If both are same, branch to match.  */
-	blt	cr6, L(match)
-	/* Find if the first char is present in next 15 bytes.  */
-#ifdef __LITTLE_ENDIAN__
-	vspltb	v6, v5, 15
-	vsldoi	v7, v0, v4, 15
-#else
-	vspltb	v6, v5, 0
-	vspltisb	v7, 8
-	vslo	v7, v4, v7
-#endif
-	vcmpequb	v7, v6, v7
-	vcmpequb.	v6, v0, v7
-	/* Shift r3 by 16 bytes and proceed.  */
-	blt	cr6, L(shift16)
-	VCLZD_V8_v7
-#ifdef __LITTLE_ENDIAN__
-	vspltb	v6, v8, 15
-#else
-	vspltb	v6, v8, 7
-#endif
-	vcmpequb.	v6, v6, v1
-	/* Shift r3 by 8  bytes and proceed.  */
-	blt	cr6, L(shift8)
-	b	L(begin)
-
-	.align	4
-L(match):
-	/* There is a match of 16 bytes, check next bytes.  */
-	cmpdi	cr7, r31, 16
-	mr	r29, r3
-	beq	cr7, L(ret_r3)
-
-L(secondmatch):
-	addi	r3, r3, 16
-	addi	r4, r4, 16
-	/* Load next 16 bytes of r3 and r4 and compare.  */
-	clrldi	r10, r4, 60
-	cmpdi	cr7, r10, 0
-	beq	cr7, L(nextload)
-	/* Handle unaligned case.  */
-	vor	v6, v9, v9
-	vcmpequb.	v7, v0, v6
-	beq	cr6, L(nullchk2)
-	b	L(trailcheck)
-
-	.align	4
-L(nullchk2):
-#ifdef __LITTLE_ENDIAN__
-	lvsr	v7, 0, r4
-#else
-	lvsl	v7, 0, r4
-#endif
-	addi	r5, r4, 16
-	/* If r4 is unaligned, load another 16 bytes.  */
-	lvx	v9, 0, r5
-#ifdef __LITTLE_ENDIAN__
-	vperm	v11, v9, v6, v7
-#else
-	vperm	v11, v6, v9, v7
-#endif
-	b	L(compare)
-
-	.align	4
-L(nextload):
-	lvx	v11, 0, r4
-L(compare):
-	vcmpequb.	v7, v0, v11
-	beq	cr6, L(nullchk3)
-	b	L(trailcheck)
-
-	.align	4
-L(nullchk3):
-	clrldi	r10, r3, 60
-	cmpdi 	cr7, r10, 0
-	beq 	cr7, L(nextload1)
-	/* Handle unaligned case.  */
-	vor	v4, v10, v10
-	vcmpequb.	v7, v0, v4
-	beq	cr6, L(nullchk4)
-	b	L(retnull)
-
-	.align	4
-L(nullchk4):
-#ifdef __LITTLE_ENDIAN__
-	lvsr	v7, 0, r3
-#else
-	lvsl	v7, 0, r3
-#endif
-	addi	r5, r3, 16
-	/* If r3 is unaligned, load another 16 bytes.  */
-	lvx	v10, 0, r5
-#ifdef __LITTLE_ENDIAN__
-	vperm	v4, v10, v4, v7
-#else
-	vperm	v4, v4, v10, v7
-#endif
-	b	L(compare1)
-
-	.align	4
-L(nextload1):
-	lvx	v4, 0, r3
-L(compare1):
-	vcmpequb.	v7, v0, v4
-	beq	cr6, L(nullchk5)
-	b	L(retnull)
-
-	.align	4
-L(nullchk5):
-	/* Convert both v3 and v4 to lower.  */
-	TOLOWER(v11)
-	/* If both are same, branch to secondmatch.  */
-	blt 	cr6, L(secondmatch)
-	/* Continue the search.  */
-        b	L(begin)
-
-	.align	4
-L(trailcheck):
-	ld	r10, __libc_tsd_LOCALE@got@tprel(r2)
-	add	r11, r10, __libc_tsd_LOCALE@tls
-	ld	r11, 0(r11)
-	ld	r11, LOCALE_CTYPE_TOLOWER(r11)
-L(loop2):
-	lbz	r5, 0(r3)               /* Load byte from r3.  */
-	lbz	r6, 0(r4)               /* Load next byte from r4.  */
-	cmpdi 	cr7, r6, 0              /* Is it null?  */
-	beq 	cr7, L(updater3)
-	cmpdi 	cr7, r5, 0              /* Is it null?  */
-	beq 	cr7, L(retnull)         /* If yes, return.  */
-	addi	r3, r3, 1
-	addi	r4, r4, 1               /* Increment r4.  */
-	sldi	r10, r5, 2              /* Convert to lower case.  */
-	lwzx	r10, r11, r10
-	sldi	r7, r6, 2               /* Convert to lower case.  */
-	lwzx	r7, r11, r7
-	cmpw	cr7, r7, r10            /* Compare with byte from r4.  */
-	bne	cr7, L(begin)
-	b	L(loop2)
-
-	.align	4
-L(shift8):
-	addi	r8, r8, 7
-	b	L(begin)
-	.align	4
-L(shift16):
-	addi	r8, r8, 15
-	.align	4
-L(begin):
-	addi	r8, r8, 1
-	mr	r3, r8
-	/* When our iterations exceed ITERATIONS,fall back to default.  */
-	addi	r27, r27, 1
-	cmpdi	cr7, r27, ITERATIONS
-	beq	cr7, L(default)
-	mr	r4, r30         /* Restore r4.  */
-	b	L(begin2)
-
-	/* Handling byte by byte.  */
-	.align	4
-L(loop1):
-	mr	r3, r8
-	addi	r27, r27, 1
-	cmpdi	cr7, r27, ITERATIONS
-	beq	cr7, L(default)
-	mr	r29, r8
-	srdi	r4, r28, 8
-	/* Check if the first char is present.  */
-	bl	STRCHR
-	nop
-	mr	r5, r3
-	mr	r3, r29
-	mr	r29, r5
-	sldi	r4, r28, 56
-	srdi	r4, r4, 56
-	bl	STRCHR
-	nop
-	cmpdi	cr7, r29, 0
-	beq	cr7, L(nextpos)
-	cmpdi	cr7, r3, 0
-	beq	cr7, L(skipcheck1)
-	cmpw	cr7, r3, r29
-	ble 	cr7, L(nextpos)
-	/* Move r3 to first occurence.  */
-L(skipcheck1):
-	mr	r3, r29
-L(nextpos):
-	mr	r29, r3
-	cmpdi 	cr7, r3, 0
-	ble 	cr7, L(retnull)
-L(bytebybyte):
-	ld	r10, __libc_tsd_LOCALE@got@tprel(r2)
-	add	r11, r10, __libc_tsd_LOCALE@tls
-	ld	r11, 0(r11)
-	ld	r11, LOCALE_CTYPE_TOLOWER(r11)
-	mr	r4, r30                 /* Restore r4.  */
-	mr	r8, r3                  /* Save r3.  */
-	addi	r8, r8, 1
-
-L(loop):
-	addi	r3, r3, 1
-	lbz	r5, 0(r3)               /* Load byte from r3.  */
-	addi	r4, r4, 1               /* Increment r4.  */
-	lbz	r6, 0(r4)               /* Load next byte from r4.  */
-	cmpdi 	cr7, r6, 0              /* Is it null?  */
-	beq 	cr7, L(updater3)
-	cmpdi 	cr7, r5, 0              /* Is it null?  */
-	beq 	cr7, L(retnull)         /* If yes, return.  */
-	sldi	r10, r5, 2              /* Convert to lower case.  */
-	lwzx	r10, r11, r10
-	sldi	r7, r6, 2               /* Convert to lower case.  */
-	lwzx	r7, r11, r7
-	cmpw	cr7, r7, r10            /* Compare with byte from r4.  */
-	bne 	cr7, L(loop1)
-	b	L(loop)
-
-	/* Handling return values.  */
-	.align	4
-L(updater3):
-	subf	r3, r31, r3	/* Reduce r31 (len of r4) from r3.  */
-	b	L(end)
-
-	.align	4
-L(ret_r3):
-	mr	r3, r29		/* Return point of match.  */
-	b	L(end)
-
-	.align	4
-L(retnull):
-	li	r3, 0		/* Substring was not found.  */
-	b	L(end)
-
-	.align	4
-L(default):
-	mr	r4, r30
-	bl	__strcasestr_ppc
-	nop
-
-	.align	4
-L(end):
-	addi	r1, r1, FRAMESIZE	/* Restore stack pointer.  */
-	cfi_adjust_cfa_offset(-FRAMESIZE)
-	ld	r0, 16(r1)	/* Restore the saved link register.  */
-	ld	r27, -40(r1)
-	ld	r28, -32(r1)
-	ld	r29, -24(r1)	/* Restore callers save register r29.  */
-	ld	r30, -16(r1)	/* Restore callers save register r30.  */
-	ld	r31, -8(r1)	/* Restore callers save register r31.  */
-	cfi_restore(lr)
-	cfi_restore(r27)
-	cfi_restore(r28)
-	cfi_restore(r29)
-	cfi_restore(r30)
-	cfi_restore(r31)
-	mtlr	r0		/* Branch to link register.  */
-	blr
-END (STRCASESTR)
-
-weak_alias (__strcasestr, strcasestr)
-libc_hidden_def (__strcasestr)
-libc_hidden_builtin_def (strcasestr)
diff --git a/sysdeps/powerpc/powerpc64/power8/strchr.S b/sysdeps/powerpc/powerpc64/power8/strchr.S
deleted file mode 100644
index c5e28d9..0000000
--- a/sysdeps/powerpc/powerpc64/power8/strchr.S
+++ /dev/null
@@ -1,377 +0,0 @@
-/* Optimized strchr implementation for PowerPC64/POWER8.
-   Copyright (C) 2016-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-#ifdef USE_AS_STRCHRNUL
-# ifndef STRCHRNUL
-#   define FUNC_NAME __strchrnul
-# else
-#   define FUNC_NAME STRCHRNUL
-# endif
-#else
-# ifndef STRCHR
-#  define FUNC_NAME strchr
-# else
-#  define FUNC_NAME STRCHR
-# endif
-#endif  /* !USE_AS_STRCHRNUL  */
-
-/* int [r3] strchr (char *s [r3], int c [r4])  */
-/* TODO: change these to the actual instructions when the minimum required
-   binutils allows it.  */
-#define MTVRD(v,r) .long (0x7c000167 | ((v)<<(32-11)) | ((r)<<(32-16)))
-#define MFVRD(r,v) .long (0x7c000067 | ((v)<<(32-11)) | ((r)<<(32-16)))
-#define VBPERMQ(t,a,b)  .long (0x1000054c \
-			| ((t)<<(32-11)) \
-			| ((a)<<(32-16)) \
-			| ((b)<<(32-21)) )
-/* TODO: change this to .machine power8 when the minimum required binutils
-   allows it.  */
-	.machine  power7
-ENTRY_TOCLESS (FUNC_NAME)
-	CALL_MCOUNT 2
-	dcbt	0,r3
-	clrrdi	r8,r3,3	      /* Align the address to doubleword boundary.  */
-	cmpdi	cr7,r4,0
-	ld	r12,0(r8)     /* Load doubleword from memory.  */
-	li	r0,0	      /* Doubleword with null chars to use
-				 with cmpb.  */
-
-	rlwinm	r6,r3,3,26,28 /* Calculate padding.  */
-
-	beq	cr7,L(null_match)
-
-	/* Replicate byte to doubleword.  */
-	insrdi	r4,r4,8,48
-	insrdi	r4,r4,16,32
-	insrdi  r4,r4,32,0
-
-	/* Now r4 has a doubleword of c bytes and r0 has
-	   a doubleword of null bytes.  */
-
-	cmpb	r10,r12,r4     /* Compare each byte against c byte.  */
-	cmpb	r11,r12,r0     /* Compare each byte against null byte.  */
-
-	/* Move the doublewords left and right to discard the bits that are
-	   not part of the string and bring them back as zeros.  */
-#ifdef __LITTLE_ENDIAN__
-	srd	r10,r10,r6
-	srd	r11,r11,r6
-	sld	r10,r10,r6
-	sld	r11,r11,r6
-#else
-	sld	r10,r10,r6
-	sld	r11,r11,r6
-	srd	r10,r10,r6
-	srd	r11,r11,r6
-#endif
-	or	r5,r10,r11    /* OR the results to speed things up.  */
-	cmpdi	cr7,r5,0      /* If r5 == 0, no c or null bytes
-				 have been found.  */
-	bne	cr7,L(done)
-
-	mtcrf   0x01,r8
-
-	/* Are we now aligned to a doubleword boundary?  If so, skip to
-	   the main loop.  Otherwise, go through the alignment code.  */
-
-	bt	28,L(loop)
-
-	/* Handle WORD2 of pair.  */
-	ldu	r12,8(r8)
-	cmpb    r10,r12,r4
-	cmpb	r11,r12,r0
-	or	r5,r10,r11
-	cmpdi	cr7,r5,0
-	bne	cr7,L(done)
-	b	L(loop)	      /* We branch here (rather than falling through)
-				 to skip the nops due to heavy alignment
-				 of the loop below.  */
-
-	.p2align  5
-L(loop):
-	/* Load two doublewords, compare and merge in a
-	   single register for speed.  This is an attempt
-	   to speed up the null-checking process for bigger strings.  */
-	ld	r12,8(r8)
-	ldu	r9,16(r8)
-	cmpb	r10,r12,r4
-	cmpb	r11,r12,r0
-	cmpb	r6,r9,r4
-	cmpb	r7,r9,r0
-	or	r5,r10,r11
-	or	r9,r6,r7
-	or	r12,r5,r9
-	cmpdi	cr7,r12,0
-	beq	cr7,L(vector)
-	/* OK, one (or both) of the doublewords contains a c/null byte.  Check
-	   the first doubleword and decrement the address in case the first
-	   doubleword really contains a c/null byte.  */
-
-	cmpdi	cr6,r5,0
-	addi	r8,r8,-8
-	bne	cr6,L(done)
-
-	/* The c/null byte must be in the second doubleword.  Adjust the
-	   address again and move the result of cmpb to r10 so we can calculate
-	   the pointer.  */
-
-	mr	r10,r6
-	mr	r11,r7
-	addi	r8,r8,8
-#ifdef USE_AS_STRCHRNUL
-	mr	r5, r9
-#endif
-	/* r10/r11 have the output of the cmpb instructions, that is,
-	   0xff in the same position as the c/null byte in the original
-	   doubleword from the string.  Use that to calculate the pointer.  */
-L(done):
-#ifdef USE_AS_STRCHRNUL
-	mr	r10, r5
-#endif
-#ifdef __LITTLE_ENDIAN__
-	addi    r3,r10,-1
-	andc    r3,r3,r10
-	popcntd	r0,r3
-# ifndef USE_AS_STRCHRNUL
-	addi    r4,r11,-1
-	andc    r4,r4,r11
-	cmpld	cr7,r3,r4
-	bgt	cr7,L(no_match)
-# endif
-#else
-	cntlzd	r0,r10	      /* Count leading zeros before c matches.  */
-# ifndef USE_AS_STRCHRNUL
-	cmpld	cr7,r11,r10
-	bgt	cr7,L(no_match)
-# endif
-#endif
-	srdi	r0,r0,3	      /* Convert leading zeros to bytes.  */
-	add	r3,r8,r0      /* Return address of the matching c byte
-				 or null in case c was not found.  */
-	blr
-
-	/* Check the first 32B in GPR's and move to vectorized loop.  */
-	.p2align  5
-L(vector):
-	addi	r3, r8, 8
-	andi.	r10, r3, 31
-	bne	cr0, L(loop)
-	vspltisb	v0, 0
-	/* Precompute vbpermq constant.  */
-	vspltisb	v10, 3
-	lvsl	v11, r0, r0
-	vslb	v10, v11, v10
-	MTVRD(v1,r4)
-	li	r5, 16
-	vspltb	v1, v1, 7
-	/* Compare 32 bytes in each loop.  */
-L(continue):
-	lvx	v4, 0, r3
-	lvx	v5, r3, r5
-	vcmpequb	v2, v0, v4
-	vcmpequb	v3, v0, v5
-	vcmpequb	v6, v1, v4
-	vcmpequb	v7, v1, v5
-	vor	v8, v2, v3
-	vor	v9, v6, v7
-	vor	v11, v8, v9
-	vcmpequb.	v11, v0, v11
-	addi	r3, r3, 32
-	blt	cr6, L(continue)
-	/* One (or both) of the quadwords contains a c/null byte.  */
-	addi	r3, r3, -32
-#ifndef USE_AS_STRCHRNUL
-	vcmpequb.	v11, v0, v9
-	blt	cr6, L(no_match)
-#endif
-	/* Permute the first bit of each byte into bits 48-63.  */
-	VBPERMQ(v2, v2, v10)
-	VBPERMQ(v3, v3, v10)
-	VBPERMQ(v6, v6, v10)
-	VBPERMQ(v7, v7, v10)
-	/* Shift each component into its correct position for merging.  */
-#ifdef __LITTLE_ENDIAN__
-	vsldoi	v3, v3, v3, 2
-	vsldoi	v7, v7, v7, 2
-#else
-	vsldoi	v2, v2, v2, 6
-	vsldoi	v3, v3, v3, 4
-	vsldoi	v6, v6, v6, 6
-	vsldoi	v7, v7, v7, 4
-#endif
-
-        /* Merge the results and move to a GPR.  */
-        vor     v1, v3, v2
-        vor     v2, v6, v7
-        vor     v4, v1, v2
-	MFVRD(r5, v4)
-#ifdef __LITTLE_ENDIAN__
-	addi	r6, r5, -1
-	andc	r6, r6, r5
-	popcntd	r6, r6
-#else
-	cntlzd	r6, r5	/* Count leading zeros before the match.  */
-#endif
-	add	r3, r3, r6	/* Compute final length.  */
-	/* Return NULL if null found before c.  */
-#ifndef USE_AS_STRCHRNUL
-	lbz	r4, 0(r3)
-	cmpdi	cr7, r4, 0
-	beq	cr7, L(no_match)
-#endif
-	blr
-
-#ifndef USE_AS_STRCHRNUL
-	.align	4
-L(no_match):
-	li	r3,0
-	blr
-#endif
-
-/* We are here because strchr was called with a null byte.  */
-	.align	4
-L(null_match):
-	/* r0 has a doubleword of null bytes.  */
-
-	cmpb	r5,r12,r0     /* Compare each byte against null bytes.  */
-
-	/* Move the doublewords left and right to discard the bits that are
-	   not part of the string and bring them back as zeros.  */
-#ifdef __LITTLE_ENDIAN__
-	srd	r5,r5,r6
-	sld	r5,r5,r6
-#else
-	sld	r5,r5,r6
-	srd	r5,r5,r6
-#endif
-	cmpdi	cr7,r5,0      /* If r10 == 0, no c or null bytes
-				 have been found.  */
-	bne	cr7,L(done_null)
-
-	mtcrf   0x01,r8
-
-	/* Are we now aligned to a quadword boundary?  If so, skip to
-	   the main loop.  Otherwise, go through the alignment code.  */
-
-	bt	28,L(loop_null)
-
-	/* Handle WORD2 of pair.  */
-	ldu	r12,8(r8)
-	cmpb    r5,r12,r0
-	cmpdi	cr7,r5,0
-	bne	cr7,L(done_null)
-	b	L(loop_null)  /* We branch here (rather than falling through)
-				 to skip the nops due to heavy alignment
-				 of the loop below.  */
-
-	/* Main loop to look for the end of the string.  Since it's a
-	   small loop (< 8 instructions), align it to 32-bytes.  */
-	.p2align  5
-L(loop_null):
-	/* Load two doublewords, compare and merge in a
-	   single register for speed.  This is an attempt
-	   to speed up the null-checking process for bigger strings.  */
-	ld	r12,8(r8)
-	ldu     r11,16(r8)
-	cmpb	r5,r12,r0
-	cmpb	r10,r11,r0
-	or	r6,r5,r10
-	cmpdi	cr7,r6,0
-	beq	cr7,L(vector1)
-
-	/* OK, one (or both) of the doublewords contains a null byte.  Check
-	   the first doubleword and decrement the address in case the first
-	   doubleword really contains a null byte.  */
-
-	cmpdi	cr6,r5,0
-	addi	r8,r8,-8
-	bne	cr6,L(done_null)
-
-	/* The null byte must be in the second doubleword.  Adjust the address
-	   again and move the result of cmpb to r10 so we can calculate the
-	   pointer.  */
-
-	mr	r5,r10
-	addi	r8,r8,8
-
-	/* r5 has the output of the cmpb instruction, that is, it contains
-	   0xff in the same position as the null byte in the original
-	   doubleword from the string.  Use that to calculate the pointer.  */
-L(done_null):
-#ifdef __LITTLE_ENDIAN__
-	addi    r0,r5,-1
-	andc    r0,r0,r5
-	popcntd	r0,r0
-#else
-	cntlzd	r0,r5	      /* Count leading zeros before the match.  */
-#endif
-	srdi	r0,r0,3	      /* Convert leading zeros to bytes.  */
-	add	r3,r8,r0      /* Return address of the matching null byte.  */
-	blr
-	.p2align  5
-L(vector1):
-	addi    r3, r8, 8
-	andi.	r10, r3, 31
-	bne	cr0, L(loop_null)
-	vspltisb	v8, -1
-	vspltisb	v0, 0
-	vspltisb	v10, 3
-	lvsl	v11, r0, r0
-	vslb	v10, v11, v10
-	li	r5, 16
-L(continue1):
-	lvx	v4, 0, r3
-	lvx	v5, r3, r5
-	vcmpequb	v2, v0, v4
-	vcmpequb	v3, v0, v5
-	vor	v8, v2, v3
-	vcmpequb.	v11, v0, v8
-	addi	r3, r3, 32
-	blt	cr6, L(continue1)
-	addi	r3, r3, -32
-L(end1):
-	VBPERMQ(v2, v2, v10)
-	VBPERMQ(v3, v3, v10)
-	/* Shift each component into its correct position for merging.  */
-#ifdef __LITTLE_ENDIAN__
-	vsldoi	v3, v3, v3, 2
-#else
-	vsldoi	v2, v2, v2, 6
-	vsldoi	v3, v3, v3, 4
-#endif
-
-        /* Merge the results and move to a GPR.  */
-        vor     v4, v3, v2
-	MFVRD(r5, v4)
-#ifdef __LITTLE_ENDIAN__
-	addi	r6, r5, -1
-	andc	r6, r6, r5
-	popcntd	r6, r6
-#else
-	cntlzd	r6, r5	/* Count leading zeros before the match.  */
-#endif
-	add	r3, r3, r6	/* Compute final length.  */
-	blr
-END (FUNC_NAME)
-
-#ifndef USE_AS_STRCHRNUL
-weak_alias (strchr, index)
-libc_hidden_builtin_def (strchr)
-#endif
diff --git a/sysdeps/powerpc/powerpc64/power8/strchrnul.S b/sysdeps/powerpc/powerpc64/power8/strchrnul.S
deleted file mode 100644
index 022ad67..0000000
--- a/sysdeps/powerpc/powerpc64/power8/strchrnul.S
+++ /dev/null
@@ -1,23 +0,0 @@
-/* Optimized strchrnul implementation for PowerPC64/POWER8.
-   Copyright (C) 2016-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define USE_AS_STRCHRNUL 1
-#include <sysdeps/powerpc/powerpc64/power8/strchr.S>
-
-weak_alias (__strchrnul,strchrnul)
-libc_hidden_builtin_def (__strchrnul)
diff --git a/sysdeps/powerpc/powerpc64/power8/strcmp.S b/sysdeps/powerpc/powerpc64/power8/strcmp.S
deleted file mode 100644
index 15e7351..0000000
--- a/sysdeps/powerpc/powerpc64/power8/strcmp.S
+++ /dev/null
@@ -1,247 +0,0 @@
-/* Optimized strcmp implementation for PowerPC64/POWER8.
-   Copyright (C) 2015-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-#ifndef STRCMP
-# define STRCMP strcmp
-#endif
-
-/* Implements the function
-
-   size_t [r3] strcmp (const char *s1 [r3], const char *s2 [r4])
-
-   The implementation uses unaligned doubleword access to avoid specialized
-   code paths depending of data alignment.  Although recent powerpc64 uses
-   64K as default, the page cross handling assumes minimum page size of
-   4k.  */
-
-ENTRY_TOCLESS (STRCMP, 4)
-	li	r0,0
-
-	/* Check if [s1]+16 or [s2]+16 will cross a 4K page boundary using
-	   the code:
-
-	    (((size_t) s1) % PAGE_SIZE > (PAGE_SIZE - ITER_SIZE))
-
-	   with PAGE_SIZE being 4096 and ITER_SIZE begin 16.  */
-
-	rldicl	r7,r3,0,52
-	rldicl	r9,r4,0,52
-	cmpldi	cr7,r7,4096-16
-	bgt	cr7,L(pagecross_check)
-	cmpldi	cr5,r9,4096-16
-	bgt	cr5,L(pagecross_check)
-
-	/* For short string up to 16 bytes, load both s1 and s2 using
-	   unaligned dwords and compare.  */
-	ld	r8,0(r3)
-	ld	r10,0(r4)
-	cmpb	r12,r8,r0
-	cmpb	r11,r8,r10
-	orc.	r9,r12,r11
-	bne	cr0,L(different_nocmpb)
-
-	ld	r8,8(r3)
-	ld	r10,8(r4)
-	cmpb	r12,r8,r0
-	cmpb	r11,r8,r10
-	orc.	r9,r12,r11
-	bne	cr0,L(different_nocmpb)
-
-	addi	r7,r3,16
-	addi	r4,r4,16
-
-L(align_8b):
-	/* Now it has checked for first 16 bytes, align source1 to doubleword
-	   and adjust source2 address.  */
-	rldicl	r9,r7,0,61	/* source1 alignment to doubleword  */
-	subf	r4,r9,r4	/* Adjust source2 address based on source1
-				   alignment.  */
-	rldicr	r7,r7,0,60	/* Align source1 to doubleword.  */
-
-	/* At this point, source1 alignment is 0 and source2 alignment is
-	   between 0 and 7.  Check is source2 alignment is 0, meaning both
-	   sources have the same alignment.  */
-	andi.	r9,r4,0x7
-	bne	cr0,L(loop_diff_align)
-
-	/* If both source1 and source2 are doubleword aligned, there is no
-	   need for page boundary cross checks.  */
-
-	ld	r8,0(r7)
-	ld	r10,0(r4)
-	cmpb	r12,r8,r0
-	cmpb	r11,r8,r10
-	orc.	r9,r12,r11
-	bne	cr0,L(different_nocmpb)
-
-	.align 4
-L(loop_equal_align):
-	ld	r8,8(r7)
-	ld	r10,8(r4)
-	cmpb	r12,r8,r0
-	cmpb	r11,r8,r10
-	orc.	r9,r12,r11
-	bne	cr0,L(different_nocmpb)
-
-	ld	r8,16(r7)
-	ld	r10,16(r4)
-	cmpb	r12,r8,r0
-	cmpb	r11,r8,r10
-	orc.	r9,r12,r11
-	bne	cr0,L(different_nocmpb)
-
-	ldu	r8,24(r7)
-	ldu	r10,24(r4)
-	cmpb	r12,r8,r0
-	cmpb	r11,r8,r10
-	orc.	r9,r12,r11
-	bne	cr0,L(different_nocmpb)
-
-	b	L(loop_equal_align)
-
-	/* A zero byte was found in r8 (s1 dword), r9 contains the cmpb
-	   result and r10 the dword from s2.  To code isolate the byte
-	   up to end (including the '\0'), masking with 0xFF the remaining
-	   ones:
-
-           #if __LITTLE_ENDIAN__
-	     (__builtin_ffsl (x) - 1) = counting trailing zero bits
-	     r9 = (__builtin_ffsl (r9) - 1) + 8;
-	     r9 = -1UL << r9
-	   #else
-	     r9  = __builtin_clzl (r9) + 8;
-	     r9  = -1UL >> r9
-	   #endif
-	     r8  = r8  | r9
-	     r10 = r10 | r9  */
-
-#ifdef __LITTLE_ENDIAN__
-	nor 	r9,r9,r9
-L(different_nocmpb):
-	neg	r3,r9
-	and	r9,r9,r3
-	cntlzd	r9,r9
-	subfic	r9,r9,63
-#else
-	not	r9,r9
-L(different_nocmpb):
-	cntlzd	r9,r9
-	subfic	r9,r9,56
-#endif
-	srd	r3,r8,r9
-	srd	r10,r10,r9
-	rldicl	r10,r10,0,56
-	rldicl	r3,r3,0,56
-	subf	r3,r10,r3
-	extsw	r3,r3
-	blr
-
-	.align	4
-L(pagecross_check):
-	subfic	r9,r9,4096
-	subfic	r7,r7,4096
-	cmpld	cr7,r7,r9
-	bge	cr7,L(pagecross)
-	mr	r7,r9
-
-	/* If unaligned 16 bytes reads across a 4K page boundary, it uses
-	   a simple byte a byte comparison until the page alignment for s1
-	   is reached.  */
-L(pagecross):
-	add	r7,r3,r7
-	subf	r9,r3,r7
-	mtctr	r9
-
-	.align	4
-L(pagecross_loop):
-	/* Loads a byte from s1 and s2, compare if *s1 is equal to *s2
-	   and if *s1 is '\0'.  */
-	lbz	r9,0(r3)
-	lbz	r10,0(r4)
-	addi	r3,r3,1
-	addi	r4,r4,1
-	cmplw	cr7,r9,r10
-	cmpdi	cr5,r9,r0
-	bne	cr7,L(pagecross_ne)
-	beq	cr5,L(pagecross_nullfound)
-	bdnz	L(pagecross_loop)
-	b	L(align_8b)
-
-	.align	4
-	/* The unaligned read of source2 will cross a 4K page boundary,
-	   and the different byte or NULL maybe be in the remaining page
-	   bytes. Since it can not use the unaligned load, the algorithm
-	   reads and compares 8 bytes to keep source1 doubleword aligned.  */
-L(check_source2_byte):
-	li	r9,8
-	mtctr	r9
-
-	.align	4
-L(check_source2_byte_loop):
-	lbz	r9,0(r7)
-	lbz	r10,0(r4)
-	addi	r7,r7,1
-	addi	r4,r4,1
-	cmplw	cr7,r9,10
-	cmpdi	r5,r9,0
-	bne	cr7,L(pagecross_ne)
-	beq	cr5,L(pagecross_nullfound)
-	bdnz	L(check_source2_byte_loop)
-
-	/* If source2 is unaligned to doubleword, the code needs to check
-	   on each interation if the unaligned doubleword access will cross
-	   a 4k page boundary.  */
-	.align	5
-L(loop_unaligned):
-	ld	r8,0(r7)
-	ld	r10,0(r4)
-	cmpb	r12,r8,r0
-	cmpb	r11,r8,r10
-	orc.	r9,r12,r11
-	bne	cr0,L(different_nocmpb)
-	addi	r7,r7,8
-	addi	r4,r4,8
-
-L(loop_diff_align):
-	/* Check if [src2]+8 cross a 4k page boundary:
-
-	     srcin2 % PAGE_SIZE > (PAGE_SIZE - 8)
-
-	     with PAGE_SIZE being 4096.  */
-	rldicl	r9,r4,0,52
-	cmpldi	cr7,r9,4088
-	ble	cr7,L(loop_unaligned)
-	b	L(check_source2_byte)
-
-	.align	4
-L(pagecross_ne):
-	extsw	r3,r9
-	mr	r9,r10
-L(pagecross_retdiff):
-	subf	r9,r9,r3
-	extsw	r3,r9
-	blr
-
-	.align	4
-L(pagecross_nullfound):
-	li	r3,0
-	b	L(pagecross_retdiff)
-END (STRCMP)
-libc_hidden_builtin_def (strcmp)
diff --git a/sysdeps/powerpc/powerpc64/power8/strcpy.S b/sysdeps/powerpc/powerpc64/power8/strcpy.S
deleted file mode 100644
index 956faf7..0000000
--- a/sysdeps/powerpc/powerpc64/power8/strcpy.S
+++ /dev/null
@@ -1,413 +0,0 @@
-/* Optimized strcpy/stpcpy implementation for PowerPC64/POWER8.
-   Copyright (C) 2015-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-#ifdef USE_AS_STPCPY
-# ifndef STPCPY
-#   define FUNC_NAME __stpcpy
-# else
-#   define FUNC_NAME STPCPY
-# endif
-#else
-# ifndef STRCPY
-#  define FUNC_NAME strcpy
-# else
-#  define FUNC_NAME STRCPY
-# endif
-#endif  /* !USE_AS_STPCPY  */
-
-/* Implements the function
-
-   char * [r3] strcpy (char *dest [r3], const char *src [r4])
-
-   or
-
-   char * [r3] stpcpy (char *dest [r3], const char *src [r4])
-
-   if USE_AS_STPCPY is defined.
-
-   The implementation uses unaligned doubleword access to avoid specialized
-   code paths depending of data alignment.  Although recent powerpc64 uses
-   64K as default, the page cross handling assumes minimum page size of
-   4k.  */
-
-	.machine  power8
-ENTRY_TOCLESS (FUNC_NAME, 4)
-        li      r0,0          /* Doubleword with null chars to use
-                                 with cmpb.  */
-
-	/* Check if the [src]+15 will cross a 4K page by checking if the bit
-	   indicating the page size changes.  Basically:
-
-	   uint64_t srcin = (uint64_t)src;
-	   uint64_t ob = srcin & 4096UL;
-	   uint64_t nb = (srcin+15UL) & 4096UL;
-	   if (ob ^ nb)
-	     goto pagecross;  */
-
-	addi	r9,r4,15
-	xor	r9,r9,r4
-	rlwinm.	r9,r9,0,19,19
-	bne	L(pagecross)
-
-	/* For short string (less than 16 bytes), just calculate its size as
-	   strlen and issues a memcpy if null is found.  */
-	mr	r7,r4
-        ld      r12,0(r7)     /* Load doubleword from memory.  */
-        cmpb    r10,r12,r0    /* Check for null bytes in DWORD1.  */
-        cmpdi   cr7,r10,0     /* If r10 == 0, no null's have been found.  */
-        bne     cr7,L(done)
-
-        ldu     r8,8(r7)
-        cmpb    r10,r8,r0
-        cmpdi   cr7,r10,0
-        bne     cr7,L(done)
-
-	b	L(loop_before)
-
-	.align	4
-L(pagecross):
-	clrrdi  r7,r4,3       /* Align the address to doubleword boundary.  */
-	rlwinm  r6,r4,3,26,28 /* Calculate padding.  */
-	li      r5,-1         /* MASK = 0xffffffffffffffff.  */
-        ld      r12,0(r7)     /* Load doubleword from memory.  */
-#ifdef __LITTLE_ENDIAN__
-        sld     r5,r5,r6
-#else
-        srd     r5,r5,r6      /* MASK = MASK >> padding.  */
-#endif
-        orc     r9,r12,r5     /* Mask bits that are not part of the string.  */
-        cmpb    r10,r9,r0     /* Check for null bytes in DWORD1.  */
-        cmpdi   cr7,r10,0     /* If r10 == 0, no null's have been found.  */
-        bne     cr7,L(done)
-
-        ldu     r6,8(r7)
-        cmpb    r10,r6,r0
-        cmpdi   cr7,r10,0
-        bne     cr7,L(done)
-
-        ld      r12,0(r7)
-        cmpb    r10,r12,r0
-        cmpdi   cr7,r10,0
-        bne     cr7,L(done)
-
-        ldu     r6,8(r7)
-        cmpb    r10,r6,r0
-        cmpdi   cr7,r10,0
-        bne     cr7,L(done)
-
-	/* We checked for 24 - x bytes, with x being the source alignment
-	   (0 <= x <= 16), and no zero has been found.  Start the loop
-	   copy with doubleword aligned address.  */
-	mr	r7,r4
-	ld	r12, 0(r7)
-	ldu	r8, 8(r7)
-
-L(loop_before):
-	/* Save the two doublewords read from source and align the source
-	   to 16 bytes for the loop.  */
-	mr	r11,r3
-	std	r12,0(r11)
-	std	r8,8(r11)
-	addi	r11,r11,16
-	rldicl	r9,r4,0,60
-	subf	r7,r9,r7
-	subf	r11,r9,r11
-	/* Source is adjusted to 16B alignment and destination r11 is
-	   also moved based on that adjustment.  Now check if r11 is
-	   also 16B aligned to move to vectorized loop.  */
-	andi.	r6, r11, 0xF
-	bne	L(loop_start)
-
-	/* Prepare for the loop.  */
-	subf	r4, r9, r4	/* Adjust r4 based on alignment.  */
-	li	r7, 16	/* Load required offsets.  */
-	li	r8, 32
-	li	r9, 48
-	vspltisb	v0, 0
-	addi	r4, r4, 16
-	/* Are we 64-byte aligned? If so, jump to the vectorized loop.
-	   Else copy 16B till r4 is 64B aligned.  */
-	andi.	r6, r4, 63
-	beq	L(qw_loop)
-
-	lvx	v6, 0, r4	/* Load 16 bytes from memory.  */
-	vcmpequb.	v5, v0, v6	/* Check for null.  */
-	bne	cr6, L(qw_done)
-	stvx	v6, 0, r11	/* Store 16 bytes.  */
-	addi	r4, r4, 16	/* Increment the address.  */
-	addi	r11, r11, 16
-	andi.	r6, r4, 63
-	beq	L(qw_loop)
-
-	lvx	v6, 0, r4
-	vcmpequb.	v5, v0, v6
-	bne	cr6, L(qw_done)
-	stvx	v6, 0, r11
-	addi	r4, r4, 16
-	addi	r11, r11, 16
-	andi.	r6, r4, 63
-	beq	L(qw_loop)
-
-	lvx	v6, 0, r4
-	vcmpequb.	v5, v0, v6
-	bne	cr6, L(qw_done)
-	stvx	v6, 0, r11
-	addi	r4, r4, 16
-	addi	r11, r11, 16
-
-	.align	4
-L(qw_loop):
-	lvx	v1, r4, r0  /* Load 4 quadwords.  */
-	lvx	v2, r4, r7
-	lvx	v3, r4, r8
-	lvx	v4, r4, r9
-	vminub	v5, v1, v2  /* Compare and merge into one VR for speed.  */
-	vminub	v8, v3, v4
-	vminub	v7, v5, v8
-	vcmpequb.	v7, v7, v0  /* Check for NULLs.  */
-	bne	cr6, L(qw_loop_done)
-	stvx	v1, r11, r0	/* Store 4 quadwords.  */
-	stvx	v2, r11, r7
-	stvx	v3, r11, r8
-	stvx	v4, r11, r9
-	addi	r4, r4, 64  /* Adjust address for the next iteration.  */
-	addi	r11, r11, 64	/* Adjust address for the next iteration.  */
-
-	lvx	v1, r4, r0  /* Load 4 quadwords.  */
-	lvx	v2, r4, r7
-	lvx	v3, r4, r8
-	lvx	v4, r4, r9
-	vminub	v5, v1, v2  /* Compare and merge into one VR for speed.  */
-	vminub	v8, v3, v4
-	vminub	v7, v5, v8
-	vcmpequb.	v7, v7, v0  /* Check for NULLs.  */
-	bne	cr6, L(qw_loop_done)
-	stvx	v1, r11, r0	/* Store 4 quadwords.  */
-	stvx	v2, r11, r7
-	stvx	v3, r11, r8
-	stvx	v4, r11, r9
-	addi	r4, r4, 64  /* Adjust address for the next iteration.  */
-	addi	r11, r11, 64	/* Adjust address for the next iteration.  */
-
-	lvx	v1, r4, r0  /* Load 4 quadwords.  */
-	lvx	v2, r4, r7
-	lvx	v3, r4, r8
-	lvx	v4, r4, r9
-	vminub	v5, v1, v2  /* Compare and merge into one VR for speed.  */
-	vminub	v8, v3, v4
-	vminub	v7, v5, v8
-	vcmpequb.	v7, v7, v0  /* Check for NULLs.  */
-	bne	cr6, L(qw_loop_done)
-	stvx	v1, r11, r0	/* Store 4 quadwords.  */
-	stvx	v2, r11, r7
-	stvx	v3, r11, r8
-	stvx	v4, r11, r9
-	addi	r4, r4, 64  /* Adjust address for the next iteration.  */
-	addi	r11, r11, 64	/* Adjust address for the next iteration.  */
-	b	L(qw_loop)
-
-	.align	4
-L(qw_loop_done):
-	/* Null found in one of the 4 loads.  */
-	vcmpequb.	v7, v1, v0
-	vor	v6, v1, v1
-	bne	cr6, L(qw_done)
-	/* Not on the first 16B, So store it.  */
-	stvx	v1, r11, r0
-	addi	r4, r4, 16
-	addi	r11, r11, 16
-	vcmpequb.	v7, v2, v0
-	vor	v6, v2, v2
-	bne	cr6, L(qw_done)
-	/* Not on the second 16B, So store it.  */
-	stvx	v2, r11, r0
-	addi	r4, r4, 16
-	addi	r11, r11, 16
-	vcmpequb.	v7, v3, v0
-	vor	v6, v3, v3
-	bne	cr6, L(qw_done)
-	/* Not on the third 16B, So store it.  */
-	stvx	v6, r11, r0
-	addi	r4, r4, 16
-	addi	r11, r11, 16
-	vor	v6, v4, v4
-
-	.align	4
-L(qw_done):
-	mr	r7, r4
-	/* Move the result to GPR.  */
-#ifdef __LITTLE_ENDIAN__
-	vsldoi	v4, v6, v0, 8
-	mfvrd	r12, v4
-#else
-	mfvrd	r12, v6
-#endif
-	/* Check for null in the first 8 bytes.  */
-	cmpb	r10, r12, r0
-	cmpdi	cr6, r10, 0
-	bne	cr6, L(done2)
-	/* Null found in second doubleword.  */
-#ifdef __LITTLE_ENDIAN__
-	mfvrd	r6, v6
-#else
-	vsldoi	v6, v6, v0, 8
-	mfvrd	r6, v6
-#endif
-	cmpb	r10, r6, r0
-	addi	r7, r7, 8
-	b	L(done2)
-
-        .align  5
-L(loop):
-        std     r12, 0(r11)
-        std     r6, 8(r11)
-	addi	r11,r11,16
-L(loop_start):
-        /* Load two doublewords, compare and merge in a
-           single register for speed.  This is an attempt
-           to speed up the null-checking process for bigger strings.  */
-
-        ld      r12, 8(r7)
-        ldu     r6, 16(r7)
-        cmpb    r10,r12,r0
-        cmpb    r9,r6,r0
-        or      r8,r9,r10     /* Merge everything in one doubleword.  */
-        cmpdi   cr7,r8,0
-        beq     cr7,L(loop)
-
-
-        /* OK, one (or both) of the doublewords contains a null byte.  Check
-           the first doubleword and decrement the address in case the first
-           doubleword really contains a null byte.  */
-
-	addi	r4,r7,-8
-        cmpdi   cr6,r10,0
-        addi    r7,r7,-8
-        bne     cr6,L(done2)
-
-        /* The null byte must be in the second doubleword.  Adjust the address
-           again and move the result of cmpb to r10 so we can calculate the
-           length.  */
-
-        mr      r10,r9
-        addi    r7,r7,8
-	b	L(done2)
-
-        /* r10 has the output of the cmpb instruction, that is, it contains
-           0xff in the same position as the null byte in the original
-           doubleword from the string.  Use that to calculate the length.  */
-L(done):
-	mr	r11,r3
-L(done2):
-#ifdef __LITTLE_ENDIAN__
-        addi    r9, r10, -1   /* Form a mask from trailing zeros.  */
-        andc    r9, r9, r10
-        popcntd r6, r9        /* Count the bits in the mask.  */
-#else
-        cntlzd  r6,r10        /* Count leading zeros before the match.  */
-#endif
-        subf    r5,r4,r7
-        srdi    r6,r6,3       /* Convert leading/trailing zeros to bytes.  */
-        add     r8,r5,r6      /* Compute final length.  */
-#ifdef USE_AS_STPCPY
-	/* stpcpy returns the dest address plus the size not counting the
-	   final '\0'.  */
-	add	r3,r11,r8
-#endif
-	addi	r8,r8,1       /* Final '/0'.  */
-
-	cmpldi	cr6,r8,8
-	mtocrf	0x01,r8
-	ble	cr6,L(copy_LE_8)
-
-	cmpldi	cr1,r8,16
-	blt	cr1,8f
-
-	/* Handle copies of 0~31 bytes.  */
-	.align	4
-L(copy_LT_32):
-	/* At least 6 bytes to go.  */
-	blt	cr1,8f
-
-	/* Copy 16 bytes.  */
-	ld	r6,0(r4)
-	ld	r8,8(r4)
-	addi	r4,r4,16
-	std	r6,0(r11)
-	std	r8,8(r11)
-	addi	r11,r11,16
-8:	/* Copy 8 bytes.  */
-	bf	28,L(tail4)
-	ld	r6,0(r4)
-	addi	r4,r4,8
-	std	r6,0(r11)
-	addi	r11,r11,8
-
-	.align	4
-/* Copies 4~7 bytes.  */
-L(tail4):
-	bf	29,L(tail2)
-	lwz	r6,0(r4)
-	stw	r6,0(r11)
-	bf	30,L(tail5)
-	lhz	r7,4(r4)
-	sth	r7,4(r11)
-	bflr	31
-	lbz	r8,6(r4)
-	stb	r8,6(r11)
-	blr
-
-	.align	4
-/* Copies 2~3 bytes.  */
-L(tail2):
-	bf	30,1f
-	lhz	r6,0(r4)
-	sth	r6,0(r11)
-	bflr	31
-	lbz	r7,2(r4)
-	stb	r7,2(r11)
-	blr
-
-	.align	4
-L(tail5):
-	bf	31,1f
-	lbz	r6,4(r4)
-	stb	r6,4(r11)
-	blr
-
-	.align	4
-1:
-	bflr	31
-	lbz	r6,0(r4)
-	stb	r6,0(r11)
-	blr
-
-/* Handles copies of 0~8 bytes.  */
-	.align	4
-L(copy_LE_8):
-	bne	cr6,L(tail4)
-	ld	r6,0(r4)
-	std	r6,0(r11)
-	blr
-END (FUNC_NAME)
-
-#ifndef USE_AS_STPCPY
-libc_hidden_builtin_def (strcpy)
-#endif
diff --git a/sysdeps/powerpc/powerpc64/power8/strcspn.S b/sysdeps/powerpc/powerpc64/power8/strcspn.S
deleted file mode 100644
index c2d130e..0000000
--- a/sysdeps/powerpc/powerpc64/power8/strcspn.S
+++ /dev/null
@@ -1,20 +0,0 @@
-/* Optimized strcspn implementation for PowerPC64/POWER8.
-   Copyright (C) 2016-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define USE_AS_STRCSPN 1
-#include <sysdeps/powerpc/powerpc64/power8/strspn.S>
diff --git a/sysdeps/powerpc/powerpc64/power8/strlen.S b/sysdeps/powerpc/powerpc64/power8/strlen.S
deleted file mode 100644
index 719b5c6..0000000
--- a/sysdeps/powerpc/powerpc64/power8/strlen.S
+++ /dev/null
@@ -1,290 +0,0 @@
-/* Optimized strlen implementation for PowerPC64/POWER8 using a vectorized
-   loop.
-   Copyright (C) 2016-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* TODO: change these to the actual instructions when the minimum required
-   binutils allows it.  */
-#define MFVRD(r,v)	.long (0x7c000067 | ((v)<<(32-11)) | ((r)<<(32-16)))
-#define VBPERMQ(t,a,b)	.long (0x1000054c \
-			       | ((t)<<(32-11))	\
-			       | ((a)<<(32-16))	\
-			       | ((b)<<(32-21)) )
-
-/* int [r3] strlen (char *s [r3])  */
-
-#ifndef STRLEN
-# define STRLEN strlen
-#endif
-
-/* TODO: change this to .machine power8 when the minimum required binutils
-   allows it.  */
-	.machine  power7
-ENTRY_TOCLESS (STRLEN, 4)
-	CALL_MCOUNT 1
-	dcbt	0,r3
-	clrrdi	r4,r3,3	      /* Align the address to doubleword boundary.  */
-	rlwinm	r6,r3,3,26,28 /* Calculate padding.  */
-	li	r0,0	      /* Doubleword with null chars to use
-				 with cmpb.  */
-	li	r5,-1	      /* MASK = 0xffffffffffffffff.  */
-	ld	r12,0(r4)     /* Load doubleword from memory.  */
-#ifdef __LITTLE_ENDIAN__
-	sld	r5,r5,r6
-#else
-	srd	r5,r5,r6      /* MASK = MASK >> padding.  */
-#endif
-	orc	r9,r12,r5     /* Mask bits that are not part of the string.  */
-	cmpb	r10,r9,r0     /* Check for null bytes in DWORD1.  */
-	cmpdi	cr7,r10,0     /* If r10 == 0, no null's have been found.  */
-	bne	cr7,L(done)
-
-	/* For shorter strings (< 64 bytes), we will not use vector registers,
-	   as the overhead isn't worth it.  So, let's use GPRs instead.  This
-	   will be done the same way as we do in the POWER7 implementation.
-	   Let's see if we are aligned to a quadword boundary.  If so, we can
-	   jump to the first (non-vectorized) loop.  Otherwise, we have to
-	   handle the next DWORD first.  */
-	mtcrf	0x01,r4
-	mr	r9,r4
-	addi	r9,r9,8
-	bt	28,L(align64)
-
-	/* Handle the next 8 bytes so we are aligned to a quadword
-	   boundary.  */
-	ldu	r5,8(r4)
-	cmpb	r10,r5,r0
-	cmpdi	cr7,r10,0
-	addi	r9,r9,8
-	bne	cr7,L(done)
-
-L(align64):
-	/* Proceed to the old (POWER7) implementation, checking two doublewords
-	   per iteraction.  For the first 56 bytes, we will just check for null
-	   characters.  After that, we will also check if we are 64-byte aligned
-	   so we can jump to the vectorized implementation.  We will unroll
-	   these loops to avoid excessive branching.  */
-	ld	r6,8(r4)
-	ldu	r5,16(r4)
-	cmpb	r10,r6,r0
-	cmpb	r11,r5,r0
-	or	r5,r10,r11
-	cmpdi	cr7,r5,0
-	addi	r9,r9,16
-	bne	cr7,L(dword_zero)
-
-	ld	r6,8(r4)
-	ldu	r5,16(r4)
-	cmpb	r10,r6,r0
-	cmpb	r11,r5,r0
-	or	r5,r10,r11
-	cmpdi	cr7,r5,0
-	addi	r9,r9,16
-	bne	cr7,L(dword_zero)
-
-	ld	r6,8(r4)
-	ldu	r5,16(r4)
-	cmpb	r10,r6,r0
-	cmpb	r11,r5,r0
-	or	r5,r10,r11
-	cmpdi	cr7,r5,0
-	addi	r9,r9,16
-	bne	cr7,L(dword_zero)
-
-	/* Are we 64-byte aligned? If so, jump to the vectorized loop.
-	   Note: aligning to 64-byte will necessarily slow down performance for
-	   strings around 64 bytes in length due to the extra comparisons
-	   required to check alignment for the vectorized loop.  This is a
-	   necessary tradeoff we are willing to take in order to speed up the
-	   calculation for larger strings.  */
-	andi.	r10,r9,63
-	beq	cr0,L(preloop)
-	ld	r6,8(r4)
-	ldu	r5,16(r4)
-	cmpb	r10,r6,r0
-	cmpb	r11,r5,r0
-	or	r5,r10,r11
-	cmpdi	cr7,r5,0
-	addi	r9,r9,16
-	bne	cr7,L(dword_zero)
-
-	andi.	r10,r9,63
-	beq	cr0,L(preloop)
-	ld	r6,8(r4)
-	ldu	r5,16(r4)
-	cmpb	r10,r6,r0
-	cmpb	r11,r5,r0
-	or	r5,r10,r11
-	cmpdi	cr7,r5,0
-	addi	r9,r9,16
-	bne	cr7,L(dword_zero)
-
-	andi.	r10,r9,63
-	beq	cr0,L(preloop)
-	ld	r6,8(r4)
-	ldu	r5,16(r4)
-	cmpb	r10,r6,r0
-	cmpb	r11,r5,r0
-	or	r5,r10,r11
-	cmpdi	cr7,r5,0
-	addi	r9,r9,16
-
-	/* At this point, we are necessarily 64-byte aligned.  If no zeroes were
-	   found, jump to the vectorized loop.  */
-	beq	cr7,L(preloop)
-
-L(dword_zero):
-	/* OK, one (or both) of the doublewords contains a null byte.  Check
-	   the first doubleword and decrement the address in case the first
-	   doubleword really contains a null byte.  */
-
-	cmpdi	cr6,r10,0
-	addi	r4,r4,-8
-	bne	cr6,L(done)
-
-	/* The null byte must be in the second doubleword.  Adjust the address
-	   again and move the result of cmpb to r10 so we can calculate the
-	   length.  */
-
-	mr	r10,r11
-	addi	r4,r4,8
-
-	/* If the null byte was found in the non-vectorized code, compute the
-	   final length.  r10 has the output of the cmpb instruction, that is,
-	   it contains 0xff in the same position as the null byte in the
-	   original doubleword from the string.  Use that to calculate the
-	   length.  */
-L(done):
-#ifdef __LITTLE_ENDIAN__
-	addi	r9, r10,-1    /* Form a mask from trailing zeros.  */
-	andc	r9, r9,r10
-	popcntd	r0, r9	      /* Count the bits in the mask.  */
-#else
-	cntlzd	r0,r10	      /* Count leading zeros before the match.  */
-#endif
-	subf	r5,r3,r4
-	srdi	r0,r0,3	      /* Convert leading/trailing zeros to bytes.  */
-	add	r3,r5,r0      /* Compute final length.  */
-	blr
-
-	/* Vectorized implementation starts here.  */
-	.p2align  4
-L(preloop):
-	/* Set up for the loop.  */
-	mr	r4,r9
-	li	r7, 16	      /* Load required offsets.  */
-	li	r8, 32
-	li	r9, 48
-	li	r12, 8
-	vxor	v0,v0,v0      /* VR with null chars to use with
-				 vcmpequb.  */
-
-	/* Main loop to look for the end of the string.  We will read in
-	   64-byte chunks.  Align it to 32 bytes and unroll it 3 times to
-	   leverage the icache performance.  */
-	.p2align  5
-L(loop):
-	lvx	  v1,r4,r0  /* Load 4 quadwords.  */
-	lvx	  v2,r4,r7
-	lvx	  v3,r4,r8
-	lvx	  v4,r4,r9
-	vminub	  v5,v1,v2  /* Compare and merge into one VR for speed.  */
-	vminub	  v6,v3,v4
-	vminub	  v7,v5,v6
-	vcmpequb. v7,v7,v0  /* Check for NULLs.  */
-	addi	  r4,r4,64  /* Adjust address for the next iteration.  */
-	bne	  cr6,L(vmx_zero)
-
-	lvx	  v1,r4,r0  /* Load 4 quadwords.  */
-	lvx	  v2,r4,r7
-	lvx	  v3,r4,r8
-	lvx	  v4,r4,r9
-	vminub	  v5,v1,v2  /* Compare and merge into one VR for speed.  */
-	vminub	  v6,v3,v4
-	vminub	  v7,v5,v6
-	vcmpequb. v7,v7,v0  /* Check for NULLs.  */
-	addi	  r4,r4,64  /* Adjust address for the next iteration.  */
-	bne	  cr6,L(vmx_zero)
-
-	lvx	  v1,r4,r0  /* Load 4 quadwords.  */
-	lvx	  v2,r4,r7
-	lvx	  v3,r4,r8
-	lvx	  v4,r4,r9
-	vminub	  v5,v1,v2  /* Compare and merge into one VR for speed.  */
-	vminub	  v6,v3,v4
-	vminub	  v7,v5,v6
-	vcmpequb. v7,v7,v0  /* Check for NULLs.  */
-	addi	  r4,r4,64  /* Adjust address for the next iteration.  */
-	beq	  cr6,L(loop)
-
-L(vmx_zero):
-	/* OK, we found a null byte.  Let's look for it in the current 64-byte
-	   block and mark it in its corresponding VR.  */
-	vcmpequb  v1,v1,v0
-	vcmpequb  v2,v2,v0
-	vcmpequb  v3,v3,v0
-	vcmpequb  v4,v4,v0
-
-	/* We will now 'compress' the result into a single doubleword, so it
-	   can be moved to a GPR for the final calculation.  First, we
-	   generate an appropriate mask for vbpermq, so we can permute bits into
-	   the first halfword.  */
-	vspltisb  v10,3
-	lvsl	  v11,r0,r0
-	vslb	  v10,v11,v10
-
-	/* Permute the first bit of each byte into bits 48-63.  */
-	VBPERMQ(v1,v1,v10)
-	VBPERMQ(v2,v2,v10)
-	VBPERMQ(v3,v3,v10)
-	VBPERMQ(v4,v4,v10)
-
-	/* Shift each component into its correct position for merging.  */
-#ifdef __LITTLE_ENDIAN__
-	vsldoi  v2,v2,v2,2
-	vsldoi  v3,v3,v3,4
-	vsldoi  v4,v4,v4,6
-#else
-	vsldoi	v1,v1,v1,6
-	vsldoi	v2,v2,v2,4
-	vsldoi	v3,v3,v3,2
-#endif
-
-	/* Merge the results and move to a GPR.  */
-	vor	v1,v2,v1
-	vor	v2,v3,v4
-	vor	v4,v1,v2
-	MFVRD(r10,v4)
-
-	 /* Adjust address to the begninning of the current 64-byte block.  */
-	addi	r4,r4,-64
-
-#ifdef __LITTLE_ENDIAN__
-	addi	r9, r10,-1    /* Form a mask from trailing zeros.  */
-	andc	r9, r9,r10
-	popcntd	r0, r9	      /* Count the bits in the mask.  */
-#else
-	cntlzd	r0,r10	      /* Count leading zeros before the match.  */
-#endif
-	subf	r5,r3,r4
-	add	r3,r5,r0      /* Compute final length.  */
-	blr
-
-END (STRLEN)
-libc_hidden_builtin_def (strlen)
diff --git a/sysdeps/powerpc/powerpc64/power8/strncase.S b/sysdeps/powerpc/powerpc64/power8/strncase.S
deleted file mode 100644
index 050b63a..0000000
--- a/sysdeps/powerpc/powerpc64/power8/strncase.S
+++ /dev/null
@@ -1,20 +0,0 @@
-/* Optimized strncasecmp implementation for POWER8.
-   Copyright (C) 2016-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#define USE_AS_STRNCASECMP 1
-#include <sysdeps/powerpc/powerpc64/power8/strcasecmp.S>
diff --git a/sysdeps/powerpc/powerpc64/power8/strncmp.S b/sysdeps/powerpc/powerpc64/power8/strncmp.S
deleted file mode 100644
index 2eefa4a..0000000
--- a/sysdeps/powerpc/powerpc64/power8/strncmp.S
+++ /dev/null
@@ -1,327 +0,0 @@
-/* Optimized strncmp implementation for PowerPC64/POWER8.
-   Copyright (C) 2015-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-#ifndef STRNCMP
-# define STRNCMP strncmp
-#endif
-
-/* Implements the function
-
-   int [r3] strncmp (const char *s1 [r3], const char *s2 [r4], size_t [r5] n)
-
-   The implementation uses unaligned doubleword access to avoid specialized
-   code paths depending of data alignment.  Although recent powerpc64 uses
-   64K as default, the page cross handling assumes minimum page size of
-   4k.  */
-
-	.machine  power7
-ENTRY_TOCLESS (STRNCMP, 4)
-	/* Check if size is 0.  */
-	mr.	r10,r5
-	beq	cr0,L(ret0)
-
-	/* Check if [s1]+16 or [s2]+16 will cross a 4K page boundary using
-	   the code:
-
-	    (((size_t) s1) % PAGE_SIZE > (PAGE_SIZE - ITER_SIZE))
-
-	   with PAGE_SIZE being 4096 and ITER_SIZE begin 16.  */
-	rldicl	r8,r3,0,52
-	cmpldi	cr7,r8,4096-16
-	bgt	cr7,L(pagecross)
-	rldicl	r9,r4,0,52
-	cmpldi	cr7,r9,4096-16
-	bgt	cr7,L(pagecross)
-
-	/* For short string up to 16 bytes, load both s1 and s2 using
-	   unaligned dwords and compare.  */
-	ld	r7,0(r3)
-	ld	r9,0(r4)
-	li	r8,0
-	cmpb	r8,r7,r8
-	cmpb	r6,r7,r9
-	orc.	r8,r8,r6
-	bne	cr0,L(different1)
-
-	/* If the string compared are equal, but size is less or equal
-	   to 8, return 0.  */
-	cmpldi	cr7,r10,8
-	li	r9,0
-	ble	cr7,L(ret1)
-	addi	r5,r10,-8
-
-	ld	r7,8(r3)
-	ld	r9,8(r4)
-	cmpb	r8,r7,r8
-	cmpb	r6,r7,r9
-	orc.	r8,r8,r6
-	bne	cr0,L(different0)
-
-	cmpldi	cr7,r5,8
-	mr	r9,r8
-	ble	cr7,L(ret1)
-
-	/* Update pointers and size.  */
-	addi	r10,r10,-16
-	addi	r3,r3,16
-	addi	r4,r4,16
-
-	/* Now it has checked for first 16 bytes, align source1 to doubleword
-	   and adjust source2 address.  */
-L(align_8b):
-	rldicl	r5,r3,0,61
-	rldicr	r3,r3,0,60
-	subf	r4,r5,r4
-	add	r10,r10,r5
-
-	/* At this point, source1 alignment is 0 and source2 alignment is
-	   between 0 and 7.  Check is source2 alignment is 0, meaning both
-	   sources have the same alignment.  */
-	andi.	r8,r4,0x7
-	beq	cr0,L(loop_eq_align_0)
-
-	li	r5,0
-	b	L(loop_ne_align_1)
-
-	/* If source2 is unaligned to doubleword, the code needs to check
-	   on each interation if the unaligned doubleword access will cross
-	   a 4k page boundary.  */
-	.align 4
-L(loop_ne_align_0):
-	ld	r7,0(r3)
-	ld	r9,0(r4)
-	cmpb	r8,r7,r5
-	cmpb	r6,r7,r9
-	orc.	r8,r8,r6
-	bne	cr0,L(different1)
-
-	cmpldi	cr7,r10,8
-	ble	cr7,L(ret0)
-	addi	r10,r10,-8
-	addi	r3,r3,8
-	addi	r4,r4,8
-L(loop_ne_align_1):
-	rldicl	r9,r4,0,52
-	cmpldi	r7,r9,4088
-	ble	cr7,L(loop_ne_align_0)
-	cmpdi	cr7,r10,0
-	beq	cr7,L(ret0)
-
-	lbz	r9,0(r3)
-	lbz	r8,0(r4)
-	cmplw	cr7,r9,r8
-	bne	cr7,L(byte_ne_4)
-	cmpdi	cr7,r9,0
-	beq	cr7,L(size_reached_0)
-
-	li	r9,r7
-	addi	r8,r3,1
-	mtctr	r9
-	addi	r4,r4,1
-	addi	r10,r10,-1
-	addi	r3,r3,8
-
-	/* The unaligned read of source2 will cross a 4K page boundary,
-	   and the different byte or NULL maybe be in the remaining page
-	   bytes.  Since it can not use the unaligned load the algorithm
-	   reads and compares 8 bytes to keep source1 doubleword aligned.  */
-	.align 4
-L(loop_ne_align_byte):
-	cmpdi	cr7,r10,0
-	addi	r10,r10,-1
-	beq	cr7,L(ret0)
-	lbz	r9,0(r8)
-	lbz	r7,0(r4)
-	addi	r8,r8,1
-	addi	r4,r4,1
-	cmplw	cr7,r9,r7
-	cmpdi	cr5,r9,0
-	bne	cr7,L(size_reached_2)
-	beq	cr5,L(size_reached_0)
-	bdnz	L(loop_ne_align_byte)
-
-	cmpdi	cr7,r10,0
-	bne+	cr7,L(loop_ne_align_0)
-
-	.align 4
-L(ret0):
-	li	r9,0
-L(ret1):
-	mr	r3,r9
-	blr
-
-	/* The code now check if r8 and r10 are different by issuing a
-	   cmpb and shift the result based on its output:
-
-	#ifdef __LITTLE_ENDIAN__
-	  leadzero = (__builtin_ffsl (z1) - 1);
-	  leadzero = leadzero > (n-1)*8 ? (n-1)*8 : leadzero;
-	  r1 = (r1 >> leadzero) & 0xFFUL;
-	  r2 = (r2 >> leadzero) & 0xFFUL;
-	#else
-	  leadzero = __builtin_clzl (z1);
-	  leadzero = leadzero > (n-1)*8 ? (n-1)*8 : leadzero;
-	  r1 = (r1 >> (56 - leadzero)) & 0xFFUL;
-	  r2 = (r2 >> (56 - leadzero)) & 0xFFUL;
-	#endif
-	  return r1 - r2;  */
-
-	.align 4
-L(different0):
-	mr	r10,r5
-#ifdef __LITTLE_ENDIAN__
-L(different1):
-        neg	r11,r8
-        sldi	r10,r10,3
-        and	r8,r11,r8
-        addi	r10,r10,-8
-        cntlzd	r8,r8
-        subfic	r8,r8,63
-        extsw 	r8,r8
-        cmpld	cr7,r8,r10
-        ble	cr7,L(different2)
-        mr	r8,r10
-L(different2):
-        extsw	r8,r8
-#else
-L(different1):
-	addi	r10,r10,-1
-	cntlzd	r8,r8
-	sldi	r10,r10,3
-	cmpld	cr7,r8,r10
-	blt	cr7,L(different2)
-	mr	r8,r10
-L(different2):
-	subfic	r8,r8,56
-#endif
-	srd	r7,r7,r8
-	srd	r9,r9,r8
-	rldicl	r3,r7,0,56
-	rldicl	r9,r9,0,56
-	subf	r9,r9,3
-	extsw	r9,r9
-	mr	r3,r9
-	blr
-
-	/* If unaligned 16 bytes reads across a 4K page boundary, it uses
-	   a simple byte a byte comparison until the page alignment for s1
-	   is reached.  */
-	.align 4
-L(pagecross):
-	lbz	r7,0(r3)
-	lbz	r9,0(r4)
-	subfic	r8,r8,4095
-	cmplw	cr7,r9,r7
-	bne	cr7,L(byte_ne_3)
-	cmpdi	cr7,r9,0
-	beq	cr7,L(byte_ne_0)
-	addi	r10,r10,-1
-	subf	r7,r8,r10
-	subf	r9,r7,r10
-	addi	r9,r9,1
-	mtctr	r9
-	b	L(pagecross_loop1)
-
-	.align 4
-L(pagecross_loop0):
-	beq	cr7,L(ret0)
-	lbz	r9,0(r3)
-	lbz	r8,0(r4)
-	addi	r10,r10,-1
-	cmplw	cr7,r9,r8
-	cmpdi	cr5,r9,0
-	bne	r7,L(byte_ne_2)
-	beq	r5,L(byte_ne_0)
-L(pagecross_loop1):
-	cmpdi	cr7,r10,0
-	addi	r3,r3,1
-	addi	r4,r4,1
-	bdnz	L(pagecross_loop0)
-	cmpdi	cr7,r7,0
-	li	r9,0
-	bne+	cr7,L(align_8b)
-	b	L(ret1)
-
-	/* If both source1 and source2 are doubleword aligned, there is no
-	   need for page boundary cross checks.  */
-	.align 4
-L(loop_eq_align_0):
-	ld	r7,0(r3)
-	ld	r9,0(r4)
-	cmpb	r8,r7,r8
-	cmpb	r6,r7,r9
-	orc.	r8,r8,r6
-	bne	cr0,L(different1)
-
-	cmpldi	cr7,r10,8
-	ble	cr7,L(ret0)
-	addi	r9,r10,-9
-
-	li	r5,0
-	srdi	r9,r9,3
-	addi	r9,r9,1
-	mtctr	r9
-	b	L(loop_eq_align_2)
-
-	.align 4
-L(loop_eq_align_1):
-	bdz	L(ret0)
-L(loop_eq_align_2):
-	ldu	r7,8(r3)
-	addi	r10,r10,-8
-	ldu	r9,8(r4)
-	cmpb	r8,r7,r5
-	cmpb	r6,r7,r9
-	orc.	r8,r8,r6
-	beq	cr0,L(loop_eq_align_1)
-	b	L(different1)
-
-	.align 4
-L(byte_ne_0):
-	li	r7,0
-L(byte_ne_1):
-	subf	r9,r9,r7
-	extsw	r9,r9
-	b	L(ret1)
-
-	.align 4
-L(byte_ne_2):
-	extsw	r7,r9
-	mr	r9,r8
-	b	L(byte_ne_1)
-L(size_reached_0):
-	li	r10,0
-L(size_reached_1):
-	subf	r9,r9,r10
-	extsw	r9,r9
-	b	L(ret1)
-L(size_reached_2):
-	extsw	r10,r9
-	mr	r9,r7
-	b	L(size_reached_1)
-L(byte_ne_3):
-	extsw	r7,r7
-	b	L(byte_ne_1)
-L(byte_ne_4):
-	extsw	r10,r9
-	mr	r9,r8
-	b	L(size_reached_1)
-END(STRNCMP)
-libc_hidden_builtin_def(strncmp)
diff --git a/sysdeps/powerpc/powerpc64/power8/strncpy.S b/sysdeps/powerpc/powerpc64/power8/strncpy.S
deleted file mode 100644
index e8c5c71..0000000
--- a/sysdeps/powerpc/powerpc64/power8/strncpy.S
+++ /dev/null
@@ -1,474 +0,0 @@
-/* Optimized strncpy/stpncpy implementation for PowerPC64/POWER8.
-   Copyright (C) 2015-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-#ifdef USE_AS_STPNCPY
-# ifndef STPNCPY
-#   define FUNC_NAME __stpncpy
-# else
-#   define FUNC_NAME STPNCPY
-# endif
-#else
-# ifndef STRNCPY
-#  define FUNC_NAME strncpy
-# else
-#  define FUNC_NAME STRNCPY
-# endif
-#endif  /* !USE_AS_STPNCPY  */
-
-#ifndef MEMSET
-/* For builds without IFUNC support, local calls should be made to internal
-   GLIBC symbol (created by libc_hidden_builtin_def).  */
-# ifdef SHARED
-#  define MEMSET_is_local
-#  define MEMSET   __GI_memset
-# else
-#  define MEMSET   memset
-# endif
-#endif
-
-#define FRAMESIZE (FRAME_MIN_SIZE+48)
-
-/* Implements the function
-
-   char * [r3] strncpy (char *dest [r3], const char *src [r4], size_t n [r5])
-
-   or
-
-   char * [r3] stpncpy (char *dest [r3], const char *src [r4], size_t n [r5])
-
-   if USE_AS_STPCPY is defined.
-
-   The implementation uses unaligned doubleword access to avoid specialized
-   code paths depending of data alignment.  Although recent powerpc64 uses
-   64K as default, the page cross handling assumes minimum page size of
-   4k.  */
-
-	.machine  power7
-#ifdef MEMSET_is_local
-ENTRY_TOCLESS (FUNC_NAME, 4)
-#else
-ENTRY (FUNC_NAME, 4)
-#endif
-	CALL_MCOUNT 3
-
-        /* Check if the [src]+15 will cross a 4K page by checking if the bit
-           indicating the page size changes.  Basically:
-
-           uint64_t srcin = (uint64_t)src;
-           uint64_t ob = srcin & 4096UL;
-           uint64_t nb = (srcin+15UL) & 4096UL;
-           if (ob ^ nb)
-             goto pagecross;  */
-
-	addi	r10,r4,16
-	rlwinm	r9,r4,0,19,19
-
-	/* Save some non-volatile registers on the stack.  */
-	std	r26,-48(r1)
-	std	r27,-40(r1)
-
-	rlwinm	r8,r10,0,19,19
-
-	std	r28,-32(r1)
-	std	r29,-24(r1)
-
-	cmpld	cr7,r9,r8
-
-	std	r30,-16(r1)
-	std	r31,-8(r1)
-
-	/* Update CFI.  */
-	cfi_offset(r26, -48)
-	cfi_offset(r27, -40)
-	cfi_offset(r28, -32)
-	cfi_offset(r29, -24)
-	cfi_offset(r30, -16)
-	cfi_offset(r31, -8)
-
-	beq	cr7,L(unaligned_lt_16)
-	rldicl	r9,r4,0,61
-	subfic	r8,r9,8
-	cmpld	cr7,r5,r8
-	bgt 	cr7,L(pagecross)
-
-	/* At this points there is 1 to 15 bytes to check and write.  Since it could
-	   be either from first unaligned 16 bytes access or from bulk copy, the code
-	   uses an unrolled byte read/write instead of trying to analyze the cmpb
-	   results.  */
-L(short_path):
-	mr	r9,r3
-L(short_path_1):
-	/* Return if there are no more bytes to be written.  */
-	cmpdi	cr7,r5,0
-	beq	cr7,L(short_path_loop_end_1)
-L(short_path_2):
-	/* Copy one char from src (r4) and write it to dest (r9).  If it is the
-	   end-of-string, start the null padding.  Continue, otherwise.  */
-	lbz	r10,0(r4)
-	cmpdi	cr7,r10,0
-	stb	r10,0(r9)
-	beq	cr7,L(zero_pad_start_1)
-	/* If there are no more bytes to be written, return.  */
-	cmpdi	cr0,r5,1
-	addi	r8,r9,1
-	addi	r6,r5,-1
-	beq	cr0,L(short_path_loop_end_0)
-	/* Copy another char from src (r4) to dest (r9).  Check again if it is
-	   the end-of-string.  If so, start the null padding.  */
-	lbz	r10,1(r4)
-	cmpdi	cr7,r10,0
-	stb	r10,1(r9)
-	beq	cr7,L(zero_pad_start_prepare_1)
-	/* Eagerly decrement r5 by 3, which is the number of bytes already
-	   written, plus one write that will be performed later on.  */
-	addi	r10,r5,-3
-	b	L(short_path_loop_1)
-
-	.align	4
-L(short_path_loop):
-	/* At this point, the induction variable, r5, as well as the pointers
-	   to dest and src (r9 and r4, respectivelly) have been updated.
-
-	   Note: The registers r7 and r10 are induction variables derived from
-	   r5.  They are used to determine if the total number of writes has
-	   been reached at every other write.
-
-	   Copy one char from src (r4) and write it to dest (r9).  If it is the
-	   end-of-string, start the null padding.  Continue, otherwise.  */
-	lbz	r8,0(r4)
-	addi	r7,r10,-2
-	cmpdi	cr5,r8,0
-	stb	r8,0(r9)
-	beq	cr5,L(zero_pad_start_1)
-	beq	cr7,L(short_path_loop_end_0)
-	/* Copy another char from src (r4) to dest (r9).  Check again if it is
-	   the end-of-string.  If so, start the null padding.  */
-	lbz	r8,1(r4)
-	cmpdi	cr7,r8,0
-	stb	r8,1(r9)
-	beq	cr7,L(zero_pad_start)
-	mr	r10,r7
-L(short_path_loop_1):
-	/* This block is reached after two chars have been already written to
-	   dest.  Nevertheless, r5 (the induction variable), r9 (the pointer to
-	   dest), and r4 (the pointer to src) have not yet been updated.
-
-	   At this point:
-	     r5 holds the count of bytes yet to be written plus 2.
-	     r9 points to the last two chars that were already written to dest.
-	     r4 points to the last two chars that were already copied from src.
-
-	   The algorithm continues by decrementing r5, the induction variable,
-	   so that it reflects the last two writes.  The pointers to dest (r9)
-	   and to src (r4) are increment by two, for the same reason.
-
-	   Note: Register r10 is another induction variable, derived from r5,
-	   which determines if the total number of writes has been reached.  */
-	addic.	r5,r5,-2
-	addi	r9,r9,2
-	cmpdi	cr7,r10,0 /* Eagerly check if the next write is the last.  */
-	addi	r4,r4,2
-	addi	r6,r9,1
-	bne	cr0,L(short_path_loop) /* Check if the total number of writes
-					  has been reached at every other
-					  write.  */
-#ifdef USE_AS_STPNCPY
-	mr	r3,r9
-	b	L(short_path_loop_end)
-#endif
-
-L(short_path_loop_end_0):
-#ifdef USE_AS_STPNCPY
-	addi	r3,r9,1
-	b	L(short_path_loop_end)
-#endif
-L(short_path_loop_end_1):
-#ifdef USE_AS_STPNCPY
-	mr	r3,r9
-#endif
-L(short_path_loop_end):
-	/* Restore non-volatile registers.  */
-	ld	r26,-48(r1)
-	ld	r27,-40(r1)
-	ld	r28,-32(r1)
-	ld	r29,-24(r1)
-	ld	r30,-16(r1)
-	ld	r31,-8(r1)
-	blr
-
-	/* This code pads the remainder of dest with NULL bytes.  The algorithm
-	   calculates the remaining size and calls memset.  */
-	.align	4
-L(zero_pad_start):
-	mr	r5,r10
-	mr	r9,r6
-L(zero_pad_start_1):
-	/* At this point:
-	     - r5 holds the number of bytes that still have to be written to
-	       dest.
-	     - r9 points to the position, in dest, where the first null byte
-	       will be written.
-	   The above statements are true both when control reaches this label
-	   from a branch or when falling through the previous lines.  */
-#ifndef USE_AS_STPNCPY
-	mr	r30,r3       /* Save the return value of strncpy.  */
-#endif
-	/* Prepare the call to memset.  */
-	mr	r3,r9        /* Pointer to the area to be zero-filled.  */
-	li	r4,0         /* Byte to be written (zero).  */
-
-	/* We delayed the creation of the stack frame, as well as the saving of
-	   the link register, because only at this point, we are sure that
-	   doing so is actually needed.  */
-
-	/* Save the link register.  */
-	mflr	r0
-	std	r0,16(r1)
-
-	/* Create the stack frame.  */
-	stdu	r1,-FRAMESIZE(r1)
-	cfi_adjust_cfa_offset(FRAMESIZE)
-	cfi_offset(lr, 16)
-
-	bl	MEMSET
-#ifndef MEMSET_is_local
-	nop
-#endif
-
-	ld	r0,FRAMESIZE+16(r1)
-
-#ifndef USE_AS_STPNCPY
-	mr	r3,r30       /* Restore the return value of strncpy, i.e.:
-				dest.  For stpncpy, the return value is the
-				same as return value of memset.  */
-#endif
-
-	/* Restore non-volatile registers and return.  */
-	ld	r26,FRAMESIZE-48(r1)
-	ld	r27,FRAMESIZE-40(r1)
-	ld	r28,FRAMESIZE-32(r1)
-	ld	r29,FRAMESIZE-24(r1)
-	ld	r30,FRAMESIZE-16(r1)
-	ld	r31,FRAMESIZE-8(r1)
-	/* Restore the stack frame.  */
-	addi	r1,r1,FRAMESIZE
-	cfi_adjust_cfa_offset(-FRAMESIZE)
-	/* Restore the link register.  */
-	mtlr	r0
-	cfi_restore(lr)
-	blr
-
-	/* The common case where [src]+16 will not cross a 4K page boundary.
-	   In this case the code fast check the first 16 bytes by using doubleword
-	   read/compares and update destiny if neither total size or null byte
-	   is found in destiny. */
-	.align	4
-L(unaligned_lt_16):
-	cmpldi	cr7,r5,7
-	ble	cr7,L(short_path)
-	ld	r7,0(r4)
-	li	r8,0
-	cmpb	r8,r7,r8
-	cmpdi	cr7,r8,0
-	bne	cr7,L(short_path_prepare_2)
-	addi	r6,r5,-8
-	std	r7,0(r3)
-	addi	r9,r3,8
-	cmpldi	cr7,r6,7
-	addi	r7,r4,8
-	ble	cr7,L(short_path_prepare_1_1)
-	ld	r4,8(r4)
-	cmpb	r8,r4,r8
-	cmpdi	cr7,r8,0
-	bne	cr7,L(short_path_prepare_2_1)
-	std	r4,8(r3)
-	addi	r29,r3,16
-	addi	r5,r5,-16
-	/* Neither the null byte was found or total length was reached,
-	   align to 16 bytes and issue a bulk copy/compare.  */
-	b	L(align_to_16b)
-
-	/* In the case of 4k page boundary cross, the algorithm first align
-	   the address to a doubleword, calculate a mask based on alignment
-	   to ignore the bytes and continue using doubleword.  */
-	.align	4
-L(pagecross):
-	rldicr	r11,r4,0,59	/* Align the address to 8 bytes boundary.  */
-	li	r6,-1		/* MASK = 0xffffffffffffffffUL.  */
-	sldi	r9,r9,3		/* Calculate padding.  */
-	ld	r7,0(r11)	/* Load doubleword from memory.  */
-#ifdef __LITTLE_ENDIAN__
-	sld	r9,r6,r9	/* MASK = MASK << padding.  */
-#else
-	srd	r9,r6,r9	/* MASK = MASK >> padding.  */
-#endif
-	orc	r9,r7,r9	/* Mask bits that are not part of the
-				   string.  */
-	li	r7,0
-	cmpb	r9,r9,r7	/* Check for null bytes in DWORD1.  */
-	cmpdi	cr7,r9,0
-	bne	cr7,L(short_path_prepare_2)
-	subf	r8,r8,r5	/* Adjust total length.  */
-	cmpldi	cr7,r8,8	/* Check if length was reached.  */
-	ble	cr7,L(short_path_prepare_2)
-
-	/* For next checks we have aligned address, so we check for more
-	   three doublewords to make sure we can read 16 unaligned bytes
-	   to start the bulk copy with 16 aligned addresses.  */
-	ld	r7,8(r11)
-	cmpb	r9,r7,r9
-	cmpdi	cr7,r9,0
-	bne	cr7,L(short_path_prepare_2)
-	addi	r7,r8,-8
-	cmpldi	cr7,r7,8
-	ble	cr7,L(short_path_prepare_2)
-	ld	r7,16(r11)
-	cmpb	r9,r7,r9
-	cmpdi	cr7,r9,0
-	bne	cr7,L(short_path_prepare_2)
-	addi	r8,r8,-16
-	cmpldi	cr7,r8,8
-	ble	cr7,L(short_path_prepare_2)
-	ld	r8,24(r11)
-	cmpb	r9,r8,r9
-	cmpdi	cr7,r9,0
-	bne	cr7,L(short_path_prepare_2)
-
-	/* No null byte found in the 32 bytes readed and length not reached,
-	   read source again using unaligned loads and store them.  */
-	ld	r9,0(r4)
-	addi	r29,r3,16
-	addi	r5,r5,-16
-	std	r9,0(r3)
-	ld	r9,8(r4)
-	std	r9,8(r3)
-
-	/* Align source to 16 bytes and adjust destiny and size.  */
-L(align_to_16b):
-	rldicl	r9,r10,0,60
-	rldicr	r28,r10,0,59
-	add	r12,r5,r9
-	subf	r29,r9,r29
-
-	/* The bulk read/compare/copy loads two doublewords, compare and merge
-	   in a single register for speed.  This is an attempt to speed up the
-	   null-checking process for bigger strings.  */
-
-	cmpldi	cr7,r12,15
-	ble	cr7,L(short_path_prepare_1_2)
-
-	/* Main loop for large sizes, unrolled 2 times to get better use of
-	   pipeline.  */
-	ld	r8,0(28)
-	ld	r10,8(28)
-	li	r9,0
-	cmpb	r7,r8,r9
-	cmpb	r9,r10,r9
-	or.	r6,r9,r7
-	bne	cr0,L(short_path_prepare_2_3)
-	addi	r5,r12,-16
-	addi	r4,r28,16
-	std	r8,0(r29)
-	std	r10,8(r29)
-	cmpldi	cr7,r5,15
-	addi	r9,r29,16
-	ble	cr7,L(short_path_1)
-	mr	r11,r28
-	mr	r6,r29
-	li	r30,0
-	subfic	r26,r4,48
-	subfic	r27,r9,48
-
-	b	L(loop_16b)
-
-	.align	4
-L(loop_start):
-	ld	r31,0(r11)
-	ld	r10,8(r11)
-	cmpb	r0,r31,r7
-	cmpb	r8,r10,r7
-	or.	r7,r0,r8
-	addi	r5,r5,-32
-	cmpldi	cr7,r5,15
-	add	r4,r4,r26
-	add	r9,r9,r27
-	bne	cr0,L(short_path_prepare_2_2)
-	add	r4,r28,r4
-	std	r31,0(r6)
-	add	r9,r29,r9
-	std	r10,8(r6)
-	ble	cr7,L(short_path_1)
-
-L(loop_16b):
-	ld	r10,16(r11)
-	ld	r0,24(r11)
-	cmpb	r8,r10,r30
-	cmpb	r7,r0,r30
-	or.	r7,r8,r7
-	addi	r12,r12,-32
-	cmpldi	cr7,r12,15
-	addi	r11,r11,32
-	bne	cr0,L(short_path_2)
-	std	r10,16(r6)
-	addi	r6,r6,32
-	std	r0,-8(r6)
-	bgt	cr7,L(loop_start)
-
-	mr	r5,r12
-	mr	r4,r11
-	mr	r9,r6
-	b	L(short_path_1)
-
-	.align	4
-L(short_path_prepare_1_1):
-	mr	r5,r6
-	mr	r4,r7
-	b	L(short_path_1)
-L(short_path_prepare_1_2):
-	mr	r5,r12
-	mr	r4,r28
-	mr	r9,r29
-	b	L(short_path_1)
-L(short_path_prepare_2):
-	mr	r9,r3
-	b	L(short_path_2)
-L(short_path_prepare_2_1):
-	mr	r5,r6
-	mr	r4,r7
-	b	L(short_path_2)
-L(short_path_prepare_2_2):
-	mr	r5,r12
-	mr	r4,r11
-	mr	r9,r6
-	b	L(short_path_2)
-L(short_path_prepare_2_3):
-	mr	r5,r12
-	mr	r4,r28
-	mr	r9,r29
-	b	L(short_path_2)
-L(zero_pad_start_prepare_1):
-	mr	r5,r6
-	mr	r9,r8
-	b	L(zero_pad_start_1)
-END (FUNC_NAME)
-
-#ifndef USE_AS_STPNCPY
-libc_hidden_builtin_def (strncpy)
-#endif
diff --git a/sysdeps/powerpc/powerpc64/power8/strnlen.S b/sysdeps/powerpc/powerpc64/power8/strnlen.S
deleted file mode 100644
index a98dfba..0000000
--- a/sysdeps/powerpc/powerpc64/power8/strnlen.S
+++ /dev/null
@@ -1,425 +0,0 @@
-/* Optimized strnlen implementation for POWER8 using a vmx loop.
-
-   Copyright (C) 2017-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-/* It is implemented the following heuristic:
-	1. Case maxlen <= 32: align the pointer to 8 bytes to loop through
-	reading doublewords. Uses the POWER7 algorithm.
-	2. Case maxlen > 32: check for null bytes in the first 16 bytes using
-	unaligned accesses. Return length if found. Otherwise:
-		2.1 Case maxlen < 64: deduct the bytes previously read, align
-		the pointer to 16 bytes and loop through reading quadwords
-		until find null bytes or reach maxlen.
-		2.2 Case maxlen > 64: deduct the bytes previously read, align
-		the pointer to 64 bytes and set up a counter to loop through
-		reading in strides of 64 bytes. In case it finished the loop
-		with null bytes not found, process the remainder bytes by
-		switching to the loop to heuristic in 2.1.  */
-
-#include <sysdep.h>
-
-/* Define default page size to 4KB.  */
-#define PAGE_SIZE 4096
-
-/* The following macros implement Power ISA v2.07 opcodes
-   that could not be used directly into this code to the keep
-   compatibility with older binutils versions.  */
-
-/* Move from vector register doubleword.  */
-#define MFVRD(r,v) .long (0x7c000067 | ((v)<<(32-11)) | ((r)<<(32-16)))
-
-/* Move to vector register doubleword.  */
-#define MTVRD(v,r) .long (0x7c000167 | ((v)<<(32-11)) | ((r)<<(32-16)))
-
-/* Vector Bit Permute Quadword.  */
-#define VBPERMQ(t,a,b)	.long (0x1000054c	\
-			       | ((t)<<(32-11))	\
-			       | ((a)<<(32-16))	\
-			       | ((b)<<(32-21)) )
-
-/* Vector Population Count Halfword.  */
-#define VPOPCNTH(t,b) .long (0x10000743 | ((t)<<(32-11)) | ((b)<<(32-21)))
-
-/* Vector Count Leading Zeros Halfword.  */
-#define VCLZH(t,b) .long (0x10000742 | ((t)<<(32-11)) | ((b)<<(32-21)))
-
-
-/* int [r3] strnlen (char *s [r3], size_t maxlen [r4])  */
-/* TODO: change to power8 when minimum required binutils allows it.  */
-	.machine  power7
-ENTRY_TOCLESS (__strnlen)
-	CALL_MCOUNT 2
-	dcbt	0,r3
-
-	cmpldi	r4,32           /* Check if maxlen <= 32.  */
-	ble	L(small_range)  /* If maxlen <= 32.  */
-
-	/* Upcoming 16 bytes unaligned accesses cannot cross the page boundary
-	   otherwise the processor throws an memory access error.
-	   Use following code to check there is room for such as accesses:
-	     (((size_t) s) % PAGE_SIZE > (PAGE_SIZE - 16)
-	   If it is disallowed then switch to the code that handles
-	   the string when maxlen <= 32.  */
-	clrldi	r10,r3,52
-	cmpldi  cr7,r10,PAGE_SIZE-16
-	bgt     cr7,L(small_range)	/* If less than 16B of page end.  */
-
-	/* Compute our permute constant r8.  */
-	li	r7,0
-	/* Compute a bpermd constant to move bit 0 of each word into
-	   a halfword value, and count trailing zeros.  */
-#ifdef __LITTLE_ENDIAN__
-	li	r8,0x2820
-	oris	r8,r8,0x3830
-	sldi	r8,r8,32
-	ori	r8,r8,0x0800
-	oris	r8,r8,0x1810
-#else
-	li	r8,0x1018
-	oris	r8,r8,0x0008
-	sldi	r8,r8,32
-	ori	r8,r8,0x3038
-	oris	r8,r8,0x2028
-#endif
-
-	/* maxlen > 32. Optimistically check for null bytes in the first
-	   16 bytes of the string using unaligned accesses.  */
-	ld	r5,0(r3)
-	ld	r6,8(r3)
-	cmpb	r10,r7,r5		/* Check for null bytes in DWORD1.  */
-	cmpb	r11,r7,r6		/* Check for null bytes in DWORD2.  */
-	or.	r7,r10,r11
-	bne	cr0, L(early_find)	/* If found null bytes.  */
-
-	/* At this point maxlen > 32 and null bytes were not found at first
-	   16 bytes. Prepare for loop using VMX.  */
-
-	/* r3 == s, r4 == maxlen. All other volatile regs are unused now.  */
-
-	addi	r5,r3,16	/* Align up, or just add the 16B we
-				   already checked.  */
-	li	r0,15
-	and	r7,r5,r0	/* Find offset into 16B alignment.  */
-	andc	r5,r5,r0	/* Quadword align up s to the next quadword.  */
-	li	r0,16
-	subf	r0,r7,r0
-	subf	r4,r0,r4	/* Deduct unaligned bytes from maxlen.  */
-
-
-	/* Compute offsets for vmx loads, and precompute the vbpermq
-	   constants for both the 64B and 16B loops.  */
-	li	r6,0
-	vspltisb  v0,0
-	vspltisb  v10,3
-	lvsl	  v11,r6,r6
-	vslb	  v10,v11,v10
-
-	cmpldi  r4,64		/* Check maxlen < 64.  */
-	blt	L(smaller)	/* If maxlen < 64 */
-
-	/* In order to begin the 64B loop, it needs to be 64
-	   bytes aligned. So read quadwords until it is aligned or found null
-	   bytes. At worst case it will be aligned after the fourth iteration,
-	   so unroll the loop to avoid counter checking.  */
-	andi.   r7,r5,63		/* Check if is 64 bytes aligned.  */
-	beq     cr0,L(preloop_64B)	/* If it is already 64B aligned.  */
-	lvx     v1,r5,r6
-	vcmpequb.       v1,v1,v0
-	addi    r5,r5,16
-	addi    r4,r4,-16		/* Decrement maxlen in 16 bytes. */
-	bne     cr6,L(found_aligning64B) /* If found null bytes.  */
-
-	/* Unroll 2x above code block until aligned or find null bytes.  */
-	andi.   r7,r5,63
-	beq     cr0,L(preloop_64B)
-	lvx     v1,r5,r6
-	vcmpequb.      v1,v1,v0
-	addi    r5,r5,16
-	addi    r4,r4,-16
-	bne     cr6,L(found_aligning64B)
-
-	andi.   r7,r5,63
-	beq     cr0,L(preloop_64B)
-	lvx     v1,r5,r6
-	vcmpequb.      v1,v1,v0
-	addi    r5,r5,16
-	addi    r4,r4,-16
-	bne     cr6,L(found_aligning64B)
-
-	/* At this point it should be 16 bytes aligned.
-	   Prepare for the 64B loop.  */
-	.p2align 4
-L(preloop_64B):
-	/* Check if maxlen became is less than 64, therefore disallowing the
-	   64B loop. If it happened switch to the 16B loop code.  */
-	cmpldi  r4,64		/* Check if maxlen < 64.  */
-	blt     L(smaller)	/* If maxlen < 64.  */
-	/* Set some constant values.  */
-	li      r7,16
-	li      r10,32
-	li      r9,48
-
-	/* Compute the number of 64 bytes iterations needed.  */
-	srdi	r11,r4,6	/* Compute loop count (maxlen / 64).  */
-	andi.	r4,r4,63	/* Set maxlen the remainder (maxlen % 64).  */
-	mtctr	r11		/* Move loop count to counter register.  */
-
-	/* Handle maxlen > 64. Loop over the bytes in strides of 64B.  */
-	.p2align 4
-L(loop_64B):
-	lvx	v1,r5,r6	/* r5 is the pointer to s.  */
-	lvx	v2,r5,r7
-	lvx	v3,r5,r10
-	lvx	v4,r5,r9
-	/* Compare the four 16B vectors to obtain the least 16 values.
-	   Null bytes should emerge into v7, then check for null bytes.  */
-	vminub	v5,v1,v2
-	vminub	v6,v3,v4
-	vminub	v7,v5,v6
-	vcmpequb. v7,v7,v0		/* Check for null bytes.  */
-	addi	r5,r5,64		/* Add pointer to next iteraction.  */
-	bne	cr6,L(found_64B)	/* If found null bytes.  */
-	bdnz	L(loop_64B)		/* Continue the loop if count > 0. */
-
-/* Hit loop end without null match. So branch to handle the remainder.  */
-
-	/* Prepare a 16B loop to handle two cases:
-		1. If 32 > maxlen < 64.
-		2. If maxlen >= 64, and reached end of the 64B loop with null
-		bytes not found. Thus handle the remainder bytes here. */
-	.p2align 4
-L(smaller):
-        cmpldi  r4,0            /* Check maxlen is zero.  */
-        beq     L(done)         /* If maxlen is zero.  */
-
-	/* Place rounded up number of qw's to check into a vmx
-	   register, and use some vector tricks to minimize
-	   branching.  */
-        MTVRD(v7,r4)            /* Copy maxlen from GPR to vector register. */
-        vspltisb v5,1
-        vspltisb v6,15
-        vspltb   v2,v7,7
-        vaddubs  v3,v5,v6
-
-#ifdef __LITTLE_ENDIAN__
-	vspltish v5,1           /* Compute 16 in each byte.  */
-#endif
-
-	/* Loop in 16B aligned incremements now. */
-	.p2align 4
-L(loop_16B):
-	lvx     v1,r5,r6        /* Load quadword into vector register.  */
-	addi    r5,r5,16        /* Increment address to next 16B block.  */
-	vor     v7,v2,v2        /* Save loop count (v2) into v7. */
-	vsububs v2,v2,v3        /* Subtract 16B from count, saturate at 0. */
-	vminub  v4,v1,v2
-	vcmpequb. v4,v4,v0      /* Checking for null bytes.  */
-	beq     cr6,L(loop_16B) /* If null bytes not found.  */
-
-	vcmpequb  v1,v1,v0
-	VBPERMQ(v1,v1,v10)
-#ifdef __LITTLE_ENDIAN__
-	vsubuhm  v2,v1,v5       /* Form a mask of trailing zeros.  */
-	vandc    v2,v2,v1
-	VPOPCNTH(v1,v2)         /* Count of trailing zeros, 16 if none.  */
-#else
-	VCLZH(v1,v1)            /* Count the leading zeros, 16 if none.  */
-#endif
-	/* Truncate to maximum allowable offset.  */
-	vcmpgtub v2,v1,v7       /* Compare and truncate for matches beyond
-				   maxlen.  */
-	vsel     v1,v1,v7,v2    /* 0-16 is now in byte 7.  */
-
-	MFVRD(r0,v1)
-	addi    r5,r5,-16       /* Undo speculative bump.  */
-	extsb   r0,r0           /* Clear whatever gunk is in the high 56b.  */
-	add     r5,r5,r0        /* Add the offset of whatever was found.  */
-L(done):
-	subf    r3,r3,r5        /* Length is equal to the offset of null byte
-				   matched minus the pointer to s.  */
-	blr                     /* Done.  */
-
-	/* Handle case of maxlen > 64 and found null bytes in last block
-	   of 64 bytes read.  */
-	.p2align 4
-L(found_64B):
-	/* A zero was found. Reduce the result.  */
-	vcmpequb  v1,v1,v0
-	vcmpequb  v2,v2,v0
-	vcmpequb  v3,v3,v0
-	vcmpequb  v4,v4,v0
-
-	/* Permute the first bit of each byte into bits 48-63.  */
-	VBPERMQ(v1,v1,v10)
-	VBPERMQ(v2,v2,v10)
-	VBPERMQ(v3,v3,v10)
-	VBPERMQ(v4,v4,v10)
-
-	/* Shift each component into its correct position for merging.  */
-#ifdef __LITTLE_ENDIAN__
-	vsldoi	v2,v2,v2,2
-	vsldoi	v3,v3,v3,4
-	vsldoi	v4,v4,v4,6
-#else
-	vsldoi	v1,v1,v1,6
-	vsldoi	v2,v2,v2,4
-	vsldoi	v3,v3,v3,2
-#endif
-
-	/* Merge the results and move to a GPR.  */
-	vor	v1,v2,v1
-	vor	v2,v3,v4
-	vor	v4,v1,v2
-
-	/* Adjust address to the start of the current 64B block.  */
-	addi	r5,r5,-64
-
-	MFVRD(r10,v4)
-#ifdef __LITTLE_ENDIAN__
-	addi	r9,r10,-1	/* Form a mask from trailing zeros.  */
-	andc	r9,r9,r10
-	popcntd	r0,r9		/* Count the bits in the mask.  */
-#else
-	cntlzd	r0,r10		/* Count leading zeros before the match.  */
-#endif
-	subf	r5,r3,r5
-	add	r3,r5,r0	/* Compute final length.  */
-	blr                     /* Done.  */
-
-	/* Handle case where null bytes were found while aligning
-	   as a preparation for the 64B loop.  */
-	.p2align 4
-L(found_aligning64B):
-	VBPERMQ(v1,v1,v10)
-#ifdef __LITTLE_ENDIAN__
-	MFVRD(r10,v1)
-	addi    r9,r10,-1       /* Form a mask from trailing zeros.  */
-	andc    r9,r9,r10
-	popcntd r0,r9           /* Count the bits in the mask.  */
-#else
-	vsldoi  v1,v1,v1,6
-	MFVRD(r10,v1)
-	cntlzd  r0,r10          /* Count leading zeros before the match.  */
-#endif
-	addi    r5,r5,-16	/* Adjust address to offset of last 16 bytes
-				   read.  */
-	/* Calculate length as subtracted the pointer to s of last 16 bytes
-	   offset, added with the bytes before the match.  */
-	subf    r5,r3,r5
-	add     r3,r5,r0
-	blr			/* Done.  */
-
-	/* Handle case of maxlen > 32 and found a null bytes within the first
-	   16 bytes of s.  */
-	.p2align 4
-L(early_find):
-	bpermd	r5,r8,r10        /* r8 contains the bit permute constants.  */
-	bpermd	r6,r8,r11
-	sldi	r5,r5,8
-	or	r5,r5,r6	/* r5 should hold a 16B mask of
-				   a potential 0.  */
-	cntlzd	r5,r5		/* Count leading zeros.  */
-	addi	r3,r5,-48	/* Deduct the 48 leading zeros always
-				   present.  */
-	blr			/* Done.  */
-
-	/* Handle case of maxlen <= 32. Use the POWER7 algorithm.  */
-	.p2align 4
-L(small_range):
-	clrrdi	r8,r3,3  	/* Align the pointer to 8B.  */
-	li	r0,0
-	/* Register's content at this point:
-	   r3 == pointer to s, r4 == maxlen, r8 == pointer to s aligned to 8B,
-	   r7 == last acceptable address. */
-	cmpldi	r4,0                 /* Check if maxlen is zero.  */
-	beq	L(end_max)	     /* If maxlen is zero.  */
-
-	/* Calculate the last acceptable address and check for possible
-	   addition overflow by using satured math:
-	   r7 = r3 + r4
-	   r7 |= -(r7 < x)  */
-	add     r7,r3,r4
-	subfc   r6,r3,r7
-	subfe   r9,r9,r9
-	extsw   r6,r9
-	or      r7,r7,r6
-	addi    r7,r7,-1
-
-	clrrdi	r7,r7,3              /* Align to 8B address of last
-					acceptable address.  */
-
-	rlwinm	r6,r3,3,26,28        /* Calculate padding.  */
-	ld	r12,0(r8)            /* Load aligned doubleword.  */
-	cmpb	r10,r12,r0           /* Check for null bytes. */
-#ifdef __LITTLE_ENDIAN__
-	srd	r10,r10,r6
-	sld	r10,r10,r6
-#else
-	sld	r10,r10,r6
-	srd	r10,r10,r6
-#endif /* __LITTLE_ENDIAN__  */
-	cmpldi	cr7,r10,0
-	bne	cr7,L(done_small)    /* If found null byte.  */
-
-	cmpld	r8,r7                /* Check if reached maxlen.  */
-	beq	L(end_max)	     /* If reached maxlen.  */
-
-	/* Still handling case of maxlen <= 32. Read doubleword aligned until
-	   find null bytes or reach maxlen.  */
-	.p2align 4
-L(loop_small):
-	ldu	r12,8(r8)         /* Load next doubleword and update r8.  */
-	cmpb	r10,r12,r0        /* Check for null bytes.  */
-	cmpldi	cr6,r10,0
-	bne	cr6,L(done_small) /* If found null bytes.  */
-	cmpld	r8,r7             /* Check if reached maxlen. */
-	bne	L(loop_small)	  /* If it has more bytes to read.  */
-	mr	r3,r4             /* Reached maxlen with null bytes not found.
-				     Length is equal to maxlen.  */
-	blr			  /* Done.  */
-
-	/* Still handling case of maxlen <= 32. Found null bytes.
-	   Registers: r10 == match bits within doubleword, r8 == address of
-	   last doubleword read, r3 == pointer to s, r4 == maxlen.  */
-	.p2align 4
-L(done_small):
-#ifdef __LITTLE_ENDIAN__
-	/* Count trailing zeros.  */
-	addi	r0,r10,-1
-	andc	r0,r0,r10
-	popcntd	r0,r0
-#else
-	cntlzd	r0,r10	      /* Count leading zeros before the match.  */
-#endif
-	sub	r3,r8,r3      /* Calculate total of bytes before the match.  */
-	srdi	r0,r0,3	      /* Convert leading/trailing zeros to bytes.  */
-	add	r3,r3,r0      /* Length until the match.  */
-	cmpld	r3,r4         /* Check length is greater than maxlen.  */
-	blelr
-	mr	r3,r4	      /* If length is greater than maxlen, return
-				 maxlen.  */
-	blr
-
-	/* Handle case of reached maxlen with null bytes not found.  */
-	.p2align 4
-L(end_max):
-	mr	r3,r4	/* Length is equal to maxlen.  */
-	blr		/* Done.  */
-
-
-END (__strnlen)
-libc_hidden_def (__strnlen)
-weak_alias (__strnlen, strnlen)
-libc_hidden_def (strnlen)
diff --git a/sysdeps/powerpc/powerpc64/power8/strrchr.S b/sysdeps/powerpc/powerpc64/power8/strrchr.S
deleted file mode 100644
index 6ff8a52..0000000
--- a/sysdeps/powerpc/powerpc64/power8/strrchr.S
+++ /dev/null
@@ -1,468 +0,0 @@
-/* Optimized strrchr implementation for PowerPC64/POWER7 using cmpb insn.
-   Copyright (C) 2017-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* char *[r3] strrchr (char *s [r3], int c [r4])  */
-/* TODO: change these to the actual instructions when the minimum required
-   binutils allows it.  */
-#define MTVRD(v,r) .long (0x7c000167 | ((v)<<(32-11)) | ((r)<<(32-16)))
-#define MFVRD(r,v) .long (0x7c000067 | ((v)<<(32-11)) | ((r)<<(32-16)))
-#define VBPERMQ(t,a,b)  .long (0x1000054c \
-				| ((t)<<(32-11)) \
-				| ((a)<<(32-16)) \
-				| ((b)<<(32-21)) )
-#define VCLZD(r,v) .long (0x100007c2 | ((r)<<(32-11)) | ((v)<<(32-21)))
-#define VPOPCNTD(r,v) .long (0x100007c3 | ((r)<<(32-11)) | ((v)<<(32-21)))
-#define VADDUQM(t,a,b)  .long (0x10000100 \
-				| ((t)<<(32-11)) \
-				| ((a)<<(32-16)) \
-				| ((b)<<(32-21)) )
-#ifdef __LITTLE_ENDIAN__
-/* Find the match position from v6 and place result in r6.  */
-# define CALCULATE_MATCH() \
-	VBPERMQ(v6, v6, v10); \
-	vsldoi	v6, v6, v6, 6; \
-	MFVRD(r7, v6); \
-	cntlzd	r6, r7; \
-	subfic	r6, r6, 15;
-/*
- * Find the first null position to mask bytes after null.
- * (reg): vcmpequb result: v2 for 1st qw v3 for 2nd qw.
- * Result placed at v2.
- */
-# define FIND_NULL_POS(reg) \
-	vspltisb	v11, -1; \
-	VADDUQM(v11, reg, v11); \
-	vandc	v11, v11, reg; \
-	VPOPCNTD(v2, v11); \
-	vspltb	v11, v2, 15; \
-	vcmpequb.	v11, v11, v9; \
-	blt	cr6, 1f; \
-	vsldoi	v9, v0, v9, 1; \
-	vslo	v2, v2, v9; \
-1: \
-	vsumsws	v2, v2, v0;
-#else
-# define CALCULATE_MATCH() \
-	VBPERMQ(v6, v6, v10); \
-	MFVRD(r7, v6); \
-	addi	r6, r7, -1; \
-	andc	r6, r6, r7; \
-	popcntd	r6, r6; \
-	subfic	r6, r6, 15;
-# define FIND_NULL_POS(reg) \
-	VCLZD(v2, reg); \
-	vspltb	v11, v2, 7; \
-	vcmpequb.	v11, v11, v9; \
-	blt	cr6, 1f; \
-	vsldoi	v9, v0, v9, 1; \
-	vsro	v2, v2, v9; \
-1: \
-	vsumsws	v2, v2, v0;
-#endif	/* !__LITTLE_ENDIAN__  */
-
-#ifndef STRRCHR
-# define STRRCHR strrchr
-#endif
-	.machine  power7
-ENTRY_TOCLESS (STRRCHR)
-	CALL_MCOUNT 2
-	dcbt	0,r3
-	clrrdi	r8,r3,3	      /* Align the address to doubleword boundary.  */
-	cmpdi	cr7,r4,0
-	ld	r12,0(r8)     /* Load doubleword from memory.  */
-	li	r9,0	      /* Used to store last occurence.  */
-	li	r0,0	      /* Doubleword with null chars to use
-				 with cmpb.  */
-
-	rlwinm	r6,r3,3,26,28 /* Calculate padding.  */
-
-	beq	cr7,L(null_match)
-
-	/* Replicate byte to doubleword.  */
-	insrdi	r4,r4,8,48
-	insrdi	r4,r4,16,32
-	insrdi	r4,r4,32,0
-
-	/* r4 is changed now.  If it's passed more chars, then
-	   check for null again.  */
-	cmpdi	cr7,r4,0
-	beq	cr7,L(null_match)
-	/* Now r4 has a doubleword of c bytes and r0 has
-	   a doubleword of null bytes.  */
-
-	cmpb	r10,r12,r4     /* Compare each byte against c byte.  */
-	cmpb	r11,r12,r0     /* Compare each byte against null byte.  */
-
-	/* Move the doublewords left and right to discard the bits that are
-	   not part of the string and bring them back as zeros.  */
-#ifdef __LITTLE_ENDIAN__
-	srd	r10,r10,r6
-	srd	r11,r11,r6
-	sld	r10,r10,r6
-	sld	r11,r11,r6
-#else
-	sld	r10,r10,r6
-	sld	r11,r11,r6
-	srd	r10,r10,r6
-	srd	r11,r11,r6
-#endif
-	or	r5,r10,r11    /* OR the results to speed things up.  */
-	cmpdi	cr7,r5,0      /* If r5 == 0, no c or null bytes
-				 have been found.  */
-	bne	cr7,L(done)
-
-L(align):
-	andi.	r12, r8, 15
-
-	/* Are we now aligned to a doubleword boundary?  If so, skip to
-	   the main loop.  Otherwise, go through the alignment code.  */
-
-	bne	cr0, L(loop)
-
-	/* Handle WORD2 of pair.  */
-	ldu	r12,8(r8)
-	cmpb	r10,r12,r4
-	cmpb	r11,r12,r0
-	or	r5,r10,r11
-	cmpdi	cr7,r5,0
-	bne	cr7,L(done)
-	b	L(loop)	      /* We branch here (rather than falling through)
-				 to skip the nops due to heavy alignment
-				 of the loop below.  */
-	.p2align  5
-L(loop):
-	/* Load two doublewords, compare and merge in a
-	   single register for speed.  This is an attempt
-	   to speed up the null-checking process for bigger strings.  */
-	ld	r12,8(r8)
-	ldu	r7,16(r8)
-	cmpb	r10,r12,r4
-	cmpb	r11,r12,r0
-	cmpb	r6,r7,r4
-	cmpb	r7,r7,r0
-	or	r12,r10,r11
-	or	r5,r6,r7
-	or	r5,r12,r5
-	cmpdi	cr7,r5,0
-	beq	cr7,L(vector)
-
-	/* OK, one (or both) of the doublewords contains a c/null byte.  Check
-	   the first doubleword and decrement the address in case the first
-	   doubleword really contains a c/null byte.  */
-	cmpdi	cr6,r12,0
-	addi	r8,r8,-8
-	bne	cr6,L(done)
-
-	/* The c/null byte must be in the second doubleword.  Adjust the
-	   address again and move the result of cmpb to r10 so we can calculate
-	   the pointer.  */
-
-	mr	r10,r6
-	mr	r11,r7
-	addi	r8,r8,8
-
-	/* r10/r11 have the output of the cmpb instructions, that is,
-	   0xff in the same position as the c/null byte in the original
-	   doubleword from the string.  Use that to calculate the pointer.  */
-
-L(done):
-	/* If there are more than one 0xff in r11, find the first position of
-	   0xff in r11 and fill r10 with 0 from that position.  */
-	cmpdi	cr7,r11,0
-	beq	cr7,L(no_null)
-#ifdef __LITTLE_ENDIAN__
-	addi	r3,r11,-1
-	andc	r3,r3,r11
-	popcntd r0,r3
-#else
-	cntlzd	r0,r11
-#endif
-	subfic	r0,r0,63
-	li	r6,-1
-#ifdef __LITTLE_ENDIAN__
-	srd	r0,r6,r0
-#else
-	sld	r0,r6,r0
-#endif
-	and	r10,r0,r10
-L(no_null):
-#ifdef __LITTLE_ENDIAN__
-	cntlzd	r0,r10		/* Count leading zeros before c matches.  */
-	addi	r3,r10,-1
-	andc	r3,r3,r10
-	addi	r10,r11,-1
-	andc	r10,r10,r11
-	cmpld	cr7,r3,r10
-	bgt	cr7,L(no_match)
-#else
-	addi	r3,r10,-1	/* Count trailing zeros before c matches.  */
-	andc	r3,r3,r10
-	popcntd	r0,r3
-	cmpld	cr7,r11,r10
-	bgt	cr7,L(no_match)
-#endif
-	srdi	r0,r0,3		/* Convert trailing zeros to bytes.  */
-	subfic	r0,r0,7
-	add	r9,r8,r0      /* Return address of the matching c byte
-				 or null in case c was not found.  */
-	li	r0,0
-	cmpdi	cr7,r11,0     /* If r11 == 0, no null's have been found.  */
-	beq	cr7,L(align)
-
-	.align	4
-L(no_match):
-	mr	r3,r9
-	blr
-
-/* Check the first 32B in GPR's and move to vectorized loop.  */
-	.p2align  5
-L(vector):
-	addi	r3, r8, 8
-	/* Make sure 32B aligned.  */
-	andi.	r10, r3, 31
-	bne	cr0, L(loop)
-	vspltisb	v0, 0
-	/* Precompute vbpermq constant.  */
-	vspltisb	v10, 3
-	lvsl	v11, r0, r0
-	vslb	v10, v11, v10
-	MTVRD(v1, r4)
-	li	r5, 16
-	vspltb	v1, v1, 7
-	/* Compare 32 bytes in each loop.  */
-L(continue):
-	lvx	v4, 0, r3
-	lvx	v5, r3, r5
-	vcmpequb	v2, v0, v4
-	vcmpequb	v3, v0, v5
-	vcmpequb	v6, v1, v4
-	vcmpequb	v7, v1, v5
-	vor	v8, v2, v3
-	vor	v9, v6, v7
-	vor	v11, v8, v9
-	vcmpequb.	v11, v0, v11
-	addi	r3, r3, 32
-	blt	cr6, L(continue)
-	vcmpequb.	v8, v0, v8
-	blt	cr6, L(match)
-
-	/* One (or both) of the quadwords contains c/null.  */
-	vspltisb	v8, 2
-	vspltisb	v9, 5
-	/* Precompute values used for comparison.  */
-	vsl	v9, v8, v9	/* v9 = 0x4040404040404040.  */
-	vaddubm	v8, v9, v9
-	vsldoi	v8, v0, v8, 1	/* v8 = 0x80.  */
-
-	/* Check if null is in second qw.  */
-	vcmpequb.	v11, v0, v2
-	blt	cr6, L(secondqw)
-
-	/* Null found in first qw.  */
-	addi	r8, r3, -32
-	/* Calculate the null position.  */
-	FIND_NULL_POS(v2)
-	/* Check if null is in the first byte.  */
-	vcmpequb.	v11, v0, v2
-	blt	cr6, L(no_match)
-	vsububm	v2, v8, v2
-	/* Mask unwanted bytes after null.  */
-#ifdef __LITTLE_ENDIAN__
-	vslo	v6, v6, v2
-	vsro	v6, v6, v2
-#else
-	vsro	v6, v6, v2
-	vslo	v6, v6, v2
-#endif
-	vcmpequb.	v11, v0, v6
-	blt	cr6, L(no_match)
-	/* Found a match before null.  */
-	CALCULATE_MATCH()
-	add	r3, r8, r6
-	blr
-
-L(secondqw):
-	addi	r8, r3, -16
-	FIND_NULL_POS(v3)
-	vcmpequb.	v11, v0, v2
-	blt	cr6, L(no_match1)
-	vsububm	v2, v8, v2
-	/* Mask unwanted bytes after null.  */
-#ifdef __LITTLE_ENDIAN__
-	vslo	v7, v7, v2
-	vsro	v7, v7, v2
-#else
-	vsro	v7, v7, v2
-	vslo	v7, v7, v2
-#endif
-	vcmpequb.	v11, v0, v7
-	blt	cr6, L(no_match1)
-	addi	r8, r8, 16
-	vor	v6, v0, v7
-L(no_match1):
-	addi	r8, r8, -16
-	vcmpequb.	v11, v0, v6
-	blt	cr6, L(no_match)
-	/* Found a match before null.  */
-	CALCULATE_MATCH()
-	add	r3, r8, r6
-	blr
-
-L(match):
-	/* One (or both) of the quadwords contains a match.  */
-	mr	r8, r3
-	vcmpequb.	v8, v0, v7
-	blt	cr6, L(firstqw)
-	/* Match found in second qw.  */
-	addi	r8, r8, 16
-	vor	v6, v0, v7
-L(firstqw):
-	addi	r8, r8, -32
-	CALCULATE_MATCH()
-	add	r9, r8, r6      /* Compute final length.  */
-	b	L(continue)
-/* We are here because strrchr was called with a null byte.  */
-	.align	4
-L(null_match):
-	/* r0 has a doubleword of null bytes.  */
-
-	cmpb	r5,r12,r0     /* Compare each byte against null bytes.  */
-
-	/* Move the doublewords left and right to discard the bits that are
-	   not part of the string and bring them back as zeros.  */
-#ifdef __LITTLE_ENDIAN__
-	srd	r5,r5,r6
-	sld	r5,r5,r6
-#else
-	sld	r5,r5,r6
-	srd	r5,r5,r6
-#endif
-	cmpdi	cr7,r5,0      /* If r5 == 0, no c or null bytes
-				 have been found.  */
-	bne	cr7,L(done_null)
-
-	andi.	r12, r8, 15
-
-	/* Are we now aligned to a quadword boundary?  If so, skip to
-	   the main loop.  Otherwise, go through the alignment code.  */
-
-	bne	cr0, L(loop_null)
-
-	/* Handle WORD2 of pair.  */
-	ldu	r12,8(r8)
-	cmpb	r5,r12,r0
-	cmpdi	cr7,r5,0
-	bne	cr7,L(done_null)
-	b	L(loop_null)  /* We branch here (rather than falling through)
-				 to skip the nops due to heavy alignment
-				 of the loop below.  */
-
-	/* Main loop to look for the end of the string.  Since it's a
-	   small loop (< 8 instructions), align it to 32-bytes.  */
-	.p2align  5
-L(loop_null):
-	/* Load two doublewords, compare and merge in a
-	   single register for speed.  This is an attempt
-	   to speed up the null-checking process for bigger strings.  */
-	ld	r12,8(r8)
-	ldu	r11,16(r8)
-	cmpb	r5,r12,r0
-	cmpb	r10,r11,r0
-	or	r6,r5,r10
-	cmpdi	cr7,r6,0
-	beq	cr7,L(vector1)
-
-	/* OK, one (or both) of the doublewords contains a null byte.  Check
-	   the first doubleword and decrement the address in case the first
-	   doubleword really contains a null byte.  */
-
-	cmpdi	cr6,r5,0
-	addi	r8,r8,-8
-	bne	cr6,L(done_null)
-
-	/* The null byte must be in the second doubleword.  Adjust the address
-	   again and move the result of cmpb to r10 so we can calculate the
-	   pointer.  */
-
-	mr	r5,r10
-	addi	r8,r8,8
-
-	/* r5 has the output of the cmpb instruction, that is, it contains
-	   0xff in the same position as the null byte in the original
-	   doubleword from the string.  Use that to calculate the pointer.  */
-L(done_null):
-#ifdef __LITTLE_ENDIAN__
-	addi	r0,r5,-1
-	andc	r0,r0,r5
-	popcntd	r0,r0
-#else
-	cntlzd	r0,r5	      /* Count leading zeros before the match.  */
-#endif
-	srdi	r0,r0,3	      /* Convert trailing zeros to bytes.  */
-	add	r3,r8,r0      /* Return address of the matching null byte.  */
-	blr
-/* Check the first 32B in GPR's and move to vectorized loop.  */
-	.p2align  5
-L(vector1):
-	addi	r3, r8, 8
-	/* Make sure 32B aligned.  */
-	andi.	r10, r3, 31
-	bne	cr0, L(loop_null)
-	vspltisb	v0, 0
-	/* Precompute vbpermq constant.  */
-	vspltisb	v10, 3
-	lvsl	v11, r0, r0
-	vslb	v10, v11, v10
-	li	r5, 16
-	/* Compare 32 bytes in each loop.  */
-L(continue1):
-	lvx	v4, 0, r3
-	lvx	v5, r3, r5
-	vcmpequb	v2, v0, v4
-	vcmpequb	v3, v0, v5
-	vor	v8, v2, v3
-	vcmpequb.	v11, v0, v8
-	addi	r3, r3, 32
-	blt	cr6, L(continue1)
-	addi	r3, r3, -32
-	VBPERMQ(v2, v2, v10)
-	VBPERMQ(v3, v3, v10)
-	/* Shift each component into its correct position for merging.  */
-#ifdef __LITTLE_ENDIAN__
-	vsldoi	v3, v3, v3, 2
-#else
-	vsldoi	v2, v2, v2, 6
-	vsldoi	v3, v3, v3, 4
-#endif
-	/* Merge the results and move to a GPR.  */
-	vor	v4, v3, v2
-	MFVRD(r5, v4)
-#ifdef __LITTLE_ENDIAN__
-	addi	r6, r5, -1
-	andc	r6, r6, r5
-	popcntd	r6, r6
-#else
-	cntlzd	r6, r5  /* Count leading zeros before the match.  */
-#endif
-	add	r3, r3, r6      /* Compute final length.  */
-	blr
-END_GEN_TB (STRRCHR, TB_TOCLESS)
-weak_alias (strrchr, rindex)
-libc_hidden_builtin_def (strrchr)
diff --git a/sysdeps/powerpc/powerpc64/power8/strspn.S b/sysdeps/powerpc/powerpc64/power8/strspn.S
deleted file mode 100644
index 095f6d6..0000000
--- a/sysdeps/powerpc/powerpc64/power8/strspn.S
+++ /dev/null
@@ -1,202 +0,0 @@
-/* Optimized strspn implementation for Power8.
-
-   Copyright (C) 2016-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-/* size_t [r3] strspn (const char *string [r3],
-                       const char *needleAccept [r4])  */
-
-/* This takes a novel approach by computing a 256 bit mask whereby
-   each set bit implies the byte is "accepted".  P8 vector hardware
-   has extremely efficient hardware for selecting bits from a mask.
-
-   One might ask "why not use bpermd for short strings"?  It is
-   so slow that its performance about matches the generic PPC64
-   variant without any fancy masking, with the added expense of
-   making the mask.  That was the first variant of this.  */
-
-
-
-#include "sysdep.h"
-
-#ifndef USE_AS_STRCSPN
-#  define USE_AS_STRCSPN 0
-#  ifndef STRSPN
-#    define STRSPN strspn
-#  endif
-#  define INITIAL_MASK 0
-#  define UPDATE_MASK(RA, RS, RB) or	RA, RS, RB
-#else
-#  ifndef STRSPN
-#    define STRSPN strcspn
-#  endif
-#  define INITIAL_MASK -1
-#  define UPDATE_MASK(RA, RS, RB) andc	RA, RS, RB
-#endif
-
-/* Simple macro to use VSX instructions in overlapping VR's.  */
-#define XXVR(insn, vrt, vra, vrb) \
-	insn 32+vrt, 32+vra, 32+vrb
-
-/* ISA 2.07B instructions are not all defined for older binutils.
-   Macros are defined below for these newer instructions in order
-   to maintain compatibility.  */
-
-/* Note, TX/SX is always set as VMX regs are the high 32 VSX regs.  */
-#define MTVRD(v,r) .long (0x7c000167 | ((v)<<(32-11)) | ((r)<<(32-16)))
-#define MFVRD(r,v) .long (0x7c000067 | ((v)<<(32-11)) | ((r)<<(32-16)))
-
-#define VBPERMQ(t,a,b) .long (0x1000054c \
-			      | ((t)<<(32-11))	\
-			      | ((a)<<(32-16))	\
-			      | ((b)<<(32-21)) )
-
-	/* This can be updated to power8 once the minimum version of
-	   binutils supports power8 and the above instructions.  */
-	.machine power7
-ENTRY_TOCLESS (STRSPN, 4)
-	CALL_MCOUNT 2
-
-	/* Generate useful constants for later on.  */
-	vspltisb v1, 7
-	vspltisb v2, -1
-	vslb	v1, v1, v1	/* 0x80 to swap high bit for vbpermq.  */
-	vspltisb v10, 0
-	vsldoi	v4, v10, v2, 2	/* 0xFFFF into vr4.  */
-	XXVR(xxmrgld, v4, v4, v10) /* Mask for checking matches.  */
-
-	/* Prepare to compute 256b mask.  */
-	addi	r4, r4, -1
-	li	r5, INITIAL_MASK
-	li	r6, INITIAL_MASK
-	li	r7, INITIAL_MASK
-	li	r8, INITIAL_MASK
-
-#if USE_AS_STRCSPN
-	/* Ensure the null character never matches by clearing ISA bit 0 in
-	   in r5 which is the bit which will check for it in the later usage
-	   of vbpermq.  */
-	srdi	r5, r5, 1
-#endif
-
-	li	r11, 1
-	sldi	r11, r11, 63
-
-	/* Start interleaved Mask computation.
-	   This will eventually or 1's into ignored bits from vbpermq.  */
-	lvsr	v11, 0, r3
-	vspltb  v11, v11, 0	/* Splat shift constant.  */
-
-	/* Build a 256b mask in r5-r8.  */
-	.align 4
-L(next_needle):
-	lbzu	r9, 1(r4)
-
-	cmpldi	cr0, r9, 0
-	cmpldi	cr1, r9, 128
-
-	/* This is a little tricky.  srd only uses the first 7 bits,
-	   and if bit 7 is set, value is always 0.  So, we can
-	   effectively shift 128b in this case.  */
-	xori	r12, r9,  0x40	/* Invert bit 6.  */
-	srd	r10, r11, r9	/* Mask for bits 0-63.  */
-	srd	r12, r11, r12	/* Mask for bits 64-127.  */
-
-	beq	cr0, L(start_cmp)
-
-	/* Now, or the value into the correct GPR.  */
-	bge cr1,L(needle_gt128)
-	UPDATE_MASK (r5, r5, r10)	/* 0 - 63.  */
-	UPDATE_MASK (r6, r6, r12)	/* 64 - 127.  */
-	b L(next_needle)
-
-	.align 4
-L(needle_gt128):
-	UPDATE_MASK (r7, r7, r10)	/* 128 - 191.  */
-	UPDATE_MASK (r8, r8, r12)	/* 192 - 255.  */
-	b L(next_needle)
-
-
-	.align 4
-L(start_cmp):
-	/* Move and merge bitmap into 2 VRs.  bpermd is slower on P8.  */
-	mr	r0, r3		/* Save r3 for final length computation.  */
-	MTVRD (v5, r5)
-	MTVRD (v6, r6)
-	MTVRD (v7, r7)
-	MTVRD (v8, r8)
-
-	/* Continue interleaved mask generation.  */
-#ifdef __LITTLE_ENDIAN__
-	vsrw	v11, v2, v11	/* Note, shift ignores higher order bits.  */
-	vsplth  v11, v11, 0	/* Only care about the high 16 bits of v10.  */
-#else
-	vslw	v11, v2, v11	/* Note, shift ignores higher order bits.  */
-	vsplth  v11, v11, 1	/* Only care about the low 16 bits of v10.  */
-#endif
-	lvx	v0, 0, r3	/* Note, unaligned load ignores lower bits.  */
-
-	/* Do the merging of the bitmask.  */
-	XXVR(xxmrghd, v5, v5, v6)
-	XXVR(xxmrghd, v6, v7, v8)
-
-	/* Finish mask generation.  */
-	vand	v11, v11, v4	/* Throwaway bits not in the mask.  */
-
-	/* Compare the first 1-16B, while masking unwanted bytes.  */
-	clrrdi  r3, r3, 4	/* Note,  counts from qw boundaries.  */
-	vxor	v9, v0, v1	/* Swap high bit.  */
-	VBPERMQ (v8, v5, v0)
-	VBPERMQ (v7, v6, v9)
-	vor	v7, v7, v8
-	vor	v7, v7, v11	/* Ignore non-participating bytes.  */
-	vcmpequh. v8, v7, v4
-	bnl	cr6, L(done)
-
-	addi	r3, r3, 16
-
-	.align 4
-L(vec):
-	lvx	v0, 0, r3
-	addi	r3, r3, 16
-	vxor	v9, v0, v1	/* Swap high bit.  */
-	VBPERMQ (v8, v5, v0)
-	VBPERMQ (v7, v6, v9)
-	vor	v7, v7, v8
-	vcmpequh. v8, v7, v4
-	blt	cr6, L(vec)
-
-	addi	r3, r3, -16
-L(done):
-	subf	r3, r0, r3
-	MFVRD (r10, v7)
-
-#ifdef __LITTLE_ENDIAN__
-	addi	r0,  r10, 1	/* Count the trailing 1's.  */
-	andc	r10, r10, r0
-	popcntd	r10, r10
-#else
-	xori	r10, r10, 0xffff /* Count leading 1's by inverting.  */
-	addi	r3,  r3,  -48	/* Account for the extra leading zeros.  */
-	cntlzd  r10, r10
-#endif
-
-	add	r3, r3, r10
-	blr
-
-END(STRSPN)
-libc_hidden_builtin_def (STRSPN)
diff --git a/sysdeps/powerpc/powerpc64/power9/strcmp.S b/sysdeps/powerpc/powerpc64/power9/strcmp.S
deleted file mode 100644
index 98243a9..0000000
--- a/sysdeps/powerpc/powerpc64/power9/strcmp.S
+++ /dev/null
@@ -1,268 +0,0 @@
-/* Optimized strcmp implementation for PowerPC64/POWER9.
-   Copyright (C) 2016-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-#ifdef __LITTLE_ENDIAN__
-#include <sysdep.h>
-
-#ifndef STRCMP
-# define STRCMP strcmp
-#endif
-
-/* Implements the function
-
-   int [r3] strcmp (const char *s1 [r3], const char *s2 [r4])
-
-   The implementation uses unaligned doubleword access for first 32 bytes
-   as in POWER8 patch and uses vectorised loops after that.  */
-
-/* TODO: Change this to actual instructions when minimum binutils is upgraded
-   to 2.27. Macros are defined below for these newer instructions in order
-   to maintain compatibility.  */
-# define VCTZLSBB(r,v) .long (0x10010602 | ((r)<<(32-11)) | ((v)<<(32-21)))
-
-# define VEXTUBRX(t,a,b) .long (0x1000070d \
-				| ((t)<<(32-11))  \
-				| ((a)<<(32-16))  \
-				| ((b)<<(32-21)) )
-
-# define VCMPNEZB(t,a,b) .long (0x10000507 \
-				| ((t)<<(32-11))  \
-				| ((a)<<(32-16))  \
-				| ((b)<<(32-21)) )
-
-/* Get 16 bytes for unaligned case.
-   reg1: Vector to hold next 16 bytes.
-   reg2: Address to read from.
-   reg3: Permute control vector.  */
-# define GET16BYTES(reg1, reg2, reg3) \
-	lvx	reg1, 0, reg2; \
-	vperm	v8, v2, reg1, reg3; \
-	vcmpequb.	v8, v0, v8; \
-	beq	cr6, 1f; \
-	vspltisb	v9, 0; \
-	b	2f; \
-	.align 4; \
-1: \
-	addi    r6, reg2, 16; \
-	lvx     v9, 0, r6; \
-2: \
-	vperm   reg1, v9, reg1, reg3;
-
-/* TODO: change this to .machine power9 when the minimum required binutils
-   allows it.  */
-
-	.machine  power7
-ENTRY_TOCLESS (STRCMP, 4)
-	li	r0, 0
-
-	/* Check if [s1]+16 or [s2]+16 will cross a 4K page boundary using
-	   the code:
-
-	    (((size_t) s1) % PAGE_SIZE > (PAGE_SIZE - ITER_SIZE))
-
-	   with PAGE_SIZE being 4096 and ITER_SIZE begin 16.  */
-
-	rldicl	r7, r3, 0, 52
-	rldicl	r9, r4, 0, 52
-	cmpldi	cr7, r7, 4096-16
-	bgt	cr7, L(pagecross_check)
-	cmpldi	cr5, r9, 4096-16
-	bgt	cr5, L(pagecross_check)
-
-	/* For short strings up to 16 bytes,  load both s1 and s2 using
-	   unaligned dwords and compare.  */
-	ld	r8, 0(r3)
-	ld	r10, 0(r4)
-	cmpb	r12, r8, r0
-	cmpb	r11, r8, r10
-	orc.	r9, r12, r11
-	bne	cr0, L(different_nocmpb)
-
-	ld	r8, 8(r3)
-	ld	r10, 8(r4)
-	cmpb	r12, r8, r0
-	cmpb	r11, r8, r10
-	orc.	r9, r12, r11
-	bne	cr0, L(different_nocmpb)
-
-	addi	r7, r3, 16
-	addi	r4, r4, 16
-
-L(align):
-	/* Now it has checked for first 16 bytes.  */
-	vspltisb	v0, 0
-	vspltisb	v2, -1
-	lvsr	v6, 0, r4   /* Compute mask.  */
-	or	r5, r4, r7
-	andi.	r5, r5, 0xF
-	beq	cr0, L(aligned)
-	andi.	r5, r7, 0xF
-	beq	cr0, L(s1_align)
-	lvsr	v10, 0, r7   /* Compute mask.  */
-
-	/* Both s1 and s2 are unaligned.  */
-	GET16BYTES(v4, r7, v10)
-	GET16BYTES(v5, r4, v6)
-	VCMPNEZB(v7, v5, v4)
-	beq	cr6, L(match)
-	b	L(different)
-
-	/* Align s1 to qw and adjust s2 address.  */
-	.align  4
-L(match):
-	clrldi	r6, r7, 60
-	subfic	r5, r6, 16
-	add	r7, r7, r5
-	add	r4, r4, r5
-	andi.	r5, r4, 0xF
-	beq	cr0, L(aligned)
-	lvsr	v6, 0, r4
-	/* There are 2 loops depending on the input alignment.
-	   Each loop gets 16 bytes from s1 and s2 and compares.
-	   Loop until a mismatch or null occurs.  */
-L(s1_align):
-	lvx	v4, r7, r0
-	GET16BYTES(v5, r4, v6)
-	VCMPNEZB(v7, v5, v4)
-	addi	r7, r7, 16
-	addi	r4, r4, 16
-	bne	cr6, L(different)
-
-	lvx	v4, r7, r0
-	GET16BYTES(v5, r4, v6)
-	VCMPNEZB(v7, v5, v4)
-	addi	r7, r7, 16
-	addi	r4, r4, 16
-	bne	cr6, L(different)
-
-	lvx	v4, r7, r0
-	GET16BYTES(v5, r4, v6)
-	VCMPNEZB(v7, v5, v4)
-	addi	r7, r7, 16
-	addi	r4, r4, 16
-	bne	cr6, L(different)
-
-	lvx	v4, r7, r0
-	GET16BYTES(v5, r4, v6)
-	VCMPNEZB(v7, v5, v4)
-	addi	r7, r7, 16
-	addi	r4, r4, 16
-	beq	cr6, L(s1_align)
-	b	L(different)
-
-	.align  4
-L(aligned):
-	lvx	v4, 0, r7
-	lvx	v5, 0, r4
-	VCMPNEZB(v7, v5, v4)
-	addi	r7, r7, 16
-	addi	r4, r4, 16
-	bne	cr6, L(different)
-
-	lvx	v4, 0, r7
-	lvx	v5, 0, r4
-	VCMPNEZB(v7, v5, v4)
-	addi	r7, r7, 16
-	addi	r4, r4, 16
-	bne	cr6, L(different)
-
-	lvx	v4, 0, r7
-	lvx	v5, 0, r4
-	VCMPNEZB(v7, v5, v4)
-	addi	r7, r7, 16
-	addi	r4, r4, 16
-	bne	cr6, L(different)
-
-	lvx	v4, 0, r7
-	lvx	v5, 0, r4
-	VCMPNEZB(v7, v5, v4)
-	addi	r7, r7, 16
-	addi	r4, r4, 16
-	beq	cr6, L(aligned)
-
-	/* Calculate and return the difference.  */
-L(different):
-	VCTZLSBB(r6, v7)
-	VEXTUBRX(r5, r6, v4)
-	VEXTUBRX(r4, r6, v5)
-	subf	r3, r4, r5
-	extsw	r3, r3
-	blr
-
-	.align  4
-L(different_nocmpb):
-	neg	r3, r9
-	and	r9, r9, r3
-	cntlzd	r9, r9
-	subfic	r9, r9, 63
-	srd	r3, r8, r9
-	srd	r10, r10, r9
-	rldicl	r10, r10, 0, 56
-	rldicl	r3, r3, 0, 56
-	subf	r3, r10, r3
-	extsw	r3, r3
-	blr
-
-	.align	4
-L(pagecross_check):
-	subfic	r9, r9, 4096
-	subfic	r7, r7, 4096
-	cmpld	cr7, r7, r9
-	bge	cr7, L(pagecross)
-	mr	r7, r9
-
-	/* If unaligned 16 bytes reads across a 4K page boundary, it uses
-	   a simple byte a byte comparison until the page alignment for s1
-	   is reached.  */
-L(pagecross):
-	add	r7, r3, r7
-	subf	r9, r3, r7
-	mtctr	r9
-
-	.align	4
-L(pagecross_loop):
-	/* Loads a byte from s1 and s2, compare if *s1 is equal to *s2
-	   and if *s1 is '\0'.  */
-	lbz	r9, 0(r3)
-	lbz	r10, 0(r4)
-	addi	r3, r3, 1
-	addi	r4, r4, 1
-	cmplw	cr7, r9, r10
-	cmpdi	cr5, r9, r0
-	bne	cr7, L(pagecross_ne)
-	beq	cr5, L(pagecross_nullfound)
-	bdnz	L(pagecross_loop)
-	b	L(align)
-
-	.align	4
-L(pagecross_ne):
-	extsw	r3, r9
-	mr	r9, r10
-L(pagecross_retdiff):
-	subf	r9, r9, r3
-	extsw	r3, r9
-	blr
-
-	.align	4
-L(pagecross_nullfound):
-	li	r3, 0
-	b	L(pagecross_retdiff)
-END (STRCMP)
-libc_hidden_builtin_def (strcmp)
-#else
-#include <sysdeps/powerpc/powerpc64/power8/strcmp.S>
-#endif
diff --git a/sysdeps/powerpc/powerpc64/power9/strncmp.S b/sysdeps/powerpc/powerpc64/power9/strncmp.S
deleted file mode 100644
index 40be98f..0000000
--- a/sysdeps/powerpc/powerpc64/power9/strncmp.S
+++ /dev/null
@@ -1,379 +0,0 @@
-/* Optimized strncmp implementation for PowerPC64/POWER9.
-   Copyright (C) 2016-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-#ifdef __LITTLE_ENDIAN__
-#include <sysdep.h>
-
-/* Implements the function
-
-   int [r3] strncmp (const char *s1 [r3], const char *s2 [r4], size_t [r5] n)
-
-   The implementation uses unaligned doubleword access to avoid specialized
-   code paths depending of data alignment for first 32 bytes and uses
-   vectorised loops after that.  */
-
-#ifndef STRNCMP
-# define STRNCMP strncmp
-#endif
-
-/* TODO: Change this to actual instructions when minimum binutils is upgraded
-   to 2.27. Macros are defined below for these newer instructions in order
-   to maintain compatibility.  */
-# define VCTZLSBB(r,v) .long (0x10010602 | ((r)<<(32-11)) | ((v)<<(32-21)))
-
-# define VEXTUBRX(t,a,b) .long (0x1000070d \
-				| ((t)<<(32-11))  \
-				| ((a)<<(32-16))  \
-				| ((b)<<(32-21)) )
-
-# define VCMPNEZB(t,a,b) .long (0x10000507 \
-				| ((t)<<(32-11))  \
-				| ((a)<<(32-16))  \
-				| ((b)<<(32-21)) )
-
-/* Get 16 bytes for unaligned case.
-   reg1: Vector to hold next 16 bytes.
-   reg2: Address to read from.
-   reg3: Permute control vector.  */
-# define GET16BYTES(reg1, reg2, reg3) \
-	lvx	reg1, 0, reg2; \
-	vperm	v8, v2, reg1, reg3; \
-	vcmpequb.	v8, v0, v8; \
-	beq	cr6, 1f; \
-	vspltisb	v9, 0; \
-	b	2f; \
-	.align 4; \
-1: \
-	cmplw	cr6, r5, r11; \
-	ble	cr6, 2f; \
-	addi	r6, reg2, 16; \
-	lvx	v9, 0, r6; \
-2: \
-	vperm	reg1, v9, reg1, reg3;
-
-/* TODO: change this to .machine power9 when minimum binutils
-   is upgraded to 2.27.  */
-	.machine  power7
-ENTRY_TOCLESS (STRNCMP, 4)
-	/* Check if size is 0.  */
-	cmpdi	cr0, r5, 0
-	beq	cr0, L(ret0)
-	li	r0, 0
-
-	/* Check if [s1]+32 or [s2]+32 will cross a 4K page boundary using
-	   the code:
-
-	    (((size_t) s1) % PAGE_SIZE > (PAGE_SIZE - ITER_SIZE))
-
-	   with PAGE_SIZE being 4096 and ITER_SIZE begin 32.  */
-	rldicl	r8, r3, 0, 52
-	cmpldi	cr7, r8, 4096-32
-	bgt	cr7, L(pagecross)
-	rldicl	r9, r4, 0, 52
-	cmpldi	cr7, r9, 4096-32
-	bgt	cr7, L(pagecross)
-
-	/* For short strings up to 32 bytes, load both s1 and s2 using
-	   unaligned dwords and compare.  */
-
-	ld	r7, 0(r3)
-	ld	r9, 0(r4)
-	li	r8, 0
-	cmpb	r8, r7, r8
-	cmpb	r6, r7, r9
-	orc.	r8, r8, r6
-	bne	cr0, L(different1)
-
-	/* If the strings compared are equal, but size is less or equal
-	   to 8, return 0.  */
-	cmpldi	cr7, r5, 8
-	li	r9, 0
-	ble	cr7, L(ret1)
-	addi	r5, r5, -8
-
-	ld	r7, 8(r3)
-	ld	r9, 8(r4)
-	cmpb	r8, r7, r8
-	cmpb	r6, r7, r9
-	orc.	r8, r8, r6
-	bne	cr0, L(different1)
-	cmpldi	cr7, r5, 8
-	mr	r9, r8
-	ble	cr7, L(ret1)
-	/* Update pointers and size.  */
-	addi	r5, r5, -8
-	addi	r3, r3, 16
-	addi	r4, r4, 16
-
-	ld	r7, 0(r3)
-	ld	r9, 0(r4)
-	li	r8, 0
-	cmpb	r8, r7, r8
-	cmpb	r6, r7, r9
-	orc.	r8, r8, r6
-	bne	cr0, L(different1)
-	cmpldi	cr7, r5, 8
-	li	r9, 0
-	ble	cr7, L(ret1)
-	addi	r5, r5, -8
-
-	ld	r7, 8(r3)
-	ld	r9, 8(r4)
-	cmpb	r8, r7, r8
-	cmpb	r6, r7, r9
-	orc.	r8, r8, r6
-	bne	cr0, L(different1)
-	cmpldi	cr7, r5, 8
-	mr	r9, r8
-	ble	cr7, L(ret1)
-
-	/* Update pointers and size.  */
-	addi	r5, r5, -8
-	addi	r3, r3, 16
-	addi	r4, r4, 16
-L(align):
-	/* Now it has checked for first 32 bytes, align source1 to doubleword
-	   and adjust source2 address.  */
-	vspltisb	v0, 0
-	vspltisb	v2, -1
-	or	r6, r4, r3
-	andi.	r6, r6, 0xF
-	beq	cr0, L(aligned)
-	lvsr	v6, 0, r4   /* Compute mask.  */
-	clrldi	r6, r4, 60
-	subfic	r11, r6, 16
-	andi.	r6, r3, 0xF
-	beq	cr0, L(s1_align)
-	/* Both s1 and s2 are unaligned.  */
-	GET16BYTES(v5, r4, v6)
-	lvsr	v10, 0, r3   /* Compute mask.  */
-	clrldi	r6, r3, 60
-	subfic	r11, r6, 16
-	GET16BYTES(v4, r3, v10)
-	VCMPNEZB(v7, v5, v4)
-	beq	cr6, L(match)
-	b	L(different)
-
-	/* Align s1 to qw and adjust s2 address.  */
-	.align  4
-L(match):
-	cmpldi	cr7, r5, 16
-	ble	cr7, L(ret0)
-	subf	r5, r11, r5
-	add	r3, r3, r11
-	add	r4, r4, r11
-	andi.	r11, r4, 0xF
-	beq	cr0, L(aligned)
-	lvsr	v6, 0, r4
-	clrldi	r6, r4, 60
-	subfic	r11, r6, 16
-	/* There are 2 loops depending on the input alignment.
-	   Each loop gets 16 bytes from s1 and s2, checks for null
-	   and compares them. Loops until a mismatch or  null occurs.  */
-L(s1_align):
-	lvx	v4, 0, r3
-	GET16BYTES(v5, r4, v6)
-	VCMPNEZB(v7, v5, v4)
-	bne	cr6, L(different)
-	cmpldi	cr7, r5, 16
-	ble	cr7, L(ret0)
-	addi	r5, r5, -16
-	addi	r3, r3, 16
-	addi	r4, r4, 16
-
-	lvx	v4, 0, r3
-	GET16BYTES(v5, r4, v6)
-	VCMPNEZB(v7, v5, v4)
-	bne	cr6, L(different)
-	cmpldi	cr7, r5, 16
-	ble	cr7, L(ret0)
-	addi	r5, r5, -16
-	addi	r3, r3, 16
-	addi	r4, r4, 16
-
-	lvx	v4, 0, r3
-	GET16BYTES(v5, r4, v6)
-	VCMPNEZB(v7, v5, v4)
-	bne	cr6, L(different)
-	cmpldi	cr7, r5, 16
-	ble	cr7, L(ret0)
-	addi	r5, r5, -16
-	addi	r3, r3, 16
-	addi	r4, r4, 16
-
-	lvx	v4, 0, r3
-	GET16BYTES(v5, r4, v6)
-	VCMPNEZB(v7, v5, v4)
-	bne	cr6, L(different)
-	cmpldi	cr7, r5, 16
-	ble	cr7, L(ret0)
-	addi	r5, r5, -16
-	addi	r3, r3, 16
-	addi	r4, r4, 16
-	b	L(s1_align)
-	.align  4
-L(aligned):
-	lvx	v4, 0, r3
-	lvx	v5, 0, r4
-	VCMPNEZB(v7, v5, v4)
-	bne	cr6, L(different)
-	cmpldi	cr7, r5, 16
-	ble	cr7, L(ret0)
-	addi	r5, r5, -16
-	addi	r3, r3, 16
-	addi	r4, r4, 16
-
-	lvx	v4, 0, r3
-	lvx	v5, 0, r4
-	VCMPNEZB(v7, v5, v4)
-	bne	cr6, L(different)
-	cmpldi	cr7, r5, 16
-	ble	cr7, L(ret0)
-	addi	r5, r5, -16
-	addi	r3, r3, 16
-	addi	r4, r4, 16
-
-	lvx	v4, 0, r3
-	lvx	v5, 0, r4
-	VCMPNEZB(v7, v5, v4)
-	bne	cr6, L(different)
-	cmpldi	cr7, r5, 16
-	ble	cr7, L(ret0)
-	addi	r5, r5, -16
-	addi	r3, r3, 16
-	addi	r4, r4, 16
-
-	lvx	v4, 0, r3
-	lvx	v5, 0, r4
-	VCMPNEZB(v7, v5, v4)
-	bne	cr6, L(different)
-	cmpldi	cr7, r5, 16
-	ble	cr7, L(ret0)
-	addi	r5, r5, -16
-	addi	r3, r3, 16
-	addi	r4, r4, 16
-	b	L(aligned)
-	/* Calculate and return the difference.  */
-L(different):
-	VCTZLSBB(r6, v7)
-	cmplw	cr7, r5, r6
-	ble	cr7, L(ret0)
-	VEXTUBRX(r5, r6, v4)
-	VEXTUBRX(r4, r6, v5)
-	subf	r3, r4, r5
-	extsw	r3, r3
-	blr
-
-	.align 4
-L(ret0):
-	li	r9, 0
-L(ret1):
-	mr	r3, r9
-	blr
-
-	/* The code now checks if r8 and r5 are different by issuing a
-	   cmpb and shifts the result based on its output:
-
-	  leadzero = (__builtin_ffsl (z1) - 1);
-	  leadzero = leadzero > (n-1)*8 ? (n-1)*8 : leadzero;
-	  r1 = (r1 >> leadzero) & 0xFFUL;
-	  r2 = (r2 >> leadzero) & 0xFFUL;
-	  return r1 - r2;  */
-
-	.align 4
-L(different1):
-	neg	r11, r8
-	sldi	r5, r5, 3
-	and	r8, r11, r8
-	addi	r5, r5, -8
-	cntlzd	r8, r8
-	subfic	r8, r8, 63
-	extsw 	r8, r8
-	cmpld	cr7, r8, r5
-	ble	cr7, L(different2)
-	mr	r8, r5
-L(different2):
-	extsw	r8, r8
-	srd	r7, r7, r8
-	srd	r9, r9, r8
-	rldicl	r3, r7, 0, 56
-	rldicl	r9, r9, 0, 56
-	subf	r9, r9, 3
-	extsw	r9, r9
-	mr	r3, r9
-	blr
-
-	/* If unaligned 16 bytes reads across a 4K page boundary, it uses
-	   a simple byte a byte comparison until the page alignment for s1
-	   is reached.  */
-	.align 4
-L(pagecross):
-	lbz	r7, 0(r3)
-	lbz	r9, 0(r4)
-	subfic	r8, r8,4095
-	cmplw	cr7, r9, r7
-	bne	cr7, L(byte_ne_3)
-	cmpdi	cr7, r9, 0
-	beq	cr7, L(byte_ne_0)
-	addi	r5, r5, -1
-	subf	r7, r8, r5
-	subf	r9, r7, r5
-	addi	r9, r9, 1
-	mtctr	r9
-	b	L(pagecross_loop1)
-
-	.align 4
-L(pagecross_loop0):
-	beq	cr7, L(ret0)
-	lbz	r9, 0(r3)
-	lbz	r8, 0(r4)
-	addi	r5, r5, -1
-	cmplw	cr7, r9, r8
-	cmpdi	cr5, r9, 0
-	bne	cr7, L(byte_ne_2)
-	beq	cr5, L(byte_ne_0)
-L(pagecross_loop1):
-	cmpdi	cr7, r5, 0
-	addi	r3, r3, 1
-	addi	r4, r4, 1
-	bdnz	L(pagecross_loop0)
-	cmpdi	cr7, r7, 0
-	li	r9, 0
-	bne+	cr7, L(align)
-	b	L(ret1)
-
-	.align 4
-L(byte_ne_0):
-	li	r7, 0
-L(byte_ne_1):
-	subf	r9, r9, r7
-	extsw	r9, r9
-	b	L(ret1)
-
-	.align 4
-L(byte_ne_2):
-	extsw	r7, r9
-	mr	r9, r8
-	b	L(byte_ne_1)
-L(byte_ne_3):
-	extsw	r7, r7
-	b	L(byte_ne_1)
-END(STRNCMP)
-libc_hidden_builtin_def(strncmp)
-#else
-#include <sysdeps/powerpc/powerpc64/power8/strncmp.S>
-#endif
diff --git a/sysdeps/powerpc/powerpc64/rtld-memset.c b/sysdeps/powerpc/powerpc64/rtld-memset.c
deleted file mode 100644
index f3ed8ad..0000000
--- a/sysdeps/powerpc/powerpc64/rtld-memset.c
+++ /dev/null
@@ -1,4 +0,0 @@
-/* PPCA2 has a different cache-line size than the usual 128 bytes.  To avoid
-   using code that assumes cache-line size to be 128 bytes (with dcbz
-   instructions) we use the generic code instead.  */
-#include <string/memset.c>
diff --git a/sysdeps/powerpc/powerpc64/strchr.S b/sysdeps/powerpc/powerpc64/strchr.S
deleted file mode 100644
index f4fbbea..0000000
--- a/sysdeps/powerpc/powerpc64/strchr.S
+++ /dev/null
@@ -1,155 +0,0 @@
-/* Optimized strchr implementation for PowerPC64.
-   Copyright (C) 1997-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* See strlen.s for comments on how this works.  */
-
-/* char * [r3] strchr (const char *s [r3] , int c [r4] )  */
-
-#ifndef STRCHR
-# define STRCHR strchr
-#endif
-
-ENTRY_TOCLESS (STRCHR)
-	CALL_MCOUNT 2
-
-#define rTMP1	r0
-#define rRTN	r3	/* outgoing result */
-#define rSTR	r8	/* current word pointer */
-#define rCHR	r4	/* byte we're looking for, spread over the whole word */
-#define rWORD	r5	/* the current word */
-#define rCLZB	rCHR	/* leading zero byte count */
-#define rFEFE	r6	/* constant 0xfefefefefefefeff (-0x0101010101010101) */
-#define r7F7F	r7	/* constant 0x7f7f7f7f7f7f7f7f */
-#define rTMP2	r9
-#define rIGN	r10	/* number of bits we should ignore in the first word */
-#define rMASK	r11	/* mask with the bits to ignore set to 0 */
-#define rTMP3	r12
-#define rTMP4	rIGN
-#define rTMP5	rMASK
-
-	dcbt	0,rRTN
-	insrdi	rCHR, rCHR, 8, 48
-	li	rMASK, -1
-	insrdi	rCHR, rCHR, 16, 32
-	rlwinm	rIGN, rRTN, 3, 26, 28
-	insrdi	rCHR, rCHR, 32, 0
-	lis	rFEFE, -0x101
-	lis	r7F7F, 0x7f7f
-	clrrdi	rSTR, rRTN, 3
-	addi	rFEFE, rFEFE, -0x101
-	addi	r7F7F, r7F7F, 0x7f7f
-	sldi	rTMP1, rFEFE, 32
-	insrdi	r7F7F, r7F7F, 32, 0
-	add	rFEFE, rFEFE, rTMP1
-/* Test the first (partial?) word.  */
-	ld	rWORD, 0(rSTR)
-#ifdef __LITTLE_ENDIAN__
-	sld	rMASK, rMASK, rIGN
-#else
-	srd	rMASK, rMASK, rIGN
-#endif
-	orc	rWORD, rWORD, rMASK
-	add	rTMP1, rFEFE, rWORD
-	nor	rTMP2, r7F7F, rWORD
-	and.	rTMP4, rTMP1, rTMP2
-	xor	rTMP3, rCHR, rWORD
-	orc	rTMP3, rTMP3, rMASK
-	b	L(loopentry)
-
-/* The loop.  */
-
-L(loop):
-	ldu	rWORD, 8(rSTR)
-	and.	rTMP5, rTMP1, rTMP2
-/* Test for 0.	*/
-	add	rTMP1, rFEFE, rWORD /* x - 0x01010101.  */
-	nor	rTMP2, r7F7F, rWORD /* ~(x | 0x7f7f7f7f) == ~x & 0x80808080.  */
-	bne	L(foundit)
-	and.	rTMP4, rTMP1, rTMP2 /* (x - 0x01010101) & ~x & 0x80808080.  */
-/* Start test for the bytes we're looking for.  */
-	xor	rTMP3, rCHR, rWORD
-L(loopentry):
-	add	rTMP1, rFEFE, rTMP3
-	nor	rTMP2, r7F7F, rTMP3
-	beq	L(loop)
-
-/* There is a zero byte in the word, but may also be a matching byte (either
-   before or after the zero byte).  In fact, we may be looking for a
-   zero byte, in which case we return a match.  */
-	and.	rTMP5, rTMP1, rTMP2
-	li	rRTN, 0
-	beqlr
-/* At this point:
-   rTMP5 bytes are 0x80 for each match of c, 0 otherwise.
-   rTMP4 bytes are 0x80 for each match of 0, 0 otherwise.
-   But there may be false matches in the next most significant byte from
-   a true match due to carries.  This means we need to recalculate the
-   matches using a longer method for big-endian.  */
-#ifdef __LITTLE_ENDIAN__
-	addi	rTMP1, rTMP5, -1
-	andc	rTMP1, rTMP1, rTMP5
-	cntlzd	rCLZB, rTMP1
-	addi	rTMP2, rTMP4, -1
-	andc	rTMP2, rTMP2, rTMP4
-	cmpld	rTMP1, rTMP2
-	bgtlr
-	subfic	rCLZB, rCLZB, 64-7
-#else
-/* I think we could reduce this by two instructions by keeping the "nor"
-   results from the loop for reuse here.  See strlen.S tail.  Similarly
-   one instruction could be pruned from L(foundit).  */
-	and	rFEFE, r7F7F, rWORD
-	or	rTMP5, r7F7F, rWORD
-	and	rTMP1, r7F7F, rTMP3
-	or	rTMP4, r7F7F, rTMP3
-	add	rFEFE, rFEFE, r7F7F
-	add	rTMP1, rTMP1, r7F7F
-	nor	rWORD, rTMP5, rFEFE
-	nor	rTMP2, rTMP4, rTMP1
-	cntlzd	rCLZB, rTMP2
-	cmpld	rWORD, rTMP2
-	bgtlr
-#endif
-	srdi	rCLZB, rCLZB, 3
-	add	rRTN, rSTR, rCLZB
-	blr
-
-L(foundit):
-#ifdef __LITTLE_ENDIAN__
-	addi	rTMP1, rTMP5, -1
-	andc	rTMP1, rTMP1, rTMP5
-	cntlzd	rCLZB, rTMP1
-	subfic	rCLZB, rCLZB, 64-7-64
-	sradi	rCLZB, rCLZB, 3
-#else
-	and	rTMP1, r7F7F, rTMP3
-	or	rTMP4, r7F7F, rTMP3
-	add	rTMP1, rTMP1, r7F7F
-	nor	rTMP2, rTMP4, rTMP1
-	cntlzd	rCLZB, rTMP2
-	subi	rSTR, rSTR, 8
-	srdi	rCLZB, rCLZB, 3
-#endif
-	add	rRTN, rSTR, rCLZB
-	blr
-END (STRCHR)
-
-weak_alias (strchr, index)
-libc_hidden_builtin_def (strchr)
diff --git a/sysdeps/powerpc/powerpc64/strcmp.S b/sysdeps/powerpc/powerpc64/strcmp.S
deleted file mode 100644
index 1862a2e..0000000
--- a/sysdeps/powerpc/powerpc64/strcmp.S
+++ /dev/null
@@ -1,180 +0,0 @@
-/* Optimized strcmp implementation for PowerPC64.
-   Copyright (C) 1997-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* See strlen.s for comments on how the end-of-string testing works.  */
-
-/* int [r3] strcmp (const char *s1 [r3], const char *s2 [r4])  */
-
-#ifndef STRCMP
-# define STRCMP strcmp
-#endif
-
-ENTRY_TOCLESS (STRCMP, 4)
-	CALL_MCOUNT 2
-
-#define rTMP2	r0
-#define rRTN	r3
-#define rSTR1	r3	/* first string arg */
-#define rSTR2	r4	/* second string arg */
-#define rWORD1	r5	/* current word in s1 */
-#define rWORD2	r6	/* current word in s2 */
-#define rFEFE	r7	/* constant 0xfefefefefefefeff (-0x0101010101010101) */
-#define r7F7F	r8	/* constant 0x7f7f7f7f7f7f7f7f */
-#define rNEG	r9	/* ~(word in s1 | 0x7f7f7f7f7f7f7f7f) */
-#define rBITDIF	r10	/* bits that differ in s1 & s2 words */
-#define rTMP	r11
-
-	dcbt	0,rSTR1
-	or	rTMP, rSTR2, rSTR1
-	dcbt	0,rSTR2
-	clrldi.	rTMP, rTMP, 61
-	lis	rFEFE, -0x101
-	bne	L(unaligned)
-
-	ld	rWORD1, 0(rSTR1)
-	ld	rWORD2, 0(rSTR2)
-	lis	r7F7F, 0x7f7f
-	addi	rFEFE, rFEFE, -0x101
-	addi	r7F7F, r7F7F, 0x7f7f
-	sldi	rTMP, rFEFE, 32
-	insrdi	r7F7F, r7F7F, 32, 0
-	add	rFEFE, rFEFE, rTMP
-	b	L(g1)
-
-L(g0):	ldu	rWORD1, 8(rSTR1)
-	bne	cr1, L(different)
-	ldu	rWORD2, 8(rSTR2)
-L(g1):	add	rTMP, rFEFE, rWORD1
-	nor	rNEG, r7F7F, rWORD1
-	and.	rTMP, rTMP, rNEG
-	cmpd	cr1, rWORD1, rWORD2
-	beq+	L(g0)
-
-/* OK. We've hit the end of the string. We need to be careful that
-   we don't compare two strings as different because of gunk beyond
-   the end of the strings...  */
-#ifdef __LITTLE_ENDIAN__
-L(endstring):
-	addi    rTMP2, rTMP, -1
-	beq	cr1, L(equal)
-	andc    rTMP2, rTMP2, rTMP
-	rldimi	rTMP2, rTMP2, 1, 0
-	and	rWORD2, rWORD2, rTMP2	/* Mask off gunk.  */
-	and	rWORD1, rWORD1, rTMP2
-	cmpd	cr1, rWORD1, rWORD2
-	beq	cr1, L(equal)
-	xor	rBITDIF, rWORD1, rWORD2	/* rBITDIF has bits that differ.  */
-	neg	rNEG, rBITDIF
-	and	rNEG, rNEG, rBITDIF	/* rNEG has LS bit that differs.  */
-	cntlzd	rNEG, rNEG		/* bitcount of the bit.  */
-	andi.	rNEG, rNEG, 56		/* bitcount to LS byte that differs. */
-	sld	rWORD1, rWORD1, rNEG	/* shift left to clear MS bytes.  */
-	sld	rWORD2, rWORD2, rNEG
-	xor.	rBITDIF, rWORD1, rWORD2
-	sub	rRTN, rWORD1, rWORD2
-	blt-	L(highbit)
-	sradi	rRTN, rRTN, 63		/* must return an int.  */
-	ori	rRTN, rRTN, 1
-	blr
-L(equal):
-	li	rRTN, 0
-	blr
-
-L(different):
-	ld	rWORD1, -8(rSTR1)
-	xor	rBITDIF, rWORD1, rWORD2	/* rBITDIF has bits that differ.  */
-	neg	rNEG, rBITDIF
-	and	rNEG, rNEG, rBITDIF	/* rNEG has LS bit that differs.  */
-	cntlzd	rNEG, rNEG		/* bitcount of the bit.  */
-	andi.	rNEG, rNEG, 56		/* bitcount to LS byte that differs. */
-	sld	rWORD1, rWORD1, rNEG	/* shift left to clear MS bytes.  */
-	sld	rWORD2, rWORD2, rNEG
-	xor.	rBITDIF, rWORD1, rWORD2
-	sub	rRTN, rWORD1, rWORD2
-	blt-	L(highbit)
-	sradi	rRTN, rRTN, 63
-	ori	rRTN, rRTN, 1
-	blr
-L(highbit):
-	sradi	rRTN, rWORD2, 63
-	ori	rRTN, rRTN, 1
-	blr
-
-#else
-L(endstring):
-	and	rTMP, r7F7F, rWORD1
-	beq	cr1, L(equal)
-	add	rTMP, rTMP, r7F7F
-	xor.	rBITDIF, rWORD1, rWORD2
-	andc	rNEG, rNEG, rTMP
-	blt-	L(highbit)
-	cntlzd	rBITDIF, rBITDIF
-	cntlzd	rNEG, rNEG
-	addi	rNEG, rNEG, 7
-	cmpd	cr1, rNEG, rBITDIF
-	sub	rRTN, rWORD1, rWORD2
-	blt-	cr1, L(equal)
-	sradi	rRTN, rRTN, 63		/* must return an int.  */
-	ori	rRTN, rRTN, 1
-	blr
-L(equal):
-	li	rRTN, 0
-	blr
-
-L(different):
-	ld	rWORD1, -8(rSTR1)
-	xor.	rBITDIF, rWORD1, rWORD2
-	sub	rRTN, rWORD1, rWORD2
-	blt-	L(highbit)
-	sradi	rRTN, rRTN, 63
-	ori	rRTN, rRTN, 1
-	blr
-L(highbit):
-	sradi	rRTN, rWORD2, 63
-	ori	rRTN, rRTN, 1
-	blr
-#endif
-
-/* Oh well.  In this case, we just do a byte-by-byte comparison.  */
-	.align 4
-L(unaligned):
-	lbz	rWORD1, 0(rSTR1)
-	lbz	rWORD2, 0(rSTR2)
-	b	L(u1)
-
-L(u0):	lbzu	rWORD1, 1(rSTR1)
-	bne-	L(u4)
-	lbzu	rWORD2, 1(rSTR2)
-L(u1):	cmpwi	cr1, rWORD1, 0
-	beq-	cr1, L(u3)
-	cmpd	rWORD1, rWORD2
-	bne-	L(u3)
-	lbzu	rWORD1, 1(rSTR1)
-	lbzu	rWORD2, 1(rSTR2)
-	cmpdi	cr1, rWORD1, 0
-	cmpd	rWORD1, rWORD2
-	bne+	cr1, L(u0)
-L(u3):	sub	rRTN, rWORD1, rWORD2
-	blr
-L(u4):	lbz	rWORD1, -1(rSTR1)
-	sub	rRTN, rWORD1, rWORD2
-	blr
-END (STRCMP)
-libc_hidden_builtin_def (strcmp)
diff --git a/sysdeps/powerpc/powerpc64/strlen.S b/sysdeps/powerpc/powerpc64/strlen.S
deleted file mode 100644
index 4604f9c..0000000
--- a/sysdeps/powerpc/powerpc64/strlen.S
+++ /dev/null
@@ -1,203 +0,0 @@
-/* Optimized strlen implementation for PowerPC64.
-   Copyright (C) 1997-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* The algorithm here uses the following techniques:
-
-   1) Given a word 'x', we can test to see if it contains any 0 bytes
-      by subtracting 0x01010101, and seeing if any of the high bits of each
-      byte changed from 0 to 1. This works because the least significant
-      0 byte must have had no incoming carry (otherwise it's not the least
-      significant), so it is 0x00 - 0x01 == 0xff. For all other
-      byte values, either they have the high bit set initially, or when
-      1 is subtracted you get a value in the range 0x00-0x7f, none of which
-      have their high bit set. The expression here is
-      (x + 0xfefefeff) & ~(x | 0x7f7f7f7f), which gives 0x00000000 when
-      there were no 0x00 bytes in the word.  You get 0x80 in bytes that
-      match, but possibly false 0x80 matches in the next more significant
-      byte to a true match due to carries.  For little-endian this is
-      of no consequence since the least significant match is the one
-      we're interested in, but big-endian needs method 2 to find which
-      byte matches.
-
-   2) Given a word 'x', we can test to see _which_ byte was zero by
-      calculating ~(((x & 0x7f7f7f7f) + 0x7f7f7f7f) | x | 0x7f7f7f7f).
-      This produces 0x80 in each byte that was zero, and 0x00 in all
-      the other bytes. The '| 0x7f7f7f7f' clears the low 7 bits in each
-      byte, and the '| x' part ensures that bytes with the high bit set
-      produce 0x00. The addition will carry into the high bit of each byte
-      iff that byte had one of its low 7 bits set. We can then just see
-      which was the most significant bit set and divide by 8 to find how
-      many to add to the index.
-      This is from the book 'The PowerPC Compiler Writer's Guide',
-      by Steve Hoxey, Faraydon Karim, Bill Hay and Hank Warren.
-
-   We deal with strings not aligned to a word boundary by taking the
-   first word and ensuring that bytes not part of the string
-   are treated as nonzero. To allow for memory latency, we unroll the
-   loop a few times, being careful to ensure that we do not read ahead
-   across cache line boundaries.
-
-   Questions to answer:
-   1) How long are strings passed to strlen? If they're often really long,
-   we should probably use cache management instructions and/or unroll the
-   loop more. If they're often quite short, it might be better to use
-   fact (2) in the inner loop than have to recalculate it.
-   2) How popular are bytes with the high bit set? If they are very rare,
-   on some processors it might be useful to use the simpler expression
-   ~((x - 0x01010101) | 0x7f7f7f7f) (that is, on processors with only one
-   ALU), but this fails when any character has its high bit set.
-
-   Answer:
-   1) Added a Data Cache Block Touch early to prefetch the first 128
-   byte cache line. Adding dcbt instructions to the loop would not be
-   effective since most strings will be shorter than the cache line.  */
-
-/* Some notes on register usage: Under the SVR4 ABI, we can use registers
-   0 and 3 through 12 (so long as we don't call any procedures) without
-   saving them. We can also use registers 14 through 31 if we save them.
-   We can't use r1 (it's the stack pointer), r2 nor r13 because the user
-   program may expect them to hold their usual value if we get sent
-   a signal. Integer parameters are passed in r3 through r10.
-   We can use condition registers cr0, cr1, cr5, cr6, and cr7 without saving
-   them, the others we must save.  */
-
-/* int [r3] strlen (char *s [r3])  */
-
-#ifndef STRLEN
-# define STRLEN strlen
-#endif
-
-ENTRY_TOCLESS (STRLEN)
-	CALL_MCOUNT 1
-
-#define rTMP4	r0
-#define rRTN	r3	/* incoming STR arg, outgoing result */
-#define rSTR	r4	/* current string position */
-#define rPADN	r5	/* number of padding bits we prepend to the
-			   string to make it start at a word boundary */
-#define rFEFE	r6	/* constant 0xfefefefefefefeff (-0x0101010101010101) */
-#define r7F7F	r7	/* constant 0x7f7f7f7f7f7f7f7f */
-#define rWORD1	r8	/* current string doubleword */
-#define rWORD2	r9	/* next string doubleword */
-#define rMASK	r9	/* mask for first string doubleword */
-#define rTMP1	r10
-#define rTMP2	r11
-#define rTMP3	r12
-
-	dcbt	0,rRTN
-	clrrdi	rSTR, rRTN, 3
-	lis	r7F7F, 0x7f7f
-	rlwinm	rPADN, rRTN, 3, 26, 28
-	ld	rWORD1, 0(rSTR)
-	addi	r7F7F, r7F7F, 0x7f7f
-	li	rMASK, -1
-	insrdi	r7F7F, r7F7F, 32, 0
-/* We use method (2) on the first two doublewords, because rFEFE isn't
-   required which reduces setup overhead.  Also gives a faster return
-   for small strings on big-endian due to needing to recalculate with
-   method (2) anyway.  */
-#ifdef __LITTLE_ENDIAN__
-	sld	rMASK, rMASK, rPADN
-#else
-	srd	rMASK, rMASK, rPADN
-#endif
-	and	rTMP1, r7F7F, rWORD1
-	or	rTMP2, r7F7F, rWORD1
-	lis	rFEFE, -0x101
-	add	rTMP1, rTMP1, r7F7F
-	addi	rFEFE, rFEFE, -0x101
-	nor	rTMP3, rTMP2, rTMP1
-	and.	rTMP3, rTMP3, rMASK
-	mtcrf	0x01, rRTN
-	bne	L(done0)
-	sldi	rTMP1, rFEFE, 32
-	add	rFEFE, rFEFE, rTMP1
-/* Are we now aligned to a doubleword boundary?  */
-	bt	28, L(loop)
-
-/* Handle second doubleword of pair.  */
-/* Perhaps use method (1) here for little-endian, saving one instruction?  */
-	ldu	rWORD1, 8(rSTR)
-	and	rTMP1, r7F7F, rWORD1
-	or	rTMP2, r7F7F, rWORD1
-	add	rTMP1, rTMP1, r7F7F
-	nor.	rTMP3, rTMP2, rTMP1
-	bne	L(done0)
-
-/* The loop.  */
-
-L(loop):
-	ld	rWORD1, 8(rSTR)
-	ldu	rWORD2, 16(rSTR)
-	add	rTMP1, rFEFE, rWORD1
-	nor	rTMP2, r7F7F, rWORD1
-	and.	rTMP1, rTMP1, rTMP2
-	add	rTMP3, rFEFE, rWORD2
-	nor	rTMP4, r7F7F, rWORD2
-	bne	L(done1)
-	and.	rTMP3, rTMP3, rTMP4
-	beq	L(loop)
-
-#ifndef __LITTLE_ENDIAN__
-	and	rTMP1, r7F7F, rWORD2
-	add	rTMP1, rTMP1, r7F7F
-	andc	rTMP3, rTMP4, rTMP1
-	b	L(done0)
-
-L(done1):
-	and	rTMP1, r7F7F, rWORD1
-	subi	rSTR, rSTR, 8
-	add	rTMP1, rTMP1, r7F7F
-	andc	rTMP3, rTMP2, rTMP1
-
-/* When we get to here, rSTR points to the first doubleword in the string that
-   contains a zero byte, and rTMP3 has 0x80 for bytes that are zero, and 0x00
-   otherwise.  */
-L(done0):
-	cntlzd	rTMP3, rTMP3
-	subf	rTMP1, rRTN, rSTR
-	srdi	rTMP3, rTMP3, 3
-	add	rRTN, rTMP1, rTMP3
-	blr
-#else
-
-L(done0):
-	addi	rTMP1, rTMP3, -1	/* Form a mask from trailing zeros.  */
-	andc	rTMP1, rTMP1, rTMP3
-	cntlzd	rTMP1, rTMP1		/* Count bits not in the mask.  */
-	subf	rTMP3, rRTN, rSTR
-	subfic	rTMP1, rTMP1, 64-7
-	srdi	rTMP1, rTMP1, 3
-	add	rRTN, rTMP1, rTMP3
-	blr
-
-L(done1):
-	addi	rTMP3, rTMP1, -1
-	andc	rTMP3, rTMP3, rTMP1
-	cntlzd	rTMP3, rTMP3
-	subf	rTMP1, rRTN, rSTR
-	subfic	rTMP3, rTMP3, 64-7-64
-	sradi	rTMP3, rTMP3, 3
-	add	rRTN, rTMP1, rTMP3
-	blr
-#endif
-
-END (STRLEN)
-libc_hidden_builtin_def (strlen)
diff --git a/sysdeps/powerpc/powerpc64/strncmp.S b/sysdeps/powerpc/powerpc64/strncmp.S
deleted file mode 100644
index bf53583..0000000
--- a/sysdeps/powerpc/powerpc64/strncmp.S
+++ /dev/null
@@ -1,210 +0,0 @@
-/* Optimized strcmp implementation for PowerPC64.
-   Copyright (C) 2003-2018 Free Software Foundation, Inc.
-   This file is part of the GNU C Library.
-
-   The GNU C Library is free software; you can redistribute it and/or
-   modify it under the terms of the GNU Lesser General Public
-   License as published by the Free Software Foundation; either
-   version 2.1 of the License, or (at your option) any later version.
-
-   The GNU C Library is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   Lesser General Public License for more details.
-
-   You should have received a copy of the GNU Lesser General Public
-   License along with the GNU C Library; if not, see
-   <http://www.gnu.org/licenses/>.  */
-
-#include <sysdep.h>
-
-/* See strlen.s for comments on how the end-of-string testing works.  */
-
-/* int [r3] strncmp (const char *s1 [r3], const char *s2 [r4], size_t size [r5])  */
-
-#ifndef STRNCMP
-# define STRNCMP strncmp
-#endif
-
-ENTRY_TOCLESS (STRNCMP, 4)
-	CALL_MCOUNT 3
-
-#define rTMP2	r0
-#define rRTN	r3
-#define rSTR1	r3	/* first string arg */
-#define rSTR2	r4	/* second string arg */
-#define rN	r5	/* max string length */
-#define rWORD1	r6	/* current word in s1 */
-#define rWORD2	r7	/* current word in s2 */
-#define rFEFE	r8	/* constant 0xfefefefefefefeff (-0x0101010101010101) */
-#define r7F7F	r9	/* constant 0x7f7f7f7f7f7f7f7f */
-#define rNEG	r10	/* ~(word in s1 | 0x7f7f7f7f7f7f7f7f) */
-#define rBITDIF	r11	/* bits that differ in s1 & s2 words */
-#define rTMP	r12
-
-	dcbt	0,rSTR1
-	or	rTMP, rSTR2, rSTR1
-	lis	r7F7F, 0x7f7f
-	dcbt	0,rSTR2
-	clrldi.	rTMP, rTMP, 61
-	cmpldi	cr1, rN, 0
-	lis	rFEFE, -0x101
-	bne	L(unaligned)
-/* We are doubleword aligned so set up for two loops.  first a double word
-   loop, then fall into the byte loop if any residual.  */
-	srdi.	rTMP, rN, 3
-	clrldi	rN, rN, 61
-	addi	rFEFE, rFEFE, -0x101
-	addi	r7F7F, r7F7F, 0x7f7f
-	cmpldi	cr1, rN, 0
-	beq	L(unaligned)
-
-	mtctr	rTMP	/* Power4 wants mtctr 1st in dispatch group.  */
-	ld	rWORD1, 0(rSTR1)
-	ld	rWORD2, 0(rSTR2)
-	sldi	rTMP, rFEFE, 32
-	insrdi	r7F7F, r7F7F, 32, 0
-	add	rFEFE, rFEFE, rTMP
-	b	L(g1)
-
-L(g0):
-	ldu	rWORD1, 8(rSTR1)
-	bne-	cr1, L(different)
-	ldu	rWORD2, 8(rSTR2)
-L(g1):	add	rTMP, rFEFE, rWORD1
-	nor	rNEG, r7F7F, rWORD1
-	bdz	L(tail)
-	and.	rTMP, rTMP, rNEG
-	cmpd	cr1, rWORD1, rWORD2
-	beq+	L(g0)
-
-/* OK. We've hit the end of the string. We need to be careful that
-   we don't compare two strings as different because of gunk beyond
-   the end of the strings...  */
-
-#ifdef __LITTLE_ENDIAN__
-L(endstring):
-	addi    rTMP2, rTMP, -1
-	beq	cr1, L(equal)
-	andc    rTMP2, rTMP2, rTMP
-	rldimi	rTMP2, rTMP2, 1, 0
-	and	rWORD2, rWORD2, rTMP2	/* Mask off gunk.  */
-	and	rWORD1, rWORD1, rTMP2
-	cmpd	cr1, rWORD1, rWORD2
-	beq	cr1, L(equal)
-	xor	rBITDIF, rWORD1, rWORD2	/* rBITDIF has bits that differ.  */
-	neg	rNEG, rBITDIF
-	and	rNEG, rNEG, rBITDIF	/* rNEG has LS bit that differs.  */
-	cntlzd	rNEG, rNEG		/* bitcount of the bit.  */
-	andi.	rNEG, rNEG, 56		/* bitcount to LS byte that differs. */
-	sld	rWORD1, rWORD1, rNEG	/* shift left to clear MS bytes.  */
-	sld	rWORD2, rWORD2, rNEG
-	xor.	rBITDIF, rWORD1, rWORD2
-	sub	rRTN, rWORD1, rWORD2
-	blt-	L(highbit)
-	sradi	rRTN, rRTN, 63		/* must return an int.  */
-	ori	rRTN, rRTN, 1
-	blr
-L(equal):
-	li	rRTN, 0
-	blr
-
-L(different):
-	ld	rWORD1, -8(rSTR1)
-	xor	rBITDIF, rWORD1, rWORD2	/* rBITDIF has bits that differ.  */
-	neg	rNEG, rBITDIF
-	and	rNEG, rNEG, rBITDIF	/* rNEG has LS bit that differs.  */
-	cntlzd	rNEG, rNEG		/* bitcount of the bit.  */
-	andi.	rNEG, rNEG, 56		/* bitcount to LS byte that differs. */
-	sld	rWORD1, rWORD1, rNEG	/* shift left to clear MS bytes.  */
-	sld	rWORD2, rWORD2, rNEG
-	xor.	rBITDIF, rWORD1, rWORD2
-	sub	rRTN, rWORD1, rWORD2
-	blt-	L(highbit)
-	sradi	rRTN, rRTN, 63
-	ori	rRTN, rRTN, 1
-	blr
-L(highbit):
-	sradi	rRTN, rWORD2, 63
-	ori	rRTN, rRTN, 1
-	blr
-
-#else
-L(endstring):
-	and	rTMP, r7F7F, rWORD1
-	beq	cr1, L(equal)
-	add	rTMP, rTMP, r7F7F
-	xor.	rBITDIF, rWORD1, rWORD2
-	andc	rNEG, rNEG, rTMP
-	blt-	L(highbit)
-	cntlzd	rBITDIF, rBITDIF
-	cntlzd	rNEG, rNEG
-	addi	rNEG, rNEG, 7
-	cmpd	cr1, rNEG, rBITDIF
-	sub	rRTN, rWORD1, rWORD2
-	blt-	cr1, L(equal)
-	sradi	rRTN, rRTN, 63		/* must return an int.  */
-	ori	rRTN, rRTN, 1
-	blr
-L(equal):
-	li	rRTN, 0
-	blr
-
-L(different):
-	ld	rWORD1, -8(rSTR1)
-	xor.	rBITDIF, rWORD1, rWORD2
-	sub	rRTN, rWORD1, rWORD2
-	blt-	L(highbit)
-	sradi	rRTN, rRTN, 63
-	ori	rRTN, rRTN, 1
-	blr
-L(highbit):
-	sradi	rRTN, rWORD2, 63
-	ori	rRTN, rRTN, 1
-	blr
-#endif
-
-/* Oh well.  In this case, we just do a byte-by-byte comparison.  */
-	.align 4
-L(tail):
-	and.	rTMP, rTMP, rNEG
-	cmpd	cr1, rWORD1, rWORD2
-	bne-	L(endstring)
-	addi	rSTR1, rSTR1, 8
-	bne-	cr1, L(different)
-	addi	rSTR2, rSTR2, 8
-	cmpldi	cr1, rN, 0
-L(unaligned):
-	mtctr   rN	/* Power4 wants mtctr 1st in dispatch group */
-	bgt	cr1, L(uz)
-L(ux):
-	li	rRTN, 0
-	blr
-	.align 4
-L(uz):
-	lbz	rWORD1, 0(rSTR1)
-	lbz	rWORD2, 0(rSTR2)
-	nop
-	b	L(u1)
-L(u0):
-	lbzu	rWORD2, 1(rSTR2)
-L(u1):
-	bdz	L(u3)
-	cmpdi	cr1, rWORD1, 0
-	cmpd	rWORD1, rWORD2
-	beq-	cr1, L(u3)
-	lbzu	rWORD1, 1(rSTR1)
-	bne-	L(u2)
-	lbzu	rWORD2, 1(rSTR2)
-	bdz	L(u3)
-	cmpdi	cr1, rWORD1, 0
-	cmpd	rWORD1, rWORD2
-	bne-	L(u3)
-	lbzu	rWORD1, 1(rSTR1)
-	bne+	cr1, L(u0)
-
-L(u2):	lbzu	rWORD1, -1(rSTR1)
-L(u3):	sub	rRTN, rWORD1, rWORD2
-	blr
-END (STRNCMP)
-libc_hidden_builtin_def (strncmp)
